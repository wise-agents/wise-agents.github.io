{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to wise-agents Welcome to Wise Agents project, an open source implementation of a multi agents framework released under Apche 2.0 License What is wise-agents Wise agents is an implementation of a multi agents framework in Python. Wise agents is designed as a fully distributed multi agents framework implementation, where agents and their models can be deployed in a cloud architecture. Agents communicate with each other using different distributed mechanism and are designed with enterprise needs in mind in terms of security, reliability and privacy. Getting involved Join our community and don't miss our \"how to contribute\" page ! architecture If you need more details about the architecure of the framework, please check the Wise Agents architectue page","title":"Home"},{"location":"#welcome-to-wise-agents","text":"Welcome to Wise Agents project, an open source implementation of a multi agents framework released under Apche 2.0 License","title":"Welcome to wise-agents"},{"location":"#what-is-wise-agents","text":"Wise agents is an implementation of a multi agents framework in Python. Wise agents is designed as a fully distributed multi agents framework implementation, where agents and their models can be deployed in a cloud architecture. Agents communicate with each other using different distributed mechanism and are designed with enterprise needs in mind in terms of security, reliability and privacy.","title":"What is wise-agents"},{"location":"#getting-involved","text":"Join our community and don't miss our \"how to contribute\" page !","title":"Getting involved"},{"location":"#architecture","text":"If you need more details about the architecure of the framework, please check the Wise Agents architectue page","title":"architecture"},{"location":"agentic_chatbot/","text":"Wise Agents Example: Memory Agentic Chatbot This guide walks you through running a practical example of a multi-agent system using Wise Agents. In this example, two agents (a web interface agent and an intelligent agent) are started, allowing you to experiment with agent communication and interaction in a simulated environment. Example Overview The example consists of two main agents: Web Interface Agent : Simulates a web-based client for interacting with other agents. Intelligent Agent : Handles requests and provides intelligent responses based on memory and context. These agents are defined in YAML configuration files located in the examples/memory_agentic_chatbot directory. Running the Example Step 1: Clone the Repository If you haven't already, clone the Wise Agents repository from GitHub: git clone https://github.com/wise-agents/wise-agents.git cd wise-agents Step 2: Configure and Start Redis In this step, we will set up Redis for agent context and registry. Create a hidden directory .wise-agents in the root of your project: bash mkdir .wise-agents Copy the Redis configuration file as shown in the .wise-agents directory from the GitHub repo. Create a file named redis-config.yaml inside .wise-agents : yaml redis: host: localhost port: 6379 Ensure Redis is installed and running . You can start redis as podman/docker image following instruction in redis README.MD Step 3: Start artemis To support async communication between agents you need to have artemis up and running Start artemis podman/docker image following instructions in artemis README.MD Set the environment variables for artemis secure login. If you haven't changed any configuration, starting artemis following the previous point instructions they are: export STOMP_USER=artemis export STOMP_PASSWORD=artemis Step 4: Start Ollama with Llama 3.1 To support the Llama model, you need to ensure that Ollama is installed and running: Install Ollama if it\u2019s not installed already by following the Ollama installation instructions . Start Ollama with Llama 3.1 : bash ollama run llama3.1 This will load the Llama 3.1 model into Ollama, which is necessary for running the intelligent agent. Step 5: Start the Intelligent Agent In a second console, run the intelligent agent, also from the project\u2019s home directory, using the following command: python src/wiseagents/cli/wise_agent_cli.py examples/memory_agentic_chatbot/intelligent-agent.yaml This will initialize the intelligent agent, which will be ready to respond to requests sent by the web interface agent. Step 6: Start the Web Interface Agent In your first console, navigate to the project\u2019s home directory and run the web interface agent using the provided YAML configuration file: python src/wiseagents/cli/wise_agent_cli.py examples/memory_agentic_chatbot/web-interface.yaml This will initialize the Assitant agent with its web interface. You should see logs indicating that the agent is started and waiting for requests. You will see in the console also a web server listening at http://127.0.0.1:7860 Running on local URL: http://127.0.0.1:7860 Step 7: Interaction Once both agents are up and running, you can use the web interface agent as a chatbot and it will start sending requests to the intelligent agent. You will be able to see the interaction between the two agents through the logs in both consoles. Step 8: Experiment You can experiment with different agent configurations or modify the agent behaviors by editing the YAML files located in the examples/memory_agentic_chatbot directory. These configuration files define the agents' properties, including memory, communication methods, and response patterns. Understanding the YAML Configuration web-interface.yaml : Defines the web interface agent, which serves as the client interface for interacting with other agents. intelligent-agent.yaml : Defines the intelligent agent, which processes the requests and generates responses based on the provided input. These YAML files include the specific WiseAgent classes and configuration needed to run the agents. Feel free to explore and modify these files to customize the agents' behavior. Additional Resources For more information about the architecture and advanced configurations of wise-agents, refer to the Wise Agents Architecture Document , which provides insights into how the system can be scaled and deployed in distributed environments. Conclusion By following these steps, you have successfully run a simple memory-agentic chatbot using Wise Agents. You can now explore further by modifying agent behaviors, adding new agents, or experimenting with different message flows. For any further assistance, feel free to refer to the official Wise Agents documentation or reach out to the repository maintainers.","title":"Agentic chatbot"},{"location":"agentic_chatbot/#wise-agents-example-memory-agentic-chatbot","text":"This guide walks you through running a practical example of a multi-agent system using Wise Agents. In this example, two agents (a web interface agent and an intelligent agent) are started, allowing you to experiment with agent communication and interaction in a simulated environment.","title":"Wise Agents Example: Memory Agentic Chatbot"},{"location":"agentic_chatbot/#example-overview","text":"The example consists of two main agents: Web Interface Agent : Simulates a web-based client for interacting with other agents. Intelligent Agent : Handles requests and provides intelligent responses based on memory and context. These agents are defined in YAML configuration files located in the examples/memory_agentic_chatbot directory.","title":"Example Overview"},{"location":"agentic_chatbot/#running-the-example","text":"","title":"Running the Example"},{"location":"agentic_chatbot/#step-1-clone-the-repository","text":"If you haven't already, clone the Wise Agents repository from GitHub: git clone https://github.com/wise-agents/wise-agents.git cd wise-agents","title":"Step 1: Clone the Repository"},{"location":"agentic_chatbot/#step-2-configure-and-start-redis","text":"In this step, we will set up Redis for agent context and registry. Create a hidden directory .wise-agents in the root of your project: bash mkdir .wise-agents Copy the Redis configuration file as shown in the .wise-agents directory from the GitHub repo. Create a file named redis-config.yaml inside .wise-agents : yaml redis: host: localhost port: 6379 Ensure Redis is installed and running . You can start redis as podman/docker image following instruction in redis README.MD","title":"Step 2: Configure and Start Redis"},{"location":"agentic_chatbot/#step-3-start-artemis","text":"To support async communication between agents you need to have artemis up and running Start artemis podman/docker image following instructions in artemis README.MD Set the environment variables for artemis secure login. If you haven't changed any configuration, starting artemis following the previous point instructions they are: export STOMP_USER=artemis export STOMP_PASSWORD=artemis","title":"Step 3: Start artemis"},{"location":"agentic_chatbot/#step-4-start-ollama-with-llama-31","text":"To support the Llama model, you need to ensure that Ollama is installed and running: Install Ollama if it\u2019s not installed already by following the Ollama installation instructions . Start Ollama with Llama 3.1 : bash ollama run llama3.1 This will load the Llama 3.1 model into Ollama, which is necessary for running the intelligent agent.","title":"Step 4: Start Ollama with Llama 3.1"},{"location":"agentic_chatbot/#step-5-start-the-intelligent-agent","text":"In a second console, run the intelligent agent, also from the project\u2019s home directory, using the following command: python src/wiseagents/cli/wise_agent_cli.py examples/memory_agentic_chatbot/intelligent-agent.yaml This will initialize the intelligent agent, which will be ready to respond to requests sent by the web interface agent.","title":"Step 5: Start the Intelligent Agent"},{"location":"agentic_chatbot/#step-6-start-the-web-interface-agent","text":"In your first console, navigate to the project\u2019s home directory and run the web interface agent using the provided YAML configuration file: python src/wiseagents/cli/wise_agent_cli.py examples/memory_agentic_chatbot/web-interface.yaml This will initialize the Assitant agent with its web interface. You should see logs indicating that the agent is started and waiting for requests. You will see in the console also a web server listening at http://127.0.0.1:7860 Running on local URL: http://127.0.0.1:7860","title":"Step 6: Start the Web Interface Agent"},{"location":"agentic_chatbot/#step-7-interaction","text":"Once both agents are up and running, you can use the web interface agent as a chatbot and it will start sending requests to the intelligent agent. You will be able to see the interaction between the two agents through the logs in both consoles.","title":"Step 7: Interaction"},{"location":"agentic_chatbot/#step-8-experiment","text":"You can experiment with different agent configurations or modify the agent behaviors by editing the YAML files located in the examples/memory_agentic_chatbot directory. These configuration files define the agents' properties, including memory, communication methods, and response patterns.","title":"Step 8: Experiment"},{"location":"agentic_chatbot/#understanding-the-yaml-configuration","text":"web-interface.yaml : Defines the web interface agent, which serves as the client interface for interacting with other agents. intelligent-agent.yaml : Defines the intelligent agent, which processes the requests and generates responses based on the provided input. These YAML files include the specific WiseAgent classes and configuration needed to run the agents. Feel free to explore and modify these files to customize the agents' behavior.","title":"Understanding the YAML Configuration"},{"location":"agentic_chatbot/#additional-resources","text":"For more information about the architecture and advanced configurations of wise-agents, refer to the Wise Agents Architecture Document , which provides insights into how the system can be scaled and deployed in distributed environments.","title":"Additional Resources"},{"location":"agentic_chatbot/#conclusion","text":"By following these steps, you have successfully run a simple memory-agentic chatbot using Wise Agents. You can now explore further by modifying agent behaviors, adding new agents, or experimenting with different message flows. For any further assistance, feel free to refer to the official Wise Agents documentation or reach out to the repository maintainers.","title":"Conclusion"},{"location":"community/","text":"Community GitHub Wise-agents is an open source project hosted on github https://github.com/wise-agents/wise-agents Please join us, fork the project or add a star. Issue tracker If you need to create an issue please go to https://github.com/wise-agents/wise-agents/issues How to contribute see our dedicated page \ud83d\udc4b GitHub Discussion! We\u2019re using Discussions as a place to connect with other members of our community. We hope that you: * Ask questions you\u2019re wondering about. * Share ideas. * Engage with other community members. * Please introduce yourself if you are posting the first time * Welcome others and are open-minded. Remember that this is a community we build together \ud83d\udcaa. To get started, jump to GitHub Discussion and start your first thread. \ud83d\udc4b Zulip Chat! We\u2019re using Zulip Chat as another place to connect with other members of our community. This is a good place to connect directly and quickly with other community members. You can ask question and start discussions there, just remember it's not a support chat, but just a community chat. For more involved discussions or to help keep track things, other community members might ask you to start a GitHub Discussion. Chat gives the community a great power...but you know from a great power comes great responsibility, so be open-minded and remember this is a community we are building together. To get started, jump on wise-agents.zulip.com and start your first chat. \ud83d\udc40 Follow Us Stay tuned for updates about the Wise Agents project by following us on: * X","title":"Community"},{"location":"community/#community","text":"","title":"Community"},{"location":"community/#github","text":"Wise-agents is an open source project hosted on github https://github.com/wise-agents/wise-agents Please join us, fork the project or add a star.","title":"GitHub"},{"location":"community/#issue-tracker","text":"If you need to create an issue please go to https://github.com/wise-agents/wise-agents/issues","title":"Issue tracker"},{"location":"community/#how-to-contribute","text":"see our dedicated page","title":"How to contribute"},{"location":"community/#github-discussion","text":"We\u2019re using Discussions as a place to connect with other members of our community. We hope that you: * Ask questions you\u2019re wondering about. * Share ideas. * Engage with other community members. * Please introduce yourself if you are posting the first time * Welcome others and are open-minded. Remember that this is a community we build together \ud83d\udcaa. To get started, jump to GitHub Discussion and start your first thread.","title":"\ud83d\udc4b GitHub Discussion!"},{"location":"community/#zulip-chat","text":"We\u2019re using Zulip Chat as another place to connect with other members of our community. This is a good place to connect directly and quickly with other community members. You can ask question and start discussions there, just remember it's not a support chat, but just a community chat. For more involved discussions or to help keep track things, other community members might ask you to start a GitHub Discussion. Chat gives the community a great power...but you know from a great power comes great responsibility, so be open-minded and remember this is a community we are building together. To get started, jump on wise-agents.zulip.com and start your first chat.","title":"\ud83d\udc4b Zulip Chat!"},{"location":"community/#follow-us","text":"Stay tuned for updates about the Wise Agents project by following us on: * X","title":"\ud83d\udc40 Follow Us"},{"location":"contributing/","text":"Contributing to wise-agents Welcome to the wise-agents project! We welcome contributions from the community. This guide will walk you through the steps for getting started on our project. Forking the Project Issues Good First Issues Setting up your Developer Environment Contributing Guidelines Community Forking the Project To contribute, you will first need to fork the wise-agents repository. This can be done by looking in the top-right corner of the repository page and clicking \"Fork\". The next step is to clone your newly forked repository onto your local workspace. This can be done by going to your newly forked repository, which should be at https://github.com/USERNAME/wise-agents . Then, there will be a green button that says \"Code\". Click on that and copy the URL. Then, in your terminal, paste the following command: git clone [URL] Be sure to replace [URL] with the URL that you copied. Now you have the repository on your computer! Issues The wise-agents project uses GitHub to manage issues. All issues can be found here . To create a new issue, comment on an existing issue, or assign an issue to yourself, you'll need to first create a GitHub account . Good First Issues Want to contribute to the wise-agents project but aren't quite sure where to start? Check out our issues with the good-first-issue label. These are a triaged set of issues that are great for getting started on our project. These can be found here . Once you have selected an issue you'd like to work on, make sure it's not already assigned to someone else, and assign it to yourself. It is recommended that you use a separate branch for every issue you work on. To keep things straightforward and memorable, you can name each branch using the GitHub issue number. This way, you can have multiple PRs open for different issues. For example, if you were working on issue-125 , you could use issue-125 as your branch name. Setting up your Developer Environment You will need: Python 3.12+ Git An IDE (e.g., Microsoft Visual Studio Code ) To setup your development environment you need to: First cd to the directory where you cloned the project (eg: cd wise-agents ) Create a Python virtual environment for the project. The venv module supports creating lightweight \u201cvirtual environments\u201d, each with their own independent set of Python packages installed in their site directories. A virtual environment is created on top of an existing Python installation, known as the virtual environment\u2019s \u201cbase\u201d Python, and may optionally be isolated from the packages in the base environment, so only those explicitly installed in the virtual environment are available. For more information about virtual environment see here python -m venv .venv OR just using our Makefile make venv Activate the venv source .venv/bin/activate Notice that the Makefile requires the venv to be activated in order to build the project or run the tests. Add a remote ref to upstream, for pulling future updates. For example: git remote add upstream https://github.com/wise-agents/wise-agents To build wise-agents run: make install To run the tests: start artemis: set .env for artemis see artemis/README.MD . Then start it using make artemis start graphdb: set .env for graphdb see graphdb/README.MD . Then start it using make graphdb start vectordb: set .env for vectordb see vectordb/README.MD . Then start it using make vectordb start LLM model serving: set .env for model-serving see model-serving/README.MD . Then start it using make model run the tests: make test To run only a specific test, use: If you want to run a single test you can specify the test with -k option: pytest -k test_register_agents --log-cli-level=DEBUG You can also run all tests contained in a single file with the same option pytest -k test_WiseAgentRegistry --log-cli-level=DEBUG Note the name of the file could be partial so for example pytest -k test_yaml --log-cli-level=DEBUG will run test contained in tests/wiseagents/test_yaml_deserializer.py and ``tests/wiseagents/test_yaml_serialization.py) Contributing Guidelines When submitting a PR, please keep the following guidelines in mind: In general, it's good practice to squash all of your commits into a single commit. For larger changes, it's ok to have multiple meaningful commits. If you need help with squashing your commits, feel free to ask us how to do this on your pull request. We're more than happy to help! Please link the issue you worked on in the description of your pull request and in your commit message. For example, for issue-125, the PR description and commit message could be: Go through TODOs in the code and create issues for them Fixes #125 Your PR should include docstrings for all functions and classes, as well as comments to help make your code easier to understand. Your PR should include tests for the functionality that you are adding. Your PR should include appropriate documentation for the functionality that you are adding. This could involve updating an existing section in the documentation or adding a new page in the documentation. Your PR should include an example of how to use the new functionality that you are adding. [!NOTE] There might be times where the documentation or example you need to add is a bit more involved. For cases like this, if the functionality you are adding is needed urgently (e.g., to allow someone else to work on a feature that depends on yours), you can create an issue to track the documentation or example to be added and make sure to reference this issue in your PR. This way, we can merge your PR while still ensuring that the documentation or example is added soon after. Code Reviews All submissions, including submissions by project members, need to be reviewed by at least one wise-agents committer before being merged. The GitHub Pull Request Review Process is followed for every pull request. Community For more information on how to get involved with Wise Agents, check out our community page.","title":"How to contribute"},{"location":"contributing/#contributing-to-wise-agents","text":"Welcome to the wise-agents project! We welcome contributions from the community. This guide will walk you through the steps for getting started on our project. Forking the Project Issues Good First Issues Setting up your Developer Environment Contributing Guidelines Community","title":"Contributing to wise-agents"},{"location":"contributing/#forking-the-project","text":"To contribute, you will first need to fork the wise-agents repository. This can be done by looking in the top-right corner of the repository page and clicking \"Fork\". The next step is to clone your newly forked repository onto your local workspace. This can be done by going to your newly forked repository, which should be at https://github.com/USERNAME/wise-agents . Then, there will be a green button that says \"Code\". Click on that and copy the URL. Then, in your terminal, paste the following command: git clone [URL] Be sure to replace [URL] with the URL that you copied. Now you have the repository on your computer!","title":"Forking the Project"},{"location":"contributing/#issues","text":"The wise-agents project uses GitHub to manage issues. All issues can be found here . To create a new issue, comment on an existing issue, or assign an issue to yourself, you'll need to first create a GitHub account .","title":"Issues"},{"location":"contributing/#good-first-issues","text":"Want to contribute to the wise-agents project but aren't quite sure where to start? Check out our issues with the good-first-issue label. These are a triaged set of issues that are great for getting started on our project. These can be found here . Once you have selected an issue you'd like to work on, make sure it's not already assigned to someone else, and assign it to yourself. It is recommended that you use a separate branch for every issue you work on. To keep things straightforward and memorable, you can name each branch using the GitHub issue number. This way, you can have multiple PRs open for different issues. For example, if you were working on issue-125 , you could use issue-125 as your branch name.","title":"Good First Issues"},{"location":"contributing/#setting-up-your-developer-environment","text":"You will need: Python 3.12+ Git An IDE (e.g., Microsoft Visual Studio Code ) To setup your development environment you need to: First cd to the directory where you cloned the project (eg: cd wise-agents ) Create a Python virtual environment for the project. The venv module supports creating lightweight \u201cvirtual environments\u201d, each with their own independent set of Python packages installed in their site directories. A virtual environment is created on top of an existing Python installation, known as the virtual environment\u2019s \u201cbase\u201d Python, and may optionally be isolated from the packages in the base environment, so only those explicitly installed in the virtual environment are available. For more information about virtual environment see here python -m venv .venv OR just using our Makefile make venv Activate the venv source .venv/bin/activate Notice that the Makefile requires the venv to be activated in order to build the project or run the tests. Add a remote ref to upstream, for pulling future updates. For example: git remote add upstream https://github.com/wise-agents/wise-agents To build wise-agents run: make install To run the tests: start artemis: set .env for artemis see artemis/README.MD . Then start it using make artemis start graphdb: set .env for graphdb see graphdb/README.MD . Then start it using make graphdb start vectordb: set .env for vectordb see vectordb/README.MD . Then start it using make vectordb start LLM model serving: set .env for model-serving see model-serving/README.MD . Then start it using make model run the tests: make test To run only a specific test, use: If you want to run a single test you can specify the test with -k option: pytest -k test_register_agents --log-cli-level=DEBUG You can also run all tests contained in a single file with the same option pytest -k test_WiseAgentRegistry --log-cli-level=DEBUG Note the name of the file could be partial so for example pytest -k test_yaml --log-cli-level=DEBUG will run test contained in tests/wiseagents/test_yaml_deserializer.py and ``tests/wiseagents/test_yaml_serialization.py)","title":"Setting up your Developer Environment"},{"location":"contributing/#contributing-guidelines","text":"When submitting a PR, please keep the following guidelines in mind: In general, it's good practice to squash all of your commits into a single commit. For larger changes, it's ok to have multiple meaningful commits. If you need help with squashing your commits, feel free to ask us how to do this on your pull request. We're more than happy to help! Please link the issue you worked on in the description of your pull request and in your commit message. For example, for issue-125, the PR description and commit message could be: Go through TODOs in the code and create issues for them Fixes #125 Your PR should include docstrings for all functions and classes, as well as comments to help make your code easier to understand. Your PR should include tests for the functionality that you are adding. Your PR should include appropriate documentation for the functionality that you are adding. This could involve updating an existing section in the documentation or adding a new page in the documentation. Your PR should include an example of how to use the new functionality that you are adding. [!NOTE] There might be times where the documentation or example you need to add is a bit more involved. For cases like this, if the functionality you are adding is needed urgently (e.g., to allow someone else to work on a feature that depends on yours), you can create an issue to track the documentation or example to be added and make sure to reference this issue in your PR. This way, we can merge your PR while still ensuring that the documentation or example is added soon after.","title":"Contributing Guidelines"},{"location":"contributing/#code-reviews","text":"All submissions, including submissions by project members, need to be reviewed by at least one wise-agents committer before being merged. The GitHub Pull Request Review Process is followed for every pull request.","title":"Code Reviews"},{"location":"contributing/#community","text":"For more information on how to get involved with Wise Agents, check out our community page.","title":"Community"},{"location":"contributing_lnk/","text":"Contributing to wise-agents Welcome to the wise-agents project! We welcome contributions from the community. This guide will walk you through the steps for getting started on our project. Forking the Project Issues Good First Issues Setting up your Developer Environment Contributing Guidelines Community Forking the Project To contribute, you will first need to fork the wise-agents repository. This can be done by looking in the top-right corner of the repository page and clicking \"Fork\". The next step is to clone your newly forked repository onto your local workspace. This can be done by going to your newly forked repository, which should be at https://github.com/USERNAME/wise-agents . Then, there will be a green button that says \"Code\". Click on that and copy the URL. Then, in your terminal, paste the following command: git clone [URL] Be sure to replace [URL] with the URL that you copied. Now you have the repository on your computer! Issues The wise-agents project uses GitHub to manage issues. All issues can be found here . To create a new issue, comment on an existing issue, or assign an issue to yourself, you'll need to first create a GitHub account . Good First Issues Want to contribute to the wise-agents project but aren't quite sure where to start? Check out our issues with the good-first-issue label. These are a triaged set of issues that are great for getting started on our project. These can be found here . Once you have selected an issue you'd like to work on, make sure it's not already assigned to someone else, and assign it to yourself. It is recommended that you use a separate branch for every issue you work on. To keep things straightforward and memorable, you can name each branch using the GitHub issue number. This way, you can have multiple PRs open for different issues. For example, if you were working on issue-125 , you could use issue-125 as your branch name. Setting up your Developer Environment You will need: Python 3.12+ Git An IDE (e.g., Microsoft Visual Studio Code ) To setup your development environment you need to: First cd to the directory where you cloned the project (eg: cd wise-agents ) Create a Python virtual environment for the project. The venv module supports creating lightweight \u201cvirtual environments\u201d, each with their own independent set of Python packages installed in their site directories. A virtual environment is created on top of an existing Python installation, known as the virtual environment\u2019s \u201cbase\u201d Python, and may optionally be isolated from the packages in the base environment, so only those explicitly installed in the virtual environment are available. For more information about virtual environment see here python -m venv .venv OR just using our Makefile make venv Activate the venv source .venv/bin/activate Notice that the Makefile requires the venv to be activated in order to build the project or run the tests. Add a remote ref to upstream, for pulling future updates. For example: git remote add upstream https://github.com/wise-agents/wise-agents To build wise-agents run: make install To run the tests: start artemis: set .env for artemis see artemis/README.MD . Then start it using make artemis start graphdb: set .env for graphdb see graphdb/README.MD . Then start it using make graphdb start vectordb: set .env for vectordb see vectordb/README.MD . Then start it using make vectordb start LLM model serving: set .env for model-serving see model-serving/README.MD . Then start it using make model run the tests: make test To run only a specific test, use: If you want to run a single test you can specify the test with -k option: pytest -k test_register_agents --log-cli-level=DEBUG You can also run all tests contained in a single file with the same option pytest -k test_WiseAgentRegistry --log-cli-level=DEBUG Note the name of the file could be partial so for example pytest -k test_yaml --log-cli-level=DEBUG will run test contained in tests/wiseagents/test_yaml_deserializer.py and ``tests/wiseagents/test_yaml_serialization.py) Contributing Guidelines When submitting a PR, please keep the following guidelines in mind: In general, it's good practice to squash all of your commits into a single commit. For larger changes, it's ok to have multiple meaningful commits. If you need help with squashing your commits, feel free to ask us how to do this on your pull request. We're more than happy to help! Please link the issue you worked on in the description of your pull request and in your commit message. For example, for issue-125, the PR description and commit message could be: Go through TODOs in the code and create issues for them Fixes #125 Your PR should include docstrings for all functions and classes, as well as comments to help make your code easier to understand. Your PR should include tests for the functionality that you are adding. Your PR should include appropriate documentation for the functionality that you are adding. This could involve updating an existing section in the documentation or adding a new page in the documentation. Your PR should include an example of how to use the new functionality that you are adding. [!NOTE] There might be times where the documentation or example you need to add is a bit more involved. For cases like this, if the functionality you are adding is needed urgently (e.g., to allow someone else to work on a feature that depends on yours), you can create an issue to track the documentation or example to be added and make sure to reference this issue in your PR. This way, we can merge your PR while still ensuring that the documentation or example is added soon after. Code Reviews All submissions, including submissions by project members, need to be reviewed by at least one wise-agents committer before being merged. The GitHub Pull Request Review Process is followed for every pull request. Community For more information on how to get involved with Wise Agents, check out our community page.","title":"Contributing"},{"location":"contributing_lnk/#contributing-to-wise-agents","text":"Welcome to the wise-agents project! We welcome contributions from the community. This guide will walk you through the steps for getting started on our project. Forking the Project Issues Good First Issues Setting up your Developer Environment Contributing Guidelines Community","title":"Contributing to wise-agents"},{"location":"contributing_lnk/#forking-the-project","text":"To contribute, you will first need to fork the wise-agents repository. This can be done by looking in the top-right corner of the repository page and clicking \"Fork\". The next step is to clone your newly forked repository onto your local workspace. This can be done by going to your newly forked repository, which should be at https://github.com/USERNAME/wise-agents . Then, there will be a green button that says \"Code\". Click on that and copy the URL. Then, in your terminal, paste the following command: git clone [URL] Be sure to replace [URL] with the URL that you copied. Now you have the repository on your computer!","title":"Forking the Project"},{"location":"contributing_lnk/#issues","text":"The wise-agents project uses GitHub to manage issues. All issues can be found here . To create a new issue, comment on an existing issue, or assign an issue to yourself, you'll need to first create a GitHub account .","title":"Issues"},{"location":"contributing_lnk/#good-first-issues","text":"Want to contribute to the wise-agents project but aren't quite sure where to start? Check out our issues with the good-first-issue label. These are a triaged set of issues that are great for getting started on our project. These can be found here . Once you have selected an issue you'd like to work on, make sure it's not already assigned to someone else, and assign it to yourself. It is recommended that you use a separate branch for every issue you work on. To keep things straightforward and memorable, you can name each branch using the GitHub issue number. This way, you can have multiple PRs open for different issues. For example, if you were working on issue-125 , you could use issue-125 as your branch name.","title":"Good First Issues"},{"location":"contributing_lnk/#setting-up-your-developer-environment","text":"You will need: Python 3.12+ Git An IDE (e.g., Microsoft Visual Studio Code ) To setup your development environment you need to: First cd to the directory where you cloned the project (eg: cd wise-agents ) Create a Python virtual environment for the project. The venv module supports creating lightweight \u201cvirtual environments\u201d, each with their own independent set of Python packages installed in their site directories. A virtual environment is created on top of an existing Python installation, known as the virtual environment\u2019s \u201cbase\u201d Python, and may optionally be isolated from the packages in the base environment, so only those explicitly installed in the virtual environment are available. For more information about virtual environment see here python -m venv .venv OR just using our Makefile make venv Activate the venv source .venv/bin/activate Notice that the Makefile requires the venv to be activated in order to build the project or run the tests. Add a remote ref to upstream, for pulling future updates. For example: git remote add upstream https://github.com/wise-agents/wise-agents To build wise-agents run: make install To run the tests: start artemis: set .env for artemis see artemis/README.MD . Then start it using make artemis start graphdb: set .env for graphdb see graphdb/README.MD . Then start it using make graphdb start vectordb: set .env for vectordb see vectordb/README.MD . Then start it using make vectordb start LLM model serving: set .env for model-serving see model-serving/README.MD . Then start it using make model run the tests: make test To run only a specific test, use: If you want to run a single test you can specify the test with -k option: pytest -k test_register_agents --log-cli-level=DEBUG You can also run all tests contained in a single file with the same option pytest -k test_WiseAgentRegistry --log-cli-level=DEBUG Note the name of the file could be partial so for example pytest -k test_yaml --log-cli-level=DEBUG will run test contained in tests/wiseagents/test_yaml_deserializer.py and ``tests/wiseagents/test_yaml_serialization.py)","title":"Setting up your Developer Environment"},{"location":"contributing_lnk/#contributing-guidelines","text":"When submitting a PR, please keep the following guidelines in mind: In general, it's good practice to squash all of your commits into a single commit. For larger changes, it's ok to have multiple meaningful commits. If you need help with squashing your commits, feel free to ask us how to do this on your pull request. We're more than happy to help! Please link the issue you worked on in the description of your pull request and in your commit message. For example, for issue-125, the PR description and commit message could be: Go through TODOs in the code and create issues for them Fixes #125 Your PR should include docstrings for all functions and classes, as well as comments to help make your code easier to understand. Your PR should include tests for the functionality that you are adding. Your PR should include appropriate documentation for the functionality that you are adding. This could involve updating an existing section in the documentation or adding a new page in the documentation. Your PR should include an example of how to use the new functionality that you are adding. [!NOTE] There might be times where the documentation or example you need to add is a bit more involved. For cases like this, if the functionality you are adding is needed urgently (e.g., to allow someone else to work on a feature that depends on yours), you can create an issue to track the documentation or example to be added and make sure to reference this issue in your PR. This way, we can merge your PR while still ensuring that the documentation or example is added soon after.","title":"Contributing Guidelines"},{"location":"contributing_lnk/#code-reviews","text":"All submissions, including submissions by project members, need to be reviewed by at least one wise-agents committer before being merged. The GitHub Pull Request Review Process is followed for every pull request.","title":"Code Reviews"},{"location":"contributing_lnk/#community","text":"For more information on how to get involved with Wise Agents, check out our community page.","title":"Community"},{"location":"custom_agents/","text":"How To Create Custom Agents Wise Agents provides some agent implementations out of the box in the wiseagents.agents package, but you can also create your own agents. To create a custom agent, you need to extend the wiseagents.core.WiseAgent class and implement the following abstract methods from this class: process_request , process_response , process_error , and process_event . Let's take a closer look at these methods. Implementing the process_request method Method signature: def process_request(self, request: WiseAgentMessage, conversation_history: List[ChatCompletionMessageParam]) -> Optional[str]: This method is used by the agent to process the given request message. It is invoked by WiseAgent.handle_request . This method should return the agent's response to the given request as a str or None if there is no response needed. When processing the request, the agent can make use of the given conversation_history , which is a List of ChatCompletionMessageParam objects. If there is a chat session associated with the request, this list will contain the message history. In particular, if the agent has been invoked by a PhasedCoordinatorWiseAgent or an AssistantAgent , there will be a chat session associated with the request. The agent can make use of this conversation history when calling its WiseAgentLLM 's process_chat_completion method. If there isn't a chat session associated with the request, the conversation_history list will be empty. The response returned by the process_request method will be used by WiseAgent.handle_request to create and send a message to the appropriate agent. This destination agent will depend on the type of collaboration that the agent is involved in. For example, if the agent has been invoked by a PhasedCoordinatorWiseAgent or an AssistantAgent , the response message will be sent back to that agent and the conversation history will be updated with the response as well. If the agent is involved in sequential collaboration, the response will be sent to either the next agent in the sequence or back to the original requester if there are no more agents remaining. Implementing the process_response method Method signature: def process_response(self, message: WiseAgentMessage) -> bool: This method is used by the agent to process a response message that it has received from another agent, i.e., this method is invoked after this agent has sent a request to another agent and receives a response message back from the other agent. This method should return True if the given message was processed successfully and False otherwise. Implementing the process_error method Method signature: def process_error(self, error: Exception) -> bool: This method is used by the agent to process an error. This method should return True if the given error was process successfully and False otherwise. Implementing the process_event method Method signature: def process_event(self, event: WiseAgentEvent) -> bool: This method will be used by an agent to process an event. The WiseAgentEvent class is still under construction (keep an eye on https://github.com/wise-agents/wise-agents/issues/8 for future updates). For now, this method can be implemented by simply using a pass statement as the method body.","title":"How To Create Custom Agents"},{"location":"custom_agents/#how-to-create-custom-agents","text":"Wise Agents provides some agent implementations out of the box in the wiseagents.agents package, but you can also create your own agents. To create a custom agent, you need to extend the wiseagents.core.WiseAgent class and implement the following abstract methods from this class: process_request , process_response , process_error , and process_event . Let's take a closer look at these methods.","title":"How To Create Custom Agents"},{"location":"custom_agents/#implementing-the-process_request-method","text":"Method signature: def process_request(self, request: WiseAgentMessage, conversation_history: List[ChatCompletionMessageParam]) -> Optional[str]: This method is used by the agent to process the given request message. It is invoked by WiseAgent.handle_request . This method should return the agent's response to the given request as a str or None if there is no response needed. When processing the request, the agent can make use of the given conversation_history , which is a List of ChatCompletionMessageParam objects. If there is a chat session associated with the request, this list will contain the message history. In particular, if the agent has been invoked by a PhasedCoordinatorWiseAgent or an AssistantAgent , there will be a chat session associated with the request. The agent can make use of this conversation history when calling its WiseAgentLLM 's process_chat_completion method. If there isn't a chat session associated with the request, the conversation_history list will be empty. The response returned by the process_request method will be used by WiseAgent.handle_request to create and send a message to the appropriate agent. This destination agent will depend on the type of collaboration that the agent is involved in. For example, if the agent has been invoked by a PhasedCoordinatorWiseAgent or an AssistantAgent , the response message will be sent back to that agent and the conversation history will be updated with the response as well. If the agent is involved in sequential collaboration, the response will be sent to either the next agent in the sequence or back to the original requester if there are no more agents remaining.","title":"Implementing the process_request method"},{"location":"custom_agents/#implementing-the-process_response-method","text":"Method signature: def process_response(self, message: WiseAgentMessage) -> bool: This method is used by the agent to process a response message that it has received from another agent, i.e., this method is invoked after this agent has sent a request to another agent and receives a response message back from the other agent. This method should return True if the given message was processed successfully and False otherwise.","title":"Implementing the process_response method"},{"location":"custom_agents/#implementing-the-process_error-method","text":"Method signature: def process_error(self, error: Exception) -> bool: This method is used by the agent to process an error. This method should return True if the given error was process successfully and False otherwise.","title":"Implementing the process_error method"},{"location":"custom_agents/#implementing-the-process_event-method","text":"Method signature: def process_event(self, event: WiseAgentEvent) -> bool: This method will be used by an agent to process an event. The WiseAgentEvent class is still under construction (keep an eye on https://github.com/wise-agents/wise-agents/issues/8 for future updates). For now, this method can be implemented by simply using a pass statement as the method body.","title":"Implementing the process_event method"},{"location":"declare_agents/","text":"Declare agents in YAML","title":"Declare agents in YAML"},{"location":"declare_agents/#declare-agents-in-yaml","text":"","title":"Declare agents in YAML"},{"location":"license/","text":"Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright yyyy Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"multi_agents/","text":"What are AI Agents? AI agents are autonomous software systems that can perceive their environment, make decisions, and take actions to achieve specific goals. They are designed to operate without human intervention (even if sometimes human input could be considered as part of the process), leveraging advanced AI techniques like natural language processing and machine learning. Key characteristics of AI agents Autonomy : AI agents can make decisions and act independently based on their goals and the information they gather. Flexibility : They can adapt to changing circumstances and learn from experience to improve their performance over time. Reactivity : AI agents can perceive their environment and respond to changes in real-time. Components of an AI Agent AI agents are composed of several key components that enable their autonomous behavior: * Sensors : Used to gather information from the environment, such as user inputs, sensor data, or external APIs. * Agent Function : The core decision-making algorithm that maps sensor inputs to actions. * Actuators : Mechanisms that allow the agent to affect its environment, such as generating text responses, making API calls, or sending notifications. * Goals : The objectives the agent is designed to achieve, which guide its decision-making process. What is a multi-agent AI framework? A multi-agent AI framework is a system where multiple intelligent agents interact or work together to perform complex tasks, solve problems, or simulate environments. These agents can be autonomous entities, each with its own capabilities, knowledge base, and goals. Here\u2019s a detailed description of a multi-agent AI framework: Key Components of a multi-agent AI framework Agents : Reactive Agents: Respond to changes in the environment. Deliberative Agents: Use reasoning and planning to achieve goals. Hybrid Agents: Combine reactive and deliberative strategies. Communication Mechanism : Direct Communication: Agents send messages to each other. Indirect Communication: Agents use shared context or memory. Coordination and Cooperation : Strategies for agents to work together towards common goals, avoid conflicts, and optimize joint performance. Examples: Task Allocation: Dividing tasks among agents based on their capabilities. Task planning and prioritization Negotiation/reasoning: Agents discuss to reach agreements. Conflict resolution: Avoid loops or infinite loops for the same question Challenge other agents: challenge previous steps to reduce hallucinations Decision-Making: Methods for agents to make choices based on their goals, perceptions, and available information. LLMs or other AI algorithms (tule engine, game theory etc) can be used. Retrieve additional informations : RAG agents can retrieve informations for better results. The agentic approach also permit a multi-step RAG refining progressively the information retrieved Advantages of multi-agent AI framework Scalability : Easily add more agents to the system to handle increased complexity or workload. Flexibility : Agents can be designed to specialize in different tasks, improving overall system performance. Robustness : Failure of one agent does not necessarily compromise the entire system, enhancing reliability. Efficiency : Distributed problem-solving can lead to faster and more efficient solutions. In summary, a multi-agent AI framework is a sophisticated and versatile system designed to handle complex, dynamic tasks by leveraging the collective intelligence and capabilities of multiple interacting agents. Applications of AI Agents AI agents have a wide range of applications across various industries: * Conversational AI: Chatbots and virtual assistants that can interact naturally. The interaction can be more complex and benefits of the multi-agent system characteristics described above. * Automation: Agents that can automate complex workflows and decision-making processes. * Problem-solving: Agents that can break down complex problems, generate solutions, and execute tasks.","title":"What are AI Agents"},{"location":"multi_agents/#what-are-ai-agents","text":"AI agents are autonomous software systems that can perceive their environment, make decisions, and take actions to achieve specific goals. They are designed to operate without human intervention (even if sometimes human input could be considered as part of the process), leveraging advanced AI techniques like natural language processing and machine learning.","title":"What are AI Agents?"},{"location":"multi_agents/#key-characteristics-of-ai-agents","text":"Autonomy : AI agents can make decisions and act independently based on their goals and the information they gather. Flexibility : They can adapt to changing circumstances and learn from experience to improve their performance over time. Reactivity : AI agents can perceive their environment and respond to changes in real-time.","title":"Key characteristics of AI agents"},{"location":"multi_agents/#components-of-an-ai-agent","text":"AI agents are composed of several key components that enable their autonomous behavior: * Sensors : Used to gather information from the environment, such as user inputs, sensor data, or external APIs. * Agent Function : The core decision-making algorithm that maps sensor inputs to actions. * Actuators : Mechanisms that allow the agent to affect its environment, such as generating text responses, making API calls, or sending notifications. * Goals : The objectives the agent is designed to achieve, which guide its decision-making process.","title":"Components of an AI Agent"},{"location":"multi_agents/#what-is-a-multi-agent-ai-framework","text":"A multi-agent AI framework is a system where multiple intelligent agents interact or work together to perform complex tasks, solve problems, or simulate environments. These agents can be autonomous entities, each with its own capabilities, knowledge base, and goals. Here\u2019s a detailed description of a multi-agent AI framework:","title":"What is a multi-agent AI framework?"},{"location":"multi_agents/#key-components-of-a-multi-agent-ai-framework","text":"Agents : Reactive Agents: Respond to changes in the environment. Deliberative Agents: Use reasoning and planning to achieve goals. Hybrid Agents: Combine reactive and deliberative strategies. Communication Mechanism : Direct Communication: Agents send messages to each other. Indirect Communication: Agents use shared context or memory. Coordination and Cooperation : Strategies for agents to work together towards common goals, avoid conflicts, and optimize joint performance. Examples: Task Allocation: Dividing tasks among agents based on their capabilities. Task planning and prioritization Negotiation/reasoning: Agents discuss to reach agreements. Conflict resolution: Avoid loops or infinite loops for the same question Challenge other agents: challenge previous steps to reduce hallucinations Decision-Making: Methods for agents to make choices based on their goals, perceptions, and available information. LLMs or other AI algorithms (tule engine, game theory etc) can be used. Retrieve additional informations : RAG agents can retrieve informations for better results. The agentic approach also permit a multi-step RAG refining progressively the information retrieved","title":"Key Components of a multi-agent AI framework"},{"location":"multi_agents/#advantages-of-multi-agent-ai-framework","text":"Scalability : Easily add more agents to the system to handle increased complexity or workload. Flexibility : Agents can be designed to specialize in different tasks, improving overall system performance. Robustness : Failure of one agent does not necessarily compromise the entire system, enhancing reliability. Efficiency : Distributed problem-solving can lead to faster and more efficient solutions. In summary, a multi-agent AI framework is a sophisticated and versatile system designed to handle complex, dynamic tasks by leveraging the collective intelligence and capabilities of multiple interacting agents.","title":"Advantages of multi-agent AI framework"},{"location":"multi_agents/#applications-of-ai-agents","text":"AI agents have a wide range of applications across various industries: * Conversational AI: Chatbots and virtual assistants that can interact naturally. The interaction can be more complex and benefits of the multi-agent system characteristics described above. * Automation: Agents that can automate complex workflows and decision-making processes. * Problem-solving: Agents that can break down complex problems, generate solutions, and execute tasks.","title":"Applications of AI Agents"},{"location":"rag_architecture/","text":"wise-agents RAG architecture Wise Agents provides agent implementations that can be used for both standard retrieval augmented generation (RAG) and also for RAG with knowledge graphs (Graph RAG). What is RAG? Retrieval augmented generation (RAG) provides the ability to enhance the knowledge of a large language model (LLM) by incorporating additional information during response generation. This is very important because although LLMs are trained with extremely large quantities of data, this data is static, has a cut-off date, and likely lacks domain-specific information. RAG provides the ability to incorporate additional information obtained from knowledge sources to ground LLM responses using this information, resulting in better quality responses. How does RAG work? To be able to make use of RAG, the very first step is ingestion. Here, knowledge sources are processed, split into chunks of text, each chunk of text is converted to a vector representation (also known as an embedding), and then stored in a vector database. After this initial step, upon receiving a query, the goal is to retrieve the information that is most relevant to the query from the vector database. This is done by converting the query to a vector representation (i.e., embedding) and then querying the vector database to retrieve the chunks that are most similar to the query. The retrieved information is then included in a prompt to the LLM along with the original query. This helps the LLM to generate a response that is grounded in the retrieved information. Our implementation Wise Agents provides a wiseagents.agents.RAGWiseAgent that you can use or extend to answer questions using RAG. Vector Database Integration A RAGWiseAgent makes use of a wiseagents.vectordb.WiseAgentVectorDB , which provides integration with a vector database. Wise Agents provides an implementation of this abstract class that makes use of pgvector , see wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB . We are planning on adding integration with additional vector databases in the future. You can also create your own implementations depending on the vector database you'd like to use. What is Graph RAG? Graph RAG is a more structured approach to RAG. In standard RAG, as described above, the knowledge sources are simply split into chunks of text. However, there are many sources of information that actually have a lot of structure to them where this structure would be lost if just convert the knowledge source to text as is and split into chunks. For example, think about a bug report that has many different fields like \"Description\", \"Steps to Reproduce\", \"Relates To\", \"Resolution\", etc. If we just take the text from the bug report as is and just split the text into chunks, we'd lose all the structure that is inherently present in the bug report and the relationships to other bug reports. Graph RAG involves converting knowledge sources to knowledge graphs consisting of entities and relationships to preserve the structure that's inherent in the sources. How does Graph RAG work? Just like with standard RAG, the very first step is ingestion. Here, knowledge sources are processed and split into entities and relationships that are stored in a graph database. This can either be done manually or automatically using an LLM. After this initial step, upon receiving a query, the goal is to retrieve the information that is most relevant to the query from the graph database. This can be done by querying the graph database to extract relevant nodes and/or sub-graphs. As an example, let's consider the case where we have a graph database that consists of entities and relationships that have been derived from bug reports. If the query is \"NullPointerException when invoking method foo \", we can query the graph database to find bug reports with similar \"Descriptions\" and then extract additional relevant information from these bug reports like the \"Resolution\" for example. The retrieved information is then included in a prompt to the LLM along with the original query. This helps the LLM to generate a response that is grounded in the retrieved information. Graph RAG with Embedding-Based Retrieval In addition to simply querying the graph database, it's also possible to create a vector representation (embedding) for each entity in the graph and then use embedding-based retrieval as in standard RAG to retrieve sub-graphs from the graph database that are most similar to the query. Our implementation Wise Agents provides a wiseagents.agents.GraphRAGWiseAgent that you can use or extend to answer questions using Graph RAG with embedding-based retrieval. Graph Database Integration A GraphRAGWiseAgent makes use of a wiseagents.graphdb.WiseAgentGraphDB , which provides integration with a graph database. Wise Agents provides an implementation of this abstract class that makes use of Neo4j , see wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB . An advantage of using Neo4j for the graph database integration is that it's possible to make use of embedding-based retrieval very easily. We are planning on adding integration with additional graph databases in the future. You can also create your own implementations depending on the graph database you'd like to use. A GraphRAGWiseAgent makes use of a wiseagents.graphdb.WiseAgentGraphDB . What are Hallucinations? Although retrieval augmented generation (RAG) and graph-based retrieval augmented generation (Graph RAG) are meant to ground LLM responses using retrieved information, it's still possible for the LLM to \"hallucinate\", i.e., generate responses that are not factually correct. To address this, Wise Agents also provides agent implementations that can be used to challenge the response that's been obtained from an LLM using the Chain-of-Verification (CoVe) method to try to prevent hallucinations. How does Chain-of-Verification (CoVe) work? Chain-of-Verification (CoVe) is a method that involves verifying the baseline response generated by an LLM by planning verification questions to try to fact-check the baseline response. These verification questions are answered independently to avoid biases from the other answers and then a final revised response is determined using the baseline response together with the verification results that might have found inconsistencies. The CoVe method helps to decrease hallucinations. Our implementation Wise Agents provides a wiseagents.agents.CoVeChallengerRAGWiseAgent that you can use or extend to challenge responses for RAG obtained from an LLM using the CoVe method. Wise Agents also provides a wiseagents.agents.CoVeChallengerGraphRAGWiseAgent that you can use or extend to challenge responses for Graph RAG obtained from an LLM using the CoVe method.","title":"RAG Architecture"},{"location":"rag_architecture/#wise-agents-rag-architecture","text":"Wise Agents provides agent implementations that can be used for both standard retrieval augmented generation (RAG) and also for RAG with knowledge graphs (Graph RAG).","title":"wise-agents RAG architecture"},{"location":"rag_architecture/#what-is-rag","text":"Retrieval augmented generation (RAG) provides the ability to enhance the knowledge of a large language model (LLM) by incorporating additional information during response generation. This is very important because although LLMs are trained with extremely large quantities of data, this data is static, has a cut-off date, and likely lacks domain-specific information. RAG provides the ability to incorporate additional information obtained from knowledge sources to ground LLM responses using this information, resulting in better quality responses.","title":"What is RAG?"},{"location":"rag_architecture/#how-does-rag-work","text":"To be able to make use of RAG, the very first step is ingestion. Here, knowledge sources are processed, split into chunks of text, each chunk of text is converted to a vector representation (also known as an embedding), and then stored in a vector database. After this initial step, upon receiving a query, the goal is to retrieve the information that is most relevant to the query from the vector database. This is done by converting the query to a vector representation (i.e., embedding) and then querying the vector database to retrieve the chunks that are most similar to the query. The retrieved information is then included in a prompt to the LLM along with the original query. This helps the LLM to generate a response that is grounded in the retrieved information.","title":"How does RAG work?"},{"location":"rag_architecture/#our-implementation","text":"Wise Agents provides a wiseagents.agents.RAGWiseAgent that you can use or extend to answer questions using RAG.","title":"Our implementation"},{"location":"rag_architecture/#vector-database-integration","text":"A RAGWiseAgent makes use of a wiseagents.vectordb.WiseAgentVectorDB , which provides integration with a vector database. Wise Agents provides an implementation of this abstract class that makes use of pgvector , see wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB . We are planning on adding integration with additional vector databases in the future. You can also create your own implementations depending on the vector database you'd like to use.","title":"Vector Database Integration"},{"location":"rag_architecture/#what-is-graph-rag","text":"Graph RAG is a more structured approach to RAG. In standard RAG, as described above, the knowledge sources are simply split into chunks of text. However, there are many sources of information that actually have a lot of structure to them where this structure would be lost if just convert the knowledge source to text as is and split into chunks. For example, think about a bug report that has many different fields like \"Description\", \"Steps to Reproduce\", \"Relates To\", \"Resolution\", etc. If we just take the text from the bug report as is and just split the text into chunks, we'd lose all the structure that is inherently present in the bug report and the relationships to other bug reports. Graph RAG involves converting knowledge sources to knowledge graphs consisting of entities and relationships to preserve the structure that's inherent in the sources.","title":"What is Graph RAG?"},{"location":"rag_architecture/#how-does-graph-rag-work","text":"Just like with standard RAG, the very first step is ingestion. Here, knowledge sources are processed and split into entities and relationships that are stored in a graph database. This can either be done manually or automatically using an LLM. After this initial step, upon receiving a query, the goal is to retrieve the information that is most relevant to the query from the graph database. This can be done by querying the graph database to extract relevant nodes and/or sub-graphs. As an example, let's consider the case where we have a graph database that consists of entities and relationships that have been derived from bug reports. If the query is \"NullPointerException when invoking method foo \", we can query the graph database to find bug reports with similar \"Descriptions\" and then extract additional relevant information from these bug reports like the \"Resolution\" for example. The retrieved information is then included in a prompt to the LLM along with the original query. This helps the LLM to generate a response that is grounded in the retrieved information.","title":"How does Graph RAG work?"},{"location":"rag_architecture/#graph-rag-with-embedding-based-retrieval","text":"In addition to simply querying the graph database, it's also possible to create a vector representation (embedding) for each entity in the graph and then use embedding-based retrieval as in standard RAG to retrieve sub-graphs from the graph database that are most similar to the query.","title":"Graph RAG with Embedding-Based Retrieval"},{"location":"rag_architecture/#our-implementation_1","text":"Wise Agents provides a wiseagents.agents.GraphRAGWiseAgent that you can use or extend to answer questions using Graph RAG with embedding-based retrieval.","title":"Our implementation"},{"location":"rag_architecture/#graph-database-integration","text":"A GraphRAGWiseAgent makes use of a wiseagents.graphdb.WiseAgentGraphDB , which provides integration with a graph database. Wise Agents provides an implementation of this abstract class that makes use of Neo4j , see wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB . An advantage of using Neo4j for the graph database integration is that it's possible to make use of embedding-based retrieval very easily. We are planning on adding integration with additional graph databases in the future. You can also create your own implementations depending on the graph database you'd like to use. A GraphRAGWiseAgent makes use of a wiseagents.graphdb.WiseAgentGraphDB .","title":"Graph Database Integration"},{"location":"rag_architecture/#what-are-hallucinations","text":"Although retrieval augmented generation (RAG) and graph-based retrieval augmented generation (Graph RAG) are meant to ground LLM responses using retrieved information, it's still possible for the LLM to \"hallucinate\", i.e., generate responses that are not factually correct. To address this, Wise Agents also provides agent implementations that can be used to challenge the response that's been obtained from an LLM using the Chain-of-Verification (CoVe) method to try to prevent hallucinations.","title":"What are Hallucinations?"},{"location":"rag_architecture/#how-does-chain-of-verification-cove-work","text":"Chain-of-Verification (CoVe) is a method that involves verifying the baseline response generated by an LLM by planning verification questions to try to fact-check the baseline response. These verification questions are answered independently to avoid biases from the other answers and then a final revised response is determined using the baseline response together with the verification results that might have found inconsistencies. The CoVe method helps to decrease hallucinations.","title":"How does Chain-of-Verification (CoVe) work?"},{"location":"rag_architecture/#our-implementation_2","text":"Wise Agents provides a wiseagents.agents.CoVeChallengerRAGWiseAgent that you can use or extend to challenge responses for RAG obtained from an LLM using the CoVe method. Wise Agents also provides a wiseagents.agents.CoVeChallengerGraphRAGWiseAgent that you can use or extend to challenge responses for Graph RAG obtained from an LLM using the CoVe method.","title":"Our implementation"},{"location":"security/","text":"Reporting of CVEs and Security Issues The Wise Agents community takes security bugs very seriously We aim to take immediate action to address serious security-related problems that involve our project. Note that we will only fix such issues in the most recent minor release of Wise Agents. Reporting of Security Issues When reporting a security vulnerability it is important to not accidentally broadcast to the world that the issue exists, as this makes it easier for people to exploit it. The software industry uses the term embargo to describe the time a security issue is known internally until it is public knowledge. Our preferred way of reporting security issues in Wise Agents is listed below. Email the Wise Agents team To report a security issue, please email fjuma@redhat.com and/or smaestri@redhat.com . A member of the Wise Agents team will open the required issues. Other considerations If you would like to work with us on a fix for the security vulnerability, please include your GitHub username in the above email, and we will provide you access to a temporary private fork where we can collaborate on a fix without it being disclosed publicly, including in your own publicly visible git repository . Do not open a public issue, send a pull request, or disclose any information about the suspected vulnerability publicly, including in your own publicly visible git repository . If you discover any publicly disclosed security vulnerabilities, please notify us immediately through the emails listed in the section above.","title":"Security"},{"location":"security/#reporting-of-cves-and-security-issues","text":"","title":"Reporting of CVEs and Security Issues"},{"location":"security/#the-wise-agents-community-takes-security-bugs-very-seriously","text":"We aim to take immediate action to address serious security-related problems that involve our project. Note that we will only fix such issues in the most recent minor release of Wise Agents.","title":"The Wise Agents community takes security bugs very seriously"},{"location":"security/#reporting-of-security-issues","text":"When reporting a security vulnerability it is important to not accidentally broadcast to the world that the issue exists, as this makes it easier for people to exploit it. The software industry uses the term embargo to describe the time a security issue is known internally until it is public knowledge. Our preferred way of reporting security issues in Wise Agents is listed below.","title":"Reporting of Security Issues"},{"location":"security/#email-the-wise-agents-team","text":"To report a security issue, please email fjuma@redhat.com and/or smaestri@redhat.com . A member of the Wise Agents team will open the required issues.","title":"Email the Wise Agents team"},{"location":"security/#other-considerations","text":"If you would like to work with us on a fix for the security vulnerability, please include your GitHub username in the above email, and we will provide you access to a temporary private fork where we can collaborate on a fix without it being disclosed publicly, including in your own publicly visible git repository . Do not open a public issue, send a pull request, or disclose any information about the suspected vulnerability publicly, including in your own publicly visible git repository . If you discover any publicly disclosed security vulnerabilities, please notify us immediately through the emails listed in the section above.","title":"Other considerations"},{"location":"sequential_coordinator_example/","text":"Sequential Coordinator Example: Answer and Translate Chatbot This guide walks you through running a practical example of a multi-agent system using Wise Agents. In this example, four agents (a web interface agent, a sequential agent coordinator, and two intelligent agents) are started, allowing you to experiment with agent communication and interaction in a simulated environment, with a sequential coordination. Example Overview The example consists of four agents: Web Interface Agent : Simulates a web-based client for interacting with coordinator agent. Literature Agent : Handles requests and provides intelligent responses. Its system message says: \"You are an english literature expert. Answer questions about english literature. Try to give context to your answers and provide quote from the books described. Your user is a native english speaker, with limited background in english literature.\" Translator Agent : Handles requests and provides intelligent responses. Its system message says: \"You are an expert translator from english to italian. Translate the provided text from english to italian. \" 4 SequentialCoordinator *: Take care of coordinating the request handling from the user delagating the work to other agents in a predetermined order. These agents are defined in YAML configuration files located in the examples/sequential_coordinator directory. Running the Example Step 1: Clone the Repository If you haven't already, clone the Wise Agents repository from GitHub: git clone https://github.com/wise-agents/wise-agents.git cd wise-agents Step 2: Configure and Start Redis In this step, we will set up Redis for agent context and registry. Create a hidden directory .wise-agents in the root of your project: bash mkdir .wise-agents Copy the Redis configuration file as shown in the .wise-agents directory from the GitHub repo. Create a file named redis-config.yaml inside .wise-agents : yaml redis: host: localhost port: 6379 Ensure Redis is installed and running . You can start redis as podman/docker image following instruction in redis README.MD Step 3: Start artemis To support async communication between agents you need to have artemis up and running Start artemis podman/docker image following instructions in artemis README.MD Set the environment variables for artemis secure login. If you haven't changed any configuration, starting artemis following the previous point instructions they are: export STOMP_USER=artemis export STOMP_PASSWORD=artemis Step 4: Start Ollama with Llama 3.1 To support the Llama model, you need to ensure that Ollama is installed and running: Install Ollama if it\u2019s not installed already by following the Ollama installation instructions . Start Ollama with Llama 3.1 : bash ollama run llama3.1 This will load the Llama 3.1 model into Ollama, which is necessary for running the intelligent agent. Step 5: Start the Intelligent Agent In a first console, run the intelligent agents and coordinator agent, also from the project\u2019s home directory, using the following command: python src/wiseagents/cli/wise_agent_cli.py examples/sequential_coordinator/intelligent-agent.yaml This will initialize the intelligent agents and coordinator agent, which will be ready to respond to requests sent by the web interface agent. Step 6: Start the Web Interface Agent In your second console, navigate to the project\u2019s home directory and run the web interface agent using the provided YAML configuration file: python src/wiseagents/cli/wise_agent_cli.py examples/sequential_coordinator/web-interface.yaml This will initialize the Assistant agent with its web interface. You should see logs indicating that the agent is started and waiting for requests. You will see in the console also a web server listening at http://127.0.0.1:7860 Running on local URL: http://127.0.0.1:7860 Step 7: Interaction Once all agents are up and running, you can use the web interface agent as a chatbot and it will start sending requests to the intelligent agent. You will be able to see the interaction between the agents through the logs in both consoles. Try as an example to ask something like \"Can you give me detailed information about Harry Potter\". You will get the detailed information about Rowling's books translated in Italian :) Step 8: Experiment You can experiment with different agent configurations or modify the agent behaviors by editing the YAML files located in the examples/memory_agentic_chatbot directory. These configuration files define the agents' properties, including memory, communication methods, and response patterns. You can do that without restarting everything, just edit the yaml file(s) and use CLI's /reload command (see our documentation for more details on how to use CLI) Understanding the YAML Configuration web-interface.yaml : Defines the web interface agent, which serves as the client interface for interacting with other agents. intelligent-agents.yaml : Defines the intelligent agents and coordinator agent, which processes the requests and generates responses based on the provided input. These YAML files include the specific WiseAgent classes and configuration needed to run the agents. Feel free to explore and modify these files to customize the agents' behavior. Additional Resources For more information about the architecture and advanced configurations of wise-agents, refer to the Wise Agents Architecture Document , which provides insights into how the system can be scaled and deployed in distributed environments. Conclusion By following these steps, you have successfully run a simple sequential coordinated multi-agent chatbot using Wise Agents. You can now explore further by modifying agent behaviors, adding new agents, or experimenting with different message flows. For any further assistance, feel free to refer to the official Wise Agents documentation or reach out to the repository maintainers.","title":"Sequential Coordinator Example"},{"location":"sequential_coordinator_example/#sequential-coordinator-example-answer-and-translate-chatbot","text":"This guide walks you through running a practical example of a multi-agent system using Wise Agents. In this example, four agents (a web interface agent, a sequential agent coordinator, and two intelligent agents) are started, allowing you to experiment with agent communication and interaction in a simulated environment, with a sequential coordination.","title":"Sequential Coordinator Example: Answer and Translate Chatbot"},{"location":"sequential_coordinator_example/#example-overview","text":"The example consists of four agents: Web Interface Agent : Simulates a web-based client for interacting with coordinator agent. Literature Agent : Handles requests and provides intelligent responses. Its system message says: \"You are an english literature expert. Answer questions about english literature. Try to give context to your answers and provide quote from the books described. Your user is a native english speaker, with limited background in english literature.\" Translator Agent : Handles requests and provides intelligent responses. Its system message says: \"You are an expert translator from english to italian. Translate the provided text from english to italian. \" 4 SequentialCoordinator *: Take care of coordinating the request handling from the user delagating the work to other agents in a predetermined order. These agents are defined in YAML configuration files located in the examples/sequential_coordinator directory.","title":"Example Overview"},{"location":"sequential_coordinator_example/#running-the-example","text":"","title":"Running the Example"},{"location":"sequential_coordinator_example/#step-1-clone-the-repository","text":"If you haven't already, clone the Wise Agents repository from GitHub: git clone https://github.com/wise-agents/wise-agents.git cd wise-agents","title":"Step 1: Clone the Repository"},{"location":"sequential_coordinator_example/#step-2-configure-and-start-redis","text":"In this step, we will set up Redis for agent context and registry. Create a hidden directory .wise-agents in the root of your project: bash mkdir .wise-agents Copy the Redis configuration file as shown in the .wise-agents directory from the GitHub repo. Create a file named redis-config.yaml inside .wise-agents : yaml redis: host: localhost port: 6379 Ensure Redis is installed and running . You can start redis as podman/docker image following instruction in redis README.MD","title":"Step 2: Configure and Start Redis"},{"location":"sequential_coordinator_example/#step-3-start-artemis","text":"To support async communication between agents you need to have artemis up and running Start artemis podman/docker image following instructions in artemis README.MD Set the environment variables for artemis secure login. If you haven't changed any configuration, starting artemis following the previous point instructions they are: export STOMP_USER=artemis export STOMP_PASSWORD=artemis","title":"Step 3: Start artemis"},{"location":"sequential_coordinator_example/#step-4-start-ollama-with-llama-31","text":"To support the Llama model, you need to ensure that Ollama is installed and running: Install Ollama if it\u2019s not installed already by following the Ollama installation instructions . Start Ollama with Llama 3.1 : bash ollama run llama3.1 This will load the Llama 3.1 model into Ollama, which is necessary for running the intelligent agent.","title":"Step 4: Start Ollama with Llama 3.1"},{"location":"sequential_coordinator_example/#step-5-start-the-intelligent-agent","text":"In a first console, run the intelligent agents and coordinator agent, also from the project\u2019s home directory, using the following command: python src/wiseagents/cli/wise_agent_cli.py examples/sequential_coordinator/intelligent-agent.yaml This will initialize the intelligent agents and coordinator agent, which will be ready to respond to requests sent by the web interface agent.","title":"Step 5: Start the Intelligent Agent"},{"location":"sequential_coordinator_example/#step-6-start-the-web-interface-agent","text":"In your second console, navigate to the project\u2019s home directory and run the web interface agent using the provided YAML configuration file: python src/wiseagents/cli/wise_agent_cli.py examples/sequential_coordinator/web-interface.yaml This will initialize the Assistant agent with its web interface. You should see logs indicating that the agent is started and waiting for requests. You will see in the console also a web server listening at http://127.0.0.1:7860 Running on local URL: http://127.0.0.1:7860","title":"Step 6: Start the Web Interface Agent"},{"location":"sequential_coordinator_example/#step-7-interaction","text":"Once all agents are up and running, you can use the web interface agent as a chatbot and it will start sending requests to the intelligent agent. You will be able to see the interaction between the agents through the logs in both consoles. Try as an example to ask something like \"Can you give me detailed information about Harry Potter\". You will get the detailed information about Rowling's books translated in Italian :)","title":"Step 7: Interaction"},{"location":"sequential_coordinator_example/#step-8-experiment","text":"You can experiment with different agent configurations or modify the agent behaviors by editing the YAML files located in the examples/memory_agentic_chatbot directory. These configuration files define the agents' properties, including memory, communication methods, and response patterns. You can do that without restarting everything, just edit the yaml file(s) and use CLI's /reload command (see our documentation for more details on how to use CLI)","title":"Step 8: Experiment"},{"location":"sequential_coordinator_example/#understanding-the-yaml-configuration","text":"web-interface.yaml : Defines the web interface agent, which serves as the client interface for interacting with other agents. intelligent-agents.yaml : Defines the intelligent agents and coordinator agent, which processes the requests and generates responses based on the provided input. These YAML files include the specific WiseAgent classes and configuration needed to run the agents. Feel free to explore and modify these files to customize the agents' behavior.","title":"Understanding the YAML Configuration"},{"location":"sequential_coordinator_example/#additional-resources","text":"For more information about the architecture and advanced configurations of wise-agents, refer to the Wise Agents Architecture Document , which provides insights into how the system can be scaled and deployed in distributed environments.","title":"Additional Resources"},{"location":"sequential_coordinator_example/#conclusion","text":"By following these steps, you have successfully run a simple sequential coordinated multi-agent chatbot using Wise Agents. You can now explore further by modifying agent behaviors, adding new agents, or experimenting with different message flows. For any further assistance, feel free to refer to the official Wise Agents documentation or reach out to the repository maintainers.","title":"Conclusion"},{"location":"using_cli/","text":"Wise Agents CLI Documentation Introduction The Wise Agents CLI is a command-line interface for interacting with a multi-agent system built using the wiseagents framework. This tool allows you to: Load agents from YAML configuration files. Manage and reload agents dynamically. Send messages between agents. Trace message interactions. Start interactive chat sessions with agents. This documentation will guide you through the installation, setup, and usage of the Wise Agents CLI. Distributed Wise Agents CLI The Wise Agents CLI can be configured to start multiple instances of agents across different processes, network nodes, or even in separate pods (in Kubernetes environments). To enable this distributed architecture, you need to configure Redis for the WiseAgentRegistry . By setting up Redis, you allow the agents to share a common registry and message context, enabling asynchronous communication across distributed systems. Distributed Architecture To learn more about how the CLI and agents can be scaled and managed in a distributed environment, please refer to the \"Distributed Architecture\" paragraph in Wise Agents Architecture Document . This document outlines the key components, such as Redis integration, inter-agent communication, and load balancing strategies for deploying agents on different network nodes or cloud environments. Table of Contents Installation and Setup Prerequisites Installing Dependencies Running the CLI Usage Available Commands /help or /h /load-agents or /l /reload-agents or /r /agents or /a /send or /s /chat or /c /trace or /t /exit or /x Agent Configuration YAML Configuration File Examples Loading Agents Sending a Message to an Agent Starting a Chat Session Notes Conclusion Running the CLI To start the Wise Agents CLI, run the script from your terminal: python src/wiseagents/cli/wise_agent_cli.py [path_to_agents_file.yaml] The [path_to_agents_file.yaml] is optional. If provided, the CLI will automatically load agents from the specified YAML file upon startup. Usage Once the CLI is running, you can interact with it using various commands. The CLI operates in a loop, prompting you for input after each command execution. Available Commands /help or /h Displays a list of available commands and their descriptions. /(l)oad-agents: Load agents from file /(r)eload agents: Reload agents from file /(c)hat: Start a chat /(t)race: Show the message trace /e(x)it: Exit the application /(h)elp: Show the available commands (a)gents: Show the registered agents (s)end: Send a message to an agent /load-agents or /l Loads agents from a YAML configuration file. Usage : Type /load-agents or /l and press ENTER. File Path Prompt : If no file path was provided when starting the CLI, you will be prompted to enter one. Press ENTER without typing anything to use the default path: src/wiseagents/cli/test-multiple.yaml . Agent Management : Starts all loaded agents /reload-agents or /r Reloads agents from the current or a new YAML configuration file. This is very useful to reload agents when you are tweaking the configuration or the system prompt Usage : Type /reload-agents or /r and press ENTER. File Path Prompt : You can provide a new file path when prompted. Agent Management : Stops all currently running agents before reloading. /agents or /a Displays a list of all registered agents along with their descriptions. /send or /s Sends a message to a specific agent. Usage : Type /send or /s and press ENTER. Enter the agent's name when prompted. Enter the message you wish to send. /chat or /c Starts an interactive chat session with an agent. Usage : Type /chat or /c and press ENTER. Enter messages when prompted. Type /back to exit the chat session. Note: This command assumes that an agent named PassThroughClientAgent1 is available and has been set up to handle chat interactions. /trace or /t Displays the message trace, showing all messages that have been sent between agents. /exit or /x Exits the CLI and stops all running agents. Agent Configuration YAML Configuration File Agents are defined in a YAML file, which the CLI loads to create and start agents. Each agent is specified with a YAML document starting with a tag that indicates the agent class. Example YAML Configuration: --- !wiseagents.agents.PassThroughClientAgent name: PassThroughClientAgent1 # Additional agent-specific configuration... The !wiseagents.agents.PassThroughClientAgent tag indicates the agent class. The name field specifies the unique name of the agent. Additional configuration parameters can be added as needed. Importing Agent Classes: When loading agents, the CLI attempts to import the necessary Python modules based on the tags in the YAML file. Ensure that: The agent classes are available in the Python path. The modules can be imported without errors. Examples Loading Agents Start the CLI without specifying a file: bash python src/wiseagents/cli/wise_agent_cli.py At the prompt , type: plaintext /load-agents or simply: plaintext /l Enter the file path when prompted: plaintext Enter the file path (ENTER for default src/wiseagents/cli/test-multiple.yaml): Press ENTER to use the default path. Or enter a custom path to your YAML configuration file. Agents are loaded : The CLI will import necessary modules and load agents, displaying messages like: plaintext Loaded agent: PassThroughClientAgent1 registered agents= {'PassThroughClientAgent1': 'Description of agent'} Sending a Message to an Agent Ensure agents are loaded and running. Type the send command : plaintext /send or: plaintext /s Enter the agent's name when prompted: plaintext Enter the agent name: Example: LLMOnlyWiseAgent2 Enter your message : plaintext Enter the message: Example: Hello, how are you? Message is sent : The CLI will handle sending the message and waiting for a response. Starting a Chat Session Ensure PassThroughClientAgent1 is loaded and running. Type the chat command : plaintext /chat or: plaintext /c Enter messages when prompted: plaintext Enter a message (or /back): Type your message and press ENTER. Repeat to continue the conversation. Exit the chat : Type /back and press ENTER to return to the main command prompt. Notes Agent Names : Ensure that agent names used in commands match those defined in your YAML configuration file. Module Importing : The CLI attempts to import agent classes based on YAML tags. Modules must be importable and accessible in your Python environment. Default File Path : The default file path is set to src/wiseagents/cli/test-multiple.yaml . Modify this path as needed for your setup. Conclusion The Wise Agents CLI provides a flexible and interactive way to manage and communicate with agents in a multi-agent system. By leveraging YAML configuration files and a straightforward command interface, you can simulate complex interactions, test agent behaviors, and monitor communications within the system. For further customization, you can modify the agents and their configurations, extend the CLI with additional commands, or integrate it into larger applications.","title":"Using CLI"},{"location":"using_cli/#wise-agents-cli-documentation","text":"","title":"Wise Agents CLI Documentation"},{"location":"using_cli/#introduction","text":"The Wise Agents CLI is a command-line interface for interacting with a multi-agent system built using the wiseagents framework. This tool allows you to: Load agents from YAML configuration files. Manage and reload agents dynamically. Send messages between agents. Trace message interactions. Start interactive chat sessions with agents. This documentation will guide you through the installation, setup, and usage of the Wise Agents CLI.","title":"Introduction"},{"location":"using_cli/#distributed-wise-agents-cli","text":"The Wise Agents CLI can be configured to start multiple instances of agents across different processes, network nodes, or even in separate pods (in Kubernetes environments). To enable this distributed architecture, you need to configure Redis for the WiseAgentRegistry . By setting up Redis, you allow the agents to share a common registry and message context, enabling asynchronous communication across distributed systems.","title":"Distributed Wise Agents CLI"},{"location":"using_cli/#distributed-architecture","text":"To learn more about how the CLI and agents can be scaled and managed in a distributed environment, please refer to the \"Distributed Architecture\" paragraph in Wise Agents Architecture Document . This document outlines the key components, such as Redis integration, inter-agent communication, and load balancing strategies for deploying agents on different network nodes or cloud environments.","title":"Distributed Architecture"},{"location":"using_cli/#table-of-contents","text":"Installation and Setup Prerequisites Installing Dependencies Running the CLI Usage Available Commands /help or /h /load-agents or /l /reload-agents or /r /agents or /a /send or /s /chat or /c /trace or /t /exit or /x Agent Configuration YAML Configuration File Examples Loading Agents Sending a Message to an Agent Starting a Chat Session Notes Conclusion","title":"Table of Contents"},{"location":"using_cli/#running-the-cli","text":"To start the Wise Agents CLI, run the script from your terminal: python src/wiseagents/cli/wise_agent_cli.py [path_to_agents_file.yaml] The [path_to_agents_file.yaml] is optional. If provided, the CLI will automatically load agents from the specified YAML file upon startup.","title":"Running the CLI"},{"location":"using_cli/#usage","text":"Once the CLI is running, you can interact with it using various commands. The CLI operates in a loop, prompting you for input after each command execution.","title":"Usage"},{"location":"using_cli/#available-commands","text":"","title":"Available Commands"},{"location":"using_cli/#help-or-h","text":"Displays a list of available commands and their descriptions. /(l)oad-agents: Load agents from file /(r)eload agents: Reload agents from file /(c)hat: Start a chat /(t)race: Show the message trace /e(x)it: Exit the application /(h)elp: Show the available commands (a)gents: Show the registered agents (s)end: Send a message to an agent","title":"/help or /h"},{"location":"using_cli/#load-agents-or-l","text":"Loads agents from a YAML configuration file. Usage : Type /load-agents or /l and press ENTER. File Path Prompt : If no file path was provided when starting the CLI, you will be prompted to enter one. Press ENTER without typing anything to use the default path: src/wiseagents/cli/test-multiple.yaml . Agent Management : Starts all loaded agents","title":"/load-agents or /l"},{"location":"using_cli/#reload-agents-or-r","text":"Reloads agents from the current or a new YAML configuration file. This is very useful to reload agents when you are tweaking the configuration or the system prompt Usage : Type /reload-agents or /r and press ENTER. File Path Prompt : You can provide a new file path when prompted. Agent Management : Stops all currently running agents before reloading.","title":"/reload-agents or /r"},{"location":"using_cli/#agents-or-a","text":"Displays a list of all registered agents along with their descriptions.","title":"/agents or /a"},{"location":"using_cli/#send-or-s","text":"Sends a message to a specific agent. Usage : Type /send or /s and press ENTER. Enter the agent's name when prompted. Enter the message you wish to send.","title":"/send or /s"},{"location":"using_cli/#chat-or-c","text":"Starts an interactive chat session with an agent. Usage : Type /chat or /c and press ENTER. Enter messages when prompted. Type /back to exit the chat session. Note: This command assumes that an agent named PassThroughClientAgent1 is available and has been set up to handle chat interactions.","title":"/chat or /c"},{"location":"using_cli/#trace-or-t","text":"Displays the message trace, showing all messages that have been sent between agents.","title":"/trace or /t"},{"location":"using_cli/#exit-or-x","text":"Exits the CLI and stops all running agents.","title":"/exit or /x"},{"location":"using_cli/#agent-configuration","text":"","title":"Agent Configuration"},{"location":"using_cli/#yaml-configuration-file","text":"Agents are defined in a YAML file, which the CLI loads to create and start agents. Each agent is specified with a YAML document starting with a tag that indicates the agent class. Example YAML Configuration: --- !wiseagents.agents.PassThroughClientAgent name: PassThroughClientAgent1 # Additional agent-specific configuration... The !wiseagents.agents.PassThroughClientAgent tag indicates the agent class. The name field specifies the unique name of the agent. Additional configuration parameters can be added as needed. Importing Agent Classes: When loading agents, the CLI attempts to import the necessary Python modules based on the tags in the YAML file. Ensure that: The agent classes are available in the Python path. The modules can be imported without errors.","title":"YAML Configuration File"},{"location":"using_cli/#examples","text":"","title":"Examples"},{"location":"using_cli/#loading-agents","text":"Start the CLI without specifying a file: bash python src/wiseagents/cli/wise_agent_cli.py At the prompt , type: plaintext /load-agents or simply: plaintext /l Enter the file path when prompted: plaintext Enter the file path (ENTER for default src/wiseagents/cli/test-multiple.yaml): Press ENTER to use the default path. Or enter a custom path to your YAML configuration file. Agents are loaded : The CLI will import necessary modules and load agents, displaying messages like: plaintext Loaded agent: PassThroughClientAgent1 registered agents= {'PassThroughClientAgent1': 'Description of agent'}","title":"Loading Agents"},{"location":"using_cli/#sending-a-message-to-an-agent","text":"Ensure agents are loaded and running. Type the send command : plaintext /send or: plaintext /s Enter the agent's name when prompted: plaintext Enter the agent name: Example: LLMOnlyWiseAgent2 Enter your message : plaintext Enter the message: Example: Hello, how are you? Message is sent : The CLI will handle sending the message and waiting for a response.","title":"Sending a Message to an Agent"},{"location":"using_cli/#starting-a-chat-session","text":"Ensure PassThroughClientAgent1 is loaded and running. Type the chat command : plaintext /chat or: plaintext /c Enter messages when prompted: plaintext Enter a message (or /back): Type your message and press ENTER. Repeat to continue the conversation. Exit the chat : Type /back and press ENTER to return to the main command prompt.","title":"Starting a Chat Session"},{"location":"using_cli/#notes","text":"Agent Names : Ensure that agent names used in commands match those defined in your YAML configuration file. Module Importing : The CLI attempts to import agent classes based on YAML tags. Modules must be importable and accessible in your Python environment. Default File Path : The default file path is set to src/wiseagents/cli/test-multiple.yaml . Modify this path as needed for your setup.","title":"Notes"},{"location":"using_cli/#conclusion","text":"The Wise Agents CLI provides a flexible and interactive way to manage and communicate with agents in a multi-agent system. By leveraging YAML configuration files and a straightforward command interface, you can simulate complex interactions, test agent behaviors, and monitor communications within the system. For further customization, you can modify the agents and their configurations, extend the CLI with additional commands, or integrate it into larger applications.","title":"Conclusion"},{"location":"wise_agents_architecture/","text":"Wise-Agent Architecture Disclaimer: This page is under construction and continuously updated. General Architecture WiseAgent is a multi-agent intelligent framework designed for distributed, asynchronous communication. It is capable of connecting to any LLM model or inference system that supports the OpenAI API, enabling the use of multiple different models within the same configuration. One of the key features of WiseAgent is its cloud readiness and distributed nature, allowing for the deployment of different components in separate pods, while also being able to run everything in a single process for simpler use cases. The following image provides a high-level overview of the architecture and flow: TODO Wise-Agent Components WiseAgents : These are the core components where the actual processing occurs. Each WiseAgent MUST be capable of communicating via the STOMP protocol. It MUST be able to process an input message in the WiseAgentMessage format and produce a WiseAgentMessage as output. An agent MAY have perceiving capabilities (such as monitoring changes in files, reacting to events, etc.). Additionally, it MAY integrate with an LLM through the OpenAI API, supporting tools (both external APIs and other agents acting as tools). A WiseAgent MAY be capable of taking actions, such as executing tools or APIs. The framework currently supports features like GraphRAG and tool calls, and it can be extended to support additional functionalities. Specialized implementations of WiseAgents can handle orchestration or triage of inputs. In essence, every component of the WiseAgent framework, except for the registry and context, is an agent with specific capabilities. WiseAgentMessage : This is the format used for communication between agents. There are generally two types of communication: The main content is carried in the WiseAgentMessage payload as natural language. The WiseAgentMessage is used solely for ACK/NACK purposes, with the actual content being part of the shared memory within a specific execution context. Communication Protocol : The WiseAgent framework is designed to enable asynchronous communication between agents. The current implementation uses the STOMP 1.0 protocol, which is supported by various message queue systems such as ArtemisMQ and RabbitMQ. LLM Integration : A WiseAgent MAY utilize an LLM to process requests and generate responses. This integration is facilitated through the standard OpenAI API, which supports any model or inference system that provides OpenAI API access. The framework manages the memory of previous message tokens that form the context for each LLM request, allowing these contexts to be shared between agents participating in the same execution context. Agents' Registry : When an agent is created and deployed, it registers itself with the Agents' Registry, providing a name and a detailed natural language description (with possible added metadata) of its capabilities. These descriptions are used by the coordinator to select the appropriate agents to solve a specific problem or to address a phase of the problem solution. Agents' Execution Context : Each session or query lifecycle is tracked within an execution context. This context stores shared information such as available and executed tools, the current phase of execution, etc. It also serves as the shared memory where agents collaborate to keep track of LLM interactions. By managing shared memory at the agents' level instead of the LLM integration level, the WiseAgent framework allows different agents\u2014potentially using different LLM models\u2014to share contextual information. Agents' Coordinator : The coordinator is responsible for organizing the work among agents. It determines which agents are needed to provide a solution, the order in which they should execute, and how they should cooperate to achieve the final result. The framework provides different coordinator implementations: SequentialCoordinator : Processes the request by routing it sequentially to various agents. Partial answers from each agent can be utilized by subsequent agents in the sequence, culminating in a final response to the client. PhasedCoordinatorWiseAgent : This coordinator groups agents into different phases and then executes each phase in parallel. The results from each agent enrich the shared context and can be selectively used by the coordinator or any other agent in subsequent phases. Agents within the same phase cannot depend on each other. Note: An agent defined to run in a specific phase can act as a SequentialCoordinator for complex compositions. Currently, it is not possible to compose another PhasedCoordinatorWiseAgent within a phase. Perceptions' Triage Agent : This is essentially another coordinator, specifically tasked with collecting, filtering, and aggregating inputs from agents with perceiving capabilities. The output from the triage process is a natural language question or problem description, complete with all relevant data and details. This output serves as the input for the Agents' Coordinator to produce a final answer or create an action plan. RAG Agents : Retrieving additional relevant information is a key capability of a multi-agent system. The WiseAgent framework provides advanced RAG (Retrieval-Augmented Generation) and GraphRAG agents that can be used or extended. For more details, see RAG Architecture . LLM Integration As mentioned earlier, LLM integration is achieved through a client-side implementation of the OpenAI API. The responsibility for tracking messages exchanged with the LLM lies with the agent, not the LLM integration layer. This design choice makes the WiseAgent framework agnostic to the specific LLM model used, as long as the model and inference system support the OpenAI API. This approach allows different agents to potentially use different models while sharing a unified memory. For more information, see RAG Architecture . Distributed architecture As said above, wise-agents has been designed as a fully distributable cloud-ready architecture. For this reason, each agent can ideally run in a different pod and communicate with others through asynchronous communication based on STOMP protocol. All agents use a shared memory to access the Agent's Registry and Agent's Context . This is done by a shared Redis server, which can be configured with a file named registry_config.yaml from the current directory. If not found in current directory it is loaded from ~/.wise-agents/registry_config.yaml . The file looks like: use_redis: true #if falseredis not used and all agents need to be in the same process redis_host: localhost redis_port: 6379 redis_db: wise-agents redis_ssl : false #ssl connection. if it's true you need to set also all the following parameters redis_username: default redis_password: secret redis_ssl_certfile: \"./redis_user.crt\" redis_ssl_keyfile: \"./redis_user_private.key\" redis_ssl_ca_certs: \"./redis_ca.pem\" Note: To configure SSL you need Redis enterprise For more information about redis connection please refer to official redis documentation","title":"Wise Agents architecture"},{"location":"wise_agents_architecture/#wise-agent-architecture","text":"Disclaimer: This page is under construction and continuously updated.","title":"Wise-Agent Architecture"},{"location":"wise_agents_architecture/#general-architecture","text":"WiseAgent is a multi-agent intelligent framework designed for distributed, asynchronous communication. It is capable of connecting to any LLM model or inference system that supports the OpenAI API, enabling the use of multiple different models within the same configuration. One of the key features of WiseAgent is its cloud readiness and distributed nature, allowing for the deployment of different components in separate pods, while also being able to run everything in a single process for simpler use cases. The following image provides a high-level overview of the architecture and flow: TODO","title":"General Architecture"},{"location":"wise_agents_architecture/#wise-agent-components","text":"WiseAgents : These are the core components where the actual processing occurs. Each WiseAgent MUST be capable of communicating via the STOMP protocol. It MUST be able to process an input message in the WiseAgentMessage format and produce a WiseAgentMessage as output. An agent MAY have perceiving capabilities (such as monitoring changes in files, reacting to events, etc.). Additionally, it MAY integrate with an LLM through the OpenAI API, supporting tools (both external APIs and other agents acting as tools). A WiseAgent MAY be capable of taking actions, such as executing tools or APIs. The framework currently supports features like GraphRAG and tool calls, and it can be extended to support additional functionalities. Specialized implementations of WiseAgents can handle orchestration or triage of inputs. In essence, every component of the WiseAgent framework, except for the registry and context, is an agent with specific capabilities. WiseAgentMessage : This is the format used for communication between agents. There are generally two types of communication: The main content is carried in the WiseAgentMessage payload as natural language. The WiseAgentMessage is used solely for ACK/NACK purposes, with the actual content being part of the shared memory within a specific execution context. Communication Protocol : The WiseAgent framework is designed to enable asynchronous communication between agents. The current implementation uses the STOMP 1.0 protocol, which is supported by various message queue systems such as ArtemisMQ and RabbitMQ. LLM Integration : A WiseAgent MAY utilize an LLM to process requests and generate responses. This integration is facilitated through the standard OpenAI API, which supports any model or inference system that provides OpenAI API access. The framework manages the memory of previous message tokens that form the context for each LLM request, allowing these contexts to be shared between agents participating in the same execution context. Agents' Registry : When an agent is created and deployed, it registers itself with the Agents' Registry, providing a name and a detailed natural language description (with possible added metadata) of its capabilities. These descriptions are used by the coordinator to select the appropriate agents to solve a specific problem or to address a phase of the problem solution. Agents' Execution Context : Each session or query lifecycle is tracked within an execution context. This context stores shared information such as available and executed tools, the current phase of execution, etc. It also serves as the shared memory where agents collaborate to keep track of LLM interactions. By managing shared memory at the agents' level instead of the LLM integration level, the WiseAgent framework allows different agents\u2014potentially using different LLM models\u2014to share contextual information. Agents' Coordinator : The coordinator is responsible for organizing the work among agents. It determines which agents are needed to provide a solution, the order in which they should execute, and how they should cooperate to achieve the final result. The framework provides different coordinator implementations: SequentialCoordinator : Processes the request by routing it sequentially to various agents. Partial answers from each agent can be utilized by subsequent agents in the sequence, culminating in a final response to the client. PhasedCoordinatorWiseAgent : This coordinator groups agents into different phases and then executes each phase in parallel. The results from each agent enrich the shared context and can be selectively used by the coordinator or any other agent in subsequent phases. Agents within the same phase cannot depend on each other. Note: An agent defined to run in a specific phase can act as a SequentialCoordinator for complex compositions. Currently, it is not possible to compose another PhasedCoordinatorWiseAgent within a phase. Perceptions' Triage Agent : This is essentially another coordinator, specifically tasked with collecting, filtering, and aggregating inputs from agents with perceiving capabilities. The output from the triage process is a natural language question or problem description, complete with all relevant data and details. This output serves as the input for the Agents' Coordinator to produce a final answer or create an action plan. RAG Agents : Retrieving additional relevant information is a key capability of a multi-agent system. The WiseAgent framework provides advanced RAG (Retrieval-Augmented Generation) and GraphRAG agents that can be used or extended. For more details, see RAG Architecture .","title":"Wise-Agent Components"},{"location":"wise_agents_architecture/#llm-integration","text":"As mentioned earlier, LLM integration is achieved through a client-side implementation of the OpenAI API. The responsibility for tracking messages exchanged with the LLM lies with the agent, not the LLM integration layer. This design choice makes the WiseAgent framework agnostic to the specific LLM model used, as long as the model and inference system support the OpenAI API. This approach allows different agents to potentially use different models while sharing a unified memory. For more information, see RAG Architecture .","title":"LLM Integration"},{"location":"wise_agents_architecture/#distributed-architecture","text":"As said above, wise-agents has been designed as a fully distributable cloud-ready architecture. For this reason, each agent can ideally run in a different pod and communicate with others through asynchronous communication based on STOMP protocol. All agents use a shared memory to access the Agent's Registry and Agent's Context . This is done by a shared Redis server, which can be configured with a file named registry_config.yaml from the current directory. If not found in current directory it is loaded from ~/.wise-agents/registry_config.yaml . The file looks like: use_redis: true #if falseredis not used and all agents need to be in the same process redis_host: localhost redis_port: 6379 redis_db: wise-agents redis_ssl : false #ssl connection. if it's true you need to set also all the following parameters redis_username: default redis_password: secret redis_ssl_certfile: \"./redis_user.crt\" redis_ssl_keyfile: \"./redis_user_private.key\" redis_ssl_ca_certs: \"./redis_ca.pem\" Note: To configure SSL you need Redis enterprise For more information about redis connection please refer to official redis documentation","title":"Distributed architecture"},{"location":"artemis/","text":"How to start a graph database There is a script named run_artemis.sh in the same directory of this document. The script starts a artemis MQ broker in a container Be sure to define POD_CONTAINER variable before running this script. If a .env file is present, it will read the environment variables from there. The .env file should be in the same directory as the script. Rename the .env.example file to .env and set the environment variables.","title":"Index"},{"location":"artemis/#how-to-start-a-graph-database","text":"There is a script named run_artemis.sh in the same directory of this document. The script starts a artemis MQ broker in a container Be sure to define POD_CONTAINER variable before running this script. If a .env file is present, it will read the environment variables from there. The .env file should be in the same directory as the script. Rename the .env.example file to .env and set the environment variables.","title":"How to start a graph database"},{"location":"graphdb/","text":"How to start a graph database There is a script named run_graphdb.sh in the same directory of this document. The script starts a graph database. It reads the username, password, and database name to be used to connect to the graph database from the environment variables. Be sure to define these variables before running this script. export NEO4J_USERNAME=USERNAME_TO_CONNECT_TO_NEO4J export NEO4J_PASSWORD=PASSWORD_TO_CONNECT_TO_NEO4J export NEO4J_DATABASE=DATABASE_NAME_TO_CONNECT_TO export POD_CONTAINER=podman | docker As an example, the above variables could be set to: export NEO4J_USERNAME=neo4j export NEO4J_PASSWORD=neo4jpassword export NEO4J_DATABASE=neo4j export POD_CONTAINER=docker If a .env file is present, it will read the environment variables from there. The .env file should be in the same directory as the script. Rename the .env.example file to .env and set the environment variables.","title":"Index"},{"location":"graphdb/#how-to-start-a-graph-database","text":"There is a script named run_graphdb.sh in the same directory of this document. The script starts a graph database. It reads the username, password, and database name to be used to connect to the graph database from the environment variables. Be sure to define these variables before running this script. export NEO4J_USERNAME=USERNAME_TO_CONNECT_TO_NEO4J export NEO4J_PASSWORD=PASSWORD_TO_CONNECT_TO_NEO4J export NEO4J_DATABASE=DATABASE_NAME_TO_CONNECT_TO export POD_CONTAINER=podman | docker As an example, the above variables could be set to: export NEO4J_USERNAME=neo4j export NEO4J_PASSWORD=neo4jpassword export NEO4J_DATABASE=neo4j export POD_CONTAINER=docker If a .env file is present, it will read the environment variables from there. The .env file should be in the same directory as the script. Rename the .env.example file to .env and set the environment variables.","title":"How to start a graph database"},{"location":"model-serving/","text":"How to start a local inference for your model Download the model Download a (small) model from https://huggingface.co/models Good oprtions are: * granite-7b-lab-Q4_K_M.gguf * Phi-3-mini-4k-instruct-q4.gguf The model need to be in gguf format. You have 2 option Filter for GGUF models in hugging face Download in HF format and convert it to gguf https://github.com/ggerganov/llama.cpp/blob/master/convert-hf-to-gguf.py running Lllama cpp image There is a script named model_inference.sh in the same directory of this document. The script run the model inference server It reads the model path and model name from the environment variables, define these variables before running the script ``` export MODEL_PATH=/absolute_path/to/your/model export POD_CONTAINER=podman | docker export MODEL_NAME=model_name.gguf ``` If a .env file is present, it will read the environment variables from there The .env file should be in the same directory as the script Rename the .env.example file to .env and set the environment variables","title":"Index"},{"location":"model-serving/#how-to-start-a-local-inference-for-your-model","text":"","title":"How to start a local inference for your model"},{"location":"model-serving/#download-the-model","text":"Download a (small) model from https://huggingface.co/models Good oprtions are: * granite-7b-lab-Q4_K_M.gguf * Phi-3-mini-4k-instruct-q4.gguf The model need to be in gguf format. You have 2 option Filter for GGUF models in hugging face Download in HF format and convert it to gguf https://github.com/ggerganov/llama.cpp/blob/master/convert-hf-to-gguf.py","title":"Download the model"},{"location":"model-serving/#running-lllama-cpp-image","text":"There is a script named model_inference.sh in the same directory of this document. The script run the model inference server It reads the model path and model name from the environment variables, define these variables before running the script ``` export MODEL_PATH=/absolute_path/to/your/model export POD_CONTAINER=podman | docker export MODEL_NAME=model_name.gguf ``` If a .env file is present, it will read the environment variables from there The .env file should be in the same directory as the script Rename the .env.example file to .env and set the environment variables","title":"running Lllama cpp image"},{"location":"reference/SUMMARY/","text":"wiseagents agents assistant coordinator_wise_agents rag_wise_agents utility_wise_agents cli wise_agent_cli constants core graphdb lang_chain_wise_agent_graph_db wise_agent_graph_db llm openai_API_wise_agent_LLM wise_agent_LLM wise_agent_remote_LLM transports stomp vectordb lang_chain_wise_agent_vector_db wise_agent_vector_db wise_agent_messaging yaml wise_yaml_loader yaml_utils","title":"SUMMARY"},{"location":"reference/wiseagents/","text":"WiseAgent Bases: YAMLObject A WiseAgent is an abstract class that represents an agent that can send and receive messages to and from other agents. Source code in wiseagents/core.py 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 class WiseAgent ( yaml . YAMLObject ): ''' A WiseAgent is an abstract class that represents an agent that can send and receive messages to and from other agents. ''' yaml_tag = u '!wiseagents.WiseAgent' yaml_loader = WiseAgentsLoader def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _llm = None obj . _vector_db = None obj . _graph_db = None obj . _collection_name = \"wise-agent-collection\" obj . _system_message = None return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : Optional [ WiseAgentLLM ] = None , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = \"wise-agent-collection\" , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): ''' Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Args: name (str): the name of the agent description (str): a description of what the agent does transport (WiseAgentTransport): the transport to use for sending and receiving messages llm (Optional[WiseAgentLLM]): the LLM associated with the agent vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent system_message Optional(str): an optional system message that can be used by the agent when processing chat completions using its LLM ''' self . _name = name self . _description = description self . _llm = llm self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db self . _transport = transport self . _system_message = system_message self . start_agent () def start_agent ( self ): ''' Start the agent by setting the call backs and starting the transport.''' self . transport . set_call_backs ( self . handle_request , self . process_event , self . process_error , self . process_response ) self . transport . start () WiseAgentRegistry . register_agent ( self . name , self . description ) def stop_agent ( self ): ''' Stop the agent by stopping the transport and removing the agent from the registry.''' self . transport . stop () WiseAgentRegistry . unregister_agent ( self . name ) def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . _collection_name } , graph_db= { self . graph_db } ,\" f \"system_message= { self . system_message } )\" ) def __eq__ ( self , value : object ) -> bool : return isinstance ( value , WiseAgent ) and self . __repr__ () == value . __repr__ () @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def description ( self ) -> str : \"\"\"Get a description of what the agent does.\"\"\" return self . _description @property def llm ( self ) -> Optional [ WiseAgentLLM ]: \"\"\"Get the LLM associated with the agent.\"\"\" return self . _llm @property def vector_db ( self ) -> Optional [ WiseAgentVectorDB ]: \"\"\"Get the vector DB associated with the agent.\"\"\" return self . _vector_db @property def collection_name ( self ) -> str : \"\"\"Get the vector DB collection name associated with the agent.\"\"\" return self . _collection_name @property def graph_db ( self ) -> Optional [ WiseAgentGraphDB ]: \"\"\"Get the graph DB associated with the agent.\"\"\" return self . _graph_db @property def transport ( self ) -> WiseAgentTransport : \"\"\"Get the transport associated with the agent.\"\"\" return self . _transport @property def system_message ( self ) -> Optional [ str ]: \"\"\"Get the system message associated with the agent.\"\"\" return self . _system_message def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_request ( message , dest_agent_name ) context . trace ( message ) def send_response ( self , message : WiseAgentMessage , dest_agent_name ): '''Send a response message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_response ( message , dest_agent_name ) context . trace ( message ) def handle_request ( self , request : WiseAgentMessage ) -> bool : \"\"\" Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Args: request (WiseAgentMessage): the request message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" context = WiseAgentRegistry . get_or_create_context ( request . context_name ) collaboration_type = context . get_collaboration_type ( request . chat_id ) conversation_history = self . get_conversation_history_if_needed ( context , request . chat_id , collaboration_type ) response_str = self . process_request ( request , conversation_history ) return self . handle_response ( response_str , request , context , collaboration_type ) def get_conversation_history_if_needed ( self , context : WiseAgentContext , chat_id : Optional [ str ], collaboration_type : str ) -> List [ ChatCompletionMessageParam ]: \"\"\" Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Args: context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent is involved in a collaboration type that makes use of the conversation history and an empty list otherwise \"\"\" if chat_id : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # this agent is involved in phased collaboration or a chat, so it needs the conversation history return context . llm_chat_completion . get ( chat_id ) # for sequential collaboration and independent agents, the shared history is not needed return [] @abstractmethod def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process the given request message to generate a response string. Args: request (WiseAgentMessage): the request message to be processed conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" ... def handle_response ( self , response_str : str , request : WiseAgentMessage , context : WiseAgentContext , collaboration_type : str ) -> bool : \"\"\" Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Args: response_str (str): the string response to be handled context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: True if the message was processed successfully, False otherwise \"\"\" if response_str : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # add this agent's response to the shared context context . append_chat_completion ( chat_uuid = request . chat_id , messages = { \"role\" : \"assistant\" , \"content\" : response_str }) # let the sender know that this agent has finished processing the request self . send_response ( WiseAgentMessage ( message = response_str , message_type = WiseAgentMessageType . ACK , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) elif collaboration_type == WiseAgentCollaborationType . SEQUENTIAL : next_agent = context . get_next_agent_in_sequence ( request . chat_id , self . name ) if next_agent is None : logging . debug ( f \"Sequential coordination complete - sending response from \" + self . name + \" to \" + context . get_route_response_to ( request . chat_id )) self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), context . get_route_response_to ( request . chat_id )) else : logging . debug ( f \"Sequential coordination continuing - sending response from \" + self . name + \" to \" + next_agent ) self . send_request ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), next_agent ) else : self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) return True @abstractmethod def process_response ( self , message : WiseAgentMessage ) -> bool : \"\"\" Callback method to process the response received from another agent which processed a request from this agent. Args: message (WiseAgentMessage): the message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" ... @abstractmethod def process_event ( self , event : WiseAgentEvent ) -> bool : \"\"\" Callback method to process the given event. Args: event (WiseAgentEvent): the event to be processed Returns: True if the event was processed successfully, False otherwise \"\"\" ... @abstractmethod def process_error ( self , error : Exception ) -> bool : \"\"\" Callback method to process the given error. Args: error (Exception): the error to be processed Returns: True if the error was processed successfully, False otherwise \"\"\" ... collection_name : str property Get the vector DB collection name associated with the agent. description : str property Get a description of what the agent does. graph_db : Optional [ WiseAgentGraphDB ] property Get the graph DB associated with the agent. llm : Optional [ WiseAgentLLM ] property Get the LLM associated with the agent. name : str property Get the name of the agent. system_message : Optional [ str ] property Get the system message associated with the agent. transport : WiseAgentTransport property Get the transport associated with the agent. vector_db : Optional [ WiseAgentVectorDB ] property Get the vector DB associated with the agent. __init__ ( name , description , transport , llm = None , vector_db = None , collection_name = 'wise-agent-collection' , graph_db = None , system_message = None ) Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of what the agent does transport ( WiseAgentTransport ) \u2013 the transport to use for sending and receiving messages llm ( Optional [ WiseAgentLLM ] , default: None ) \u2013 the LLM associated with the agent vector_db ( Optional [ WiseAgentVectorDB ] , default: None ) \u2013 the vector DB associated with the agent collection_name ( Optional[str]) = \"wise-agent-collection\" , default: 'wise-agent-collection' ) \u2013 the vector DB collection name associated with the agent graph_db ( Optional [ WiseAgentGraphDB ] , default: None ) \u2013 the graph DB associated with the agent system_message ( Optional(str , default: None ) \u2013 an optional system message that can be used by the agent when processing chat Source code in wiseagents/core.py 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : Optional [ WiseAgentLLM ] = None , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = \"wise-agent-collection\" , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): ''' Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Args: name (str): the name of the agent description (str): a description of what the agent does transport (WiseAgentTransport): the transport to use for sending and receiving messages llm (Optional[WiseAgentLLM]): the LLM associated with the agent vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent system_message Optional(str): an optional system message that can be used by the agent when processing chat completions using its LLM ''' self . _name = name self . _description = description self . _llm = llm self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db self . _transport = transport self . _system_message = system_message self . start_agent () __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/core.py 834 835 836 837 838 839 840 841 842 def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _llm = None obj . _vector_db = None obj . _graph_db = None obj . _collection_name = \"wise-agent-collection\" obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/core.py 885 886 887 888 889 def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . _collection_name } , graph_db= { self . graph_db } ,\" f \"system_message= { self . system_message } )\" ) get_conversation_history_if_needed ( context , chat_id , collaboration_type ) Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Parameters: context ( WiseAgentContext ) \u2013 the shared context chat_id ( Optional [ str ] ) \u2013 the chat id, may be None collaboration_type ( str ) \u2013 the type of collaboration this agent is involved in Returns: List [ ChatCompletionMessageParam ] \u2013 List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent List [ ChatCompletionMessageParam ] \u2013 is involved in a collaboration type that makes use of the conversation history and an empty list List [ ChatCompletionMessageParam ] \u2013 otherwise Source code in wiseagents/core.py 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 def get_conversation_history_if_needed ( self , context : WiseAgentContext , chat_id : Optional [ str ], collaboration_type : str ) -> List [ ChatCompletionMessageParam ]: \"\"\" Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Args: context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent is involved in a collaboration type that makes use of the conversation history and an empty list otherwise \"\"\" if chat_id : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # this agent is involved in phased collaboration or a chat, so it needs the conversation history return context . llm_chat_completion . get ( chat_id ) # for sequential collaboration and independent agents, the shared history is not needed return [] handle_request ( request ) Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Parameters: request ( WiseAgentMessage ) \u2013 the request message to be processed Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 def handle_request ( self , request : WiseAgentMessage ) -> bool : \"\"\" Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Args: request (WiseAgentMessage): the request message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" context = WiseAgentRegistry . get_or_create_context ( request . context_name ) collaboration_type = context . get_collaboration_type ( request . chat_id ) conversation_history = self . get_conversation_history_if_needed ( context , request . chat_id , collaboration_type ) response_str = self . process_request ( request , conversation_history ) return self . handle_response ( response_str , request , context , collaboration_type ) handle_response ( response_str , request , context , collaboration_type ) Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Parameters: response_str ( str ) \u2013 the string response to be handled context ( WiseAgentContext ) \u2013 the shared context chat_id ( Optional [ str ] ) \u2013 the chat id, may be None collaboration_type ( str ) \u2013 the type of collaboration this agent is involved in Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 def handle_response ( self , response_str : str , request : WiseAgentMessage , context : WiseAgentContext , collaboration_type : str ) -> bool : \"\"\" Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Args: response_str (str): the string response to be handled context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: True if the message was processed successfully, False otherwise \"\"\" if response_str : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # add this agent's response to the shared context context . append_chat_completion ( chat_uuid = request . chat_id , messages = { \"role\" : \"assistant\" , \"content\" : response_str }) # let the sender know that this agent has finished processing the request self . send_response ( WiseAgentMessage ( message = response_str , message_type = WiseAgentMessageType . ACK , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) elif collaboration_type == WiseAgentCollaborationType . SEQUENTIAL : next_agent = context . get_next_agent_in_sequence ( request . chat_id , self . name ) if next_agent is None : logging . debug ( f \"Sequential coordination complete - sending response from \" + self . name + \" to \" + context . get_route_response_to ( request . chat_id )) self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), context . get_route_response_to ( request . chat_id )) else : logging . debug ( f \"Sequential coordination continuing - sending response from \" + self . name + \" to \" + next_agent ) self . send_request ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), next_agent ) else : self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) return True process_error ( error ) abstractmethod Callback method to process the given error. Parameters: error ( Exception ) \u2013 the error to be processed Returns: bool \u2013 True if the error was processed successfully, False otherwise Source code in wiseagents/core.py 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 @abstractmethod def process_error ( self , error : Exception ) -> bool : \"\"\" Callback method to process the given error. Args: error (Exception): the error to be processed Returns: True if the error was processed successfully, False otherwise \"\"\" ... process_event ( event ) abstractmethod Callback method to process the given event. Parameters: event ( WiseAgentEvent ) \u2013 the event to be processed Returns: bool \u2013 True if the event was processed successfully, False otherwise Source code in wiseagents/core.py 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 @abstractmethod def process_event ( self , event : WiseAgentEvent ) -> bool : \"\"\" Callback method to process the given event. Args: event (WiseAgentEvent): the event to be processed Returns: True if the event was processed successfully, False otherwise \"\"\" ... process_request ( request , conversation_history ) abstractmethod Process the given request message to generate a response string. Parameters: request ( WiseAgentMessage ) \u2013 the request message to be processed conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/core.py 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 @abstractmethod def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process the given request message to generate a response string. Args: request (WiseAgentMessage): the request message to be processed conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" ... process_response ( message ) abstractmethod Callback method to process the response received from another agent which processed a request from this agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to be processed Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 @abstractmethod def process_response ( self , message : WiseAgentMessage ) -> bool : \"\"\" Callback method to process the response received from another agent which processed a request from this agent. Args: message (WiseAgentMessage): the message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" ... send_request ( message , dest_agent_name ) Send a request message to the destination agent with the given name. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the name of the destination agent Source code in wiseagents/core.py 934 935 936 937 938 939 940 941 942 943 944 def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_request ( message , dest_agent_name ) context . trace ( message ) send_response ( message , dest_agent_name ) Send a response message to the destination agent with the given name. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the name of the destination agent Source code in wiseagents/core.py 946 947 948 949 950 951 952 953 954 955 956 def send_response ( self , message : WiseAgentMessage , dest_agent_name ): '''Send a response message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_response ( message , dest_agent_name ) context . trace ( message ) start_agent () Start the agent by setting the call backs and starting the transport. Source code in wiseagents/core.py 873 874 875 876 877 878 def start_agent ( self ): ''' Start the agent by setting the call backs and starting the transport.''' self . transport . set_call_backs ( self . handle_request , self . process_event , self . process_error , self . process_response ) self . transport . start () WiseAgentRegistry . register_agent ( self . name , self . description ) stop_agent () Stop the agent by stopping the transport and removing the agent from the registry. Source code in wiseagents/core.py 880 881 882 883 def stop_agent ( self ): ''' Stop the agent by stopping the transport and removing the agent from the registry.''' self . transport . stop () WiseAgentRegistry . unregister_agent ( self . name ) WiseAgentContext A WiseAgentContext is a class that represents a context in which agents can communicate with each other. Source code in wiseagents/core.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 class WiseAgentContext (): ''' A WiseAgentContext is a class that represents a context in which agents can communicate with each other. ''' _message_trace : List [ str ] = [] _participants : List [ str ] = [] # Maps a chat uuid to a list of chat completion messages _llm_chat_completion : Dict [ str , List [ ChatCompletionMessageParam ]] = {} # Maps a chat uuid to a list of tool names that need to be executed _llm_required_tool_call : Dict [ str , List [ str ]] = {} # Maps a chat uuid to a list of available tools in chat _llm_available_tools_in_chat : Dict [ str , List [ ChatCompletionToolParam ]] = {} # Maps a chat uuid to a list of agent names that need to be executed in sequence # Used by a sequential coordinator _agents_sequence : Dict [ str , List [ str ]] = {} # Maps a chat uuid to the agent where the final response should be routed to # Used by both a sequential coordinator and a phased coordinator _route_response_to : Dict [ str , str ] = {} # Maps a chat uuid to a list that contains a list of agent names to be executed for each phase # Used by a phased coordinator _agent_phase_assignments : Dict [ str , List [ List [ str ]]] = {} # Maps a chat uuid to the current phase. Used by a phased coordinator. _current_phase : Dict [ str , int ] = {} # Maps a chat uuid to a list of agent names that need to be executed for the current phase # Used by a phased coordinator _required_agents_for_current_phase : Dict [ str , List [ str ]] = {} # Maps a chat uuid to a list containing the queries attempted for each iteration executed by # the phased coordinator _queries : Dict [ str , List [ str ]] = {} # Maps a chat uuid to the collaboration type _collaboration_type : Dict [ str , WiseAgentCollaborationType ] = {} _redis_db : redis . Redis = None _use_redis : bool = False _config : Dict [ str , Any ] = {} def __init__ ( self , name : str , config : Optional [ Dict [ str , Any ]] = { \"use_redis\" : False }): ''' Initialize the context with the given name. Args: name (str): the name of the context''' self . _name = name self . _config = config if config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True WiseAgentRegistry . register_context ( self ) def __repr__ ( self ) -> str : '''Return a string representation of the context.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , message_trace= { self . message_trace } ,\" f \"participants= { self . participants } , llm_chat_completion= { self . llm_chat_completion } ,\" f \"llm_required_tool_call= { self . llm_required_tool_call } , llm_available_tools_in_chat= { self . llm_available_tools_in_chat } ,\" f \"agents_sequence= { self . _agents_sequence } , route_response_to= { self . _route_response_to } ,\" f \"agent_phase_assignments= { self . _agent_phase_assignments } , current_phase= { self . _current_phase } ,\" f \"required_agents_for_current_phase= { self . _required_agents_for_current_phase } , queries= { self . _queries } )\" ) def __eq__ ( self , value : object ) -> bool : return isinstance ( value , WiseAgentContext ) and self . __repr__ () == value . __repr__ () def __getstate__ ( self ) -> object : '''Get the state of the context.''' state = self . __dict__ . copy () if '_redis_db' in state : del state [ '_redis_db' ] del state [ '_use_redis' ] return state def __setstate__ ( self , state : object ): '''Set the state of the context.''' self . __dict__ . update ( state ) if self . _config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True @property def name ( self ) -> str : \"\"\"Get the name of the context.\"\"\" return self . _name @property def message_trace ( self ) -> List [ str ]: \"\"\"Get the message trace of the context.\"\"\" if ( self . _use_redis == True ): return self . _redis_db . lrange ( \"message_trace\" , 0 , - 1 ) else : return self . _message_trace def trace ( self , message : WiseAgentMessage ): '''Trace the message.''' if ( self . _use_redis == True ): self . _redis_db . rpush ( \"message_trace\" , message . __repr__ ()) else : self . _message_trace . append ( message ) @property def participants ( self ) -> List [ str ]: \"\"\"Get the participants of the context.\"\"\" if ( self . _use_redis == True ): return self . _redis_db . lrange ( \"participants\" , 0 , - 1 ) else : return self . _participants @property def llm_chat_completion ( self ) -> Dict [ str , List [ ChatCompletionMessageParam ]]: \"\"\"Get the LLM chat completion of the context.\"\"\" if ( self . _use_redis == True ): return_dict : Dict [ str , List [ ChatCompletionMessageParam ]] = {} redis_dict = self . _redis_db . hgetall ( \"llm_chat_completion\" ) for key in redis_dict : return_dict [ key . decode ( 'utf-8' )] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _llm_chat_completion def add_participant ( self , agent_name : str ): '''Add a participant to the context. Args: agent (WiseAgent): the agent to add''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"participants\" ) try : if ( pipe . exists ( \"participants\" ) == False ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : if agent_name not in pipe . lrange ( \"participants\" , 0 , - 1 ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : pipe . unwatch () return except redis . WatchError : logging . debug ( \"WatchError in add_participant\" ) continue else : if agent_name not in self . participants : self . _participants . append ( agent_name ) def append_chat_completion ( self , chat_uuid : str , messages : Iterable [ ChatCompletionMessageParam ]): '''Append chat completion to the context. Args: chat_uuid (str): the chat uuid messages (Iterable[ChatCompletionMessageParam]): the messages to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"llm_chat_completion\" ) try : if ( pipe . hexists ( \"llm_chat_completion\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ([ messages ])) pipe . execute () return else : redis_stored_messages = pipe . hget ( \"llm_chat_completion\" , key = chat_uuid ) stored_messages : List [ ChatCompletionMessageParam ] = pickle . loads ( redis_stored_messages ) stored_messages . append ( messages ) pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ( stored_messages )) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in append_chat_completion\" ) continue else : if chat_uuid not in self . _llm_chat_completion : self . _llm_chat_completion [ chat_uuid ] = [] self . _llm_chat_completion [ chat_uuid ] . append ( messages ) @property def llm_required_tool_call ( self ) -> Dict [ str , List [ str ]]: \"\"\"Get the LLM required tool call of the context. return Dict[str, List[str]]\"\"\" if ( self . _use_redis == True ): redis_dict = self . _redis_db . hgetall ( \"llm_required_tool_call\" ) return_dict : Dict [ str , List [ str ]] = {} for key in redis_dict : return_dict [ key ] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _llm_required_tool_call def append_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Append required tool call to the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) if ( self . _redis_db . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): self . _redis_db . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ([ tool_name ])) pipe . execute () else : while True : try : pipe . watch ( \"llm_required_tool_call\" ) redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . append ( tool_name ) pipe . multi () pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_required_tool_call\" ) continue else : if chat_uuid not in self . llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] = [] self . _llm_required_tool_call [ chat_uuid ] . append ( tool_name ) def remove_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Remove required tool call from the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to remove''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_required_tool_call\" ) if ( pipe . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( redis_stored_tool_names == None ): stored_tool_names : List [ str ] = [] else : stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . remove ( tool_name ) pipe . multi () if len ( stored_tool_names ) == 0 : pipe . hdel ( \"llm_required_tool_call\" , chat_uuid ) else : pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in remove_required_tool_call\" ) continue if chat_uuid in self . _llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] . remove ( tool_name ) if len ( self . _llm_required_tool_call [ chat_uuid ]) == 0 : self . _llm_required_tool_call . pop ( chat_uuid ) def get_required_tool_calls ( self , chat_uuid : str ) -> List [ str ]: '''Get required tool calls from the context. Args: chat_uuid (str): the chat uuid return List[str]''' if ( self . _use_redis == True ): llm_req_tools = self . _redis_db . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( llm_req_tools is not None ): return pickle . loads ( llm_req_tools ) else : return [] if chat_uuid in self . _llm_required_tool_call : return self . _llm_required_tool_call [ chat_uuid ] else : return [] @property def llm_available_tools_in_chat ( self ) -> Dict [ str , List [ ChatCompletionToolParam ]]: \"\"\"Get the LLM available tools in chat of the context.\"\"\" if ( self . _use_redis == True ): redis_dict = self . _redis_db . hgetall ( \"llm_available_tools_in_chat\" ) return_dict : Dict [ str , List [ ChatCompletionToolParam ]] = {} for key in redis_dict : return_dict [ key ] = pickle . loads ( redis_dict [ key ]) return return_dict return self . _llm_available_tools_in_chat def append_available_tool_in_chat ( self , chat_uuid : str , tools : Iterable [ ChatCompletionToolParam ]): '''Append available tool in chat to the context. Args: chat_uuid (str): the chat uuid tools (Iterable[ChatCompletionToolParam]): the tools to append''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_available_tools_in_chat\" ) if ( pipe . hexists ( \"llm_available_tools_in_chat\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ([ tools ])) pipe . execute () break else : redis_stored_tools = pipe . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) stored_tools : List [ ChatCompletionToolParam ] = pickle . loads ( redis_stored_tools ) stored_tools . append ( tools ) pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ( stored_tools )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_available_tool_in_chat\" ) continue else : if chat_uuid not in self . _llm_available_tools_in_chat : self . _llm_available_tools_in_chat [ chat_uuid ] = [] self . _llm_available_tools_in_chat [ chat_uuid ] . append ( tools ) def get_available_tools_in_chat ( self , chat_uuid : str ) -> List [ ChatCompletionToolParam ]: '''Get available tools in chat from the context. Args: chat_uuid (str): the chat uuid return List[ChatCompletionToolParam]''' if ( self . _use_redis == True ): llm_av_tools = self . _redis_db . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) if ( llm_av_tools is not None ): return pickle . loads ( llm_av_tools ) else : return [] else : if chat_uuid in self . _llm_available_tools_in_chat : return self . _llm_available_tools_in_chat [ chat_uuid ] else : return [] def get_agents_sequence ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid Returns: List[str]: the sequence of agents names or an empty list if no sequence has been set for this context \"\"\" if ( self . _use_redis == True ): agent_sequence = self . _redis_db . hget ( \"agents_sequence\" , key = chat_uuid ) if ( agent_sequence is not None ): return pickle . loads ( agent_sequence ) else : return [] else : if chat_uuid in self . _agents_sequence : return self . _agents_sequence [ chat_uuid ] return [] def set_agents_sequence ( self , chat_uuid : str , agents_sequence : List [ str ]): \"\"\" Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid agents_sequence (List[str]): the sequence of agent names \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agents_sequence\" , key = chat_uuid , value = pickle . dumps ( agents_sequence )) else : self . _agents_sequence [ chat_uuid ] = agents_sequence def get_route_response_to ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set \"\"\" if ( self . _use_redis == True ): route = self . _redis_db . hget ( \"route_response_to\" , key = chat_uuid ) if ( route is not None ): return pickle . loads ( route ) else : return None else : if chat_uuid in self . _route_response_to : return self . _route_response_to [ chat_uuid ] else : return None def set_route_response_to ( self , chat_uuid : str , agent : str ): \"\"\" Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Args: chat_uuid (str): the chat uuid agent (str): the name of the agent where the final response should be routed to \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"route_response_to\" , key = chat_uuid , value = pickle . dumps ( agent )) else : self . _route_response_to [ chat_uuid ] = agent def get_next_agent_in_sequence ( self , chat_uuid : str , current_agent : str ): \"\"\" Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Args: chat_uuid (str): the chat uuid current_agent (str): the name of the current agent Returns: str: the name of the next agent in the sequence after the current agent or None if there are no remaining agents in the sequence after the current agent \"\"\" agents_sequence = self . get_agents_sequence ( chat_uuid ) if current_agent in agents_sequence : current_agent_index = agents_sequence . index ( current_agent ) next_agent_index = current_agent_index + 1 if next_agent_index < len ( agents_sequence ): return agents_sequence [ next_agent_index ] return None def get_agent_phase_assignments ( self , chat_uuid : str ) -> List [ List [ str ]]: \"\"\" Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. An empty list is returned if no phases have been set for the given chat uuid \"\"\" if ( self . _use_redis == True ): agent_phase = self . _redis_db . hget ( \"agent_phase_assignments\" , key = chat_uuid ) if ( agent_phase is not None ): return pickle . loads ( agent_phase ) else : return [] else : if chat_uuid in self . _agent_phase_assignments : return self . _agent_phase_assignments . get ( chat_uuid ) return [] def set_agent_phase_assignments ( self , chat_uuid : str , agent_phase_assignments : List [ List [ str ]]): \"\"\" Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_phase_assignments (List[List[str]]): The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agent_phase_assignments\" , key = chat_uuid , value = pickle . dumps ( agent_phase_assignments )) else : self . _agent_phase_assignments [ chat_uuid ] = agent_phase_assignments def get_current_phase ( self , chat_uuid : str ) -> int : \"\"\" Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: int: the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): cur_phase = self . _redis_db . hget ( \"current_phase\" , key = chat_uuid ) if ( cur_phase is not None ): return pickle . loads ( cur_phase ) else : return None else : return self . _current_phase . get ( chat_uuid ) def set_current_phase ( self , chat_uuid : str , phase : int ): \"\"\" Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid phase (int): the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): self . _redis_db . pipeline ( transaction = True ) \\ . hset ( \"current_phase\" , key = chat_uuid , value = pickle . dumps ( phase )) \\ . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( self . get_agent_phase_assignments ( chat_uuid )[ phase ])) \\ . execute () else : self . _current_phase [ chat_uuid ] = phase self . _required_agents_for_current_phase [ chat_uuid ] = copy . deepcopy ( self . _agent_phase_assignments [ chat_uuid ][ phase ]) def get_agents_for_next_phase ( self , chat_uuid : str ) -> Optional [ List ]: \"\"\" Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases \"\"\" current_phase = self . get_current_phase ( chat_uuid ) next_phase = current_phase + 1 if next_phase < len ( self . get_agent_phase_assignments ( chat_uuid )): self . set_current_phase ( chat_uuid , next_phase ) return self . get_agent_phase_assignments ( chat_uuid )[ next_phase ] return None def get_required_agents_for_current_phase ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[str]: the list of agent names that still need to be executed for the current phase or an empty list if there are no remaining agents that need to be executed for the current phase \"\"\" if ( self . _use_redis == True ): req_agent = self . _redis_db . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) if ( req_agent is not None ): return pickle . loads ( req_agent ) else : return [] else : if chat_uuid in self . _required_agents_for_current_phase : return self . _required_agents_for_current_phase . get ( chat_uuid ) return [] def remove_required_agent_for_current_phase ( self , chat_uuid : str , agent_name : str ): \"\"\" Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_name (str): the name of the agent to remove \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"required_agents_for_current_phase\" ) if ( pipe . hexists ( \"required_agents_for_current_phase\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_agents = pipe . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) stored_agents : List [ str ] = pickle . loads ( redis_stored_agents ) stored_agents . remove ( agent_name ) pipe . multi () if len ( stored_agents ) == 0 : pipe . hdel ( \"required_agents_for_current_phase\" , chat_uuid ) else : pipe . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( stored_agents )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to remove agent\" ) continue else : if chat_uuid in self . _required_agents_for_current_phase : self . _required_agents_for_current_phase . get ( chat_uuid ) . remove ( agent_name ) def get_current_query ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[str]: the current query or None if there is no current query \"\"\" if ( self . _use_redis == True ): queries = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( queries is not None ): return_list : List [ str ] = pickle . loads ( queries ) return return_list [ - 1 ] else : return None else : if chat_uuid in self . _queries : if self . _queries . get ( chat_uuid ): # return the last query return self . _queries . get ( chat_uuid )[ - 1 ] else : return None def add_query ( self , chat_uuid : str , query : str ): \"\"\" Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid query (str): the current query \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"queries\" ) if ( pipe . hexists ( \"queries\" , key = chat_uuid ) == False ): pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ([ query ])) else : redis_stored_queries = pipe . hget ( \"queries\" , key = chat_uuid ) stored_queries : List [ str ] = pickle . loads ( redis_stored_queries ) stored_queries . append ( query ) pipe . multi () pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ( stored_queries )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to add query\" ) continue else : if chat_uuid not in self . _queries : self . _queries [ chat_uuid ] = [] self . _queries [ chat_uuid ] . append ( query ) def get_queries ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List[str]: the queries attempted for the given chat uuid for this context \"\"\" if ( self . _use_redis == True ): query = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( query is not None ): return pickle . loads ( query ) else : return [] if chat_uuid in self . _queries : return self . _queries . get ( chat_uuid ) else : return [] @property def collaboration_type ( self ) -> Dict [ str , WiseAgentCollaborationType ]: \"\"\"Get the collaboration type for chat uuids for this context.\"\"\" if ( self . _use_redis == True ): return_dict : Dict [ str , WiseAgentCollaborationType ] = {} redis_dict = self . _redis_db . hgetall ( \"collaboration_type\" ) for key in redis_dict : return_dict [ key . decode ( 'utf-8' )] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _collaboration_type def get_collaboration_type ( self , chat_uuid : str ) -> WiseAgentCollaborationType : \"\"\" Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type \"\"\" if ( self . _use_redis == True ): if chat_uuid is not None : collaboration_type = self . _redis_db . hget ( \"collaboration_type\" , key = chat_uuid ) if ( collaboration_type is not None ): return pickle . loads ( collaboration_type ) else : return WiseAgentCollaborationType . INDEPENDENT else : if chat_uuid in self . _collaboration_type : return self . _collaboration_type . get ( chat_uuid ) else : return WiseAgentCollaborationType . INDEPENDENT def set_collaboration_type ( self , chat_uuid : str , collaboration_type : WiseAgentCollaborationType ): \"\"\" Set the collaboration type for the given chat uuid for this context. Args: chat_uuid (str): the chat uuid collaboration_type (WiseAgentCollaborationType): the collaboration type \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"collaboration_type\" , key = chat_uuid , value = pickle . dumps ( collaboration_type )) else : self . _collaboration_type [ chat_uuid ] = collaboration_type collaboration_type : Dict [ str , WiseAgentCollaborationType ] property Get the collaboration type for chat uuids for this context. llm_available_tools_in_chat : Dict [ str , List [ ChatCompletionToolParam ]] property Get the LLM available tools in chat of the context. llm_chat_completion : Dict [ str , List [ ChatCompletionMessageParam ]] property Get the LLM chat completion of the context. llm_required_tool_call : Dict [ str , List [ str ]] property Get the LLM required tool call of the context. return Dict[str, List[str]] message_trace : List [ str ] property Get the message trace of the context. name : str property Get the name of the context. participants : List [ str ] property Get the participants of the context. __getstate__ () Get the state of the context. Source code in wiseagents/core.py 183 184 185 186 187 188 189 def __getstate__ ( self ) -> object : '''Get the state of the context.''' state = self . __dict__ . copy () if '_redis_db' in state : del state [ '_redis_db' ] del state [ '_use_redis' ] return state __init__ ( name , config = { 'use_redis' : False }) Initialize the context with the given name. Parameters: name ( str ) \u2013 the name of the context Source code in wiseagents/core.py 159 160 161 162 163 164 165 166 167 168 169 170 def __init__ ( self , name : str , config : Optional [ Dict [ str , Any ]] = { \"use_redis\" : False }): ''' Initialize the context with the given name. Args: name (str): the name of the context''' self . _name = name self . _config = config if config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True WiseAgentRegistry . register_context ( self ) __repr__ () Return a string representation of the context. Source code in wiseagents/core.py 172 173 174 175 176 177 178 179 def __repr__ ( self ) -> str : '''Return a string representation of the context.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , message_trace= { self . message_trace } ,\" f \"participants= { self . participants } , llm_chat_completion= { self . llm_chat_completion } ,\" f \"llm_required_tool_call= { self . llm_required_tool_call } , llm_available_tools_in_chat= { self . llm_available_tools_in_chat } ,\" f \"agents_sequence= { self . _agents_sequence } , route_response_to= { self . _route_response_to } ,\" f \"agent_phase_assignments= { self . _agent_phase_assignments } , current_phase= { self . _current_phase } ,\" f \"required_agents_for_current_phase= { self . _required_agents_for_current_phase } , queries= { self . _queries } )\" ) __setstate__ ( state ) Set the state of the context. Source code in wiseagents/core.py 191 192 193 194 195 196 def __setstate__ ( self , state : object ): '''Set the state of the context.''' self . __dict__ . update ( state ) if self . _config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True add_participant ( agent_name ) Add a participant to the context. Parameters: agent ( WiseAgent ) \u2013 the agent to add Source code in wiseagents/core.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 def add_participant ( self , agent_name : str ): '''Add a participant to the context. Args: agent (WiseAgent): the agent to add''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"participants\" ) try : if ( pipe . exists ( \"participants\" ) == False ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : if agent_name not in pipe . lrange ( \"participants\" , 0 , - 1 ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : pipe . unwatch () return except redis . WatchError : logging . debug ( \"WatchError in add_participant\" ) continue else : if agent_name not in self . participants : self . _participants . append ( agent_name ) add_query ( chat_uuid , query ) Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid query ( str ) \u2013 the current query Source code in wiseagents/core.py 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 def add_query ( self , chat_uuid : str , query : str ): \"\"\" Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid query (str): the current query \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"queries\" ) if ( pipe . hexists ( \"queries\" , key = chat_uuid ) == False ): pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ([ query ])) else : redis_stored_queries = pipe . hget ( \"queries\" , key = chat_uuid ) stored_queries : List [ str ] = pickle . loads ( redis_stored_queries ) stored_queries . append ( query ) pipe . multi () pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ( stored_queries )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to add query\" ) continue else : if chat_uuid not in self . _queries : self . _queries [ chat_uuid ] = [] self . _queries [ chat_uuid ] . append ( query ) append_available_tool_in_chat ( chat_uuid , tools ) Append available tool in chat to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to append Source code in wiseagents/core.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 def append_available_tool_in_chat ( self , chat_uuid : str , tools : Iterable [ ChatCompletionToolParam ]): '''Append available tool in chat to the context. Args: chat_uuid (str): the chat uuid tools (Iterable[ChatCompletionToolParam]): the tools to append''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_available_tools_in_chat\" ) if ( pipe . hexists ( \"llm_available_tools_in_chat\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ([ tools ])) pipe . execute () break else : redis_stored_tools = pipe . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) stored_tools : List [ ChatCompletionToolParam ] = pickle . loads ( redis_stored_tools ) stored_tools . append ( tools ) pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ( stored_tools )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_available_tool_in_chat\" ) continue else : if chat_uuid not in self . _llm_available_tools_in_chat : self . _llm_available_tools_in_chat [ chat_uuid ] = [] self . _llm_available_tools_in_chat [ chat_uuid ] . append ( tools ) append_chat_completion ( chat_uuid , messages ) Append chat completion to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to append Source code in wiseagents/core.py 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 def append_chat_completion ( self , chat_uuid : str , messages : Iterable [ ChatCompletionMessageParam ]): '''Append chat completion to the context. Args: chat_uuid (str): the chat uuid messages (Iterable[ChatCompletionMessageParam]): the messages to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"llm_chat_completion\" ) try : if ( pipe . hexists ( \"llm_chat_completion\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ([ messages ])) pipe . execute () return else : redis_stored_messages = pipe . hget ( \"llm_chat_completion\" , key = chat_uuid ) stored_messages : List [ ChatCompletionMessageParam ] = pickle . loads ( redis_stored_messages ) stored_messages . append ( messages ) pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ( stored_messages )) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in append_chat_completion\" ) continue else : if chat_uuid not in self . _llm_chat_completion : self . _llm_chat_completion [ chat_uuid ] = [] self . _llm_chat_completion [ chat_uuid ] . append ( messages ) append_required_tool_call ( chat_uuid , tool_name ) Append required tool call to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tool_name ( str ) \u2013 the tool name to append Source code in wiseagents/core.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 def append_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Append required tool call to the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) if ( self . _redis_db . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): self . _redis_db . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ([ tool_name ])) pipe . execute () else : while True : try : pipe . watch ( \"llm_required_tool_call\" ) redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . append ( tool_name ) pipe . multi () pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_required_tool_call\" ) continue else : if chat_uuid not in self . llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] = [] self . _llm_required_tool_call [ chat_uuid ] . append ( tool_name ) get_agent_phase_assignments ( chat_uuid ) Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ List [ str ]] \u2013 List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the List [ List [ str ]] \u2013 size of the outer list corresponds to the number of phases and each element in the list is a list of List [ List [ str ]] \u2013 agent names for that phase. An empty list is returned if no phases have been set for the List [ List [ str ]] \u2013 given chat uuid Source code in wiseagents/core.py 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 def get_agent_phase_assignments ( self , chat_uuid : str ) -> List [ List [ str ]]: \"\"\" Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. An empty list is returned if no phases have been set for the given chat uuid \"\"\" if ( self . _use_redis == True ): agent_phase = self . _redis_db . hget ( \"agent_phase_assignments\" , key = chat_uuid ) if ( agent_phase is not None ): return pickle . loads ( agent_phase ) else : return [] else : if chat_uuid in self . _agent_phase_assignments : return self . _agent_phase_assignments . get ( chat_uuid ) return [] get_agents_for_next_phase ( chat_uuid ) Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: Optional [ List ] \u2013 Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases Source code in wiseagents/core.py 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 def get_agents_for_next_phase ( self , chat_uuid : str ) -> Optional [ List ]: \"\"\" Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases \"\"\" current_phase = self . get_current_phase ( chat_uuid ) next_phase = current_phase + 1 if next_phase < len ( self . get_agent_phase_assignments ( chat_uuid )): self . set_current_phase ( chat_uuid , next_phase ) return self . get_agent_phase_assignments ( chat_uuid )[ next_phase ] return None get_agents_sequence ( chat_uuid ) Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ str ] \u2013 List[str]: the sequence of agents names or an empty list if no sequence has been set for this context Source code in wiseagents/core.py 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 def get_agents_sequence ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid Returns: List[str]: the sequence of agents names or an empty list if no sequence has been set for this context \"\"\" if ( self . _use_redis == True ): agent_sequence = self . _redis_db . hget ( \"agents_sequence\" , key = chat_uuid ) if ( agent_sequence is not None ): return pickle . loads ( agent_sequence ) else : return [] else : if chat_uuid in self . _agents_sequence : return self . _agents_sequence [ chat_uuid ] return [] get_available_tools_in_chat ( chat_uuid ) Get available tools in chat from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid Source code in wiseagents/core.py 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 def get_available_tools_in_chat ( self , chat_uuid : str ) -> List [ ChatCompletionToolParam ]: '''Get available tools in chat from the context. Args: chat_uuid (str): the chat uuid return List[ChatCompletionToolParam]''' if ( self . _use_redis == True ): llm_av_tools = self . _redis_db . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) if ( llm_av_tools is not None ): return pickle . loads ( llm_av_tools ) else : return [] else : if chat_uuid in self . _llm_available_tools_in_chat : return self . _llm_available_tools_in_chat [ chat_uuid ] else : return [] get_collaboration_type ( chat_uuid ) Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type Source code in wiseagents/core.py 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 def get_collaboration_type ( self , chat_uuid : str ) -> WiseAgentCollaborationType : \"\"\" Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type \"\"\" if ( self . _use_redis == True ): if chat_uuid is not None : collaboration_type = self . _redis_db . hget ( \"collaboration_type\" , key = chat_uuid ) if ( collaboration_type is not None ): return pickle . loads ( collaboration_type ) else : return WiseAgentCollaborationType . INDEPENDENT else : if chat_uuid in self . _collaboration_type : return self . _collaboration_type . get ( chat_uuid ) else : return WiseAgentCollaborationType . INDEPENDENT get_current_phase ( chat_uuid ) Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: int ( int ) \u2013 the current phase, represented as an integer in the zero-indexed list of phases Source code in wiseagents/core.py 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 def get_current_phase ( self , chat_uuid : str ) -> int : \"\"\" Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: int: the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): cur_phase = self . _redis_db . hget ( \"current_phase\" , key = chat_uuid ) if ( cur_phase is not None ): return pickle . loads ( cur_phase ) else : return None else : return self . _current_phase . get ( chat_uuid ) get_current_query ( chat_uuid ) Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: Optional [ str ] \u2013 Optional[str]: the current query or None if there is no current query Source code in wiseagents/core.py 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 def get_current_query ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[str]: the current query or None if there is no current query \"\"\" if ( self . _use_redis == True ): queries = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( queries is not None ): return_list : List [ str ] = pickle . loads ( queries ) return return_list [ - 1 ] else : return None else : if chat_uuid in self . _queries : if self . _queries . get ( chat_uuid ): # return the last query return self . _queries . get ( chat_uuid )[ - 1 ] else : return None get_next_agent_in_sequence ( chat_uuid , current_agent ) Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Parameters: chat_uuid ( str ) \u2013 the chat uuid current_agent ( str ) \u2013 the name of the current agent Returns: str \u2013 the name of the next agent in the sequence after the current agent or None if there are no remaining \u2013 agents in the sequence after the current agent Source code in wiseagents/core.py 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 def get_next_agent_in_sequence ( self , chat_uuid : str , current_agent : str ): \"\"\" Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Args: chat_uuid (str): the chat uuid current_agent (str): the name of the current agent Returns: str: the name of the next agent in the sequence after the current agent or None if there are no remaining agents in the sequence after the current agent \"\"\" agents_sequence = self . get_agents_sequence ( chat_uuid ) if current_agent in agents_sequence : current_agent_index = agents_sequence . index ( current_agent ) next_agent_index = current_agent_index + 1 if next_agent_index < len ( agents_sequence ): return agents_sequence [ next_agent_index ] return None get_queries ( chat_uuid ) Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List [ str ] \u2013 List[str]: the queries attempted for the given chat uuid for this context Source code in wiseagents/core.py 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 def get_queries ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List[str]: the queries attempted for the given chat uuid for this context \"\"\" if ( self . _use_redis == True ): query = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( query is not None ): return pickle . loads ( query ) else : return [] if chat_uuid in self . _queries : return self . _queries . get ( chat_uuid ) else : return [] get_required_agents_for_current_phase ( chat_uuid ) Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ str ] \u2013 List[str]: the list of agent names that still need to be executed for the current phase or an empty list List [ str ] \u2013 if there are no remaining agents that need to be executed for the current phase Source code in wiseagents/core.py 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 def get_required_agents_for_current_phase ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[str]: the list of agent names that still need to be executed for the current phase or an empty list if there are no remaining agents that need to be executed for the current phase \"\"\" if ( self . _use_redis == True ): req_agent = self . _redis_db . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) if ( req_agent is not None ): return pickle . loads ( req_agent ) else : return [] else : if chat_uuid in self . _required_agents_for_current_phase : return self . _required_agents_for_current_phase . get ( chat_uuid ) return [] get_required_tool_calls ( chat_uuid ) Get required tool calls from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid Source code in wiseagents/core.py 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def get_required_tool_calls ( self , chat_uuid : str ) -> List [ str ]: '''Get required tool calls from the context. Args: chat_uuid (str): the chat uuid return List[str]''' if ( self . _use_redis == True ): llm_req_tools = self . _redis_db . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( llm_req_tools is not None ): return pickle . loads ( llm_req_tools ) else : return [] if chat_uuid in self . _llm_required_tool_call : return self . _llm_required_tool_call [ chat_uuid ] else : return [] get_route_response_to ( chat_uuid ) Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional [ str ] \u2013 Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set Source code in wiseagents/core.py 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 def get_route_response_to ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set \"\"\" if ( self . _use_redis == True ): route = self . _redis_db . hget ( \"route_response_to\" , key = chat_uuid ) if ( route is not None ): return pickle . loads ( route ) else : return None else : if chat_uuid in self . _route_response_to : return self . _route_response_to [ chat_uuid ] else : return None remove_required_agent_for_current_phase ( chat_uuid , agent_name ) Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent_name ( str ) \u2013 the name of the agent to remove Source code in wiseagents/core.py 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 def remove_required_agent_for_current_phase ( self , chat_uuid : str , agent_name : str ): \"\"\" Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_name (str): the name of the agent to remove \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"required_agents_for_current_phase\" ) if ( pipe . hexists ( \"required_agents_for_current_phase\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_agents = pipe . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) stored_agents : List [ str ] = pickle . loads ( redis_stored_agents ) stored_agents . remove ( agent_name ) pipe . multi () if len ( stored_agents ) == 0 : pipe . hdel ( \"required_agents_for_current_phase\" , chat_uuid ) else : pipe . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( stored_agents )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to remove agent\" ) continue else : if chat_uuid in self . _required_agents_for_current_phase : self . _required_agents_for_current_phase . get ( chat_uuid ) . remove ( agent_name ) remove_required_tool_call ( chat_uuid , tool_name ) Remove required tool call from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tool_name ( str ) \u2013 the tool name to remove Source code in wiseagents/core.py 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 def remove_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Remove required tool call from the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to remove''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_required_tool_call\" ) if ( pipe . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( redis_stored_tool_names == None ): stored_tool_names : List [ str ] = [] else : stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . remove ( tool_name ) pipe . multi () if len ( stored_tool_names ) == 0 : pipe . hdel ( \"llm_required_tool_call\" , chat_uuid ) else : pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in remove_required_tool_call\" ) continue if chat_uuid in self . _llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] . remove ( tool_name ) if len ( self . _llm_required_tool_call [ chat_uuid ]) == 0 : self . _llm_required_tool_call . pop ( chat_uuid ) set_agent_phase_assignments ( chat_uuid , agent_phase_assignments ) Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent_phase_assignments ( List [ List [ str ]] ) \u2013 The agents to be executed in each phase, represented as a Source code in wiseagents/core.py 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 def set_agent_phase_assignments ( self , chat_uuid : str , agent_phase_assignments : List [ List [ str ]]): \"\"\" Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_phase_assignments (List[List[str]]): The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agent_phase_assignments\" , key = chat_uuid , value = pickle . dumps ( agent_phase_assignments )) else : self . _agent_phase_assignments [ chat_uuid ] = agent_phase_assignments set_agents_sequence ( chat_uuid , agents_sequence ) Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Parameters: chat_uuid ( str ) \u2013 the chat uuid agents_sequence ( List [ str ] ) \u2013 the sequence of agent names Source code in wiseagents/core.py 484 485 486 487 488 489 490 491 492 493 494 495 496 497 def set_agents_sequence ( self , chat_uuid : str , agents_sequence : List [ str ]): \"\"\" Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid agents_sequence (List[str]): the sequence of agent names \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agents_sequence\" , key = chat_uuid , value = pickle . dumps ( agents_sequence )) else : self . _agents_sequence [ chat_uuid ] = agents_sequence set_collaboration_type ( chat_uuid , collaboration_type ) Set the collaboration type for the given chat uuid for this context. Parameters: chat_uuid ( str ) \u2013 the chat uuid collaboration_type ( WiseAgentCollaborationType ) \u2013 the collaboration type Source code in wiseagents/core.py 814 815 816 817 818 819 820 821 822 823 824 825 def set_collaboration_type ( self , chat_uuid : str , collaboration_type : WiseAgentCollaborationType ): \"\"\" Set the collaboration type for the given chat uuid for this context. Args: chat_uuid (str): the chat uuid collaboration_type (WiseAgentCollaborationType): the collaboration type \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"collaboration_type\" , key = chat_uuid , value = pickle . dumps ( collaboration_type )) else : self . _collaboration_type [ chat_uuid ] = collaboration_type set_current_phase ( chat_uuid , phase ) Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid phase ( int ) \u2013 the current phase, represented as an integer in the zero-indexed list of phases Source code in wiseagents/core.py 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 def set_current_phase ( self , chat_uuid : str , phase : int ): \"\"\" Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid phase (int): the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): self . _redis_db . pipeline ( transaction = True ) \\ . hset ( \"current_phase\" , key = chat_uuid , value = pickle . dumps ( phase )) \\ . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( self . get_agent_phase_assignments ( chat_uuid )[ phase ])) \\ . execute () else : self . _current_phase [ chat_uuid ] = phase self . _required_agents_for_current_phase [ chat_uuid ] = copy . deepcopy ( self . _agent_phase_assignments [ chat_uuid ][ phase ]) set_route_response_to ( chat_uuid , agent ) Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent ( str ) \u2013 the name of the agent where the final response should be routed to Source code in wiseagents/core.py 519 520 521 522 523 524 525 526 527 528 529 530 531 def set_route_response_to ( self , chat_uuid : str , agent : str ): \"\"\" Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Args: chat_uuid (str): the chat uuid agent (str): the name of the agent where the final response should be routed to \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"route_response_to\" , key = chat_uuid , value = pickle . dumps ( agent )) else : self . _route_response_to [ chat_uuid ] = agent trace ( message ) Trace the message. Source code in wiseagents/core.py 211 212 213 214 215 216 def trace ( self , message : WiseAgentMessage ): '''Trace the message.''' if ( self . _use_redis == True ): self . _redis_db . rpush ( \"message_trace\" , message . __repr__ ()) else : self . _message_trace . append ( message ) WiseAgentEvent TODO Source code in wiseagents/wise_agent_messaging.py 17 18 19 20 class WiseAgentEvent : \"\"\" TODO \"\"\" WiseAgentMessage Bases: YAMLObject A message that can be sent between agents. Source code in wiseagents/wise_agent_messaging.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 class WiseAgentMessage ( YAMLObject ): ''' A message that can be sent between agents. ''' yaml_tag = u '!wiseagents.WiseAgentMessage' def __init__ ( self , message : str , sender : Optional [ str ] = None , message_type : Optional [ WiseAgentMessageType ] = None , chat_id : Optional [ str ] = None , tool_id : Optional [ str ] = None , context_name : Optional [ str ] = None , route_response_to : Optional [ str ] = None ): '''Initialize the message. Args: message (str): the message contents (a natural language string) sender Optional(str): the sender of the message (or None if the sender was not specified) message_type Optional(WiseAgentMessageType): the type of the message (or None if the type was not specified) chat_id Optional(str): the id of the message tool_id Optional(str): the id of the tool context_name Optional(str): the context name of the message route_response_to Optional(str): the id of the tool to route the response to ''' self . _message = message self . _sender = sender self . _message_type = message_type self . _chat_id = chat_id self . _tool_id = tool_id self . _route_response_to = route_response_to if context_name is not None : self . _context_name = context_name else : self . _context_name = 'default' def __repr__ ( self ) -> str : return f \" { self . __class__ . __name__ } (message= { self . message } , sender= { self . sender } , message_type= { self . message_type } , id= { self . chat_id } , tool_id= { self . tool_id } , context_name= { self . context_name } , route_response_to= { self . route_response_to } , route_response_to= { self . route_response_to } )\" @property def context_name ( self ) -> str : \"\"\"Get the context name of the message.\"\"\" return self . _context_name @property def message ( self ) -> str : \"\"\"Get the message contents (a natural language string).\"\"\" return self . _message @property def sender ( self ) -> str : \"\"\"Get the sender of the message (or None if the sender was not specified).\"\"\" return self . _sender @sender . setter def sender ( self , sender : str ): '''Set the sender of the message. Args: sender (str): the sender of the message ''' self . _sender = sender @property def message_type ( self ) -> WiseAgentMessageType : \"\"\"Get the type of the message (or None if the type was not specified).\"\"\" return self . _message_type @property def chat_id ( self ) -> str : \"\"\"Get the id of the message.\"\"\" return self . _chat_id @property def tool_id ( self ) -> str : \"\"\"Get the id of the tool.\"\"\" return self . _tool_id @property def route_response_to ( self ) -> str : \"\"\"Get the id of the tool.\"\"\" return self . _route_response_to chat_id : str property Get the id of the message. context_name : str property Get the context name of the message. message : str property Get the message contents (a natural language string). message_type : WiseAgentMessageType property Get the type of the message (or None if the type was not specified). route_response_to : str property Get the id of the tool. sender : str property writable Get the sender of the message (or None if the sender was not specified). tool_id : str property Get the id of the tool. __init__ ( message , sender = None , message_type = None , chat_id = None , tool_id = None , context_name = None , route_response_to = None ) Initialize the message. Parameters: message ( str ) \u2013 the message contents (a natural language string) sender ( Optional(str , default: None ) \u2013 the sender of the message (or None if the sender was not specified) message_type ( Optional(WiseAgentMessageType , default: None ) \u2013 the type of the message (or None if the type was not specified) chat_id ( Optional(str , default: None ) \u2013 the id of the message tool_id ( Optional(str , default: None ) \u2013 the id of the tool context_name ( Optional(str , default: None ) \u2013 the context name of the message route_response_to ( Optional(str , default: None ) \u2013 the id of the tool to route the response to Source code in wiseagents/wise_agent_messaging.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , message : str , sender : Optional [ str ] = None , message_type : Optional [ WiseAgentMessageType ] = None , chat_id : Optional [ str ] = None , tool_id : Optional [ str ] = None , context_name : Optional [ str ] = None , route_response_to : Optional [ str ] = None ): '''Initialize the message. Args: message (str): the message contents (a natural language string) sender Optional(str): the sender of the message (or None if the sender was not specified) message_type Optional(WiseAgentMessageType): the type of the message (or None if the type was not specified) chat_id Optional(str): the id of the message tool_id Optional(str): the id of the tool context_name Optional(str): the context name of the message route_response_to Optional(str): the id of the tool to route the response to ''' self . _message = message self . _sender = sender self . _message_type = message_type self . _chat_id = chat_id self . _tool_id = tool_id self . _route_response_to = route_response_to if context_name is not None : self . _context_name = context_name else : self . _context_name = 'default' WiseAgentRegistry A Registry to get available agents and running contexts Source code in wiseagents/core.py 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 class WiseAgentRegistry : \"\"\" A Registry to get available agents and running contexts \"\"\" agents_descriptions_dict : dict [ str , str ] = {} contexts : dict [ str , WiseAgentContext ] = {} tools : dict [ str , WiseAgentTool ] = {} config : dict [ str , Any ] = {} redis_db : redis . Redis = None @classmethod def find_file ( cls , file_name , config_directory = \".wise-agents\" ) -> str : \"\"\" Find the file in the current directory or the home directory. \"\"\" # Step 1: Check the current directory local_path = os . path . join ( os . getcwd (), config_directory , file_name ) if os . path . isfile ( local_path ): return local_path # Step 2: Check the home directory home_dir = os . path . expanduser ( \"~\" ) home_path = os . path . join ( home_dir , config_directory , file_name ) if os . path . isfile ( home_path ): return home_path # If the file is not found in any of these locations, throw an exception raise FileNotFoundError ( f \"File ' { file_name } ' not found in current directory, home directory, as ' { config_directory } '/ { file_name } .\" ) @classmethod def get_config ( cls ) -> dict [ str , Any ]: \"\"\" Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture \"\"\" try : if cls . config is None or cls . config == {}: file_name = cls . find_file ( file_name = \"registry_config.yaml\" , config_directory = \".wise-agents\" ) cls . config : Dict [ str , Any ] = yaml . load ( open ( file_name ), Loader = yaml . FullLoader ) if cls . config . get ( \"use_redis\" ) == True and cls . redis_db is None : if ( cls . config . get ( \"redis_ssl\" ) is True ): cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ], username = cls . config [ \"redis_username\" ], # use your Redis user. More info https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/ password = cls . config [ \"redis_password\" ], # use your Redis password ssl = True , ssl_certfile = cls . config [ \"redis_ssl_certfile\" ], ssl_keyfile = cls . config [ \"redis_ssl_keyfile\" ], ssl_ca_certs = cls . config [ \"redis_ssl_ca_certs\" ]) else : cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ]) return cls . config except Exception as e : logging . error ( e ) exit ( 1 ) @classmethod def register_agent ( cls , agent_name : str , agent_description : str ): \"\"\" Register an agent with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"agents\" ) try : if ( pipe . hexists ( \"agents\" , agent_name ) == True ): pipe . unwatch () raise NameError ( f \"Agent with name { agent_name } already exists\" ) else : pipe . multi () pipe . hset ( \"agents\" , key = agent_name , value = agent_description ) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in register_agent\" ) continue else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : raise NameError ( f \"Agent with name { agent_name } already exists\" ) cls . agents_descriptions_dict [ agent_name ] = agent_description @classmethod def register_context ( cls , context : WiseAgentContext ): \"\"\" Register a context with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"contexts\" , key = context . name , value = pickle . dumps ( context )) else : cls . contexts [ context . name ] = context @classmethod def fetch_agents_descriptions_dict ( cls ) -> dict [ str , str ]: \"\"\" Get the dict with the agent names as keys and descriptions as values \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hgetall ( \"agents\" ) else : return cls . agents_descriptions_dict @classmethod def get_contexts ( cls ) -> dict [ str , WiseAgentContext ]: \"\"\" Get the list of contexts \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"contexts\" ) return_dictionary : Dict [ str , WiseAgentContext ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . contexts @classmethod def get_agent_description ( cls , agent_name : str ) -> str : \"\"\" Get the agent description for the agent with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return_byte = cls . redis_db . hget ( \"agents\" , key = agent_name ) if return_byte is not None : return return_byte . decode ( 'utf-8' ) else : return None else : return cls . agents_descriptions_dict . get ( agent_name ) @classmethod def get_or_create_context ( cls , context_name : str ) -> WiseAgentContext : \"\"\" Get the context with the given name \"\"\" context : WiseAgentContext = None if ( cls . get_config () . get ( \"use_redis\" ) == True ): ctx = cls . redis_db . hget ( \"contexts\" , key = context_name ) if ctx is not None : context : WiseAgentContext = pickle . loads ( ctx ) else : context = None else : context = cls . contexts . get ( context_name ) if context is None : # context creation will also register the context in the registry return WiseAgentContext ( context_name , cls . config ) else : return context @classmethod def does_context_exist ( cls , context_name : str ) -> bool : \"\"\" Get the context with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hexists ( \"contexts\" , key = context_name ) else : if cls . contexts . get ( context_name ) is None : return False else : return True @classmethod def unregister_agent ( cls , agent_name : str ): \"\"\" Remove the agent from the registry this should be used only on agents which already stopped transport connection \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"agents\" , agent_name ) else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : cls . agents_descriptions_dict . pop ( agent_name ) @classmethod def remove_context ( cls , context_name : str ): \"\"\" Remove the context from the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"contexts\" , context_name ) else : cls . contexts . pop ( context_name ) @classmethod def register_tool ( cls , tool : WiseAgentTool ): \"\"\" Register a tool with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"tools\" , key = tool . name , value = pickle . dumps ( tool )) else : cls . tools [ tool . name ] = tool @classmethod def get_tools ( cls ) -> dict [ str , WiseAgentTool ]: \"\"\" Get the list of tools \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"tools\" ) return_dictionary : Dict [ str , WiseAgentTool ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . tools @classmethod def get_tool ( cls , tool_name : str ) -> WiseAgentTool : \"\"\" Get the tool with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) piped_res = pipe . hexists ( \"tools\" , key = tool_name ) . hget ( \"tools\" , key = tool_name ) . execute () if piped_res [ 0 ]: return pickle . loads ( piped_res [ 1 ]) else : return None else : return cls . tools . get ( tool_name ) @classmethod def get_agent_names_and_descriptions ( cls ) -> List [ str ]: \"\"\" Get the list of agent names and descriptions. Returns: List[str]: the list of agent descriptions \"\"\" agent_descriptions = [] for agent_name , agent_description in cls . fetch_agents_descriptions_dict () . items (): agent_descriptions . append ( f \"Agent Name: { agent_name } Agent Description: { agent_description } \" ) return agent_descriptions does_context_exist ( context_name ) classmethod Get the context with the given name Source code in wiseagents/core.py 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 @classmethod def does_context_exist ( cls , context_name : str ) -> bool : \"\"\" Get the context with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hexists ( \"contexts\" , key = context_name ) else : if cls . contexts . get ( context_name ) is None : return False else : return True fetch_agents_descriptions_dict () classmethod Get the dict with the agent names as keys and descriptions as values Source code in wiseagents/core.py 1209 1210 1211 1212 1213 1214 1215 1216 1217 @classmethod def fetch_agents_descriptions_dict ( cls ) -> dict [ str , str ]: \"\"\" Get the dict with the agent names as keys and descriptions as values \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hgetall ( \"agents\" ) else : return cls . agents_descriptions_dict find_file ( file_name , config_directory = '.wise-agents' ) classmethod Find the file in the current directory or the home directory. Source code in wiseagents/core.py 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 @classmethod def find_file ( cls , file_name , config_directory = \".wise-agents\" ) -> str : \"\"\" Find the file in the current directory or the home directory. \"\"\" # Step 1: Check the current directory local_path = os . path . join ( os . getcwd (), config_directory , file_name ) if os . path . isfile ( local_path ): return local_path # Step 2: Check the home directory home_dir = os . path . expanduser ( \"~\" ) home_path = os . path . join ( home_dir , config_directory , file_name ) if os . path . isfile ( home_path ): return home_path # If the file is not found in any of these locations, throw an exception raise FileNotFoundError ( f \"File ' { file_name } ' not found in current directory, home directory, as ' { config_directory } '/ { file_name } .\" ) get_agent_description ( agent_name ) classmethod Get the agent description for the agent with the given name Source code in wiseagents/core.py 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 @classmethod def get_agent_description ( cls , agent_name : str ) -> str : \"\"\" Get the agent description for the agent with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return_byte = cls . redis_db . hget ( \"agents\" , key = agent_name ) if return_byte is not None : return return_byte . decode ( 'utf-8' ) else : return None else : return cls . agents_descriptions_dict . get ( agent_name ) get_agent_names_and_descriptions () classmethod Get the list of agent names and descriptions. Returns: List [ str ] \u2013 List[str]: the list of agent descriptions Source code in wiseagents/core.py 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 @classmethod def get_agent_names_and_descriptions ( cls ) -> List [ str ]: \"\"\" Get the list of agent names and descriptions. Returns: List[str]: the list of agent descriptions \"\"\" agent_descriptions = [] for agent_name , agent_description in cls . fetch_agents_descriptions_dict () . items (): agent_descriptions . append ( f \"Agent Name: { agent_name } Agent Description: { agent_description } \" ) return agent_descriptions get_config () classmethod Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture Source code in wiseagents/core.py 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 @classmethod def get_config ( cls ) -> dict [ str , Any ]: \"\"\" Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture \"\"\" try : if cls . config is None or cls . config == {}: file_name = cls . find_file ( file_name = \"registry_config.yaml\" , config_directory = \".wise-agents\" ) cls . config : Dict [ str , Any ] = yaml . load ( open ( file_name ), Loader = yaml . FullLoader ) if cls . config . get ( \"use_redis\" ) == True and cls . redis_db is None : if ( cls . config . get ( \"redis_ssl\" ) is True ): cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ], username = cls . config [ \"redis_username\" ], # use your Redis user. More info https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/ password = cls . config [ \"redis_password\" ], # use your Redis password ssl = True , ssl_certfile = cls . config [ \"redis_ssl_certfile\" ], ssl_keyfile = cls . config [ \"redis_ssl_keyfile\" ], ssl_ca_certs = cls . config [ \"redis_ssl_ca_certs\" ]) else : cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ]) return cls . config except Exception as e : logging . error ( e ) exit ( 1 ) get_contexts () classmethod Get the list of contexts Source code in wiseagents/core.py 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 @classmethod def get_contexts ( cls ) -> dict [ str , WiseAgentContext ]: \"\"\" Get the list of contexts \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"contexts\" ) return_dictionary : Dict [ str , WiseAgentContext ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . contexts get_or_create_context ( context_name ) classmethod Get the context with the given name Source code in wiseagents/core.py 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 @classmethod def get_or_create_context ( cls , context_name : str ) -> WiseAgentContext : \"\"\" Get the context with the given name \"\"\" context : WiseAgentContext = None if ( cls . get_config () . get ( \"use_redis\" ) == True ): ctx = cls . redis_db . hget ( \"contexts\" , key = context_name ) if ctx is not None : context : WiseAgentContext = pickle . loads ( ctx ) else : context = None else : context = cls . contexts . get ( context_name ) if context is None : # context creation will also register the context in the registry return WiseAgentContext ( context_name , cls . config ) else : return context get_tool ( tool_name ) classmethod Get the tool with the given name Source code in wiseagents/core.py 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 @classmethod def get_tool ( cls , tool_name : str ) -> WiseAgentTool : \"\"\" Get the tool with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) piped_res = pipe . hexists ( \"tools\" , key = tool_name ) . hget ( \"tools\" , key = tool_name ) . execute () if piped_res [ 0 ]: return pickle . loads ( piped_res [ 1 ]) else : return None else : return cls . tools . get ( tool_name ) get_tools () classmethod Get the list of tools Source code in wiseagents/core.py 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 @classmethod def get_tools ( cls ) -> dict [ str , WiseAgentTool ]: \"\"\" Get the list of tools \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"tools\" ) return_dictionary : Dict [ str , WiseAgentTool ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . tools register_agent ( agent_name , agent_description ) classmethod Register an agent with the registry Source code in wiseagents/core.py 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 @classmethod def register_agent ( cls , agent_name : str , agent_description : str ): \"\"\" Register an agent with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"agents\" ) try : if ( pipe . hexists ( \"agents\" , agent_name ) == True ): pipe . unwatch () raise NameError ( f \"Agent with name { agent_name } already exists\" ) else : pipe . multi () pipe . hset ( \"agents\" , key = agent_name , value = agent_description ) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in register_agent\" ) continue else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : raise NameError ( f \"Agent with name { agent_name } already exists\" ) cls . agents_descriptions_dict [ agent_name ] = agent_description register_context ( context ) classmethod Register a context with the registry Source code in wiseagents/core.py 1200 1201 1202 1203 1204 1205 1206 1207 1208 @classmethod def register_context ( cls , context : WiseAgentContext ): \"\"\" Register a context with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"contexts\" , key = context . name , value = pickle . dumps ( context )) else : cls . contexts [ context . name ] = context register_tool ( tool ) classmethod Register a tool with the registry Source code in wiseagents/core.py 1299 1300 1301 1302 1303 1304 1305 1306 1307 @classmethod def register_tool ( cls , tool : WiseAgentTool ): \"\"\" Register a tool with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"tools\" , key = tool . name , value = pickle . dumps ( tool )) else : cls . tools [ tool . name ] = tool remove_context ( context_name ) classmethod Remove the context from the registry Source code in wiseagents/core.py 1289 1290 1291 1292 1293 1294 1295 1296 1297 @classmethod def remove_context ( cls , context_name : str ): \"\"\" Remove the context from the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"contexts\" , context_name ) else : cls . contexts . pop ( context_name ) unregister_agent ( agent_name ) classmethod Remove the agent from the registry this should be used only on agents which already stopped transport connection Source code in wiseagents/core.py 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 @classmethod def unregister_agent ( cls , agent_name : str ): \"\"\" Remove the agent from the registry this should be used only on agents which already stopped transport connection \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"agents\" , agent_name ) else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : cls . agents_descriptions_dict . pop ( agent_name ) WiseAgentTool Bases: YAMLObject A WiseAgentTool is an abstract class that represents a tool that can be used by an agent to perform a specific task. Source code in wiseagents/core.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class WiseAgentTool ( yaml . YAMLObject ): ''' A WiseAgentTool is an abstract class that represents a tool that can be used by an agent to perform a specific task.''' yaml_tag = u '!wiseagents.WiseAgentTool' yaml_loader = WiseAgentsLoader def __init__ ( self , name : str , description : str , agent_tool : bool , parameters_json_schema : dict = {}, call_back : Optional [ Callable [ ... , str ]] = None ): ''' Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Args: name (str): the name of the tool description (str): a description of what the tool does agent_tool (bool): whether the tool is an agent tool parameters_json_schema (dict): the json schema for the parameters of the tool call_back Optional(Callable[...,str]): the callback function to execute the tool''' self . _name = name self . _description = description self . _parameters_json_schema = parameters_json_schema self . _agent_tool = agent_tool self . _call_back = call_back WiseAgentRegistry . register_tool ( self ) @classmethod def from_yaml ( cls , loader , node ): '''Load the tool from a YAML node. Args: loader (yaml.Loader): the YAML loader node (yaml.Node): the YAML node''' data = loader . construct_mapping ( node , deep = True ) return cls ( name = data . get ( '_name' ), description = data . get ( '_description' ), parameters_json_schema = data . get ( '_parameters_json_schema' ), call_back = data . get ( '_call_back' )) @property def name ( self ) -> str : \"\"\"Get the name of the tool.\"\"\" return self . _name @property def description ( self ) -> str : \"\"\"Get the description of the tool.\"\"\" return self . _description @property def call_back ( self ) -> Callable [ ... , str ]: \"\"\"Get the callback function of the tool.\"\"\" return self . _call_back @property def json_schema ( self ) -> dict : \"\"\"Get the json schema of the tool.\"\"\" return self . _parameters_json_schema @property def is_agent_tool ( self ) -> bool : \"\"\"Get the agent tool of the tool.\"\"\" return self . _agent_tool def get_tool_OpenAI_format ( self ) -> ChatCompletionToolParam : '''The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam''' return { \"type\" : \"function\" , \"function\" : { \"name\" : self . name , \"description\" : self . description , \"parameters\" : self . json_schema } } def default_call_back ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' return json . dumps ( kwargs ) def exec ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' if self . call_back is None : return self . default_call_back ( ** kwargs ) return self . call_back ( ** kwargs ) call_back : Callable [ ... , str ] property Get the callback function of the tool. description : str property Get the description of the tool. is_agent_tool : bool property Get the agent tool of the tool. json_schema : dict property Get the json schema of the tool. name : str property Get the name of the tool. __init__ ( name , description , agent_tool , parameters_json_schema = {}, call_back = None ) Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Parameters: name ( str ) \u2013 the name of the tool description ( str ) \u2013 a description of what the tool does agent_tool ( bool ) \u2013 whether the tool is an agent tool parameters_json_schema ( dict , default: {} ) \u2013 the json schema for the parameters of the tool call_back ( Optional(Callable[...,str] , default: None ) \u2013 the callback function to execute the tool Source code in wiseagents/core.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , name : str , description : str , agent_tool : bool , parameters_json_schema : dict = {}, call_back : Optional [ Callable [ ... , str ]] = None ): ''' Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Args: name (str): the name of the tool description (str): a description of what the tool does agent_tool (bool): whether the tool is an agent tool parameters_json_schema (dict): the json schema for the parameters of the tool call_back Optional(Callable[...,str]): the callback function to execute the tool''' self . _name = name self . _description = description self . _parameters_json_schema = parameters_json_schema self . _agent_tool = agent_tool self . _call_back = call_back WiseAgentRegistry . register_tool ( self ) default_call_back ( ** kwargs ) The tool should be able to execute the function with the given parameters Source code in wiseagents/core.py 100 101 102 def default_call_back ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' return json . dumps ( kwargs ) exec ( ** kwargs ) The tool should be able to execute the function with the given parameters Source code in wiseagents/core.py 104 105 106 107 108 def exec ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' if self . call_back is None : return self . default_call_back ( ** kwargs ) return self . call_back ( ** kwargs ) from_yaml ( loader , node ) classmethod Load the tool from a YAML node. Parameters: loader ( Loader ) \u2013 the YAML loader node ( Node ) \u2013 the YAML node Source code in wiseagents/core.py 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_yaml ( cls , loader , node ): '''Load the tool from a YAML node. Args: loader (yaml.Loader): the YAML loader node (yaml.Node): the YAML node''' data = loader . construct_mapping ( node , deep = True ) return cls ( name = data . get ( '_name' ), description = data . get ( '_description' ), parameters_json_schema = data . get ( '_parameters_json_schema' ), call_back = data . get ( '_call_back' )) get_tool_OpenAI_format () The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam \u2013 ChatCompletionToolParam Source code in wiseagents/core.py 87 88 89 90 91 92 93 94 95 96 97 98 def get_tool_OpenAI_format ( self ) -> ChatCompletionToolParam : '''The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam''' return { \"type\" : \"function\" , \"function\" : { \"name\" : self . name , \"description\" : self . description , \"parameters\" : self . json_schema } } WiseAgentTransport Bases: YAMLObject Source code in wiseagents/wise_agent_messaging.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 class WiseAgentTransport ( YAMLObject ): yaml_loader = WiseAgentsLoader ''' A transport for sending messages between agents. ''' def set_call_backs ( self , request_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , event_receiver : Optional [ Callable [[], WiseAgentEvent ]] = None , error_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , response_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None ): '''Set the call back functions for the transport. Args: request_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving requests event_receiver Optional(Callable[[], WiseAgentEvent]): the call back function for receiving events error_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving errors response_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving responses ''' self . _request_receiver = request_receiver self . _event_receiver = event_receiver self . _error_receiver = error_receiver self . _response_receiver = response_receiver def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () del state [ '_request_receiver' ] del state [ '_response_receiver' ] del state [ '_event_receiver' ] del state [ '_error_receiver' ] return state @abstractmethod def start ( self ): \"\"\" Start the transport. \"\"\" pass @abstractmethod def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass @abstractmethod def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass @abstractmethod def stop ( self ): \"\"\" Stop the transport. \"\"\" pass @property def request_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the message receiver callback.\"\"\" return self . _request_receiver @property def event_receiver ( self ) -> Optional [ Callable [[], WiseAgentEvent ]]: \"\"\"Get the event receiver callback.\"\"\" return self . _event_receiver @property def error_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the error receiver callback.\"\"\" return self . _error_receiver @property def response_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the response receiver callback.\"\"\" return self . _response_receiver error_receiver : Optional [ Callable [[], WiseAgentMessage ]] property Get the error receiver callback. event_receiver : Optional [ Callable [[], WiseAgentEvent ]] property Get the event receiver callback. request_receiver : Optional [ Callable [[], WiseAgentMessage ]] property Get the message receiver callback. response_receiver : Optional [ Callable [[], WiseAgentMessage ]] property Get the response receiver callback. yaml_loader = WiseAgentsLoader class-attribute instance-attribute A transport for sending messages between agents. __getstate__ () Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/wise_agent_messaging.py 117 118 119 120 121 122 123 124 def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () del state [ '_request_receiver' ] del state [ '_response_receiver' ] del state [ '_event_receiver' ] del state [ '_error_receiver' ] return state send_request ( message , dest_agent_name ) Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send Source code in wiseagents/wise_agent_messaging.py 134 135 136 137 138 139 140 141 142 143 @abstractmethod def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass send_response ( message , dest_agent_name ) Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send Source code in wiseagents/wise_agent_messaging.py 145 146 147 148 149 150 151 152 153 154 @abstractmethod def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass set_call_backs ( request_receiver = None , event_receiver = None , error_receiver = None , response_receiver = None ) Set the call back functions for the transport. Parameters: request_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving requests event_receiver ( Optional(Callable[[], WiseAgentEvent] , default: None ) \u2013 the call back function for receiving events error_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving errors response_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving responses Source code in wiseagents/wise_agent_messaging.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def set_call_backs ( self , request_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , event_receiver : Optional [ Callable [[], WiseAgentEvent ]] = None , error_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , response_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None ): '''Set the call back functions for the transport. Args: request_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving requests event_receiver Optional(Callable[[], WiseAgentEvent]): the call back function for receiving events error_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving errors response_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving responses ''' self . _request_receiver = request_receiver self . _event_receiver = event_receiver self . _error_receiver = error_receiver self . _response_receiver = response_receiver start () Start the transport. Source code in wiseagents/wise_agent_messaging.py 127 128 129 130 131 132 @abstractmethod def start ( self ): \"\"\" Start the transport. \"\"\" pass stop () Stop the transport. Source code in wiseagents/wise_agent_messaging.py 156 157 158 159 160 161 @abstractmethod def stop ( self ): \"\"\" Stop the transport. \"\"\" pass","title":"wiseagents"},{"location":"reference/wiseagents/#wiseagents.WiseAgent","text":"Bases: YAMLObject A WiseAgent is an abstract class that represents an agent that can send and receive messages to and from other agents. Source code in wiseagents/core.py 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 class WiseAgent ( yaml . YAMLObject ): ''' A WiseAgent is an abstract class that represents an agent that can send and receive messages to and from other agents. ''' yaml_tag = u '!wiseagents.WiseAgent' yaml_loader = WiseAgentsLoader def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _llm = None obj . _vector_db = None obj . _graph_db = None obj . _collection_name = \"wise-agent-collection\" obj . _system_message = None return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : Optional [ WiseAgentLLM ] = None , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = \"wise-agent-collection\" , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): ''' Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Args: name (str): the name of the agent description (str): a description of what the agent does transport (WiseAgentTransport): the transport to use for sending and receiving messages llm (Optional[WiseAgentLLM]): the LLM associated with the agent vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent system_message Optional(str): an optional system message that can be used by the agent when processing chat completions using its LLM ''' self . _name = name self . _description = description self . _llm = llm self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db self . _transport = transport self . _system_message = system_message self . start_agent () def start_agent ( self ): ''' Start the agent by setting the call backs and starting the transport.''' self . transport . set_call_backs ( self . handle_request , self . process_event , self . process_error , self . process_response ) self . transport . start () WiseAgentRegistry . register_agent ( self . name , self . description ) def stop_agent ( self ): ''' Stop the agent by stopping the transport and removing the agent from the registry.''' self . transport . stop () WiseAgentRegistry . unregister_agent ( self . name ) def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . _collection_name } , graph_db= { self . graph_db } ,\" f \"system_message= { self . system_message } )\" ) def __eq__ ( self , value : object ) -> bool : return isinstance ( value , WiseAgent ) and self . __repr__ () == value . __repr__ () @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def description ( self ) -> str : \"\"\"Get a description of what the agent does.\"\"\" return self . _description @property def llm ( self ) -> Optional [ WiseAgentLLM ]: \"\"\"Get the LLM associated with the agent.\"\"\" return self . _llm @property def vector_db ( self ) -> Optional [ WiseAgentVectorDB ]: \"\"\"Get the vector DB associated with the agent.\"\"\" return self . _vector_db @property def collection_name ( self ) -> str : \"\"\"Get the vector DB collection name associated with the agent.\"\"\" return self . _collection_name @property def graph_db ( self ) -> Optional [ WiseAgentGraphDB ]: \"\"\"Get the graph DB associated with the agent.\"\"\" return self . _graph_db @property def transport ( self ) -> WiseAgentTransport : \"\"\"Get the transport associated with the agent.\"\"\" return self . _transport @property def system_message ( self ) -> Optional [ str ]: \"\"\"Get the system message associated with the agent.\"\"\" return self . _system_message def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_request ( message , dest_agent_name ) context . trace ( message ) def send_response ( self , message : WiseAgentMessage , dest_agent_name ): '''Send a response message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_response ( message , dest_agent_name ) context . trace ( message ) def handle_request ( self , request : WiseAgentMessage ) -> bool : \"\"\" Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Args: request (WiseAgentMessage): the request message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" context = WiseAgentRegistry . get_or_create_context ( request . context_name ) collaboration_type = context . get_collaboration_type ( request . chat_id ) conversation_history = self . get_conversation_history_if_needed ( context , request . chat_id , collaboration_type ) response_str = self . process_request ( request , conversation_history ) return self . handle_response ( response_str , request , context , collaboration_type ) def get_conversation_history_if_needed ( self , context : WiseAgentContext , chat_id : Optional [ str ], collaboration_type : str ) -> List [ ChatCompletionMessageParam ]: \"\"\" Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Args: context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent is involved in a collaboration type that makes use of the conversation history and an empty list otherwise \"\"\" if chat_id : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # this agent is involved in phased collaboration or a chat, so it needs the conversation history return context . llm_chat_completion . get ( chat_id ) # for sequential collaboration and independent agents, the shared history is not needed return [] @abstractmethod def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process the given request message to generate a response string. Args: request (WiseAgentMessage): the request message to be processed conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" ... def handle_response ( self , response_str : str , request : WiseAgentMessage , context : WiseAgentContext , collaboration_type : str ) -> bool : \"\"\" Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Args: response_str (str): the string response to be handled context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: True if the message was processed successfully, False otherwise \"\"\" if response_str : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # add this agent's response to the shared context context . append_chat_completion ( chat_uuid = request . chat_id , messages = { \"role\" : \"assistant\" , \"content\" : response_str }) # let the sender know that this agent has finished processing the request self . send_response ( WiseAgentMessage ( message = response_str , message_type = WiseAgentMessageType . ACK , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) elif collaboration_type == WiseAgentCollaborationType . SEQUENTIAL : next_agent = context . get_next_agent_in_sequence ( request . chat_id , self . name ) if next_agent is None : logging . debug ( f \"Sequential coordination complete - sending response from \" + self . name + \" to \" + context . get_route_response_to ( request . chat_id )) self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), context . get_route_response_to ( request . chat_id )) else : logging . debug ( f \"Sequential coordination continuing - sending response from \" + self . name + \" to \" + next_agent ) self . send_request ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), next_agent ) else : self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) return True @abstractmethod def process_response ( self , message : WiseAgentMessage ) -> bool : \"\"\" Callback method to process the response received from another agent which processed a request from this agent. Args: message (WiseAgentMessage): the message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" ... @abstractmethod def process_event ( self , event : WiseAgentEvent ) -> bool : \"\"\" Callback method to process the given event. Args: event (WiseAgentEvent): the event to be processed Returns: True if the event was processed successfully, False otherwise \"\"\" ... @abstractmethod def process_error ( self , error : Exception ) -> bool : \"\"\" Callback method to process the given error. Args: error (Exception): the error to be processed Returns: True if the error was processed successfully, False otherwise \"\"\" ...","title":"WiseAgent"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.collection_name","text":"Get the vector DB collection name associated with the agent.","title":"collection_name"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.description","text":"Get a description of what the agent does.","title":"description"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.graph_db","text":"Get the graph DB associated with the agent.","title":"graph_db"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.llm","text":"Get the LLM associated with the agent.","title":"llm"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.system_message","text":"Get the system message associated with the agent.","title":"system_message"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.transport","text":"Get the transport associated with the agent.","title":"transport"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.vector_db","text":"Get the vector DB associated with the agent.","title":"vector_db"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.__init__","text":"Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of what the agent does transport ( WiseAgentTransport ) \u2013 the transport to use for sending and receiving messages llm ( Optional [ WiseAgentLLM ] , default: None ) \u2013 the LLM associated with the agent vector_db ( Optional [ WiseAgentVectorDB ] , default: None ) \u2013 the vector DB associated with the agent collection_name ( Optional[str]) = \"wise-agent-collection\" , default: 'wise-agent-collection' ) \u2013 the vector DB collection name associated with the agent graph_db ( Optional [ WiseAgentGraphDB ] , default: None ) \u2013 the graph DB associated with the agent system_message ( Optional(str , default: None ) \u2013 an optional system message that can be used by the agent when processing chat Source code in wiseagents/core.py 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : Optional [ WiseAgentLLM ] = None , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = \"wise-agent-collection\" , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): ''' Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Args: name (str): the name of the agent description (str): a description of what the agent does transport (WiseAgentTransport): the transport to use for sending and receiving messages llm (Optional[WiseAgentLLM]): the LLM associated with the agent vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent system_message Optional(str): an optional system message that can be used by the agent when processing chat completions using its LLM ''' self . _name = name self . _description = description self . _llm = llm self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db self . _transport = transport self . _system_message = system_message self . start_agent ()","title":"__init__"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/core.py 834 835 836 837 838 839 840 841 842 def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _llm = None obj . _vector_db = None obj . _graph_db = None obj . _collection_name = \"wise-agent-collection\" obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/core.py 885 886 887 888 889 def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . _collection_name } , graph_db= { self . graph_db } ,\" f \"system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.get_conversation_history_if_needed","text":"Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Parameters: context ( WiseAgentContext ) \u2013 the shared context chat_id ( Optional [ str ] ) \u2013 the chat id, may be None collaboration_type ( str ) \u2013 the type of collaboration this agent is involved in Returns: List [ ChatCompletionMessageParam ] \u2013 List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent List [ ChatCompletionMessageParam ] \u2013 is involved in a collaboration type that makes use of the conversation history and an empty list List [ ChatCompletionMessageParam ] \u2013 otherwise Source code in wiseagents/core.py 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 def get_conversation_history_if_needed ( self , context : WiseAgentContext , chat_id : Optional [ str ], collaboration_type : str ) -> List [ ChatCompletionMessageParam ]: \"\"\" Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Args: context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent is involved in a collaboration type that makes use of the conversation history and an empty list otherwise \"\"\" if chat_id : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # this agent is involved in phased collaboration or a chat, so it needs the conversation history return context . llm_chat_completion . get ( chat_id ) # for sequential collaboration and independent agents, the shared history is not needed return []","title":"get_conversation_history_if_needed"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.handle_request","text":"Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Parameters: request ( WiseAgentMessage ) \u2013 the request message to be processed Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 def handle_request ( self , request : WiseAgentMessage ) -> bool : \"\"\" Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Args: request (WiseAgentMessage): the request message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" context = WiseAgentRegistry . get_or_create_context ( request . context_name ) collaboration_type = context . get_collaboration_type ( request . chat_id ) conversation_history = self . get_conversation_history_if_needed ( context , request . chat_id , collaboration_type ) response_str = self . process_request ( request , conversation_history ) return self . handle_response ( response_str , request , context , collaboration_type )","title":"handle_request"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.handle_response","text":"Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Parameters: response_str ( str ) \u2013 the string response to be handled context ( WiseAgentContext ) \u2013 the shared context chat_id ( Optional [ str ] ) \u2013 the chat id, may be None collaboration_type ( str ) \u2013 the type of collaboration this agent is involved in Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 def handle_response ( self , response_str : str , request : WiseAgentMessage , context : WiseAgentContext , collaboration_type : str ) -> bool : \"\"\" Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Args: response_str (str): the string response to be handled context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: True if the message was processed successfully, False otherwise \"\"\" if response_str : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # add this agent's response to the shared context context . append_chat_completion ( chat_uuid = request . chat_id , messages = { \"role\" : \"assistant\" , \"content\" : response_str }) # let the sender know that this agent has finished processing the request self . send_response ( WiseAgentMessage ( message = response_str , message_type = WiseAgentMessageType . ACK , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) elif collaboration_type == WiseAgentCollaborationType . SEQUENTIAL : next_agent = context . get_next_agent_in_sequence ( request . chat_id , self . name ) if next_agent is None : logging . debug ( f \"Sequential coordination complete - sending response from \" + self . name + \" to \" + context . get_route_response_to ( request . chat_id )) self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), context . get_route_response_to ( request . chat_id )) else : logging . debug ( f \"Sequential coordination continuing - sending response from \" + self . name + \" to \" + next_agent ) self . send_request ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), next_agent ) else : self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) return True","title":"handle_response"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.process_error","text":"Callback method to process the given error. Parameters: error ( Exception ) \u2013 the error to be processed Returns: bool \u2013 True if the error was processed successfully, False otherwise Source code in wiseagents/core.py 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 @abstractmethod def process_error ( self , error : Exception ) -> bool : \"\"\" Callback method to process the given error. Args: error (Exception): the error to be processed Returns: True if the error was processed successfully, False otherwise \"\"\" ...","title":"process_error"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.process_event","text":"Callback method to process the given event. Parameters: event ( WiseAgentEvent ) \u2013 the event to be processed Returns: bool \u2013 True if the event was processed successfully, False otherwise Source code in wiseagents/core.py 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 @abstractmethod def process_event ( self , event : WiseAgentEvent ) -> bool : \"\"\" Callback method to process the given event. Args: event (WiseAgentEvent): the event to be processed Returns: True if the event was processed successfully, False otherwise \"\"\" ...","title":"process_event"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.process_request","text":"Process the given request message to generate a response string. Parameters: request ( WiseAgentMessage ) \u2013 the request message to be processed conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/core.py 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 @abstractmethod def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process the given request message to generate a response string. Args: request (WiseAgentMessage): the request message to be processed conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" ...","title":"process_request"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.process_response","text":"Callback method to process the response received from another agent which processed a request from this agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to be processed Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 @abstractmethod def process_response ( self , message : WiseAgentMessage ) -> bool : \"\"\" Callback method to process the response received from another agent which processed a request from this agent. Args: message (WiseAgentMessage): the message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" ...","title":"process_response"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.send_request","text":"Send a request message to the destination agent with the given name. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the name of the destination agent Source code in wiseagents/core.py 934 935 936 937 938 939 940 941 942 943 944 def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_request ( message , dest_agent_name ) context . trace ( message )","title":"send_request"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.send_response","text":"Send a response message to the destination agent with the given name. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the name of the destination agent Source code in wiseagents/core.py 946 947 948 949 950 951 952 953 954 955 956 def send_response ( self , message : WiseAgentMessage , dest_agent_name ): '''Send a response message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_response ( message , dest_agent_name ) context . trace ( message )","title":"send_response"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.start_agent","text":"Start the agent by setting the call backs and starting the transport. Source code in wiseagents/core.py 873 874 875 876 877 878 def start_agent ( self ): ''' Start the agent by setting the call backs and starting the transport.''' self . transport . set_call_backs ( self . handle_request , self . process_event , self . process_error , self . process_response ) self . transport . start () WiseAgentRegistry . register_agent ( self . name , self . description )","title":"start_agent"},{"location":"reference/wiseagents/#wiseagents.WiseAgent.stop_agent","text":"Stop the agent by stopping the transport and removing the agent from the registry. Source code in wiseagents/core.py 880 881 882 883 def stop_agent ( self ): ''' Stop the agent by stopping the transport and removing the agent from the registry.''' self . transport . stop () WiseAgentRegistry . unregister_agent ( self . name )","title":"stop_agent"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext","text":"A WiseAgentContext is a class that represents a context in which agents can communicate with each other. Source code in wiseagents/core.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 class WiseAgentContext (): ''' A WiseAgentContext is a class that represents a context in which agents can communicate with each other. ''' _message_trace : List [ str ] = [] _participants : List [ str ] = [] # Maps a chat uuid to a list of chat completion messages _llm_chat_completion : Dict [ str , List [ ChatCompletionMessageParam ]] = {} # Maps a chat uuid to a list of tool names that need to be executed _llm_required_tool_call : Dict [ str , List [ str ]] = {} # Maps a chat uuid to a list of available tools in chat _llm_available_tools_in_chat : Dict [ str , List [ ChatCompletionToolParam ]] = {} # Maps a chat uuid to a list of agent names that need to be executed in sequence # Used by a sequential coordinator _agents_sequence : Dict [ str , List [ str ]] = {} # Maps a chat uuid to the agent where the final response should be routed to # Used by both a sequential coordinator and a phased coordinator _route_response_to : Dict [ str , str ] = {} # Maps a chat uuid to a list that contains a list of agent names to be executed for each phase # Used by a phased coordinator _agent_phase_assignments : Dict [ str , List [ List [ str ]]] = {} # Maps a chat uuid to the current phase. Used by a phased coordinator. _current_phase : Dict [ str , int ] = {} # Maps a chat uuid to a list of agent names that need to be executed for the current phase # Used by a phased coordinator _required_agents_for_current_phase : Dict [ str , List [ str ]] = {} # Maps a chat uuid to a list containing the queries attempted for each iteration executed by # the phased coordinator _queries : Dict [ str , List [ str ]] = {} # Maps a chat uuid to the collaboration type _collaboration_type : Dict [ str , WiseAgentCollaborationType ] = {} _redis_db : redis . Redis = None _use_redis : bool = False _config : Dict [ str , Any ] = {} def __init__ ( self , name : str , config : Optional [ Dict [ str , Any ]] = { \"use_redis\" : False }): ''' Initialize the context with the given name. Args: name (str): the name of the context''' self . _name = name self . _config = config if config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True WiseAgentRegistry . register_context ( self ) def __repr__ ( self ) -> str : '''Return a string representation of the context.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , message_trace= { self . message_trace } ,\" f \"participants= { self . participants } , llm_chat_completion= { self . llm_chat_completion } ,\" f \"llm_required_tool_call= { self . llm_required_tool_call } , llm_available_tools_in_chat= { self . llm_available_tools_in_chat } ,\" f \"agents_sequence= { self . _agents_sequence } , route_response_to= { self . _route_response_to } ,\" f \"agent_phase_assignments= { self . _agent_phase_assignments } , current_phase= { self . _current_phase } ,\" f \"required_agents_for_current_phase= { self . _required_agents_for_current_phase } , queries= { self . _queries } )\" ) def __eq__ ( self , value : object ) -> bool : return isinstance ( value , WiseAgentContext ) and self . __repr__ () == value . __repr__ () def __getstate__ ( self ) -> object : '''Get the state of the context.''' state = self . __dict__ . copy () if '_redis_db' in state : del state [ '_redis_db' ] del state [ '_use_redis' ] return state def __setstate__ ( self , state : object ): '''Set the state of the context.''' self . __dict__ . update ( state ) if self . _config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True @property def name ( self ) -> str : \"\"\"Get the name of the context.\"\"\" return self . _name @property def message_trace ( self ) -> List [ str ]: \"\"\"Get the message trace of the context.\"\"\" if ( self . _use_redis == True ): return self . _redis_db . lrange ( \"message_trace\" , 0 , - 1 ) else : return self . _message_trace def trace ( self , message : WiseAgentMessage ): '''Trace the message.''' if ( self . _use_redis == True ): self . _redis_db . rpush ( \"message_trace\" , message . __repr__ ()) else : self . _message_trace . append ( message ) @property def participants ( self ) -> List [ str ]: \"\"\"Get the participants of the context.\"\"\" if ( self . _use_redis == True ): return self . _redis_db . lrange ( \"participants\" , 0 , - 1 ) else : return self . _participants @property def llm_chat_completion ( self ) -> Dict [ str , List [ ChatCompletionMessageParam ]]: \"\"\"Get the LLM chat completion of the context.\"\"\" if ( self . _use_redis == True ): return_dict : Dict [ str , List [ ChatCompletionMessageParam ]] = {} redis_dict = self . _redis_db . hgetall ( \"llm_chat_completion\" ) for key in redis_dict : return_dict [ key . decode ( 'utf-8' )] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _llm_chat_completion def add_participant ( self , agent_name : str ): '''Add a participant to the context. Args: agent (WiseAgent): the agent to add''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"participants\" ) try : if ( pipe . exists ( \"participants\" ) == False ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : if agent_name not in pipe . lrange ( \"participants\" , 0 , - 1 ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : pipe . unwatch () return except redis . WatchError : logging . debug ( \"WatchError in add_participant\" ) continue else : if agent_name not in self . participants : self . _participants . append ( agent_name ) def append_chat_completion ( self , chat_uuid : str , messages : Iterable [ ChatCompletionMessageParam ]): '''Append chat completion to the context. Args: chat_uuid (str): the chat uuid messages (Iterable[ChatCompletionMessageParam]): the messages to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"llm_chat_completion\" ) try : if ( pipe . hexists ( \"llm_chat_completion\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ([ messages ])) pipe . execute () return else : redis_stored_messages = pipe . hget ( \"llm_chat_completion\" , key = chat_uuid ) stored_messages : List [ ChatCompletionMessageParam ] = pickle . loads ( redis_stored_messages ) stored_messages . append ( messages ) pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ( stored_messages )) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in append_chat_completion\" ) continue else : if chat_uuid not in self . _llm_chat_completion : self . _llm_chat_completion [ chat_uuid ] = [] self . _llm_chat_completion [ chat_uuid ] . append ( messages ) @property def llm_required_tool_call ( self ) -> Dict [ str , List [ str ]]: \"\"\"Get the LLM required tool call of the context. return Dict[str, List[str]]\"\"\" if ( self . _use_redis == True ): redis_dict = self . _redis_db . hgetall ( \"llm_required_tool_call\" ) return_dict : Dict [ str , List [ str ]] = {} for key in redis_dict : return_dict [ key ] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _llm_required_tool_call def append_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Append required tool call to the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) if ( self . _redis_db . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): self . _redis_db . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ([ tool_name ])) pipe . execute () else : while True : try : pipe . watch ( \"llm_required_tool_call\" ) redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . append ( tool_name ) pipe . multi () pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_required_tool_call\" ) continue else : if chat_uuid not in self . llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] = [] self . _llm_required_tool_call [ chat_uuid ] . append ( tool_name ) def remove_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Remove required tool call from the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to remove''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_required_tool_call\" ) if ( pipe . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( redis_stored_tool_names == None ): stored_tool_names : List [ str ] = [] else : stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . remove ( tool_name ) pipe . multi () if len ( stored_tool_names ) == 0 : pipe . hdel ( \"llm_required_tool_call\" , chat_uuid ) else : pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in remove_required_tool_call\" ) continue if chat_uuid in self . _llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] . remove ( tool_name ) if len ( self . _llm_required_tool_call [ chat_uuid ]) == 0 : self . _llm_required_tool_call . pop ( chat_uuid ) def get_required_tool_calls ( self , chat_uuid : str ) -> List [ str ]: '''Get required tool calls from the context. Args: chat_uuid (str): the chat uuid return List[str]''' if ( self . _use_redis == True ): llm_req_tools = self . _redis_db . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( llm_req_tools is not None ): return pickle . loads ( llm_req_tools ) else : return [] if chat_uuid in self . _llm_required_tool_call : return self . _llm_required_tool_call [ chat_uuid ] else : return [] @property def llm_available_tools_in_chat ( self ) -> Dict [ str , List [ ChatCompletionToolParam ]]: \"\"\"Get the LLM available tools in chat of the context.\"\"\" if ( self . _use_redis == True ): redis_dict = self . _redis_db . hgetall ( \"llm_available_tools_in_chat\" ) return_dict : Dict [ str , List [ ChatCompletionToolParam ]] = {} for key in redis_dict : return_dict [ key ] = pickle . loads ( redis_dict [ key ]) return return_dict return self . _llm_available_tools_in_chat def append_available_tool_in_chat ( self , chat_uuid : str , tools : Iterable [ ChatCompletionToolParam ]): '''Append available tool in chat to the context. Args: chat_uuid (str): the chat uuid tools (Iterable[ChatCompletionToolParam]): the tools to append''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_available_tools_in_chat\" ) if ( pipe . hexists ( \"llm_available_tools_in_chat\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ([ tools ])) pipe . execute () break else : redis_stored_tools = pipe . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) stored_tools : List [ ChatCompletionToolParam ] = pickle . loads ( redis_stored_tools ) stored_tools . append ( tools ) pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ( stored_tools )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_available_tool_in_chat\" ) continue else : if chat_uuid not in self . _llm_available_tools_in_chat : self . _llm_available_tools_in_chat [ chat_uuid ] = [] self . _llm_available_tools_in_chat [ chat_uuid ] . append ( tools ) def get_available_tools_in_chat ( self , chat_uuid : str ) -> List [ ChatCompletionToolParam ]: '''Get available tools in chat from the context. Args: chat_uuid (str): the chat uuid return List[ChatCompletionToolParam]''' if ( self . _use_redis == True ): llm_av_tools = self . _redis_db . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) if ( llm_av_tools is not None ): return pickle . loads ( llm_av_tools ) else : return [] else : if chat_uuid in self . _llm_available_tools_in_chat : return self . _llm_available_tools_in_chat [ chat_uuid ] else : return [] def get_agents_sequence ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid Returns: List[str]: the sequence of agents names or an empty list if no sequence has been set for this context \"\"\" if ( self . _use_redis == True ): agent_sequence = self . _redis_db . hget ( \"agents_sequence\" , key = chat_uuid ) if ( agent_sequence is not None ): return pickle . loads ( agent_sequence ) else : return [] else : if chat_uuid in self . _agents_sequence : return self . _agents_sequence [ chat_uuid ] return [] def set_agents_sequence ( self , chat_uuid : str , agents_sequence : List [ str ]): \"\"\" Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid agents_sequence (List[str]): the sequence of agent names \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agents_sequence\" , key = chat_uuid , value = pickle . dumps ( agents_sequence )) else : self . _agents_sequence [ chat_uuid ] = agents_sequence def get_route_response_to ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set \"\"\" if ( self . _use_redis == True ): route = self . _redis_db . hget ( \"route_response_to\" , key = chat_uuid ) if ( route is not None ): return pickle . loads ( route ) else : return None else : if chat_uuid in self . _route_response_to : return self . _route_response_to [ chat_uuid ] else : return None def set_route_response_to ( self , chat_uuid : str , agent : str ): \"\"\" Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Args: chat_uuid (str): the chat uuid agent (str): the name of the agent where the final response should be routed to \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"route_response_to\" , key = chat_uuid , value = pickle . dumps ( agent )) else : self . _route_response_to [ chat_uuid ] = agent def get_next_agent_in_sequence ( self , chat_uuid : str , current_agent : str ): \"\"\" Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Args: chat_uuid (str): the chat uuid current_agent (str): the name of the current agent Returns: str: the name of the next agent in the sequence after the current agent or None if there are no remaining agents in the sequence after the current agent \"\"\" agents_sequence = self . get_agents_sequence ( chat_uuid ) if current_agent in agents_sequence : current_agent_index = agents_sequence . index ( current_agent ) next_agent_index = current_agent_index + 1 if next_agent_index < len ( agents_sequence ): return agents_sequence [ next_agent_index ] return None def get_agent_phase_assignments ( self , chat_uuid : str ) -> List [ List [ str ]]: \"\"\" Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. An empty list is returned if no phases have been set for the given chat uuid \"\"\" if ( self . _use_redis == True ): agent_phase = self . _redis_db . hget ( \"agent_phase_assignments\" , key = chat_uuid ) if ( agent_phase is not None ): return pickle . loads ( agent_phase ) else : return [] else : if chat_uuid in self . _agent_phase_assignments : return self . _agent_phase_assignments . get ( chat_uuid ) return [] def set_agent_phase_assignments ( self , chat_uuid : str , agent_phase_assignments : List [ List [ str ]]): \"\"\" Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_phase_assignments (List[List[str]]): The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agent_phase_assignments\" , key = chat_uuid , value = pickle . dumps ( agent_phase_assignments )) else : self . _agent_phase_assignments [ chat_uuid ] = agent_phase_assignments def get_current_phase ( self , chat_uuid : str ) -> int : \"\"\" Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: int: the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): cur_phase = self . _redis_db . hget ( \"current_phase\" , key = chat_uuid ) if ( cur_phase is not None ): return pickle . loads ( cur_phase ) else : return None else : return self . _current_phase . get ( chat_uuid ) def set_current_phase ( self , chat_uuid : str , phase : int ): \"\"\" Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid phase (int): the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): self . _redis_db . pipeline ( transaction = True ) \\ . hset ( \"current_phase\" , key = chat_uuid , value = pickle . dumps ( phase )) \\ . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( self . get_agent_phase_assignments ( chat_uuid )[ phase ])) \\ . execute () else : self . _current_phase [ chat_uuid ] = phase self . _required_agents_for_current_phase [ chat_uuid ] = copy . deepcopy ( self . _agent_phase_assignments [ chat_uuid ][ phase ]) def get_agents_for_next_phase ( self , chat_uuid : str ) -> Optional [ List ]: \"\"\" Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases \"\"\" current_phase = self . get_current_phase ( chat_uuid ) next_phase = current_phase + 1 if next_phase < len ( self . get_agent_phase_assignments ( chat_uuid )): self . set_current_phase ( chat_uuid , next_phase ) return self . get_agent_phase_assignments ( chat_uuid )[ next_phase ] return None def get_required_agents_for_current_phase ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[str]: the list of agent names that still need to be executed for the current phase or an empty list if there are no remaining agents that need to be executed for the current phase \"\"\" if ( self . _use_redis == True ): req_agent = self . _redis_db . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) if ( req_agent is not None ): return pickle . loads ( req_agent ) else : return [] else : if chat_uuid in self . _required_agents_for_current_phase : return self . _required_agents_for_current_phase . get ( chat_uuid ) return [] def remove_required_agent_for_current_phase ( self , chat_uuid : str , agent_name : str ): \"\"\" Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_name (str): the name of the agent to remove \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"required_agents_for_current_phase\" ) if ( pipe . hexists ( \"required_agents_for_current_phase\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_agents = pipe . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) stored_agents : List [ str ] = pickle . loads ( redis_stored_agents ) stored_agents . remove ( agent_name ) pipe . multi () if len ( stored_agents ) == 0 : pipe . hdel ( \"required_agents_for_current_phase\" , chat_uuid ) else : pipe . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( stored_agents )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to remove agent\" ) continue else : if chat_uuid in self . _required_agents_for_current_phase : self . _required_agents_for_current_phase . get ( chat_uuid ) . remove ( agent_name ) def get_current_query ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[str]: the current query or None if there is no current query \"\"\" if ( self . _use_redis == True ): queries = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( queries is not None ): return_list : List [ str ] = pickle . loads ( queries ) return return_list [ - 1 ] else : return None else : if chat_uuid in self . _queries : if self . _queries . get ( chat_uuid ): # return the last query return self . _queries . get ( chat_uuid )[ - 1 ] else : return None def add_query ( self , chat_uuid : str , query : str ): \"\"\" Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid query (str): the current query \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"queries\" ) if ( pipe . hexists ( \"queries\" , key = chat_uuid ) == False ): pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ([ query ])) else : redis_stored_queries = pipe . hget ( \"queries\" , key = chat_uuid ) stored_queries : List [ str ] = pickle . loads ( redis_stored_queries ) stored_queries . append ( query ) pipe . multi () pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ( stored_queries )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to add query\" ) continue else : if chat_uuid not in self . _queries : self . _queries [ chat_uuid ] = [] self . _queries [ chat_uuid ] . append ( query ) def get_queries ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List[str]: the queries attempted for the given chat uuid for this context \"\"\" if ( self . _use_redis == True ): query = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( query is not None ): return pickle . loads ( query ) else : return [] if chat_uuid in self . _queries : return self . _queries . get ( chat_uuid ) else : return [] @property def collaboration_type ( self ) -> Dict [ str , WiseAgentCollaborationType ]: \"\"\"Get the collaboration type for chat uuids for this context.\"\"\" if ( self . _use_redis == True ): return_dict : Dict [ str , WiseAgentCollaborationType ] = {} redis_dict = self . _redis_db . hgetall ( \"collaboration_type\" ) for key in redis_dict : return_dict [ key . decode ( 'utf-8' )] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _collaboration_type def get_collaboration_type ( self , chat_uuid : str ) -> WiseAgentCollaborationType : \"\"\" Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type \"\"\" if ( self . _use_redis == True ): if chat_uuid is not None : collaboration_type = self . _redis_db . hget ( \"collaboration_type\" , key = chat_uuid ) if ( collaboration_type is not None ): return pickle . loads ( collaboration_type ) else : return WiseAgentCollaborationType . INDEPENDENT else : if chat_uuid in self . _collaboration_type : return self . _collaboration_type . get ( chat_uuid ) else : return WiseAgentCollaborationType . INDEPENDENT def set_collaboration_type ( self , chat_uuid : str , collaboration_type : WiseAgentCollaborationType ): \"\"\" Set the collaboration type for the given chat uuid for this context. Args: chat_uuid (str): the chat uuid collaboration_type (WiseAgentCollaborationType): the collaboration type \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"collaboration_type\" , key = chat_uuid , value = pickle . dumps ( collaboration_type )) else : self . _collaboration_type [ chat_uuid ] = collaboration_type","title":"WiseAgentContext"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.collaboration_type","text":"Get the collaboration type for chat uuids for this context.","title":"collaboration_type"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.llm_available_tools_in_chat","text":"Get the LLM available tools in chat of the context.","title":"llm_available_tools_in_chat"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.llm_chat_completion","text":"Get the LLM chat completion of the context.","title":"llm_chat_completion"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.llm_required_tool_call","text":"Get the LLM required tool call of the context. return Dict[str, List[str]]","title":"llm_required_tool_call"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.message_trace","text":"Get the message trace of the context.","title":"message_trace"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.name","text":"Get the name of the context.","title":"name"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.participants","text":"Get the participants of the context.","title":"participants"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.__getstate__","text":"Get the state of the context. Source code in wiseagents/core.py 183 184 185 186 187 188 189 def __getstate__ ( self ) -> object : '''Get the state of the context.''' state = self . __dict__ . copy () if '_redis_db' in state : del state [ '_redis_db' ] del state [ '_use_redis' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.__init__","text":"Initialize the context with the given name. Parameters: name ( str ) \u2013 the name of the context Source code in wiseagents/core.py 159 160 161 162 163 164 165 166 167 168 169 170 def __init__ ( self , name : str , config : Optional [ Dict [ str , Any ]] = { \"use_redis\" : False }): ''' Initialize the context with the given name. Args: name (str): the name of the context''' self . _name = name self . _config = config if config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True WiseAgentRegistry . register_context ( self )","title":"__init__"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.__repr__","text":"Return a string representation of the context. Source code in wiseagents/core.py 172 173 174 175 176 177 178 179 def __repr__ ( self ) -> str : '''Return a string representation of the context.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , message_trace= { self . message_trace } ,\" f \"participants= { self . participants } , llm_chat_completion= { self . llm_chat_completion } ,\" f \"llm_required_tool_call= { self . llm_required_tool_call } , llm_available_tools_in_chat= { self . llm_available_tools_in_chat } ,\" f \"agents_sequence= { self . _agents_sequence } , route_response_to= { self . _route_response_to } ,\" f \"agent_phase_assignments= { self . _agent_phase_assignments } , current_phase= { self . _current_phase } ,\" f \"required_agents_for_current_phase= { self . _required_agents_for_current_phase } , queries= { self . _queries } )\" )","title":"__repr__"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.__setstate__","text":"Set the state of the context. Source code in wiseagents/core.py 191 192 193 194 195 196 def __setstate__ ( self , state : object ): '''Set the state of the context.''' self . __dict__ . update ( state ) if self . _config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True","title":"__setstate__"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.add_participant","text":"Add a participant to the context. Parameters: agent ( WiseAgent ) \u2013 the agent to add Source code in wiseagents/core.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 def add_participant ( self , agent_name : str ): '''Add a participant to the context. Args: agent (WiseAgent): the agent to add''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"participants\" ) try : if ( pipe . exists ( \"participants\" ) == False ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : if agent_name not in pipe . lrange ( \"participants\" , 0 , - 1 ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : pipe . unwatch () return except redis . WatchError : logging . debug ( \"WatchError in add_participant\" ) continue else : if agent_name not in self . participants : self . _participants . append ( agent_name )","title":"add_participant"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.add_query","text":"Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid query ( str ) \u2013 the current query Source code in wiseagents/core.py 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 def add_query ( self , chat_uuid : str , query : str ): \"\"\" Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid query (str): the current query \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"queries\" ) if ( pipe . hexists ( \"queries\" , key = chat_uuid ) == False ): pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ([ query ])) else : redis_stored_queries = pipe . hget ( \"queries\" , key = chat_uuid ) stored_queries : List [ str ] = pickle . loads ( redis_stored_queries ) stored_queries . append ( query ) pipe . multi () pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ( stored_queries )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to add query\" ) continue else : if chat_uuid not in self . _queries : self . _queries [ chat_uuid ] = [] self . _queries [ chat_uuid ] . append ( query )","title":"add_query"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.append_available_tool_in_chat","text":"Append available tool in chat to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to append Source code in wiseagents/core.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 def append_available_tool_in_chat ( self , chat_uuid : str , tools : Iterable [ ChatCompletionToolParam ]): '''Append available tool in chat to the context. Args: chat_uuid (str): the chat uuid tools (Iterable[ChatCompletionToolParam]): the tools to append''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_available_tools_in_chat\" ) if ( pipe . hexists ( \"llm_available_tools_in_chat\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ([ tools ])) pipe . execute () break else : redis_stored_tools = pipe . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) stored_tools : List [ ChatCompletionToolParam ] = pickle . loads ( redis_stored_tools ) stored_tools . append ( tools ) pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ( stored_tools )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_available_tool_in_chat\" ) continue else : if chat_uuid not in self . _llm_available_tools_in_chat : self . _llm_available_tools_in_chat [ chat_uuid ] = [] self . _llm_available_tools_in_chat [ chat_uuid ] . append ( tools )","title":"append_available_tool_in_chat"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.append_chat_completion","text":"Append chat completion to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to append Source code in wiseagents/core.py 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 def append_chat_completion ( self , chat_uuid : str , messages : Iterable [ ChatCompletionMessageParam ]): '''Append chat completion to the context. Args: chat_uuid (str): the chat uuid messages (Iterable[ChatCompletionMessageParam]): the messages to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"llm_chat_completion\" ) try : if ( pipe . hexists ( \"llm_chat_completion\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ([ messages ])) pipe . execute () return else : redis_stored_messages = pipe . hget ( \"llm_chat_completion\" , key = chat_uuid ) stored_messages : List [ ChatCompletionMessageParam ] = pickle . loads ( redis_stored_messages ) stored_messages . append ( messages ) pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ( stored_messages )) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in append_chat_completion\" ) continue else : if chat_uuid not in self . _llm_chat_completion : self . _llm_chat_completion [ chat_uuid ] = [] self . _llm_chat_completion [ chat_uuid ] . append ( messages )","title":"append_chat_completion"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.append_required_tool_call","text":"Append required tool call to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tool_name ( str ) \u2013 the tool name to append Source code in wiseagents/core.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 def append_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Append required tool call to the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) if ( self . _redis_db . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): self . _redis_db . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ([ tool_name ])) pipe . execute () else : while True : try : pipe . watch ( \"llm_required_tool_call\" ) redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . append ( tool_name ) pipe . multi () pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_required_tool_call\" ) continue else : if chat_uuid not in self . llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] = [] self . _llm_required_tool_call [ chat_uuid ] . append ( tool_name )","title":"append_required_tool_call"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_agent_phase_assignments","text":"Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ List [ str ]] \u2013 List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the List [ List [ str ]] \u2013 size of the outer list corresponds to the number of phases and each element in the list is a list of List [ List [ str ]] \u2013 agent names for that phase. An empty list is returned if no phases have been set for the List [ List [ str ]] \u2013 given chat uuid Source code in wiseagents/core.py 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 def get_agent_phase_assignments ( self , chat_uuid : str ) -> List [ List [ str ]]: \"\"\" Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. An empty list is returned if no phases have been set for the given chat uuid \"\"\" if ( self . _use_redis == True ): agent_phase = self . _redis_db . hget ( \"agent_phase_assignments\" , key = chat_uuid ) if ( agent_phase is not None ): return pickle . loads ( agent_phase ) else : return [] else : if chat_uuid in self . _agent_phase_assignments : return self . _agent_phase_assignments . get ( chat_uuid ) return []","title":"get_agent_phase_assignments"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_agents_for_next_phase","text":"Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: Optional [ List ] \u2013 Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases Source code in wiseagents/core.py 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 def get_agents_for_next_phase ( self , chat_uuid : str ) -> Optional [ List ]: \"\"\" Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases \"\"\" current_phase = self . get_current_phase ( chat_uuid ) next_phase = current_phase + 1 if next_phase < len ( self . get_agent_phase_assignments ( chat_uuid )): self . set_current_phase ( chat_uuid , next_phase ) return self . get_agent_phase_assignments ( chat_uuid )[ next_phase ] return None","title":"get_agents_for_next_phase"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_agents_sequence","text":"Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ str ] \u2013 List[str]: the sequence of agents names or an empty list if no sequence has been set for this context Source code in wiseagents/core.py 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 def get_agents_sequence ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid Returns: List[str]: the sequence of agents names or an empty list if no sequence has been set for this context \"\"\" if ( self . _use_redis == True ): agent_sequence = self . _redis_db . hget ( \"agents_sequence\" , key = chat_uuid ) if ( agent_sequence is not None ): return pickle . loads ( agent_sequence ) else : return [] else : if chat_uuid in self . _agents_sequence : return self . _agents_sequence [ chat_uuid ] return []","title":"get_agents_sequence"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_available_tools_in_chat","text":"Get available tools in chat from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid Source code in wiseagents/core.py 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 def get_available_tools_in_chat ( self , chat_uuid : str ) -> List [ ChatCompletionToolParam ]: '''Get available tools in chat from the context. Args: chat_uuid (str): the chat uuid return List[ChatCompletionToolParam]''' if ( self . _use_redis == True ): llm_av_tools = self . _redis_db . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) if ( llm_av_tools is not None ): return pickle . loads ( llm_av_tools ) else : return [] else : if chat_uuid in self . _llm_available_tools_in_chat : return self . _llm_available_tools_in_chat [ chat_uuid ] else : return []","title":"get_available_tools_in_chat"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_collaboration_type","text":"Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type Source code in wiseagents/core.py 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 def get_collaboration_type ( self , chat_uuid : str ) -> WiseAgentCollaborationType : \"\"\" Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type \"\"\" if ( self . _use_redis == True ): if chat_uuid is not None : collaboration_type = self . _redis_db . hget ( \"collaboration_type\" , key = chat_uuid ) if ( collaboration_type is not None ): return pickle . loads ( collaboration_type ) else : return WiseAgentCollaborationType . INDEPENDENT else : if chat_uuid in self . _collaboration_type : return self . _collaboration_type . get ( chat_uuid ) else : return WiseAgentCollaborationType . INDEPENDENT","title":"get_collaboration_type"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_current_phase","text":"Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: int ( int ) \u2013 the current phase, represented as an integer in the zero-indexed list of phases Source code in wiseagents/core.py 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 def get_current_phase ( self , chat_uuid : str ) -> int : \"\"\" Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: int: the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): cur_phase = self . _redis_db . hget ( \"current_phase\" , key = chat_uuid ) if ( cur_phase is not None ): return pickle . loads ( cur_phase ) else : return None else : return self . _current_phase . get ( chat_uuid )","title":"get_current_phase"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_current_query","text":"Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: Optional [ str ] \u2013 Optional[str]: the current query or None if there is no current query Source code in wiseagents/core.py 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 def get_current_query ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[str]: the current query or None if there is no current query \"\"\" if ( self . _use_redis == True ): queries = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( queries is not None ): return_list : List [ str ] = pickle . loads ( queries ) return return_list [ - 1 ] else : return None else : if chat_uuid in self . _queries : if self . _queries . get ( chat_uuid ): # return the last query return self . _queries . get ( chat_uuid )[ - 1 ] else : return None","title":"get_current_query"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_next_agent_in_sequence","text":"Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Parameters: chat_uuid ( str ) \u2013 the chat uuid current_agent ( str ) \u2013 the name of the current agent Returns: str \u2013 the name of the next agent in the sequence after the current agent or None if there are no remaining \u2013 agents in the sequence after the current agent Source code in wiseagents/core.py 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 def get_next_agent_in_sequence ( self , chat_uuid : str , current_agent : str ): \"\"\" Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Args: chat_uuid (str): the chat uuid current_agent (str): the name of the current agent Returns: str: the name of the next agent in the sequence after the current agent or None if there are no remaining agents in the sequence after the current agent \"\"\" agents_sequence = self . get_agents_sequence ( chat_uuid ) if current_agent in agents_sequence : current_agent_index = agents_sequence . index ( current_agent ) next_agent_index = current_agent_index + 1 if next_agent_index < len ( agents_sequence ): return agents_sequence [ next_agent_index ] return None","title":"get_next_agent_in_sequence"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_queries","text":"Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List [ str ] \u2013 List[str]: the queries attempted for the given chat uuid for this context Source code in wiseagents/core.py 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 def get_queries ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List[str]: the queries attempted for the given chat uuid for this context \"\"\" if ( self . _use_redis == True ): query = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( query is not None ): return pickle . loads ( query ) else : return [] if chat_uuid in self . _queries : return self . _queries . get ( chat_uuid ) else : return []","title":"get_queries"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_required_agents_for_current_phase","text":"Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ str ] \u2013 List[str]: the list of agent names that still need to be executed for the current phase or an empty list List [ str ] \u2013 if there are no remaining agents that need to be executed for the current phase Source code in wiseagents/core.py 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 def get_required_agents_for_current_phase ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[str]: the list of agent names that still need to be executed for the current phase or an empty list if there are no remaining agents that need to be executed for the current phase \"\"\" if ( self . _use_redis == True ): req_agent = self . _redis_db . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) if ( req_agent is not None ): return pickle . loads ( req_agent ) else : return [] else : if chat_uuid in self . _required_agents_for_current_phase : return self . _required_agents_for_current_phase . get ( chat_uuid ) return []","title":"get_required_agents_for_current_phase"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_required_tool_calls","text":"Get required tool calls from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid Source code in wiseagents/core.py 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def get_required_tool_calls ( self , chat_uuid : str ) -> List [ str ]: '''Get required tool calls from the context. Args: chat_uuid (str): the chat uuid return List[str]''' if ( self . _use_redis == True ): llm_req_tools = self . _redis_db . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( llm_req_tools is not None ): return pickle . loads ( llm_req_tools ) else : return [] if chat_uuid in self . _llm_required_tool_call : return self . _llm_required_tool_call [ chat_uuid ] else : return []","title":"get_required_tool_calls"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.get_route_response_to","text":"Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional [ str ] \u2013 Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set Source code in wiseagents/core.py 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 def get_route_response_to ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set \"\"\" if ( self . _use_redis == True ): route = self . _redis_db . hget ( \"route_response_to\" , key = chat_uuid ) if ( route is not None ): return pickle . loads ( route ) else : return None else : if chat_uuid in self . _route_response_to : return self . _route_response_to [ chat_uuid ] else : return None","title":"get_route_response_to"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.remove_required_agent_for_current_phase","text":"Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent_name ( str ) \u2013 the name of the agent to remove Source code in wiseagents/core.py 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 def remove_required_agent_for_current_phase ( self , chat_uuid : str , agent_name : str ): \"\"\" Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_name (str): the name of the agent to remove \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"required_agents_for_current_phase\" ) if ( pipe . hexists ( \"required_agents_for_current_phase\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_agents = pipe . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) stored_agents : List [ str ] = pickle . loads ( redis_stored_agents ) stored_agents . remove ( agent_name ) pipe . multi () if len ( stored_agents ) == 0 : pipe . hdel ( \"required_agents_for_current_phase\" , chat_uuid ) else : pipe . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( stored_agents )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to remove agent\" ) continue else : if chat_uuid in self . _required_agents_for_current_phase : self . _required_agents_for_current_phase . get ( chat_uuid ) . remove ( agent_name )","title":"remove_required_agent_for_current_phase"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.remove_required_tool_call","text":"Remove required tool call from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tool_name ( str ) \u2013 the tool name to remove Source code in wiseagents/core.py 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 def remove_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Remove required tool call from the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to remove''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_required_tool_call\" ) if ( pipe . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( redis_stored_tool_names == None ): stored_tool_names : List [ str ] = [] else : stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . remove ( tool_name ) pipe . multi () if len ( stored_tool_names ) == 0 : pipe . hdel ( \"llm_required_tool_call\" , chat_uuid ) else : pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in remove_required_tool_call\" ) continue if chat_uuid in self . _llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] . remove ( tool_name ) if len ( self . _llm_required_tool_call [ chat_uuid ]) == 0 : self . _llm_required_tool_call . pop ( chat_uuid )","title":"remove_required_tool_call"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.set_agent_phase_assignments","text":"Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent_phase_assignments ( List [ List [ str ]] ) \u2013 The agents to be executed in each phase, represented as a Source code in wiseagents/core.py 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 def set_agent_phase_assignments ( self , chat_uuid : str , agent_phase_assignments : List [ List [ str ]]): \"\"\" Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_phase_assignments (List[List[str]]): The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agent_phase_assignments\" , key = chat_uuid , value = pickle . dumps ( agent_phase_assignments )) else : self . _agent_phase_assignments [ chat_uuid ] = agent_phase_assignments","title":"set_agent_phase_assignments"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.set_agents_sequence","text":"Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Parameters: chat_uuid ( str ) \u2013 the chat uuid agents_sequence ( List [ str ] ) \u2013 the sequence of agent names Source code in wiseagents/core.py 484 485 486 487 488 489 490 491 492 493 494 495 496 497 def set_agents_sequence ( self , chat_uuid : str , agents_sequence : List [ str ]): \"\"\" Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid agents_sequence (List[str]): the sequence of agent names \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agents_sequence\" , key = chat_uuid , value = pickle . dumps ( agents_sequence )) else : self . _agents_sequence [ chat_uuid ] = agents_sequence","title":"set_agents_sequence"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.set_collaboration_type","text":"Set the collaboration type for the given chat uuid for this context. Parameters: chat_uuid ( str ) \u2013 the chat uuid collaboration_type ( WiseAgentCollaborationType ) \u2013 the collaboration type Source code in wiseagents/core.py 814 815 816 817 818 819 820 821 822 823 824 825 def set_collaboration_type ( self , chat_uuid : str , collaboration_type : WiseAgentCollaborationType ): \"\"\" Set the collaboration type for the given chat uuid for this context. Args: chat_uuid (str): the chat uuid collaboration_type (WiseAgentCollaborationType): the collaboration type \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"collaboration_type\" , key = chat_uuid , value = pickle . dumps ( collaboration_type )) else : self . _collaboration_type [ chat_uuid ] = collaboration_type","title":"set_collaboration_type"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.set_current_phase","text":"Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid phase ( int ) \u2013 the current phase, represented as an integer in the zero-indexed list of phases Source code in wiseagents/core.py 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 def set_current_phase ( self , chat_uuid : str , phase : int ): \"\"\" Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid phase (int): the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): self . _redis_db . pipeline ( transaction = True ) \\ . hset ( \"current_phase\" , key = chat_uuid , value = pickle . dumps ( phase )) \\ . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( self . get_agent_phase_assignments ( chat_uuid )[ phase ])) \\ . execute () else : self . _current_phase [ chat_uuid ] = phase self . _required_agents_for_current_phase [ chat_uuid ] = copy . deepcopy ( self . _agent_phase_assignments [ chat_uuid ][ phase ])","title":"set_current_phase"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.set_route_response_to","text":"Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent ( str ) \u2013 the name of the agent where the final response should be routed to Source code in wiseagents/core.py 519 520 521 522 523 524 525 526 527 528 529 530 531 def set_route_response_to ( self , chat_uuid : str , agent : str ): \"\"\" Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Args: chat_uuid (str): the chat uuid agent (str): the name of the agent where the final response should be routed to \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"route_response_to\" , key = chat_uuid , value = pickle . dumps ( agent )) else : self . _route_response_to [ chat_uuid ] = agent","title":"set_route_response_to"},{"location":"reference/wiseagents/#wiseagents.WiseAgentContext.trace","text":"Trace the message. Source code in wiseagents/core.py 211 212 213 214 215 216 def trace ( self , message : WiseAgentMessage ): '''Trace the message.''' if ( self . _use_redis == True ): self . _redis_db . rpush ( \"message_trace\" , message . __repr__ ()) else : self . _message_trace . append ( message )","title":"trace"},{"location":"reference/wiseagents/#wiseagents.WiseAgentEvent","text":"TODO Source code in wiseagents/wise_agent_messaging.py 17 18 19 20 class WiseAgentEvent : \"\"\" TODO \"\"\"","title":"WiseAgentEvent"},{"location":"reference/wiseagents/#wiseagents.WiseAgentMessage","text":"Bases: YAMLObject A message that can be sent between agents. Source code in wiseagents/wise_agent_messaging.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 class WiseAgentMessage ( YAMLObject ): ''' A message that can be sent between agents. ''' yaml_tag = u '!wiseagents.WiseAgentMessage' def __init__ ( self , message : str , sender : Optional [ str ] = None , message_type : Optional [ WiseAgentMessageType ] = None , chat_id : Optional [ str ] = None , tool_id : Optional [ str ] = None , context_name : Optional [ str ] = None , route_response_to : Optional [ str ] = None ): '''Initialize the message. Args: message (str): the message contents (a natural language string) sender Optional(str): the sender of the message (or None if the sender was not specified) message_type Optional(WiseAgentMessageType): the type of the message (or None if the type was not specified) chat_id Optional(str): the id of the message tool_id Optional(str): the id of the tool context_name Optional(str): the context name of the message route_response_to Optional(str): the id of the tool to route the response to ''' self . _message = message self . _sender = sender self . _message_type = message_type self . _chat_id = chat_id self . _tool_id = tool_id self . _route_response_to = route_response_to if context_name is not None : self . _context_name = context_name else : self . _context_name = 'default' def __repr__ ( self ) -> str : return f \" { self . __class__ . __name__ } (message= { self . message } , sender= { self . sender } , message_type= { self . message_type } , id= { self . chat_id } , tool_id= { self . tool_id } , context_name= { self . context_name } , route_response_to= { self . route_response_to } , route_response_to= { self . route_response_to } )\" @property def context_name ( self ) -> str : \"\"\"Get the context name of the message.\"\"\" return self . _context_name @property def message ( self ) -> str : \"\"\"Get the message contents (a natural language string).\"\"\" return self . _message @property def sender ( self ) -> str : \"\"\"Get the sender of the message (or None if the sender was not specified).\"\"\" return self . _sender @sender . setter def sender ( self , sender : str ): '''Set the sender of the message. Args: sender (str): the sender of the message ''' self . _sender = sender @property def message_type ( self ) -> WiseAgentMessageType : \"\"\"Get the type of the message (or None if the type was not specified).\"\"\" return self . _message_type @property def chat_id ( self ) -> str : \"\"\"Get the id of the message.\"\"\" return self . _chat_id @property def tool_id ( self ) -> str : \"\"\"Get the id of the tool.\"\"\" return self . _tool_id @property def route_response_to ( self ) -> str : \"\"\"Get the id of the tool.\"\"\" return self . _route_response_to","title":"WiseAgentMessage"},{"location":"reference/wiseagents/#wiseagents.WiseAgentMessage.chat_id","text":"Get the id of the message.","title":"chat_id"},{"location":"reference/wiseagents/#wiseagents.WiseAgentMessage.context_name","text":"Get the context name of the message.","title":"context_name"},{"location":"reference/wiseagents/#wiseagents.WiseAgentMessage.message","text":"Get the message contents (a natural language string).","title":"message"},{"location":"reference/wiseagents/#wiseagents.WiseAgentMessage.message_type","text":"Get the type of the message (or None if the type was not specified).","title":"message_type"},{"location":"reference/wiseagents/#wiseagents.WiseAgentMessage.route_response_to","text":"Get the id of the tool.","title":"route_response_to"},{"location":"reference/wiseagents/#wiseagents.WiseAgentMessage.sender","text":"Get the sender of the message (or None if the sender was not specified).","title":"sender"},{"location":"reference/wiseagents/#wiseagents.WiseAgentMessage.tool_id","text":"Get the id of the tool.","title":"tool_id"},{"location":"reference/wiseagents/#wiseagents.WiseAgentMessage.__init__","text":"Initialize the message. Parameters: message ( str ) \u2013 the message contents (a natural language string) sender ( Optional(str , default: None ) \u2013 the sender of the message (or None if the sender was not specified) message_type ( Optional(WiseAgentMessageType , default: None ) \u2013 the type of the message (or None if the type was not specified) chat_id ( Optional(str , default: None ) \u2013 the id of the message tool_id ( Optional(str , default: None ) \u2013 the id of the tool context_name ( Optional(str , default: None ) \u2013 the context name of the message route_response_to ( Optional(str , default: None ) \u2013 the id of the tool to route the response to Source code in wiseagents/wise_agent_messaging.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , message : str , sender : Optional [ str ] = None , message_type : Optional [ WiseAgentMessageType ] = None , chat_id : Optional [ str ] = None , tool_id : Optional [ str ] = None , context_name : Optional [ str ] = None , route_response_to : Optional [ str ] = None ): '''Initialize the message. Args: message (str): the message contents (a natural language string) sender Optional(str): the sender of the message (or None if the sender was not specified) message_type Optional(WiseAgentMessageType): the type of the message (or None if the type was not specified) chat_id Optional(str): the id of the message tool_id Optional(str): the id of the tool context_name Optional(str): the context name of the message route_response_to Optional(str): the id of the tool to route the response to ''' self . _message = message self . _sender = sender self . _message_type = message_type self . _chat_id = chat_id self . _tool_id = tool_id self . _route_response_to = route_response_to if context_name is not None : self . _context_name = context_name else : self . _context_name = 'default'","title":"__init__"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry","text":"A Registry to get available agents and running contexts Source code in wiseagents/core.py 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 class WiseAgentRegistry : \"\"\" A Registry to get available agents and running contexts \"\"\" agents_descriptions_dict : dict [ str , str ] = {} contexts : dict [ str , WiseAgentContext ] = {} tools : dict [ str , WiseAgentTool ] = {} config : dict [ str , Any ] = {} redis_db : redis . Redis = None @classmethod def find_file ( cls , file_name , config_directory = \".wise-agents\" ) -> str : \"\"\" Find the file in the current directory or the home directory. \"\"\" # Step 1: Check the current directory local_path = os . path . join ( os . getcwd (), config_directory , file_name ) if os . path . isfile ( local_path ): return local_path # Step 2: Check the home directory home_dir = os . path . expanduser ( \"~\" ) home_path = os . path . join ( home_dir , config_directory , file_name ) if os . path . isfile ( home_path ): return home_path # If the file is not found in any of these locations, throw an exception raise FileNotFoundError ( f \"File ' { file_name } ' not found in current directory, home directory, as ' { config_directory } '/ { file_name } .\" ) @classmethod def get_config ( cls ) -> dict [ str , Any ]: \"\"\" Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture \"\"\" try : if cls . config is None or cls . config == {}: file_name = cls . find_file ( file_name = \"registry_config.yaml\" , config_directory = \".wise-agents\" ) cls . config : Dict [ str , Any ] = yaml . load ( open ( file_name ), Loader = yaml . FullLoader ) if cls . config . get ( \"use_redis\" ) == True and cls . redis_db is None : if ( cls . config . get ( \"redis_ssl\" ) is True ): cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ], username = cls . config [ \"redis_username\" ], # use your Redis user. More info https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/ password = cls . config [ \"redis_password\" ], # use your Redis password ssl = True , ssl_certfile = cls . config [ \"redis_ssl_certfile\" ], ssl_keyfile = cls . config [ \"redis_ssl_keyfile\" ], ssl_ca_certs = cls . config [ \"redis_ssl_ca_certs\" ]) else : cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ]) return cls . config except Exception as e : logging . error ( e ) exit ( 1 ) @classmethod def register_agent ( cls , agent_name : str , agent_description : str ): \"\"\" Register an agent with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"agents\" ) try : if ( pipe . hexists ( \"agents\" , agent_name ) == True ): pipe . unwatch () raise NameError ( f \"Agent with name { agent_name } already exists\" ) else : pipe . multi () pipe . hset ( \"agents\" , key = agent_name , value = agent_description ) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in register_agent\" ) continue else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : raise NameError ( f \"Agent with name { agent_name } already exists\" ) cls . agents_descriptions_dict [ agent_name ] = agent_description @classmethod def register_context ( cls , context : WiseAgentContext ): \"\"\" Register a context with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"contexts\" , key = context . name , value = pickle . dumps ( context )) else : cls . contexts [ context . name ] = context @classmethod def fetch_agents_descriptions_dict ( cls ) -> dict [ str , str ]: \"\"\" Get the dict with the agent names as keys and descriptions as values \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hgetall ( \"agents\" ) else : return cls . agents_descriptions_dict @classmethod def get_contexts ( cls ) -> dict [ str , WiseAgentContext ]: \"\"\" Get the list of contexts \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"contexts\" ) return_dictionary : Dict [ str , WiseAgentContext ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . contexts @classmethod def get_agent_description ( cls , agent_name : str ) -> str : \"\"\" Get the agent description for the agent with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return_byte = cls . redis_db . hget ( \"agents\" , key = agent_name ) if return_byte is not None : return return_byte . decode ( 'utf-8' ) else : return None else : return cls . agents_descriptions_dict . get ( agent_name ) @classmethod def get_or_create_context ( cls , context_name : str ) -> WiseAgentContext : \"\"\" Get the context with the given name \"\"\" context : WiseAgentContext = None if ( cls . get_config () . get ( \"use_redis\" ) == True ): ctx = cls . redis_db . hget ( \"contexts\" , key = context_name ) if ctx is not None : context : WiseAgentContext = pickle . loads ( ctx ) else : context = None else : context = cls . contexts . get ( context_name ) if context is None : # context creation will also register the context in the registry return WiseAgentContext ( context_name , cls . config ) else : return context @classmethod def does_context_exist ( cls , context_name : str ) -> bool : \"\"\" Get the context with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hexists ( \"contexts\" , key = context_name ) else : if cls . contexts . get ( context_name ) is None : return False else : return True @classmethod def unregister_agent ( cls , agent_name : str ): \"\"\" Remove the agent from the registry this should be used only on agents which already stopped transport connection \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"agents\" , agent_name ) else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : cls . agents_descriptions_dict . pop ( agent_name ) @classmethod def remove_context ( cls , context_name : str ): \"\"\" Remove the context from the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"contexts\" , context_name ) else : cls . contexts . pop ( context_name ) @classmethod def register_tool ( cls , tool : WiseAgentTool ): \"\"\" Register a tool with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"tools\" , key = tool . name , value = pickle . dumps ( tool )) else : cls . tools [ tool . name ] = tool @classmethod def get_tools ( cls ) -> dict [ str , WiseAgentTool ]: \"\"\" Get the list of tools \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"tools\" ) return_dictionary : Dict [ str , WiseAgentTool ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . tools @classmethod def get_tool ( cls , tool_name : str ) -> WiseAgentTool : \"\"\" Get the tool with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) piped_res = pipe . hexists ( \"tools\" , key = tool_name ) . hget ( \"tools\" , key = tool_name ) . execute () if piped_res [ 0 ]: return pickle . loads ( piped_res [ 1 ]) else : return None else : return cls . tools . get ( tool_name ) @classmethod def get_agent_names_and_descriptions ( cls ) -> List [ str ]: \"\"\" Get the list of agent names and descriptions. Returns: List[str]: the list of agent descriptions \"\"\" agent_descriptions = [] for agent_name , agent_description in cls . fetch_agents_descriptions_dict () . items (): agent_descriptions . append ( f \"Agent Name: { agent_name } Agent Description: { agent_description } \" ) return agent_descriptions","title":"WiseAgentRegistry"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.does_context_exist","text":"Get the context with the given name Source code in wiseagents/core.py 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 @classmethod def does_context_exist ( cls , context_name : str ) -> bool : \"\"\" Get the context with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hexists ( \"contexts\" , key = context_name ) else : if cls . contexts . get ( context_name ) is None : return False else : return True","title":"does_context_exist"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.fetch_agents_descriptions_dict","text":"Get the dict with the agent names as keys and descriptions as values Source code in wiseagents/core.py 1209 1210 1211 1212 1213 1214 1215 1216 1217 @classmethod def fetch_agents_descriptions_dict ( cls ) -> dict [ str , str ]: \"\"\" Get the dict with the agent names as keys and descriptions as values \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hgetall ( \"agents\" ) else : return cls . agents_descriptions_dict","title":"fetch_agents_descriptions_dict"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.find_file","text":"Find the file in the current directory or the home directory. Source code in wiseagents/core.py 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 @classmethod def find_file ( cls , file_name , config_directory = \".wise-agents\" ) -> str : \"\"\" Find the file in the current directory or the home directory. \"\"\" # Step 1: Check the current directory local_path = os . path . join ( os . getcwd (), config_directory , file_name ) if os . path . isfile ( local_path ): return local_path # Step 2: Check the home directory home_dir = os . path . expanduser ( \"~\" ) home_path = os . path . join ( home_dir , config_directory , file_name ) if os . path . isfile ( home_path ): return home_path # If the file is not found in any of these locations, throw an exception raise FileNotFoundError ( f \"File ' { file_name } ' not found in current directory, home directory, as ' { config_directory } '/ { file_name } .\" )","title":"find_file"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.get_agent_description","text":"Get the agent description for the agent with the given name Source code in wiseagents/core.py 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 @classmethod def get_agent_description ( cls , agent_name : str ) -> str : \"\"\" Get the agent description for the agent with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return_byte = cls . redis_db . hget ( \"agents\" , key = agent_name ) if return_byte is not None : return return_byte . decode ( 'utf-8' ) else : return None else : return cls . agents_descriptions_dict . get ( agent_name )","title":"get_agent_description"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.get_agent_names_and_descriptions","text":"Get the list of agent names and descriptions. Returns: List [ str ] \u2013 List[str]: the list of agent descriptions Source code in wiseagents/core.py 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 @classmethod def get_agent_names_and_descriptions ( cls ) -> List [ str ]: \"\"\" Get the list of agent names and descriptions. Returns: List[str]: the list of agent descriptions \"\"\" agent_descriptions = [] for agent_name , agent_description in cls . fetch_agents_descriptions_dict () . items (): agent_descriptions . append ( f \"Agent Name: { agent_name } Agent Description: { agent_description } \" ) return agent_descriptions","title":"get_agent_names_and_descriptions"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.get_config","text":"Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture Source code in wiseagents/core.py 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 @classmethod def get_config ( cls ) -> dict [ str , Any ]: \"\"\" Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture \"\"\" try : if cls . config is None or cls . config == {}: file_name = cls . find_file ( file_name = \"registry_config.yaml\" , config_directory = \".wise-agents\" ) cls . config : Dict [ str , Any ] = yaml . load ( open ( file_name ), Loader = yaml . FullLoader ) if cls . config . get ( \"use_redis\" ) == True and cls . redis_db is None : if ( cls . config . get ( \"redis_ssl\" ) is True ): cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ], username = cls . config [ \"redis_username\" ], # use your Redis user. More info https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/ password = cls . config [ \"redis_password\" ], # use your Redis password ssl = True , ssl_certfile = cls . config [ \"redis_ssl_certfile\" ], ssl_keyfile = cls . config [ \"redis_ssl_keyfile\" ], ssl_ca_certs = cls . config [ \"redis_ssl_ca_certs\" ]) else : cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ]) return cls . config except Exception as e : logging . error ( e ) exit ( 1 )","title":"get_config"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.get_contexts","text":"Get the list of contexts Source code in wiseagents/core.py 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 @classmethod def get_contexts ( cls ) -> dict [ str , WiseAgentContext ]: \"\"\" Get the list of contexts \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"contexts\" ) return_dictionary : Dict [ str , WiseAgentContext ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . contexts","title":"get_contexts"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.get_or_create_context","text":"Get the context with the given name Source code in wiseagents/core.py 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 @classmethod def get_or_create_context ( cls , context_name : str ) -> WiseAgentContext : \"\"\" Get the context with the given name \"\"\" context : WiseAgentContext = None if ( cls . get_config () . get ( \"use_redis\" ) == True ): ctx = cls . redis_db . hget ( \"contexts\" , key = context_name ) if ctx is not None : context : WiseAgentContext = pickle . loads ( ctx ) else : context = None else : context = cls . contexts . get ( context_name ) if context is None : # context creation will also register the context in the registry return WiseAgentContext ( context_name , cls . config ) else : return context","title":"get_or_create_context"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.get_tool","text":"Get the tool with the given name Source code in wiseagents/core.py 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 @classmethod def get_tool ( cls , tool_name : str ) -> WiseAgentTool : \"\"\" Get the tool with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) piped_res = pipe . hexists ( \"tools\" , key = tool_name ) . hget ( \"tools\" , key = tool_name ) . execute () if piped_res [ 0 ]: return pickle . loads ( piped_res [ 1 ]) else : return None else : return cls . tools . get ( tool_name )","title":"get_tool"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.get_tools","text":"Get the list of tools Source code in wiseagents/core.py 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 @classmethod def get_tools ( cls ) -> dict [ str , WiseAgentTool ]: \"\"\" Get the list of tools \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"tools\" ) return_dictionary : Dict [ str , WiseAgentTool ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . tools","title":"get_tools"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.register_agent","text":"Register an agent with the registry Source code in wiseagents/core.py 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 @classmethod def register_agent ( cls , agent_name : str , agent_description : str ): \"\"\" Register an agent with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"agents\" ) try : if ( pipe . hexists ( \"agents\" , agent_name ) == True ): pipe . unwatch () raise NameError ( f \"Agent with name { agent_name } already exists\" ) else : pipe . multi () pipe . hset ( \"agents\" , key = agent_name , value = agent_description ) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in register_agent\" ) continue else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : raise NameError ( f \"Agent with name { agent_name } already exists\" ) cls . agents_descriptions_dict [ agent_name ] = agent_description","title":"register_agent"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.register_context","text":"Register a context with the registry Source code in wiseagents/core.py 1200 1201 1202 1203 1204 1205 1206 1207 1208 @classmethod def register_context ( cls , context : WiseAgentContext ): \"\"\" Register a context with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"contexts\" , key = context . name , value = pickle . dumps ( context )) else : cls . contexts [ context . name ] = context","title":"register_context"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.register_tool","text":"Register a tool with the registry Source code in wiseagents/core.py 1299 1300 1301 1302 1303 1304 1305 1306 1307 @classmethod def register_tool ( cls , tool : WiseAgentTool ): \"\"\" Register a tool with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"tools\" , key = tool . name , value = pickle . dumps ( tool )) else : cls . tools [ tool . name ] = tool","title":"register_tool"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.remove_context","text":"Remove the context from the registry Source code in wiseagents/core.py 1289 1290 1291 1292 1293 1294 1295 1296 1297 @classmethod def remove_context ( cls , context_name : str ): \"\"\" Remove the context from the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"contexts\" , context_name ) else : cls . contexts . pop ( context_name )","title":"remove_context"},{"location":"reference/wiseagents/#wiseagents.WiseAgentRegistry.unregister_agent","text":"Remove the agent from the registry this should be used only on agents which already stopped transport connection Source code in wiseagents/core.py 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 @classmethod def unregister_agent ( cls , agent_name : str ): \"\"\" Remove the agent from the registry this should be used only on agents which already stopped transport connection \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"agents\" , agent_name ) else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : cls . agents_descriptions_dict . pop ( agent_name )","title":"unregister_agent"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool","text":"Bases: YAMLObject A WiseAgentTool is an abstract class that represents a tool that can be used by an agent to perform a specific task. Source code in wiseagents/core.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class WiseAgentTool ( yaml . YAMLObject ): ''' A WiseAgentTool is an abstract class that represents a tool that can be used by an agent to perform a specific task.''' yaml_tag = u '!wiseagents.WiseAgentTool' yaml_loader = WiseAgentsLoader def __init__ ( self , name : str , description : str , agent_tool : bool , parameters_json_schema : dict = {}, call_back : Optional [ Callable [ ... , str ]] = None ): ''' Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Args: name (str): the name of the tool description (str): a description of what the tool does agent_tool (bool): whether the tool is an agent tool parameters_json_schema (dict): the json schema for the parameters of the tool call_back Optional(Callable[...,str]): the callback function to execute the tool''' self . _name = name self . _description = description self . _parameters_json_schema = parameters_json_schema self . _agent_tool = agent_tool self . _call_back = call_back WiseAgentRegistry . register_tool ( self ) @classmethod def from_yaml ( cls , loader , node ): '''Load the tool from a YAML node. Args: loader (yaml.Loader): the YAML loader node (yaml.Node): the YAML node''' data = loader . construct_mapping ( node , deep = True ) return cls ( name = data . get ( '_name' ), description = data . get ( '_description' ), parameters_json_schema = data . get ( '_parameters_json_schema' ), call_back = data . get ( '_call_back' )) @property def name ( self ) -> str : \"\"\"Get the name of the tool.\"\"\" return self . _name @property def description ( self ) -> str : \"\"\"Get the description of the tool.\"\"\" return self . _description @property def call_back ( self ) -> Callable [ ... , str ]: \"\"\"Get the callback function of the tool.\"\"\" return self . _call_back @property def json_schema ( self ) -> dict : \"\"\"Get the json schema of the tool.\"\"\" return self . _parameters_json_schema @property def is_agent_tool ( self ) -> bool : \"\"\"Get the agent tool of the tool.\"\"\" return self . _agent_tool def get_tool_OpenAI_format ( self ) -> ChatCompletionToolParam : '''The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam''' return { \"type\" : \"function\" , \"function\" : { \"name\" : self . name , \"description\" : self . description , \"parameters\" : self . json_schema } } def default_call_back ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' return json . dumps ( kwargs ) def exec ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' if self . call_back is None : return self . default_call_back ( ** kwargs ) return self . call_back ( ** kwargs )","title":"WiseAgentTool"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.call_back","text":"Get the callback function of the tool.","title":"call_back"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.description","text":"Get the description of the tool.","title":"description"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.is_agent_tool","text":"Get the agent tool of the tool.","title":"is_agent_tool"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.json_schema","text":"Get the json schema of the tool.","title":"json_schema"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.name","text":"Get the name of the tool.","title":"name"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.__init__","text":"Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Parameters: name ( str ) \u2013 the name of the tool description ( str ) \u2013 a description of what the tool does agent_tool ( bool ) \u2013 whether the tool is an agent tool parameters_json_schema ( dict , default: {} ) \u2013 the json schema for the parameters of the tool call_back ( Optional(Callable[...,str] , default: None ) \u2013 the callback function to execute the tool Source code in wiseagents/core.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , name : str , description : str , agent_tool : bool , parameters_json_schema : dict = {}, call_back : Optional [ Callable [ ... , str ]] = None ): ''' Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Args: name (str): the name of the tool description (str): a description of what the tool does agent_tool (bool): whether the tool is an agent tool parameters_json_schema (dict): the json schema for the parameters of the tool call_back Optional(Callable[...,str]): the callback function to execute the tool''' self . _name = name self . _description = description self . _parameters_json_schema = parameters_json_schema self . _agent_tool = agent_tool self . _call_back = call_back WiseAgentRegistry . register_tool ( self )","title":"__init__"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.default_call_back","text":"The tool should be able to execute the function with the given parameters Source code in wiseagents/core.py 100 101 102 def default_call_back ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' return json . dumps ( kwargs )","title":"default_call_back"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.exec","text":"The tool should be able to execute the function with the given parameters Source code in wiseagents/core.py 104 105 106 107 108 def exec ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' if self . call_back is None : return self . default_call_back ( ** kwargs ) return self . call_back ( ** kwargs )","title":"exec"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.from_yaml","text":"Load the tool from a YAML node. Parameters: loader ( Loader ) \u2013 the YAML loader node ( Node ) \u2013 the YAML node Source code in wiseagents/core.py 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_yaml ( cls , loader , node ): '''Load the tool from a YAML node. Args: loader (yaml.Loader): the YAML loader node (yaml.Node): the YAML node''' data = loader . construct_mapping ( node , deep = True ) return cls ( name = data . get ( '_name' ), description = data . get ( '_description' ), parameters_json_schema = data . get ( '_parameters_json_schema' ), call_back = data . get ( '_call_back' ))","title":"from_yaml"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTool.get_tool_OpenAI_format","text":"The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam \u2013 ChatCompletionToolParam Source code in wiseagents/core.py 87 88 89 90 91 92 93 94 95 96 97 98 def get_tool_OpenAI_format ( self ) -> ChatCompletionToolParam : '''The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam''' return { \"type\" : \"function\" , \"function\" : { \"name\" : self . name , \"description\" : self . description , \"parameters\" : self . json_schema } }","title":"get_tool_OpenAI_format"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport","text":"Bases: YAMLObject Source code in wiseagents/wise_agent_messaging.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 class WiseAgentTransport ( YAMLObject ): yaml_loader = WiseAgentsLoader ''' A transport for sending messages between agents. ''' def set_call_backs ( self , request_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , event_receiver : Optional [ Callable [[], WiseAgentEvent ]] = None , error_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , response_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None ): '''Set the call back functions for the transport. Args: request_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving requests event_receiver Optional(Callable[[], WiseAgentEvent]): the call back function for receiving events error_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving errors response_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving responses ''' self . _request_receiver = request_receiver self . _event_receiver = event_receiver self . _error_receiver = error_receiver self . _response_receiver = response_receiver def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () del state [ '_request_receiver' ] del state [ '_response_receiver' ] del state [ '_event_receiver' ] del state [ '_error_receiver' ] return state @abstractmethod def start ( self ): \"\"\" Start the transport. \"\"\" pass @abstractmethod def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass @abstractmethod def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass @abstractmethod def stop ( self ): \"\"\" Stop the transport. \"\"\" pass @property def request_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the message receiver callback.\"\"\" return self . _request_receiver @property def event_receiver ( self ) -> Optional [ Callable [[], WiseAgentEvent ]]: \"\"\"Get the event receiver callback.\"\"\" return self . _event_receiver @property def error_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the error receiver callback.\"\"\" return self . _error_receiver @property def response_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the response receiver callback.\"\"\" return self . _response_receiver","title":"WiseAgentTransport"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.error_receiver","text":"Get the error receiver callback.","title":"error_receiver"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.event_receiver","text":"Get the event receiver callback.","title":"event_receiver"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.request_receiver","text":"Get the message receiver callback.","title":"request_receiver"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.response_receiver","text":"Get the response receiver callback.","title":"response_receiver"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.yaml_loader","text":"A transport for sending messages between agents.","title":"yaml_loader"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.__getstate__","text":"Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/wise_agent_messaging.py 117 118 119 120 121 122 123 124 def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () del state [ '_request_receiver' ] del state [ '_response_receiver' ] del state [ '_event_receiver' ] del state [ '_error_receiver' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.send_request","text":"Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send Source code in wiseagents/wise_agent_messaging.py 134 135 136 137 138 139 140 141 142 143 @abstractmethod def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass","title":"send_request"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.send_response","text":"Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send Source code in wiseagents/wise_agent_messaging.py 145 146 147 148 149 150 151 152 153 154 @abstractmethod def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass","title":"send_response"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.set_call_backs","text":"Set the call back functions for the transport. Parameters: request_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving requests event_receiver ( Optional(Callable[[], WiseAgentEvent] , default: None ) \u2013 the call back function for receiving events error_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving errors response_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving responses Source code in wiseagents/wise_agent_messaging.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def set_call_backs ( self , request_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , event_receiver : Optional [ Callable [[], WiseAgentEvent ]] = None , error_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , response_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None ): '''Set the call back functions for the transport. Args: request_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving requests event_receiver Optional(Callable[[], WiseAgentEvent]): the call back function for receiving events error_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving errors response_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving responses ''' self . _request_receiver = request_receiver self . _event_receiver = event_receiver self . _error_receiver = error_receiver self . _response_receiver = response_receiver","title":"set_call_backs"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.start","text":"Start the transport. Source code in wiseagents/wise_agent_messaging.py 127 128 129 130 131 132 @abstractmethod def start ( self ): \"\"\" Start the transport. \"\"\" pass","title":"start"},{"location":"reference/wiseagents/#wiseagents.WiseAgentTransport.stop","text":"Stop the transport. Source code in wiseagents/wise_agent_messaging.py 156 157 158 159 160 161 @abstractmethod def stop ( self ): \"\"\" Stop the transport. \"\"\" pass","title":"stop"},{"location":"reference/wiseagents/constants/","text":"Constants for the wiseagents package.","title":"constants"},{"location":"reference/wiseagents/core/","text":"WiseAgent Bases: YAMLObject A WiseAgent is an abstract class that represents an agent that can send and receive messages to and from other agents. Source code in wiseagents/core.py 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 class WiseAgent ( yaml . YAMLObject ): ''' A WiseAgent is an abstract class that represents an agent that can send and receive messages to and from other agents. ''' yaml_tag = u '!wiseagents.WiseAgent' yaml_loader = WiseAgentsLoader def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _llm = None obj . _vector_db = None obj . _graph_db = None obj . _collection_name = \"wise-agent-collection\" obj . _system_message = None return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : Optional [ WiseAgentLLM ] = None , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = \"wise-agent-collection\" , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): ''' Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Args: name (str): the name of the agent description (str): a description of what the agent does transport (WiseAgentTransport): the transport to use for sending and receiving messages llm (Optional[WiseAgentLLM]): the LLM associated with the agent vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent system_message Optional(str): an optional system message that can be used by the agent when processing chat completions using its LLM ''' self . _name = name self . _description = description self . _llm = llm self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db self . _transport = transport self . _system_message = system_message self . start_agent () def start_agent ( self ): ''' Start the agent by setting the call backs and starting the transport.''' self . transport . set_call_backs ( self . handle_request , self . process_event , self . process_error , self . process_response ) self . transport . start () WiseAgentRegistry . register_agent ( self . name , self . description ) def stop_agent ( self ): ''' Stop the agent by stopping the transport and removing the agent from the registry.''' self . transport . stop () WiseAgentRegistry . unregister_agent ( self . name ) def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . _collection_name } , graph_db= { self . graph_db } ,\" f \"system_message= { self . system_message } )\" ) def __eq__ ( self , value : object ) -> bool : return isinstance ( value , WiseAgent ) and self . __repr__ () == value . __repr__ () @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def description ( self ) -> str : \"\"\"Get a description of what the agent does.\"\"\" return self . _description @property def llm ( self ) -> Optional [ WiseAgentLLM ]: \"\"\"Get the LLM associated with the agent.\"\"\" return self . _llm @property def vector_db ( self ) -> Optional [ WiseAgentVectorDB ]: \"\"\"Get the vector DB associated with the agent.\"\"\" return self . _vector_db @property def collection_name ( self ) -> str : \"\"\"Get the vector DB collection name associated with the agent.\"\"\" return self . _collection_name @property def graph_db ( self ) -> Optional [ WiseAgentGraphDB ]: \"\"\"Get the graph DB associated with the agent.\"\"\" return self . _graph_db @property def transport ( self ) -> WiseAgentTransport : \"\"\"Get the transport associated with the agent.\"\"\" return self . _transport @property def system_message ( self ) -> Optional [ str ]: \"\"\"Get the system message associated with the agent.\"\"\" return self . _system_message def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_request ( message , dest_agent_name ) context . trace ( message ) def send_response ( self , message : WiseAgentMessage , dest_agent_name ): '''Send a response message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_response ( message , dest_agent_name ) context . trace ( message ) def handle_request ( self , request : WiseAgentMessage ) -> bool : \"\"\" Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Args: request (WiseAgentMessage): the request message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" context = WiseAgentRegistry . get_or_create_context ( request . context_name ) collaboration_type = context . get_collaboration_type ( request . chat_id ) conversation_history = self . get_conversation_history_if_needed ( context , request . chat_id , collaboration_type ) response_str = self . process_request ( request , conversation_history ) return self . handle_response ( response_str , request , context , collaboration_type ) def get_conversation_history_if_needed ( self , context : WiseAgentContext , chat_id : Optional [ str ], collaboration_type : str ) -> List [ ChatCompletionMessageParam ]: \"\"\" Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Args: context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent is involved in a collaboration type that makes use of the conversation history and an empty list otherwise \"\"\" if chat_id : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # this agent is involved in phased collaboration or a chat, so it needs the conversation history return context . llm_chat_completion . get ( chat_id ) # for sequential collaboration and independent agents, the shared history is not needed return [] @abstractmethod def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process the given request message to generate a response string. Args: request (WiseAgentMessage): the request message to be processed conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" ... def handle_response ( self , response_str : str , request : WiseAgentMessage , context : WiseAgentContext , collaboration_type : str ) -> bool : \"\"\" Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Args: response_str (str): the string response to be handled context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: True if the message was processed successfully, False otherwise \"\"\" if response_str : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # add this agent's response to the shared context context . append_chat_completion ( chat_uuid = request . chat_id , messages = { \"role\" : \"assistant\" , \"content\" : response_str }) # let the sender know that this agent has finished processing the request self . send_response ( WiseAgentMessage ( message = response_str , message_type = WiseAgentMessageType . ACK , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) elif collaboration_type == WiseAgentCollaborationType . SEQUENTIAL : next_agent = context . get_next_agent_in_sequence ( request . chat_id , self . name ) if next_agent is None : logging . debug ( f \"Sequential coordination complete - sending response from \" + self . name + \" to \" + context . get_route_response_to ( request . chat_id )) self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), context . get_route_response_to ( request . chat_id )) else : logging . debug ( f \"Sequential coordination continuing - sending response from \" + self . name + \" to \" + next_agent ) self . send_request ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), next_agent ) else : self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) return True @abstractmethod def process_response ( self , message : WiseAgentMessage ) -> bool : \"\"\" Callback method to process the response received from another agent which processed a request from this agent. Args: message (WiseAgentMessage): the message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" ... @abstractmethod def process_event ( self , event : WiseAgentEvent ) -> bool : \"\"\" Callback method to process the given event. Args: event (WiseAgentEvent): the event to be processed Returns: True if the event was processed successfully, False otherwise \"\"\" ... @abstractmethod def process_error ( self , error : Exception ) -> bool : \"\"\" Callback method to process the given error. Args: error (Exception): the error to be processed Returns: True if the error was processed successfully, False otherwise \"\"\" ... collection_name : str property Get the vector DB collection name associated with the agent. description : str property Get a description of what the agent does. graph_db : Optional [ WiseAgentGraphDB ] property Get the graph DB associated with the agent. llm : Optional [ WiseAgentLLM ] property Get the LLM associated with the agent. name : str property Get the name of the agent. system_message : Optional [ str ] property Get the system message associated with the agent. transport : WiseAgentTransport property Get the transport associated with the agent. vector_db : Optional [ WiseAgentVectorDB ] property Get the vector DB associated with the agent. __init__ ( name , description , transport , llm = None , vector_db = None , collection_name = 'wise-agent-collection' , graph_db = None , system_message = None ) Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of what the agent does transport ( WiseAgentTransport ) \u2013 the transport to use for sending and receiving messages llm ( Optional [ WiseAgentLLM ] , default: None ) \u2013 the LLM associated with the agent vector_db ( Optional [ WiseAgentVectorDB ] , default: None ) \u2013 the vector DB associated with the agent collection_name ( Optional[str]) = \"wise-agent-collection\" , default: 'wise-agent-collection' ) \u2013 the vector DB collection name associated with the agent graph_db ( Optional [ WiseAgentGraphDB ] , default: None ) \u2013 the graph DB associated with the agent system_message ( Optional(str , default: None ) \u2013 an optional system message that can be used by the agent when processing chat Source code in wiseagents/core.py 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : Optional [ WiseAgentLLM ] = None , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = \"wise-agent-collection\" , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): ''' Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Args: name (str): the name of the agent description (str): a description of what the agent does transport (WiseAgentTransport): the transport to use for sending and receiving messages llm (Optional[WiseAgentLLM]): the LLM associated with the agent vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent system_message Optional(str): an optional system message that can be used by the agent when processing chat completions using its LLM ''' self . _name = name self . _description = description self . _llm = llm self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db self . _transport = transport self . _system_message = system_message self . start_agent () __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/core.py 834 835 836 837 838 839 840 841 842 def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _llm = None obj . _vector_db = None obj . _graph_db = None obj . _collection_name = \"wise-agent-collection\" obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/core.py 885 886 887 888 889 def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . _collection_name } , graph_db= { self . graph_db } ,\" f \"system_message= { self . system_message } )\" ) get_conversation_history_if_needed ( context , chat_id , collaboration_type ) Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Parameters: context ( WiseAgentContext ) \u2013 the shared context chat_id ( Optional [ str ] ) \u2013 the chat id, may be None collaboration_type ( str ) \u2013 the type of collaboration this agent is involved in Returns: List [ ChatCompletionMessageParam ] \u2013 List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent List [ ChatCompletionMessageParam ] \u2013 is involved in a collaboration type that makes use of the conversation history and an empty list List [ ChatCompletionMessageParam ] \u2013 otherwise Source code in wiseagents/core.py 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 def get_conversation_history_if_needed ( self , context : WiseAgentContext , chat_id : Optional [ str ], collaboration_type : str ) -> List [ ChatCompletionMessageParam ]: \"\"\" Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Args: context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent is involved in a collaboration type that makes use of the conversation history and an empty list otherwise \"\"\" if chat_id : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # this agent is involved in phased collaboration or a chat, so it needs the conversation history return context . llm_chat_completion . get ( chat_id ) # for sequential collaboration and independent agents, the shared history is not needed return [] handle_request ( request ) Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Parameters: request ( WiseAgentMessage ) \u2013 the request message to be processed Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 def handle_request ( self , request : WiseAgentMessage ) -> bool : \"\"\" Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Args: request (WiseAgentMessage): the request message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" context = WiseAgentRegistry . get_or_create_context ( request . context_name ) collaboration_type = context . get_collaboration_type ( request . chat_id ) conversation_history = self . get_conversation_history_if_needed ( context , request . chat_id , collaboration_type ) response_str = self . process_request ( request , conversation_history ) return self . handle_response ( response_str , request , context , collaboration_type ) handle_response ( response_str , request , context , collaboration_type ) Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Parameters: response_str ( str ) \u2013 the string response to be handled context ( WiseAgentContext ) \u2013 the shared context chat_id ( Optional [ str ] ) \u2013 the chat id, may be None collaboration_type ( str ) \u2013 the type of collaboration this agent is involved in Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 def handle_response ( self , response_str : str , request : WiseAgentMessage , context : WiseAgentContext , collaboration_type : str ) -> bool : \"\"\" Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Args: response_str (str): the string response to be handled context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: True if the message was processed successfully, False otherwise \"\"\" if response_str : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # add this agent's response to the shared context context . append_chat_completion ( chat_uuid = request . chat_id , messages = { \"role\" : \"assistant\" , \"content\" : response_str }) # let the sender know that this agent has finished processing the request self . send_response ( WiseAgentMessage ( message = response_str , message_type = WiseAgentMessageType . ACK , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) elif collaboration_type == WiseAgentCollaborationType . SEQUENTIAL : next_agent = context . get_next_agent_in_sequence ( request . chat_id , self . name ) if next_agent is None : logging . debug ( f \"Sequential coordination complete - sending response from \" + self . name + \" to \" + context . get_route_response_to ( request . chat_id )) self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), context . get_route_response_to ( request . chat_id )) else : logging . debug ( f \"Sequential coordination continuing - sending response from \" + self . name + \" to \" + next_agent ) self . send_request ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), next_agent ) else : self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) return True process_error ( error ) abstractmethod Callback method to process the given error. Parameters: error ( Exception ) \u2013 the error to be processed Returns: bool \u2013 True if the error was processed successfully, False otherwise Source code in wiseagents/core.py 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 @abstractmethod def process_error ( self , error : Exception ) -> bool : \"\"\" Callback method to process the given error. Args: error (Exception): the error to be processed Returns: True if the error was processed successfully, False otherwise \"\"\" ... process_event ( event ) abstractmethod Callback method to process the given event. Parameters: event ( WiseAgentEvent ) \u2013 the event to be processed Returns: bool \u2013 True if the event was processed successfully, False otherwise Source code in wiseagents/core.py 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 @abstractmethod def process_event ( self , event : WiseAgentEvent ) -> bool : \"\"\" Callback method to process the given event. Args: event (WiseAgentEvent): the event to be processed Returns: True if the event was processed successfully, False otherwise \"\"\" ... process_request ( request , conversation_history ) abstractmethod Process the given request message to generate a response string. Parameters: request ( WiseAgentMessage ) \u2013 the request message to be processed conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/core.py 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 @abstractmethod def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process the given request message to generate a response string. Args: request (WiseAgentMessage): the request message to be processed conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" ... process_response ( message ) abstractmethod Callback method to process the response received from another agent which processed a request from this agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to be processed Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 @abstractmethod def process_response ( self , message : WiseAgentMessage ) -> bool : \"\"\" Callback method to process the response received from another agent which processed a request from this agent. Args: message (WiseAgentMessage): the message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" ... send_request ( message , dest_agent_name ) Send a request message to the destination agent with the given name. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the name of the destination agent Source code in wiseagents/core.py 934 935 936 937 938 939 940 941 942 943 944 def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_request ( message , dest_agent_name ) context . trace ( message ) send_response ( message , dest_agent_name ) Send a response message to the destination agent with the given name. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the name of the destination agent Source code in wiseagents/core.py 946 947 948 949 950 951 952 953 954 955 956 def send_response ( self , message : WiseAgentMessage , dest_agent_name ): '''Send a response message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_response ( message , dest_agent_name ) context . trace ( message ) start_agent () Start the agent by setting the call backs and starting the transport. Source code in wiseagents/core.py 873 874 875 876 877 878 def start_agent ( self ): ''' Start the agent by setting the call backs and starting the transport.''' self . transport . set_call_backs ( self . handle_request , self . process_event , self . process_error , self . process_response ) self . transport . start () WiseAgentRegistry . register_agent ( self . name , self . description ) stop_agent () Stop the agent by stopping the transport and removing the agent from the registry. Source code in wiseagents/core.py 880 881 882 883 def stop_agent ( self ): ''' Stop the agent by stopping the transport and removing the agent from the registry.''' self . transport . stop () WiseAgentRegistry . unregister_agent ( self . name ) WiseAgentContext A WiseAgentContext is a class that represents a context in which agents can communicate with each other. Source code in wiseagents/core.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 class WiseAgentContext (): ''' A WiseAgentContext is a class that represents a context in which agents can communicate with each other. ''' _message_trace : List [ str ] = [] _participants : List [ str ] = [] # Maps a chat uuid to a list of chat completion messages _llm_chat_completion : Dict [ str , List [ ChatCompletionMessageParam ]] = {} # Maps a chat uuid to a list of tool names that need to be executed _llm_required_tool_call : Dict [ str , List [ str ]] = {} # Maps a chat uuid to a list of available tools in chat _llm_available_tools_in_chat : Dict [ str , List [ ChatCompletionToolParam ]] = {} # Maps a chat uuid to a list of agent names that need to be executed in sequence # Used by a sequential coordinator _agents_sequence : Dict [ str , List [ str ]] = {} # Maps a chat uuid to the agent where the final response should be routed to # Used by both a sequential coordinator and a phased coordinator _route_response_to : Dict [ str , str ] = {} # Maps a chat uuid to a list that contains a list of agent names to be executed for each phase # Used by a phased coordinator _agent_phase_assignments : Dict [ str , List [ List [ str ]]] = {} # Maps a chat uuid to the current phase. Used by a phased coordinator. _current_phase : Dict [ str , int ] = {} # Maps a chat uuid to a list of agent names that need to be executed for the current phase # Used by a phased coordinator _required_agents_for_current_phase : Dict [ str , List [ str ]] = {} # Maps a chat uuid to a list containing the queries attempted for each iteration executed by # the phased coordinator _queries : Dict [ str , List [ str ]] = {} # Maps a chat uuid to the collaboration type _collaboration_type : Dict [ str , WiseAgentCollaborationType ] = {} _redis_db : redis . Redis = None _use_redis : bool = False _config : Dict [ str , Any ] = {} def __init__ ( self , name : str , config : Optional [ Dict [ str , Any ]] = { \"use_redis\" : False }): ''' Initialize the context with the given name. Args: name (str): the name of the context''' self . _name = name self . _config = config if config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True WiseAgentRegistry . register_context ( self ) def __repr__ ( self ) -> str : '''Return a string representation of the context.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , message_trace= { self . message_trace } ,\" f \"participants= { self . participants } , llm_chat_completion= { self . llm_chat_completion } ,\" f \"llm_required_tool_call= { self . llm_required_tool_call } , llm_available_tools_in_chat= { self . llm_available_tools_in_chat } ,\" f \"agents_sequence= { self . _agents_sequence } , route_response_to= { self . _route_response_to } ,\" f \"agent_phase_assignments= { self . _agent_phase_assignments } , current_phase= { self . _current_phase } ,\" f \"required_agents_for_current_phase= { self . _required_agents_for_current_phase } , queries= { self . _queries } )\" ) def __eq__ ( self , value : object ) -> bool : return isinstance ( value , WiseAgentContext ) and self . __repr__ () == value . __repr__ () def __getstate__ ( self ) -> object : '''Get the state of the context.''' state = self . __dict__ . copy () if '_redis_db' in state : del state [ '_redis_db' ] del state [ '_use_redis' ] return state def __setstate__ ( self , state : object ): '''Set the state of the context.''' self . __dict__ . update ( state ) if self . _config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True @property def name ( self ) -> str : \"\"\"Get the name of the context.\"\"\" return self . _name @property def message_trace ( self ) -> List [ str ]: \"\"\"Get the message trace of the context.\"\"\" if ( self . _use_redis == True ): return self . _redis_db . lrange ( \"message_trace\" , 0 , - 1 ) else : return self . _message_trace def trace ( self , message : WiseAgentMessage ): '''Trace the message.''' if ( self . _use_redis == True ): self . _redis_db . rpush ( \"message_trace\" , message . __repr__ ()) else : self . _message_trace . append ( message ) @property def participants ( self ) -> List [ str ]: \"\"\"Get the participants of the context.\"\"\" if ( self . _use_redis == True ): return self . _redis_db . lrange ( \"participants\" , 0 , - 1 ) else : return self . _participants @property def llm_chat_completion ( self ) -> Dict [ str , List [ ChatCompletionMessageParam ]]: \"\"\"Get the LLM chat completion of the context.\"\"\" if ( self . _use_redis == True ): return_dict : Dict [ str , List [ ChatCompletionMessageParam ]] = {} redis_dict = self . _redis_db . hgetall ( \"llm_chat_completion\" ) for key in redis_dict : return_dict [ key . decode ( 'utf-8' )] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _llm_chat_completion def add_participant ( self , agent_name : str ): '''Add a participant to the context. Args: agent (WiseAgent): the agent to add''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"participants\" ) try : if ( pipe . exists ( \"participants\" ) == False ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : if agent_name not in pipe . lrange ( \"participants\" , 0 , - 1 ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : pipe . unwatch () return except redis . WatchError : logging . debug ( \"WatchError in add_participant\" ) continue else : if agent_name not in self . participants : self . _participants . append ( agent_name ) def append_chat_completion ( self , chat_uuid : str , messages : Iterable [ ChatCompletionMessageParam ]): '''Append chat completion to the context. Args: chat_uuid (str): the chat uuid messages (Iterable[ChatCompletionMessageParam]): the messages to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"llm_chat_completion\" ) try : if ( pipe . hexists ( \"llm_chat_completion\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ([ messages ])) pipe . execute () return else : redis_stored_messages = pipe . hget ( \"llm_chat_completion\" , key = chat_uuid ) stored_messages : List [ ChatCompletionMessageParam ] = pickle . loads ( redis_stored_messages ) stored_messages . append ( messages ) pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ( stored_messages )) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in append_chat_completion\" ) continue else : if chat_uuid not in self . _llm_chat_completion : self . _llm_chat_completion [ chat_uuid ] = [] self . _llm_chat_completion [ chat_uuid ] . append ( messages ) @property def llm_required_tool_call ( self ) -> Dict [ str , List [ str ]]: \"\"\"Get the LLM required tool call of the context. return Dict[str, List[str]]\"\"\" if ( self . _use_redis == True ): redis_dict = self . _redis_db . hgetall ( \"llm_required_tool_call\" ) return_dict : Dict [ str , List [ str ]] = {} for key in redis_dict : return_dict [ key ] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _llm_required_tool_call def append_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Append required tool call to the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) if ( self . _redis_db . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): self . _redis_db . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ([ tool_name ])) pipe . execute () else : while True : try : pipe . watch ( \"llm_required_tool_call\" ) redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . append ( tool_name ) pipe . multi () pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_required_tool_call\" ) continue else : if chat_uuid not in self . llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] = [] self . _llm_required_tool_call [ chat_uuid ] . append ( tool_name ) def remove_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Remove required tool call from the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to remove''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_required_tool_call\" ) if ( pipe . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( redis_stored_tool_names == None ): stored_tool_names : List [ str ] = [] else : stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . remove ( tool_name ) pipe . multi () if len ( stored_tool_names ) == 0 : pipe . hdel ( \"llm_required_tool_call\" , chat_uuid ) else : pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in remove_required_tool_call\" ) continue if chat_uuid in self . _llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] . remove ( tool_name ) if len ( self . _llm_required_tool_call [ chat_uuid ]) == 0 : self . _llm_required_tool_call . pop ( chat_uuid ) def get_required_tool_calls ( self , chat_uuid : str ) -> List [ str ]: '''Get required tool calls from the context. Args: chat_uuid (str): the chat uuid return List[str]''' if ( self . _use_redis == True ): llm_req_tools = self . _redis_db . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( llm_req_tools is not None ): return pickle . loads ( llm_req_tools ) else : return [] if chat_uuid in self . _llm_required_tool_call : return self . _llm_required_tool_call [ chat_uuid ] else : return [] @property def llm_available_tools_in_chat ( self ) -> Dict [ str , List [ ChatCompletionToolParam ]]: \"\"\"Get the LLM available tools in chat of the context.\"\"\" if ( self . _use_redis == True ): redis_dict = self . _redis_db . hgetall ( \"llm_available_tools_in_chat\" ) return_dict : Dict [ str , List [ ChatCompletionToolParam ]] = {} for key in redis_dict : return_dict [ key ] = pickle . loads ( redis_dict [ key ]) return return_dict return self . _llm_available_tools_in_chat def append_available_tool_in_chat ( self , chat_uuid : str , tools : Iterable [ ChatCompletionToolParam ]): '''Append available tool in chat to the context. Args: chat_uuid (str): the chat uuid tools (Iterable[ChatCompletionToolParam]): the tools to append''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_available_tools_in_chat\" ) if ( pipe . hexists ( \"llm_available_tools_in_chat\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ([ tools ])) pipe . execute () break else : redis_stored_tools = pipe . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) stored_tools : List [ ChatCompletionToolParam ] = pickle . loads ( redis_stored_tools ) stored_tools . append ( tools ) pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ( stored_tools )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_available_tool_in_chat\" ) continue else : if chat_uuid not in self . _llm_available_tools_in_chat : self . _llm_available_tools_in_chat [ chat_uuid ] = [] self . _llm_available_tools_in_chat [ chat_uuid ] . append ( tools ) def get_available_tools_in_chat ( self , chat_uuid : str ) -> List [ ChatCompletionToolParam ]: '''Get available tools in chat from the context. Args: chat_uuid (str): the chat uuid return List[ChatCompletionToolParam]''' if ( self . _use_redis == True ): llm_av_tools = self . _redis_db . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) if ( llm_av_tools is not None ): return pickle . loads ( llm_av_tools ) else : return [] else : if chat_uuid in self . _llm_available_tools_in_chat : return self . _llm_available_tools_in_chat [ chat_uuid ] else : return [] def get_agents_sequence ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid Returns: List[str]: the sequence of agents names or an empty list if no sequence has been set for this context \"\"\" if ( self . _use_redis == True ): agent_sequence = self . _redis_db . hget ( \"agents_sequence\" , key = chat_uuid ) if ( agent_sequence is not None ): return pickle . loads ( agent_sequence ) else : return [] else : if chat_uuid in self . _agents_sequence : return self . _agents_sequence [ chat_uuid ] return [] def set_agents_sequence ( self , chat_uuid : str , agents_sequence : List [ str ]): \"\"\" Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid agents_sequence (List[str]): the sequence of agent names \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agents_sequence\" , key = chat_uuid , value = pickle . dumps ( agents_sequence )) else : self . _agents_sequence [ chat_uuid ] = agents_sequence def get_route_response_to ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set \"\"\" if ( self . _use_redis == True ): route = self . _redis_db . hget ( \"route_response_to\" , key = chat_uuid ) if ( route is not None ): return pickle . loads ( route ) else : return None else : if chat_uuid in self . _route_response_to : return self . _route_response_to [ chat_uuid ] else : return None def set_route_response_to ( self , chat_uuid : str , agent : str ): \"\"\" Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Args: chat_uuid (str): the chat uuid agent (str): the name of the agent where the final response should be routed to \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"route_response_to\" , key = chat_uuid , value = pickle . dumps ( agent )) else : self . _route_response_to [ chat_uuid ] = agent def get_next_agent_in_sequence ( self , chat_uuid : str , current_agent : str ): \"\"\" Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Args: chat_uuid (str): the chat uuid current_agent (str): the name of the current agent Returns: str: the name of the next agent in the sequence after the current agent or None if there are no remaining agents in the sequence after the current agent \"\"\" agents_sequence = self . get_agents_sequence ( chat_uuid ) if current_agent in agents_sequence : current_agent_index = agents_sequence . index ( current_agent ) next_agent_index = current_agent_index + 1 if next_agent_index < len ( agents_sequence ): return agents_sequence [ next_agent_index ] return None def get_agent_phase_assignments ( self , chat_uuid : str ) -> List [ List [ str ]]: \"\"\" Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. An empty list is returned if no phases have been set for the given chat uuid \"\"\" if ( self . _use_redis == True ): agent_phase = self . _redis_db . hget ( \"agent_phase_assignments\" , key = chat_uuid ) if ( agent_phase is not None ): return pickle . loads ( agent_phase ) else : return [] else : if chat_uuid in self . _agent_phase_assignments : return self . _agent_phase_assignments . get ( chat_uuid ) return [] def set_agent_phase_assignments ( self , chat_uuid : str , agent_phase_assignments : List [ List [ str ]]): \"\"\" Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_phase_assignments (List[List[str]]): The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agent_phase_assignments\" , key = chat_uuid , value = pickle . dumps ( agent_phase_assignments )) else : self . _agent_phase_assignments [ chat_uuid ] = agent_phase_assignments def get_current_phase ( self , chat_uuid : str ) -> int : \"\"\" Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: int: the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): cur_phase = self . _redis_db . hget ( \"current_phase\" , key = chat_uuid ) if ( cur_phase is not None ): return pickle . loads ( cur_phase ) else : return None else : return self . _current_phase . get ( chat_uuid ) def set_current_phase ( self , chat_uuid : str , phase : int ): \"\"\" Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid phase (int): the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): self . _redis_db . pipeline ( transaction = True ) \\ . hset ( \"current_phase\" , key = chat_uuid , value = pickle . dumps ( phase )) \\ . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( self . get_agent_phase_assignments ( chat_uuid )[ phase ])) \\ . execute () else : self . _current_phase [ chat_uuid ] = phase self . _required_agents_for_current_phase [ chat_uuid ] = copy . deepcopy ( self . _agent_phase_assignments [ chat_uuid ][ phase ]) def get_agents_for_next_phase ( self , chat_uuid : str ) -> Optional [ List ]: \"\"\" Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases \"\"\" current_phase = self . get_current_phase ( chat_uuid ) next_phase = current_phase + 1 if next_phase < len ( self . get_agent_phase_assignments ( chat_uuid )): self . set_current_phase ( chat_uuid , next_phase ) return self . get_agent_phase_assignments ( chat_uuid )[ next_phase ] return None def get_required_agents_for_current_phase ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[str]: the list of agent names that still need to be executed for the current phase or an empty list if there are no remaining agents that need to be executed for the current phase \"\"\" if ( self . _use_redis == True ): req_agent = self . _redis_db . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) if ( req_agent is not None ): return pickle . loads ( req_agent ) else : return [] else : if chat_uuid in self . _required_agents_for_current_phase : return self . _required_agents_for_current_phase . get ( chat_uuid ) return [] def remove_required_agent_for_current_phase ( self , chat_uuid : str , agent_name : str ): \"\"\" Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_name (str): the name of the agent to remove \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"required_agents_for_current_phase\" ) if ( pipe . hexists ( \"required_agents_for_current_phase\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_agents = pipe . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) stored_agents : List [ str ] = pickle . loads ( redis_stored_agents ) stored_agents . remove ( agent_name ) pipe . multi () if len ( stored_agents ) == 0 : pipe . hdel ( \"required_agents_for_current_phase\" , chat_uuid ) else : pipe . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( stored_agents )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to remove agent\" ) continue else : if chat_uuid in self . _required_agents_for_current_phase : self . _required_agents_for_current_phase . get ( chat_uuid ) . remove ( agent_name ) def get_current_query ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[str]: the current query or None if there is no current query \"\"\" if ( self . _use_redis == True ): queries = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( queries is not None ): return_list : List [ str ] = pickle . loads ( queries ) return return_list [ - 1 ] else : return None else : if chat_uuid in self . _queries : if self . _queries . get ( chat_uuid ): # return the last query return self . _queries . get ( chat_uuid )[ - 1 ] else : return None def add_query ( self , chat_uuid : str , query : str ): \"\"\" Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid query (str): the current query \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"queries\" ) if ( pipe . hexists ( \"queries\" , key = chat_uuid ) == False ): pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ([ query ])) else : redis_stored_queries = pipe . hget ( \"queries\" , key = chat_uuid ) stored_queries : List [ str ] = pickle . loads ( redis_stored_queries ) stored_queries . append ( query ) pipe . multi () pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ( stored_queries )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to add query\" ) continue else : if chat_uuid not in self . _queries : self . _queries [ chat_uuid ] = [] self . _queries [ chat_uuid ] . append ( query ) def get_queries ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List[str]: the queries attempted for the given chat uuid for this context \"\"\" if ( self . _use_redis == True ): query = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( query is not None ): return pickle . loads ( query ) else : return [] if chat_uuid in self . _queries : return self . _queries . get ( chat_uuid ) else : return [] @property def collaboration_type ( self ) -> Dict [ str , WiseAgentCollaborationType ]: \"\"\"Get the collaboration type for chat uuids for this context.\"\"\" if ( self . _use_redis == True ): return_dict : Dict [ str , WiseAgentCollaborationType ] = {} redis_dict = self . _redis_db . hgetall ( \"collaboration_type\" ) for key in redis_dict : return_dict [ key . decode ( 'utf-8' )] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _collaboration_type def get_collaboration_type ( self , chat_uuid : str ) -> WiseAgentCollaborationType : \"\"\" Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type \"\"\" if ( self . _use_redis == True ): if chat_uuid is not None : collaboration_type = self . _redis_db . hget ( \"collaboration_type\" , key = chat_uuid ) if ( collaboration_type is not None ): return pickle . loads ( collaboration_type ) else : return WiseAgentCollaborationType . INDEPENDENT else : if chat_uuid in self . _collaboration_type : return self . _collaboration_type . get ( chat_uuid ) else : return WiseAgentCollaborationType . INDEPENDENT def set_collaboration_type ( self , chat_uuid : str , collaboration_type : WiseAgentCollaborationType ): \"\"\" Set the collaboration type for the given chat uuid for this context. Args: chat_uuid (str): the chat uuid collaboration_type (WiseAgentCollaborationType): the collaboration type \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"collaboration_type\" , key = chat_uuid , value = pickle . dumps ( collaboration_type )) else : self . _collaboration_type [ chat_uuid ] = collaboration_type collaboration_type : Dict [ str , WiseAgentCollaborationType ] property Get the collaboration type for chat uuids for this context. llm_available_tools_in_chat : Dict [ str , List [ ChatCompletionToolParam ]] property Get the LLM available tools in chat of the context. llm_chat_completion : Dict [ str , List [ ChatCompletionMessageParam ]] property Get the LLM chat completion of the context. llm_required_tool_call : Dict [ str , List [ str ]] property Get the LLM required tool call of the context. return Dict[str, List[str]] message_trace : List [ str ] property Get the message trace of the context. name : str property Get the name of the context. participants : List [ str ] property Get the participants of the context. __getstate__ () Get the state of the context. Source code in wiseagents/core.py 183 184 185 186 187 188 189 def __getstate__ ( self ) -> object : '''Get the state of the context.''' state = self . __dict__ . copy () if '_redis_db' in state : del state [ '_redis_db' ] del state [ '_use_redis' ] return state __init__ ( name , config = { 'use_redis' : False }) Initialize the context with the given name. Parameters: name ( str ) \u2013 the name of the context Source code in wiseagents/core.py 159 160 161 162 163 164 165 166 167 168 169 170 def __init__ ( self , name : str , config : Optional [ Dict [ str , Any ]] = { \"use_redis\" : False }): ''' Initialize the context with the given name. Args: name (str): the name of the context''' self . _name = name self . _config = config if config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True WiseAgentRegistry . register_context ( self ) __repr__ () Return a string representation of the context. Source code in wiseagents/core.py 172 173 174 175 176 177 178 179 def __repr__ ( self ) -> str : '''Return a string representation of the context.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , message_trace= { self . message_trace } ,\" f \"participants= { self . participants } , llm_chat_completion= { self . llm_chat_completion } ,\" f \"llm_required_tool_call= { self . llm_required_tool_call } , llm_available_tools_in_chat= { self . llm_available_tools_in_chat } ,\" f \"agents_sequence= { self . _agents_sequence } , route_response_to= { self . _route_response_to } ,\" f \"agent_phase_assignments= { self . _agent_phase_assignments } , current_phase= { self . _current_phase } ,\" f \"required_agents_for_current_phase= { self . _required_agents_for_current_phase } , queries= { self . _queries } )\" ) __setstate__ ( state ) Set the state of the context. Source code in wiseagents/core.py 191 192 193 194 195 196 def __setstate__ ( self , state : object ): '''Set the state of the context.''' self . __dict__ . update ( state ) if self . _config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True add_participant ( agent_name ) Add a participant to the context. Parameters: agent ( WiseAgent ) \u2013 the agent to add Source code in wiseagents/core.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 def add_participant ( self , agent_name : str ): '''Add a participant to the context. Args: agent (WiseAgent): the agent to add''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"participants\" ) try : if ( pipe . exists ( \"participants\" ) == False ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : if agent_name not in pipe . lrange ( \"participants\" , 0 , - 1 ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : pipe . unwatch () return except redis . WatchError : logging . debug ( \"WatchError in add_participant\" ) continue else : if agent_name not in self . participants : self . _participants . append ( agent_name ) add_query ( chat_uuid , query ) Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid query ( str ) \u2013 the current query Source code in wiseagents/core.py 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 def add_query ( self , chat_uuid : str , query : str ): \"\"\" Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid query (str): the current query \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"queries\" ) if ( pipe . hexists ( \"queries\" , key = chat_uuid ) == False ): pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ([ query ])) else : redis_stored_queries = pipe . hget ( \"queries\" , key = chat_uuid ) stored_queries : List [ str ] = pickle . loads ( redis_stored_queries ) stored_queries . append ( query ) pipe . multi () pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ( stored_queries )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to add query\" ) continue else : if chat_uuid not in self . _queries : self . _queries [ chat_uuid ] = [] self . _queries [ chat_uuid ] . append ( query ) append_available_tool_in_chat ( chat_uuid , tools ) Append available tool in chat to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to append Source code in wiseagents/core.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 def append_available_tool_in_chat ( self , chat_uuid : str , tools : Iterable [ ChatCompletionToolParam ]): '''Append available tool in chat to the context. Args: chat_uuid (str): the chat uuid tools (Iterable[ChatCompletionToolParam]): the tools to append''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_available_tools_in_chat\" ) if ( pipe . hexists ( \"llm_available_tools_in_chat\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ([ tools ])) pipe . execute () break else : redis_stored_tools = pipe . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) stored_tools : List [ ChatCompletionToolParam ] = pickle . loads ( redis_stored_tools ) stored_tools . append ( tools ) pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ( stored_tools )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_available_tool_in_chat\" ) continue else : if chat_uuid not in self . _llm_available_tools_in_chat : self . _llm_available_tools_in_chat [ chat_uuid ] = [] self . _llm_available_tools_in_chat [ chat_uuid ] . append ( tools ) append_chat_completion ( chat_uuid , messages ) Append chat completion to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to append Source code in wiseagents/core.py 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 def append_chat_completion ( self , chat_uuid : str , messages : Iterable [ ChatCompletionMessageParam ]): '''Append chat completion to the context. Args: chat_uuid (str): the chat uuid messages (Iterable[ChatCompletionMessageParam]): the messages to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"llm_chat_completion\" ) try : if ( pipe . hexists ( \"llm_chat_completion\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ([ messages ])) pipe . execute () return else : redis_stored_messages = pipe . hget ( \"llm_chat_completion\" , key = chat_uuid ) stored_messages : List [ ChatCompletionMessageParam ] = pickle . loads ( redis_stored_messages ) stored_messages . append ( messages ) pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ( stored_messages )) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in append_chat_completion\" ) continue else : if chat_uuid not in self . _llm_chat_completion : self . _llm_chat_completion [ chat_uuid ] = [] self . _llm_chat_completion [ chat_uuid ] . append ( messages ) append_required_tool_call ( chat_uuid , tool_name ) Append required tool call to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tool_name ( str ) \u2013 the tool name to append Source code in wiseagents/core.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 def append_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Append required tool call to the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) if ( self . _redis_db . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): self . _redis_db . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ([ tool_name ])) pipe . execute () else : while True : try : pipe . watch ( \"llm_required_tool_call\" ) redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . append ( tool_name ) pipe . multi () pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_required_tool_call\" ) continue else : if chat_uuid not in self . llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] = [] self . _llm_required_tool_call [ chat_uuid ] . append ( tool_name ) get_agent_phase_assignments ( chat_uuid ) Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ List [ str ]] \u2013 List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the List [ List [ str ]] \u2013 size of the outer list corresponds to the number of phases and each element in the list is a list of List [ List [ str ]] \u2013 agent names for that phase. An empty list is returned if no phases have been set for the List [ List [ str ]] \u2013 given chat uuid Source code in wiseagents/core.py 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 def get_agent_phase_assignments ( self , chat_uuid : str ) -> List [ List [ str ]]: \"\"\" Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. An empty list is returned if no phases have been set for the given chat uuid \"\"\" if ( self . _use_redis == True ): agent_phase = self . _redis_db . hget ( \"agent_phase_assignments\" , key = chat_uuid ) if ( agent_phase is not None ): return pickle . loads ( agent_phase ) else : return [] else : if chat_uuid in self . _agent_phase_assignments : return self . _agent_phase_assignments . get ( chat_uuid ) return [] get_agents_for_next_phase ( chat_uuid ) Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: Optional [ List ] \u2013 Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases Source code in wiseagents/core.py 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 def get_agents_for_next_phase ( self , chat_uuid : str ) -> Optional [ List ]: \"\"\" Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases \"\"\" current_phase = self . get_current_phase ( chat_uuid ) next_phase = current_phase + 1 if next_phase < len ( self . get_agent_phase_assignments ( chat_uuid )): self . set_current_phase ( chat_uuid , next_phase ) return self . get_agent_phase_assignments ( chat_uuid )[ next_phase ] return None get_agents_sequence ( chat_uuid ) Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ str ] \u2013 List[str]: the sequence of agents names or an empty list if no sequence has been set for this context Source code in wiseagents/core.py 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 def get_agents_sequence ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid Returns: List[str]: the sequence of agents names or an empty list if no sequence has been set for this context \"\"\" if ( self . _use_redis == True ): agent_sequence = self . _redis_db . hget ( \"agents_sequence\" , key = chat_uuid ) if ( agent_sequence is not None ): return pickle . loads ( agent_sequence ) else : return [] else : if chat_uuid in self . _agents_sequence : return self . _agents_sequence [ chat_uuid ] return [] get_available_tools_in_chat ( chat_uuid ) Get available tools in chat from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid Source code in wiseagents/core.py 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 def get_available_tools_in_chat ( self , chat_uuid : str ) -> List [ ChatCompletionToolParam ]: '''Get available tools in chat from the context. Args: chat_uuid (str): the chat uuid return List[ChatCompletionToolParam]''' if ( self . _use_redis == True ): llm_av_tools = self . _redis_db . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) if ( llm_av_tools is not None ): return pickle . loads ( llm_av_tools ) else : return [] else : if chat_uuid in self . _llm_available_tools_in_chat : return self . _llm_available_tools_in_chat [ chat_uuid ] else : return [] get_collaboration_type ( chat_uuid ) Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type Source code in wiseagents/core.py 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 def get_collaboration_type ( self , chat_uuid : str ) -> WiseAgentCollaborationType : \"\"\" Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type \"\"\" if ( self . _use_redis == True ): if chat_uuid is not None : collaboration_type = self . _redis_db . hget ( \"collaboration_type\" , key = chat_uuid ) if ( collaboration_type is not None ): return pickle . loads ( collaboration_type ) else : return WiseAgentCollaborationType . INDEPENDENT else : if chat_uuid in self . _collaboration_type : return self . _collaboration_type . get ( chat_uuid ) else : return WiseAgentCollaborationType . INDEPENDENT get_current_phase ( chat_uuid ) Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: int ( int ) \u2013 the current phase, represented as an integer in the zero-indexed list of phases Source code in wiseagents/core.py 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 def get_current_phase ( self , chat_uuid : str ) -> int : \"\"\" Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: int: the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): cur_phase = self . _redis_db . hget ( \"current_phase\" , key = chat_uuid ) if ( cur_phase is not None ): return pickle . loads ( cur_phase ) else : return None else : return self . _current_phase . get ( chat_uuid ) get_current_query ( chat_uuid ) Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: Optional [ str ] \u2013 Optional[str]: the current query or None if there is no current query Source code in wiseagents/core.py 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 def get_current_query ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[str]: the current query or None if there is no current query \"\"\" if ( self . _use_redis == True ): queries = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( queries is not None ): return_list : List [ str ] = pickle . loads ( queries ) return return_list [ - 1 ] else : return None else : if chat_uuid in self . _queries : if self . _queries . get ( chat_uuid ): # return the last query return self . _queries . get ( chat_uuid )[ - 1 ] else : return None get_next_agent_in_sequence ( chat_uuid , current_agent ) Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Parameters: chat_uuid ( str ) \u2013 the chat uuid current_agent ( str ) \u2013 the name of the current agent Returns: str \u2013 the name of the next agent in the sequence after the current agent or None if there are no remaining \u2013 agents in the sequence after the current agent Source code in wiseagents/core.py 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 def get_next_agent_in_sequence ( self , chat_uuid : str , current_agent : str ): \"\"\" Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Args: chat_uuid (str): the chat uuid current_agent (str): the name of the current agent Returns: str: the name of the next agent in the sequence after the current agent or None if there are no remaining agents in the sequence after the current agent \"\"\" agents_sequence = self . get_agents_sequence ( chat_uuid ) if current_agent in agents_sequence : current_agent_index = agents_sequence . index ( current_agent ) next_agent_index = current_agent_index + 1 if next_agent_index < len ( agents_sequence ): return agents_sequence [ next_agent_index ] return None get_queries ( chat_uuid ) Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List [ str ] \u2013 List[str]: the queries attempted for the given chat uuid for this context Source code in wiseagents/core.py 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 def get_queries ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List[str]: the queries attempted for the given chat uuid for this context \"\"\" if ( self . _use_redis == True ): query = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( query is not None ): return pickle . loads ( query ) else : return [] if chat_uuid in self . _queries : return self . _queries . get ( chat_uuid ) else : return [] get_required_agents_for_current_phase ( chat_uuid ) Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ str ] \u2013 List[str]: the list of agent names that still need to be executed for the current phase or an empty list List [ str ] \u2013 if there are no remaining agents that need to be executed for the current phase Source code in wiseagents/core.py 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 def get_required_agents_for_current_phase ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[str]: the list of agent names that still need to be executed for the current phase or an empty list if there are no remaining agents that need to be executed for the current phase \"\"\" if ( self . _use_redis == True ): req_agent = self . _redis_db . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) if ( req_agent is not None ): return pickle . loads ( req_agent ) else : return [] else : if chat_uuid in self . _required_agents_for_current_phase : return self . _required_agents_for_current_phase . get ( chat_uuid ) return [] get_required_tool_calls ( chat_uuid ) Get required tool calls from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid Source code in wiseagents/core.py 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def get_required_tool_calls ( self , chat_uuid : str ) -> List [ str ]: '''Get required tool calls from the context. Args: chat_uuid (str): the chat uuid return List[str]''' if ( self . _use_redis == True ): llm_req_tools = self . _redis_db . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( llm_req_tools is not None ): return pickle . loads ( llm_req_tools ) else : return [] if chat_uuid in self . _llm_required_tool_call : return self . _llm_required_tool_call [ chat_uuid ] else : return [] get_route_response_to ( chat_uuid ) Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional [ str ] \u2013 Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set Source code in wiseagents/core.py 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 def get_route_response_to ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set \"\"\" if ( self . _use_redis == True ): route = self . _redis_db . hget ( \"route_response_to\" , key = chat_uuid ) if ( route is not None ): return pickle . loads ( route ) else : return None else : if chat_uuid in self . _route_response_to : return self . _route_response_to [ chat_uuid ] else : return None remove_required_agent_for_current_phase ( chat_uuid , agent_name ) Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent_name ( str ) \u2013 the name of the agent to remove Source code in wiseagents/core.py 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 def remove_required_agent_for_current_phase ( self , chat_uuid : str , agent_name : str ): \"\"\" Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_name (str): the name of the agent to remove \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"required_agents_for_current_phase\" ) if ( pipe . hexists ( \"required_agents_for_current_phase\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_agents = pipe . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) stored_agents : List [ str ] = pickle . loads ( redis_stored_agents ) stored_agents . remove ( agent_name ) pipe . multi () if len ( stored_agents ) == 0 : pipe . hdel ( \"required_agents_for_current_phase\" , chat_uuid ) else : pipe . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( stored_agents )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to remove agent\" ) continue else : if chat_uuid in self . _required_agents_for_current_phase : self . _required_agents_for_current_phase . get ( chat_uuid ) . remove ( agent_name ) remove_required_tool_call ( chat_uuid , tool_name ) Remove required tool call from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tool_name ( str ) \u2013 the tool name to remove Source code in wiseagents/core.py 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 def remove_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Remove required tool call from the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to remove''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_required_tool_call\" ) if ( pipe . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( redis_stored_tool_names == None ): stored_tool_names : List [ str ] = [] else : stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . remove ( tool_name ) pipe . multi () if len ( stored_tool_names ) == 0 : pipe . hdel ( \"llm_required_tool_call\" , chat_uuid ) else : pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in remove_required_tool_call\" ) continue if chat_uuid in self . _llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] . remove ( tool_name ) if len ( self . _llm_required_tool_call [ chat_uuid ]) == 0 : self . _llm_required_tool_call . pop ( chat_uuid ) set_agent_phase_assignments ( chat_uuid , agent_phase_assignments ) Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent_phase_assignments ( List [ List [ str ]] ) \u2013 The agents to be executed in each phase, represented as a Source code in wiseagents/core.py 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 def set_agent_phase_assignments ( self , chat_uuid : str , agent_phase_assignments : List [ List [ str ]]): \"\"\" Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_phase_assignments (List[List[str]]): The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agent_phase_assignments\" , key = chat_uuid , value = pickle . dumps ( agent_phase_assignments )) else : self . _agent_phase_assignments [ chat_uuid ] = agent_phase_assignments set_agents_sequence ( chat_uuid , agents_sequence ) Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Parameters: chat_uuid ( str ) \u2013 the chat uuid agents_sequence ( List [ str ] ) \u2013 the sequence of agent names Source code in wiseagents/core.py 484 485 486 487 488 489 490 491 492 493 494 495 496 497 def set_agents_sequence ( self , chat_uuid : str , agents_sequence : List [ str ]): \"\"\" Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid agents_sequence (List[str]): the sequence of agent names \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agents_sequence\" , key = chat_uuid , value = pickle . dumps ( agents_sequence )) else : self . _agents_sequence [ chat_uuid ] = agents_sequence set_collaboration_type ( chat_uuid , collaboration_type ) Set the collaboration type for the given chat uuid for this context. Parameters: chat_uuid ( str ) \u2013 the chat uuid collaboration_type ( WiseAgentCollaborationType ) \u2013 the collaboration type Source code in wiseagents/core.py 814 815 816 817 818 819 820 821 822 823 824 825 def set_collaboration_type ( self , chat_uuid : str , collaboration_type : WiseAgentCollaborationType ): \"\"\" Set the collaboration type for the given chat uuid for this context. Args: chat_uuid (str): the chat uuid collaboration_type (WiseAgentCollaborationType): the collaboration type \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"collaboration_type\" , key = chat_uuid , value = pickle . dumps ( collaboration_type )) else : self . _collaboration_type [ chat_uuid ] = collaboration_type set_current_phase ( chat_uuid , phase ) Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid phase ( int ) \u2013 the current phase, represented as an integer in the zero-indexed list of phases Source code in wiseagents/core.py 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 def set_current_phase ( self , chat_uuid : str , phase : int ): \"\"\" Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid phase (int): the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): self . _redis_db . pipeline ( transaction = True ) \\ . hset ( \"current_phase\" , key = chat_uuid , value = pickle . dumps ( phase )) \\ . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( self . get_agent_phase_assignments ( chat_uuid )[ phase ])) \\ . execute () else : self . _current_phase [ chat_uuid ] = phase self . _required_agents_for_current_phase [ chat_uuid ] = copy . deepcopy ( self . _agent_phase_assignments [ chat_uuid ][ phase ]) set_route_response_to ( chat_uuid , agent ) Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent ( str ) \u2013 the name of the agent where the final response should be routed to Source code in wiseagents/core.py 519 520 521 522 523 524 525 526 527 528 529 530 531 def set_route_response_to ( self , chat_uuid : str , agent : str ): \"\"\" Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Args: chat_uuid (str): the chat uuid agent (str): the name of the agent where the final response should be routed to \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"route_response_to\" , key = chat_uuid , value = pickle . dumps ( agent )) else : self . _route_response_to [ chat_uuid ] = agent trace ( message ) Trace the message. Source code in wiseagents/core.py 211 212 213 214 215 216 def trace ( self , message : WiseAgentMessage ): '''Trace the message.''' if ( self . _use_redis == True ): self . _redis_db . rpush ( \"message_trace\" , message . __repr__ ()) else : self . _message_trace . append ( message ) WiseAgentRegistry A Registry to get available agents and running contexts Source code in wiseagents/core.py 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 class WiseAgentRegistry : \"\"\" A Registry to get available agents and running contexts \"\"\" agents_descriptions_dict : dict [ str , str ] = {} contexts : dict [ str , WiseAgentContext ] = {} tools : dict [ str , WiseAgentTool ] = {} config : dict [ str , Any ] = {} redis_db : redis . Redis = None @classmethod def find_file ( cls , file_name , config_directory = \".wise-agents\" ) -> str : \"\"\" Find the file in the current directory or the home directory. \"\"\" # Step 1: Check the current directory local_path = os . path . join ( os . getcwd (), config_directory , file_name ) if os . path . isfile ( local_path ): return local_path # Step 2: Check the home directory home_dir = os . path . expanduser ( \"~\" ) home_path = os . path . join ( home_dir , config_directory , file_name ) if os . path . isfile ( home_path ): return home_path # If the file is not found in any of these locations, throw an exception raise FileNotFoundError ( f \"File ' { file_name } ' not found in current directory, home directory, as ' { config_directory } '/ { file_name } .\" ) @classmethod def get_config ( cls ) -> dict [ str , Any ]: \"\"\" Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture \"\"\" try : if cls . config is None or cls . config == {}: file_name = cls . find_file ( file_name = \"registry_config.yaml\" , config_directory = \".wise-agents\" ) cls . config : Dict [ str , Any ] = yaml . load ( open ( file_name ), Loader = yaml . FullLoader ) if cls . config . get ( \"use_redis\" ) == True and cls . redis_db is None : if ( cls . config . get ( \"redis_ssl\" ) is True ): cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ], username = cls . config [ \"redis_username\" ], # use your Redis user. More info https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/ password = cls . config [ \"redis_password\" ], # use your Redis password ssl = True , ssl_certfile = cls . config [ \"redis_ssl_certfile\" ], ssl_keyfile = cls . config [ \"redis_ssl_keyfile\" ], ssl_ca_certs = cls . config [ \"redis_ssl_ca_certs\" ]) else : cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ]) return cls . config except Exception as e : logging . error ( e ) exit ( 1 ) @classmethod def register_agent ( cls , agent_name : str , agent_description : str ): \"\"\" Register an agent with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"agents\" ) try : if ( pipe . hexists ( \"agents\" , agent_name ) == True ): pipe . unwatch () raise NameError ( f \"Agent with name { agent_name } already exists\" ) else : pipe . multi () pipe . hset ( \"agents\" , key = agent_name , value = agent_description ) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in register_agent\" ) continue else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : raise NameError ( f \"Agent with name { agent_name } already exists\" ) cls . agents_descriptions_dict [ agent_name ] = agent_description @classmethod def register_context ( cls , context : WiseAgentContext ): \"\"\" Register a context with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"contexts\" , key = context . name , value = pickle . dumps ( context )) else : cls . contexts [ context . name ] = context @classmethod def fetch_agents_descriptions_dict ( cls ) -> dict [ str , str ]: \"\"\" Get the dict with the agent names as keys and descriptions as values \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hgetall ( \"agents\" ) else : return cls . agents_descriptions_dict @classmethod def get_contexts ( cls ) -> dict [ str , WiseAgentContext ]: \"\"\" Get the list of contexts \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"contexts\" ) return_dictionary : Dict [ str , WiseAgentContext ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . contexts @classmethod def get_agent_description ( cls , agent_name : str ) -> str : \"\"\" Get the agent description for the agent with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return_byte = cls . redis_db . hget ( \"agents\" , key = agent_name ) if return_byte is not None : return return_byte . decode ( 'utf-8' ) else : return None else : return cls . agents_descriptions_dict . get ( agent_name ) @classmethod def get_or_create_context ( cls , context_name : str ) -> WiseAgentContext : \"\"\" Get the context with the given name \"\"\" context : WiseAgentContext = None if ( cls . get_config () . get ( \"use_redis\" ) == True ): ctx = cls . redis_db . hget ( \"contexts\" , key = context_name ) if ctx is not None : context : WiseAgentContext = pickle . loads ( ctx ) else : context = None else : context = cls . contexts . get ( context_name ) if context is None : # context creation will also register the context in the registry return WiseAgentContext ( context_name , cls . config ) else : return context @classmethod def does_context_exist ( cls , context_name : str ) -> bool : \"\"\" Get the context with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hexists ( \"contexts\" , key = context_name ) else : if cls . contexts . get ( context_name ) is None : return False else : return True @classmethod def unregister_agent ( cls , agent_name : str ): \"\"\" Remove the agent from the registry this should be used only on agents which already stopped transport connection \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"agents\" , agent_name ) else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : cls . agents_descriptions_dict . pop ( agent_name ) @classmethod def remove_context ( cls , context_name : str ): \"\"\" Remove the context from the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"contexts\" , context_name ) else : cls . contexts . pop ( context_name ) @classmethod def register_tool ( cls , tool : WiseAgentTool ): \"\"\" Register a tool with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"tools\" , key = tool . name , value = pickle . dumps ( tool )) else : cls . tools [ tool . name ] = tool @classmethod def get_tools ( cls ) -> dict [ str , WiseAgentTool ]: \"\"\" Get the list of tools \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"tools\" ) return_dictionary : Dict [ str , WiseAgentTool ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . tools @classmethod def get_tool ( cls , tool_name : str ) -> WiseAgentTool : \"\"\" Get the tool with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) piped_res = pipe . hexists ( \"tools\" , key = tool_name ) . hget ( \"tools\" , key = tool_name ) . execute () if piped_res [ 0 ]: return pickle . loads ( piped_res [ 1 ]) else : return None else : return cls . tools . get ( tool_name ) @classmethod def get_agent_names_and_descriptions ( cls ) -> List [ str ]: \"\"\" Get the list of agent names and descriptions. Returns: List[str]: the list of agent descriptions \"\"\" agent_descriptions = [] for agent_name , agent_description in cls . fetch_agents_descriptions_dict () . items (): agent_descriptions . append ( f \"Agent Name: { agent_name } Agent Description: { agent_description } \" ) return agent_descriptions does_context_exist ( context_name ) classmethod Get the context with the given name Source code in wiseagents/core.py 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 @classmethod def does_context_exist ( cls , context_name : str ) -> bool : \"\"\" Get the context with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hexists ( \"contexts\" , key = context_name ) else : if cls . contexts . get ( context_name ) is None : return False else : return True fetch_agents_descriptions_dict () classmethod Get the dict with the agent names as keys and descriptions as values Source code in wiseagents/core.py 1209 1210 1211 1212 1213 1214 1215 1216 1217 @classmethod def fetch_agents_descriptions_dict ( cls ) -> dict [ str , str ]: \"\"\" Get the dict with the agent names as keys and descriptions as values \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hgetall ( \"agents\" ) else : return cls . agents_descriptions_dict find_file ( file_name , config_directory = '.wise-agents' ) classmethod Find the file in the current directory or the home directory. Source code in wiseagents/core.py 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 @classmethod def find_file ( cls , file_name , config_directory = \".wise-agents\" ) -> str : \"\"\" Find the file in the current directory or the home directory. \"\"\" # Step 1: Check the current directory local_path = os . path . join ( os . getcwd (), config_directory , file_name ) if os . path . isfile ( local_path ): return local_path # Step 2: Check the home directory home_dir = os . path . expanduser ( \"~\" ) home_path = os . path . join ( home_dir , config_directory , file_name ) if os . path . isfile ( home_path ): return home_path # If the file is not found in any of these locations, throw an exception raise FileNotFoundError ( f \"File ' { file_name } ' not found in current directory, home directory, as ' { config_directory } '/ { file_name } .\" ) get_agent_description ( agent_name ) classmethod Get the agent description for the agent with the given name Source code in wiseagents/core.py 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 @classmethod def get_agent_description ( cls , agent_name : str ) -> str : \"\"\" Get the agent description for the agent with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return_byte = cls . redis_db . hget ( \"agents\" , key = agent_name ) if return_byte is not None : return return_byte . decode ( 'utf-8' ) else : return None else : return cls . agents_descriptions_dict . get ( agent_name ) get_agent_names_and_descriptions () classmethod Get the list of agent names and descriptions. Returns: List [ str ] \u2013 List[str]: the list of agent descriptions Source code in wiseagents/core.py 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 @classmethod def get_agent_names_and_descriptions ( cls ) -> List [ str ]: \"\"\" Get the list of agent names and descriptions. Returns: List[str]: the list of agent descriptions \"\"\" agent_descriptions = [] for agent_name , agent_description in cls . fetch_agents_descriptions_dict () . items (): agent_descriptions . append ( f \"Agent Name: { agent_name } Agent Description: { agent_description } \" ) return agent_descriptions get_config () classmethod Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture Source code in wiseagents/core.py 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 @classmethod def get_config ( cls ) -> dict [ str , Any ]: \"\"\" Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture \"\"\" try : if cls . config is None or cls . config == {}: file_name = cls . find_file ( file_name = \"registry_config.yaml\" , config_directory = \".wise-agents\" ) cls . config : Dict [ str , Any ] = yaml . load ( open ( file_name ), Loader = yaml . FullLoader ) if cls . config . get ( \"use_redis\" ) == True and cls . redis_db is None : if ( cls . config . get ( \"redis_ssl\" ) is True ): cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ], username = cls . config [ \"redis_username\" ], # use your Redis user. More info https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/ password = cls . config [ \"redis_password\" ], # use your Redis password ssl = True , ssl_certfile = cls . config [ \"redis_ssl_certfile\" ], ssl_keyfile = cls . config [ \"redis_ssl_keyfile\" ], ssl_ca_certs = cls . config [ \"redis_ssl_ca_certs\" ]) else : cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ]) return cls . config except Exception as e : logging . error ( e ) exit ( 1 ) get_contexts () classmethod Get the list of contexts Source code in wiseagents/core.py 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 @classmethod def get_contexts ( cls ) -> dict [ str , WiseAgentContext ]: \"\"\" Get the list of contexts \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"contexts\" ) return_dictionary : Dict [ str , WiseAgentContext ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . contexts get_or_create_context ( context_name ) classmethod Get the context with the given name Source code in wiseagents/core.py 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 @classmethod def get_or_create_context ( cls , context_name : str ) -> WiseAgentContext : \"\"\" Get the context with the given name \"\"\" context : WiseAgentContext = None if ( cls . get_config () . get ( \"use_redis\" ) == True ): ctx = cls . redis_db . hget ( \"contexts\" , key = context_name ) if ctx is not None : context : WiseAgentContext = pickle . loads ( ctx ) else : context = None else : context = cls . contexts . get ( context_name ) if context is None : # context creation will also register the context in the registry return WiseAgentContext ( context_name , cls . config ) else : return context get_tool ( tool_name ) classmethod Get the tool with the given name Source code in wiseagents/core.py 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 @classmethod def get_tool ( cls , tool_name : str ) -> WiseAgentTool : \"\"\" Get the tool with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) piped_res = pipe . hexists ( \"tools\" , key = tool_name ) . hget ( \"tools\" , key = tool_name ) . execute () if piped_res [ 0 ]: return pickle . loads ( piped_res [ 1 ]) else : return None else : return cls . tools . get ( tool_name ) get_tools () classmethod Get the list of tools Source code in wiseagents/core.py 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 @classmethod def get_tools ( cls ) -> dict [ str , WiseAgentTool ]: \"\"\" Get the list of tools \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"tools\" ) return_dictionary : Dict [ str , WiseAgentTool ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . tools register_agent ( agent_name , agent_description ) classmethod Register an agent with the registry Source code in wiseagents/core.py 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 @classmethod def register_agent ( cls , agent_name : str , agent_description : str ): \"\"\" Register an agent with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"agents\" ) try : if ( pipe . hexists ( \"agents\" , agent_name ) == True ): pipe . unwatch () raise NameError ( f \"Agent with name { agent_name } already exists\" ) else : pipe . multi () pipe . hset ( \"agents\" , key = agent_name , value = agent_description ) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in register_agent\" ) continue else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : raise NameError ( f \"Agent with name { agent_name } already exists\" ) cls . agents_descriptions_dict [ agent_name ] = agent_description register_context ( context ) classmethod Register a context with the registry Source code in wiseagents/core.py 1200 1201 1202 1203 1204 1205 1206 1207 1208 @classmethod def register_context ( cls , context : WiseAgentContext ): \"\"\" Register a context with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"contexts\" , key = context . name , value = pickle . dumps ( context )) else : cls . contexts [ context . name ] = context register_tool ( tool ) classmethod Register a tool with the registry Source code in wiseagents/core.py 1299 1300 1301 1302 1303 1304 1305 1306 1307 @classmethod def register_tool ( cls , tool : WiseAgentTool ): \"\"\" Register a tool with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"tools\" , key = tool . name , value = pickle . dumps ( tool )) else : cls . tools [ tool . name ] = tool remove_context ( context_name ) classmethod Remove the context from the registry Source code in wiseagents/core.py 1289 1290 1291 1292 1293 1294 1295 1296 1297 @classmethod def remove_context ( cls , context_name : str ): \"\"\" Remove the context from the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"contexts\" , context_name ) else : cls . contexts . pop ( context_name ) unregister_agent ( agent_name ) classmethod Remove the agent from the registry this should be used only on agents which already stopped transport connection Source code in wiseagents/core.py 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 @classmethod def unregister_agent ( cls , agent_name : str ): \"\"\" Remove the agent from the registry this should be used only on agents which already stopped transport connection \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"agents\" , agent_name ) else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : cls . agents_descriptions_dict . pop ( agent_name ) WiseAgentTool Bases: YAMLObject A WiseAgentTool is an abstract class that represents a tool that can be used by an agent to perform a specific task. Source code in wiseagents/core.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class WiseAgentTool ( yaml . YAMLObject ): ''' A WiseAgentTool is an abstract class that represents a tool that can be used by an agent to perform a specific task.''' yaml_tag = u '!wiseagents.WiseAgentTool' yaml_loader = WiseAgentsLoader def __init__ ( self , name : str , description : str , agent_tool : bool , parameters_json_schema : dict = {}, call_back : Optional [ Callable [ ... , str ]] = None ): ''' Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Args: name (str): the name of the tool description (str): a description of what the tool does agent_tool (bool): whether the tool is an agent tool parameters_json_schema (dict): the json schema for the parameters of the tool call_back Optional(Callable[...,str]): the callback function to execute the tool''' self . _name = name self . _description = description self . _parameters_json_schema = parameters_json_schema self . _agent_tool = agent_tool self . _call_back = call_back WiseAgentRegistry . register_tool ( self ) @classmethod def from_yaml ( cls , loader , node ): '''Load the tool from a YAML node. Args: loader (yaml.Loader): the YAML loader node (yaml.Node): the YAML node''' data = loader . construct_mapping ( node , deep = True ) return cls ( name = data . get ( '_name' ), description = data . get ( '_description' ), parameters_json_schema = data . get ( '_parameters_json_schema' ), call_back = data . get ( '_call_back' )) @property def name ( self ) -> str : \"\"\"Get the name of the tool.\"\"\" return self . _name @property def description ( self ) -> str : \"\"\"Get the description of the tool.\"\"\" return self . _description @property def call_back ( self ) -> Callable [ ... , str ]: \"\"\"Get the callback function of the tool.\"\"\" return self . _call_back @property def json_schema ( self ) -> dict : \"\"\"Get the json schema of the tool.\"\"\" return self . _parameters_json_schema @property def is_agent_tool ( self ) -> bool : \"\"\"Get the agent tool of the tool.\"\"\" return self . _agent_tool def get_tool_OpenAI_format ( self ) -> ChatCompletionToolParam : '''The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam''' return { \"type\" : \"function\" , \"function\" : { \"name\" : self . name , \"description\" : self . description , \"parameters\" : self . json_schema } } def default_call_back ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' return json . dumps ( kwargs ) def exec ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' if self . call_back is None : return self . default_call_back ( ** kwargs ) return self . call_back ( ** kwargs ) call_back : Callable [ ... , str ] property Get the callback function of the tool. description : str property Get the description of the tool. is_agent_tool : bool property Get the agent tool of the tool. json_schema : dict property Get the json schema of the tool. name : str property Get the name of the tool. __init__ ( name , description , agent_tool , parameters_json_schema = {}, call_back = None ) Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Parameters: name ( str ) \u2013 the name of the tool description ( str ) \u2013 a description of what the tool does agent_tool ( bool ) \u2013 whether the tool is an agent tool parameters_json_schema ( dict , default: {} ) \u2013 the json schema for the parameters of the tool call_back ( Optional(Callable[...,str] , default: None ) \u2013 the callback function to execute the tool Source code in wiseagents/core.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , name : str , description : str , agent_tool : bool , parameters_json_schema : dict = {}, call_back : Optional [ Callable [ ... , str ]] = None ): ''' Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Args: name (str): the name of the tool description (str): a description of what the tool does agent_tool (bool): whether the tool is an agent tool parameters_json_schema (dict): the json schema for the parameters of the tool call_back Optional(Callable[...,str]): the callback function to execute the tool''' self . _name = name self . _description = description self . _parameters_json_schema = parameters_json_schema self . _agent_tool = agent_tool self . _call_back = call_back WiseAgentRegistry . register_tool ( self ) default_call_back ( ** kwargs ) The tool should be able to execute the function with the given parameters Source code in wiseagents/core.py 100 101 102 def default_call_back ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' return json . dumps ( kwargs ) exec ( ** kwargs ) The tool should be able to execute the function with the given parameters Source code in wiseagents/core.py 104 105 106 107 108 def exec ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' if self . call_back is None : return self . default_call_back ( ** kwargs ) return self . call_back ( ** kwargs ) from_yaml ( loader , node ) classmethod Load the tool from a YAML node. Parameters: loader ( Loader ) \u2013 the YAML loader node ( Node ) \u2013 the YAML node Source code in wiseagents/core.py 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_yaml ( cls , loader , node ): '''Load the tool from a YAML node. Args: loader (yaml.Loader): the YAML loader node (yaml.Node): the YAML node''' data = loader . construct_mapping ( node , deep = True ) return cls ( name = data . get ( '_name' ), description = data . get ( '_description' ), parameters_json_schema = data . get ( '_parameters_json_schema' ), call_back = data . get ( '_call_back' )) get_tool_OpenAI_format () The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam \u2013 ChatCompletionToolParam Source code in wiseagents/core.py 87 88 89 90 91 92 93 94 95 96 97 98 def get_tool_OpenAI_format ( self ) -> ChatCompletionToolParam : '''The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam''' return { \"type\" : \"function\" , \"function\" : { \"name\" : self . name , \"description\" : self . description , \"parameters\" : self . json_schema } }","title":"core"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent","text":"Bases: YAMLObject A WiseAgent is an abstract class that represents an agent that can send and receive messages to and from other agents. Source code in wiseagents/core.py 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 class WiseAgent ( yaml . YAMLObject ): ''' A WiseAgent is an abstract class that represents an agent that can send and receive messages to and from other agents. ''' yaml_tag = u '!wiseagents.WiseAgent' yaml_loader = WiseAgentsLoader def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _llm = None obj . _vector_db = None obj . _graph_db = None obj . _collection_name = \"wise-agent-collection\" obj . _system_message = None return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : Optional [ WiseAgentLLM ] = None , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = \"wise-agent-collection\" , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): ''' Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Args: name (str): the name of the agent description (str): a description of what the agent does transport (WiseAgentTransport): the transport to use for sending and receiving messages llm (Optional[WiseAgentLLM]): the LLM associated with the agent vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent system_message Optional(str): an optional system message that can be used by the agent when processing chat completions using its LLM ''' self . _name = name self . _description = description self . _llm = llm self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db self . _transport = transport self . _system_message = system_message self . start_agent () def start_agent ( self ): ''' Start the agent by setting the call backs and starting the transport.''' self . transport . set_call_backs ( self . handle_request , self . process_event , self . process_error , self . process_response ) self . transport . start () WiseAgentRegistry . register_agent ( self . name , self . description ) def stop_agent ( self ): ''' Stop the agent by stopping the transport and removing the agent from the registry.''' self . transport . stop () WiseAgentRegistry . unregister_agent ( self . name ) def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . _collection_name } , graph_db= { self . graph_db } ,\" f \"system_message= { self . system_message } )\" ) def __eq__ ( self , value : object ) -> bool : return isinstance ( value , WiseAgent ) and self . __repr__ () == value . __repr__ () @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def description ( self ) -> str : \"\"\"Get a description of what the agent does.\"\"\" return self . _description @property def llm ( self ) -> Optional [ WiseAgentLLM ]: \"\"\"Get the LLM associated with the agent.\"\"\" return self . _llm @property def vector_db ( self ) -> Optional [ WiseAgentVectorDB ]: \"\"\"Get the vector DB associated with the agent.\"\"\" return self . _vector_db @property def collection_name ( self ) -> str : \"\"\"Get the vector DB collection name associated with the agent.\"\"\" return self . _collection_name @property def graph_db ( self ) -> Optional [ WiseAgentGraphDB ]: \"\"\"Get the graph DB associated with the agent.\"\"\" return self . _graph_db @property def transport ( self ) -> WiseAgentTransport : \"\"\"Get the transport associated with the agent.\"\"\" return self . _transport @property def system_message ( self ) -> Optional [ str ]: \"\"\"Get the system message associated with the agent.\"\"\" return self . _system_message def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_request ( message , dest_agent_name ) context . trace ( message ) def send_response ( self , message : WiseAgentMessage , dest_agent_name ): '''Send a response message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_response ( message , dest_agent_name ) context . trace ( message ) def handle_request ( self , request : WiseAgentMessage ) -> bool : \"\"\" Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Args: request (WiseAgentMessage): the request message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" context = WiseAgentRegistry . get_or_create_context ( request . context_name ) collaboration_type = context . get_collaboration_type ( request . chat_id ) conversation_history = self . get_conversation_history_if_needed ( context , request . chat_id , collaboration_type ) response_str = self . process_request ( request , conversation_history ) return self . handle_response ( response_str , request , context , collaboration_type ) def get_conversation_history_if_needed ( self , context : WiseAgentContext , chat_id : Optional [ str ], collaboration_type : str ) -> List [ ChatCompletionMessageParam ]: \"\"\" Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Args: context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent is involved in a collaboration type that makes use of the conversation history and an empty list otherwise \"\"\" if chat_id : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # this agent is involved in phased collaboration or a chat, so it needs the conversation history return context . llm_chat_completion . get ( chat_id ) # for sequential collaboration and independent agents, the shared history is not needed return [] @abstractmethod def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process the given request message to generate a response string. Args: request (WiseAgentMessage): the request message to be processed conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" ... def handle_response ( self , response_str : str , request : WiseAgentMessage , context : WiseAgentContext , collaboration_type : str ) -> bool : \"\"\" Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Args: response_str (str): the string response to be handled context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: True if the message was processed successfully, False otherwise \"\"\" if response_str : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # add this agent's response to the shared context context . append_chat_completion ( chat_uuid = request . chat_id , messages = { \"role\" : \"assistant\" , \"content\" : response_str }) # let the sender know that this agent has finished processing the request self . send_response ( WiseAgentMessage ( message = response_str , message_type = WiseAgentMessageType . ACK , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) elif collaboration_type == WiseAgentCollaborationType . SEQUENTIAL : next_agent = context . get_next_agent_in_sequence ( request . chat_id , self . name ) if next_agent is None : logging . debug ( f \"Sequential coordination complete - sending response from \" + self . name + \" to \" + context . get_route_response_to ( request . chat_id )) self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), context . get_route_response_to ( request . chat_id )) else : logging . debug ( f \"Sequential coordination continuing - sending response from \" + self . name + \" to \" + next_agent ) self . send_request ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), next_agent ) else : self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) return True @abstractmethod def process_response ( self , message : WiseAgentMessage ) -> bool : \"\"\" Callback method to process the response received from another agent which processed a request from this agent. Args: message (WiseAgentMessage): the message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" ... @abstractmethod def process_event ( self , event : WiseAgentEvent ) -> bool : \"\"\" Callback method to process the given event. Args: event (WiseAgentEvent): the event to be processed Returns: True if the event was processed successfully, False otherwise \"\"\" ... @abstractmethod def process_error ( self , error : Exception ) -> bool : \"\"\" Callback method to process the given error. Args: error (Exception): the error to be processed Returns: True if the error was processed successfully, False otherwise \"\"\" ...","title":"WiseAgent"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.collection_name","text":"Get the vector DB collection name associated with the agent.","title":"collection_name"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.description","text":"Get a description of what the agent does.","title":"description"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.graph_db","text":"Get the graph DB associated with the agent.","title":"graph_db"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.llm","text":"Get the LLM associated with the agent.","title":"llm"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.system_message","text":"Get the system message associated with the agent.","title":"system_message"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.transport","text":"Get the transport associated with the agent.","title":"transport"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.vector_db","text":"Get the vector DB associated with the agent.","title":"vector_db"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.__init__","text":"Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of what the agent does transport ( WiseAgentTransport ) \u2013 the transport to use for sending and receiving messages llm ( Optional [ WiseAgentLLM ] , default: None ) \u2013 the LLM associated with the agent vector_db ( Optional [ WiseAgentVectorDB ] , default: None ) \u2013 the vector DB associated with the agent collection_name ( Optional[str]) = \"wise-agent-collection\" , default: 'wise-agent-collection' ) \u2013 the vector DB collection name associated with the agent graph_db ( Optional [ WiseAgentGraphDB ] , default: None ) \u2013 the graph DB associated with the agent system_message ( Optional(str , default: None ) \u2013 an optional system message that can be used by the agent when processing chat Source code in wiseagents/core.py 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : Optional [ WiseAgentLLM ] = None , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = \"wise-agent-collection\" , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): ''' Initialize the agent with the given name, description, transport, LLM, vector DB, collection name, and graph DB. Args: name (str): the name of the agent description (str): a description of what the agent does transport (WiseAgentTransport): the transport to use for sending and receiving messages llm (Optional[WiseAgentLLM]): the LLM associated with the agent vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent system_message Optional(str): an optional system message that can be used by the agent when processing chat completions using its LLM ''' self . _name = name self . _description = description self . _llm = llm self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db self . _transport = transport self . _system_message = system_message self . start_agent ()","title":"__init__"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/core.py 834 835 836 837 838 839 840 841 842 def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _llm = None obj . _vector_db = None obj . _graph_db = None obj . _collection_name = \"wise-agent-collection\" obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/core.py 885 886 887 888 889 def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . _collection_name } , graph_db= { self . graph_db } ,\" f \"system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.get_conversation_history_if_needed","text":"Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Parameters: context ( WiseAgentContext ) \u2013 the shared context chat_id ( Optional [ str ] ) \u2013 the chat id, may be None collaboration_type ( str ) \u2013 the type of collaboration this agent is involved in Returns: List [ ChatCompletionMessageParam ] \u2013 List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent List [ ChatCompletionMessageParam ] \u2013 is involved in a collaboration type that makes use of the conversation history and an empty list List [ ChatCompletionMessageParam ] \u2013 otherwise Source code in wiseagents/core.py 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 def get_conversation_history_if_needed ( self , context : WiseAgentContext , chat_id : Optional [ str ], collaboration_type : str ) -> List [ ChatCompletionMessageParam ]: \"\"\" Get the conversation history for the given chat id from the given context, depending on the type of collaboration the agent is involved in (i.e., sequential, phased, independent). Args: context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: List[ChatCompletionMessageParam]: the conversation history for the given chat id if the agent is involved in a collaboration type that makes use of the conversation history and an empty list otherwise \"\"\" if chat_id : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # this agent is involved in phased collaboration or a chat, so it needs the conversation history return context . llm_chat_completion . get ( chat_id ) # for sequential collaboration and independent agents, the shared history is not needed return []","title":"get_conversation_history_if_needed"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.handle_request","text":"Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Parameters: request ( WiseAgentMessage ) \u2013 the request message to be processed Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 def handle_request ( self , request : WiseAgentMessage ) -> bool : \"\"\" Callback method to handle the given request for this agent. This method optionally retrieves conversation history from the shared context depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent) and passes this to the process_request method. Finally, it handles the response from the process_request method, ensuring the shared context is updated if necessary, and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in. Args: request (WiseAgentMessage): the request message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" context = WiseAgentRegistry . get_or_create_context ( request . context_name ) collaboration_type = context . get_collaboration_type ( request . chat_id ) conversation_history = self . get_conversation_history_if_needed ( context , request . chat_id , collaboration_type ) response_str = self . process_request ( request , conversation_history ) return self . handle_response ( response_str , request , context , collaboration_type )","title":"handle_request"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.handle_response","text":"Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Parameters: response_str ( str ) \u2013 the string response to be handled context ( WiseAgentContext ) \u2013 the shared context chat_id ( Optional [ str ] ) \u2013 the chat id, may be None collaboration_type ( str ) \u2013 the type of collaboration this agent is involved in Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 def handle_response ( self , response_str : str , request : WiseAgentMessage , context : WiseAgentContext , collaboration_type : str ) -> bool : \"\"\" Handles the given string response, ensuring the shared context is updated if necessary and determines which agent to the send the response to, both depending on the type of collaboration the agent is involved in (i.e., sequential, phased, or independent). Args: response_str (str): the string response to be handled context (WiseAgentContext): the shared context chat_id (Optional[str]): the chat id, may be None collaboration_type (str): the type of collaboration this agent is involved in Returns: True if the message was processed successfully, False otherwise \"\"\" if response_str : if ( collaboration_type == WiseAgentCollaborationType . PHASED or collaboration_type == WiseAgentCollaborationType . CHAT ): # add this agent's response to the shared context context . append_chat_completion ( chat_uuid = request . chat_id , messages = { \"role\" : \"assistant\" , \"content\" : response_str }) # let the sender know that this agent has finished processing the request self . send_response ( WiseAgentMessage ( message = response_str , message_type = WiseAgentMessageType . ACK , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) elif collaboration_type == WiseAgentCollaborationType . SEQUENTIAL : next_agent = context . get_next_agent_in_sequence ( request . chat_id , self . name ) if next_agent is None : logging . debug ( f \"Sequential coordination complete - sending response from \" + self . name + \" to \" + context . get_route_response_to ( request . chat_id )) self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), context . get_route_response_to ( request . chat_id )) else : logging . debug ( f \"Sequential coordination continuing - sending response from \" + self . name + \" to \" + next_agent ) self . send_request ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), next_agent ) else : self . send_response ( WiseAgentMessage ( message = response_str , sender = self . name , context_name = context . name , chat_id = request . chat_id ), request . sender ) return True","title":"handle_response"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.process_error","text":"Callback method to process the given error. Parameters: error ( Exception ) \u2013 the error to be processed Returns: bool \u2013 True if the error was processed successfully, False otherwise Source code in wiseagents/core.py 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 @abstractmethod def process_error ( self , error : Exception ) -> bool : \"\"\" Callback method to process the given error. Args: error (Exception): the error to be processed Returns: True if the error was processed successfully, False otherwise \"\"\" ...","title":"process_error"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.process_event","text":"Callback method to process the given event. Parameters: event ( WiseAgentEvent ) \u2013 the event to be processed Returns: bool \u2013 True if the event was processed successfully, False otherwise Source code in wiseagents/core.py 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 @abstractmethod def process_event ( self , event : WiseAgentEvent ) -> bool : \"\"\" Callback method to process the given event. Args: event (WiseAgentEvent): the event to be processed Returns: True if the event was processed successfully, False otherwise \"\"\" ...","title":"process_event"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.process_request","text":"Process the given request message to generate a response string. Parameters: request ( WiseAgentMessage ) \u2013 the request message to be processed conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/core.py 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 @abstractmethod def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process the given request message to generate a response string. Args: request (WiseAgentMessage): the request message to be processed conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" ...","title":"process_request"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.process_response","text":"Callback method to process the response received from another agent which processed a request from this agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to be processed Returns: bool \u2013 True if the message was processed successfully, False otherwise Source code in wiseagents/core.py 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 @abstractmethod def process_response ( self , message : WiseAgentMessage ) -> bool : \"\"\" Callback method to process the response received from another agent which processed a request from this agent. Args: message (WiseAgentMessage): the message to be processed Returns: True if the message was processed successfully, False otherwise \"\"\" ...","title":"process_response"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.send_request","text":"Send a request message to the destination agent with the given name. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the name of the destination agent Source code in wiseagents/core.py 934 935 936 937 938 939 940 941 942 943 944 def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_request ( message , dest_agent_name ) context . trace ( message )","title":"send_request"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.send_response","text":"Send a response message to the destination agent with the given name. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the name of the destination agent Source code in wiseagents/core.py 946 947 948 949 950 951 952 953 954 955 956 def send_response ( self , message : WiseAgentMessage , dest_agent_name ): '''Send a response message to the destination agent with the given name. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the name of the destination agent''' message . sender = self . name context = WiseAgentRegistry . get_or_create_context ( message . context_name ) context . add_participant ( self . name ) self . transport . send_response ( message , dest_agent_name ) context . trace ( message )","title":"send_response"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.start_agent","text":"Start the agent by setting the call backs and starting the transport. Source code in wiseagents/core.py 873 874 875 876 877 878 def start_agent ( self ): ''' Start the agent by setting the call backs and starting the transport.''' self . transport . set_call_backs ( self . handle_request , self . process_event , self . process_error , self . process_response ) self . transport . start () WiseAgentRegistry . register_agent ( self . name , self . description )","title":"start_agent"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgent.stop_agent","text":"Stop the agent by stopping the transport and removing the agent from the registry. Source code in wiseagents/core.py 880 881 882 883 def stop_agent ( self ): ''' Stop the agent by stopping the transport and removing the agent from the registry.''' self . transport . stop () WiseAgentRegistry . unregister_agent ( self . name )","title":"stop_agent"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext","text":"A WiseAgentContext is a class that represents a context in which agents can communicate with each other. Source code in wiseagents/core.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 class WiseAgentContext (): ''' A WiseAgentContext is a class that represents a context in which agents can communicate with each other. ''' _message_trace : List [ str ] = [] _participants : List [ str ] = [] # Maps a chat uuid to a list of chat completion messages _llm_chat_completion : Dict [ str , List [ ChatCompletionMessageParam ]] = {} # Maps a chat uuid to a list of tool names that need to be executed _llm_required_tool_call : Dict [ str , List [ str ]] = {} # Maps a chat uuid to a list of available tools in chat _llm_available_tools_in_chat : Dict [ str , List [ ChatCompletionToolParam ]] = {} # Maps a chat uuid to a list of agent names that need to be executed in sequence # Used by a sequential coordinator _agents_sequence : Dict [ str , List [ str ]] = {} # Maps a chat uuid to the agent where the final response should be routed to # Used by both a sequential coordinator and a phased coordinator _route_response_to : Dict [ str , str ] = {} # Maps a chat uuid to a list that contains a list of agent names to be executed for each phase # Used by a phased coordinator _agent_phase_assignments : Dict [ str , List [ List [ str ]]] = {} # Maps a chat uuid to the current phase. Used by a phased coordinator. _current_phase : Dict [ str , int ] = {} # Maps a chat uuid to a list of agent names that need to be executed for the current phase # Used by a phased coordinator _required_agents_for_current_phase : Dict [ str , List [ str ]] = {} # Maps a chat uuid to a list containing the queries attempted for each iteration executed by # the phased coordinator _queries : Dict [ str , List [ str ]] = {} # Maps a chat uuid to the collaboration type _collaboration_type : Dict [ str , WiseAgentCollaborationType ] = {} _redis_db : redis . Redis = None _use_redis : bool = False _config : Dict [ str , Any ] = {} def __init__ ( self , name : str , config : Optional [ Dict [ str , Any ]] = { \"use_redis\" : False }): ''' Initialize the context with the given name. Args: name (str): the name of the context''' self . _name = name self . _config = config if config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True WiseAgentRegistry . register_context ( self ) def __repr__ ( self ) -> str : '''Return a string representation of the context.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , message_trace= { self . message_trace } ,\" f \"participants= { self . participants } , llm_chat_completion= { self . llm_chat_completion } ,\" f \"llm_required_tool_call= { self . llm_required_tool_call } , llm_available_tools_in_chat= { self . llm_available_tools_in_chat } ,\" f \"agents_sequence= { self . _agents_sequence } , route_response_to= { self . _route_response_to } ,\" f \"agent_phase_assignments= { self . _agent_phase_assignments } , current_phase= { self . _current_phase } ,\" f \"required_agents_for_current_phase= { self . _required_agents_for_current_phase } , queries= { self . _queries } )\" ) def __eq__ ( self , value : object ) -> bool : return isinstance ( value , WiseAgentContext ) and self . __repr__ () == value . __repr__ () def __getstate__ ( self ) -> object : '''Get the state of the context.''' state = self . __dict__ . copy () if '_redis_db' in state : del state [ '_redis_db' ] del state [ '_use_redis' ] return state def __setstate__ ( self , state : object ): '''Set the state of the context.''' self . __dict__ . update ( state ) if self . _config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True @property def name ( self ) -> str : \"\"\"Get the name of the context.\"\"\" return self . _name @property def message_trace ( self ) -> List [ str ]: \"\"\"Get the message trace of the context.\"\"\" if ( self . _use_redis == True ): return self . _redis_db . lrange ( \"message_trace\" , 0 , - 1 ) else : return self . _message_trace def trace ( self , message : WiseAgentMessage ): '''Trace the message.''' if ( self . _use_redis == True ): self . _redis_db . rpush ( \"message_trace\" , message . __repr__ ()) else : self . _message_trace . append ( message ) @property def participants ( self ) -> List [ str ]: \"\"\"Get the participants of the context.\"\"\" if ( self . _use_redis == True ): return self . _redis_db . lrange ( \"participants\" , 0 , - 1 ) else : return self . _participants @property def llm_chat_completion ( self ) -> Dict [ str , List [ ChatCompletionMessageParam ]]: \"\"\"Get the LLM chat completion of the context.\"\"\" if ( self . _use_redis == True ): return_dict : Dict [ str , List [ ChatCompletionMessageParam ]] = {} redis_dict = self . _redis_db . hgetall ( \"llm_chat_completion\" ) for key in redis_dict : return_dict [ key . decode ( 'utf-8' )] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _llm_chat_completion def add_participant ( self , agent_name : str ): '''Add a participant to the context. Args: agent (WiseAgent): the agent to add''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"participants\" ) try : if ( pipe . exists ( \"participants\" ) == False ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : if agent_name not in pipe . lrange ( \"participants\" , 0 , - 1 ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : pipe . unwatch () return except redis . WatchError : logging . debug ( \"WatchError in add_participant\" ) continue else : if agent_name not in self . participants : self . _participants . append ( agent_name ) def append_chat_completion ( self , chat_uuid : str , messages : Iterable [ ChatCompletionMessageParam ]): '''Append chat completion to the context. Args: chat_uuid (str): the chat uuid messages (Iterable[ChatCompletionMessageParam]): the messages to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"llm_chat_completion\" ) try : if ( pipe . hexists ( \"llm_chat_completion\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ([ messages ])) pipe . execute () return else : redis_stored_messages = pipe . hget ( \"llm_chat_completion\" , key = chat_uuid ) stored_messages : List [ ChatCompletionMessageParam ] = pickle . loads ( redis_stored_messages ) stored_messages . append ( messages ) pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ( stored_messages )) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in append_chat_completion\" ) continue else : if chat_uuid not in self . _llm_chat_completion : self . _llm_chat_completion [ chat_uuid ] = [] self . _llm_chat_completion [ chat_uuid ] . append ( messages ) @property def llm_required_tool_call ( self ) -> Dict [ str , List [ str ]]: \"\"\"Get the LLM required tool call of the context. return Dict[str, List[str]]\"\"\" if ( self . _use_redis == True ): redis_dict = self . _redis_db . hgetall ( \"llm_required_tool_call\" ) return_dict : Dict [ str , List [ str ]] = {} for key in redis_dict : return_dict [ key ] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _llm_required_tool_call def append_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Append required tool call to the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) if ( self . _redis_db . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): self . _redis_db . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ([ tool_name ])) pipe . execute () else : while True : try : pipe . watch ( \"llm_required_tool_call\" ) redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . append ( tool_name ) pipe . multi () pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_required_tool_call\" ) continue else : if chat_uuid not in self . llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] = [] self . _llm_required_tool_call [ chat_uuid ] . append ( tool_name ) def remove_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Remove required tool call from the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to remove''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_required_tool_call\" ) if ( pipe . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( redis_stored_tool_names == None ): stored_tool_names : List [ str ] = [] else : stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . remove ( tool_name ) pipe . multi () if len ( stored_tool_names ) == 0 : pipe . hdel ( \"llm_required_tool_call\" , chat_uuid ) else : pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in remove_required_tool_call\" ) continue if chat_uuid in self . _llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] . remove ( tool_name ) if len ( self . _llm_required_tool_call [ chat_uuid ]) == 0 : self . _llm_required_tool_call . pop ( chat_uuid ) def get_required_tool_calls ( self , chat_uuid : str ) -> List [ str ]: '''Get required tool calls from the context. Args: chat_uuid (str): the chat uuid return List[str]''' if ( self . _use_redis == True ): llm_req_tools = self . _redis_db . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( llm_req_tools is not None ): return pickle . loads ( llm_req_tools ) else : return [] if chat_uuid in self . _llm_required_tool_call : return self . _llm_required_tool_call [ chat_uuid ] else : return [] @property def llm_available_tools_in_chat ( self ) -> Dict [ str , List [ ChatCompletionToolParam ]]: \"\"\"Get the LLM available tools in chat of the context.\"\"\" if ( self . _use_redis == True ): redis_dict = self . _redis_db . hgetall ( \"llm_available_tools_in_chat\" ) return_dict : Dict [ str , List [ ChatCompletionToolParam ]] = {} for key in redis_dict : return_dict [ key ] = pickle . loads ( redis_dict [ key ]) return return_dict return self . _llm_available_tools_in_chat def append_available_tool_in_chat ( self , chat_uuid : str , tools : Iterable [ ChatCompletionToolParam ]): '''Append available tool in chat to the context. Args: chat_uuid (str): the chat uuid tools (Iterable[ChatCompletionToolParam]): the tools to append''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_available_tools_in_chat\" ) if ( pipe . hexists ( \"llm_available_tools_in_chat\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ([ tools ])) pipe . execute () break else : redis_stored_tools = pipe . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) stored_tools : List [ ChatCompletionToolParam ] = pickle . loads ( redis_stored_tools ) stored_tools . append ( tools ) pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ( stored_tools )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_available_tool_in_chat\" ) continue else : if chat_uuid not in self . _llm_available_tools_in_chat : self . _llm_available_tools_in_chat [ chat_uuid ] = [] self . _llm_available_tools_in_chat [ chat_uuid ] . append ( tools ) def get_available_tools_in_chat ( self , chat_uuid : str ) -> List [ ChatCompletionToolParam ]: '''Get available tools in chat from the context. Args: chat_uuid (str): the chat uuid return List[ChatCompletionToolParam]''' if ( self . _use_redis == True ): llm_av_tools = self . _redis_db . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) if ( llm_av_tools is not None ): return pickle . loads ( llm_av_tools ) else : return [] else : if chat_uuid in self . _llm_available_tools_in_chat : return self . _llm_available_tools_in_chat [ chat_uuid ] else : return [] def get_agents_sequence ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid Returns: List[str]: the sequence of agents names or an empty list if no sequence has been set for this context \"\"\" if ( self . _use_redis == True ): agent_sequence = self . _redis_db . hget ( \"agents_sequence\" , key = chat_uuid ) if ( agent_sequence is not None ): return pickle . loads ( agent_sequence ) else : return [] else : if chat_uuid in self . _agents_sequence : return self . _agents_sequence [ chat_uuid ] return [] def set_agents_sequence ( self , chat_uuid : str , agents_sequence : List [ str ]): \"\"\" Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid agents_sequence (List[str]): the sequence of agent names \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agents_sequence\" , key = chat_uuid , value = pickle . dumps ( agents_sequence )) else : self . _agents_sequence [ chat_uuid ] = agents_sequence def get_route_response_to ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set \"\"\" if ( self . _use_redis == True ): route = self . _redis_db . hget ( \"route_response_to\" , key = chat_uuid ) if ( route is not None ): return pickle . loads ( route ) else : return None else : if chat_uuid in self . _route_response_to : return self . _route_response_to [ chat_uuid ] else : return None def set_route_response_to ( self , chat_uuid : str , agent : str ): \"\"\" Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Args: chat_uuid (str): the chat uuid agent (str): the name of the agent where the final response should be routed to \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"route_response_to\" , key = chat_uuid , value = pickle . dumps ( agent )) else : self . _route_response_to [ chat_uuid ] = agent def get_next_agent_in_sequence ( self , chat_uuid : str , current_agent : str ): \"\"\" Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Args: chat_uuid (str): the chat uuid current_agent (str): the name of the current agent Returns: str: the name of the next agent in the sequence after the current agent or None if there are no remaining agents in the sequence after the current agent \"\"\" agents_sequence = self . get_agents_sequence ( chat_uuid ) if current_agent in agents_sequence : current_agent_index = agents_sequence . index ( current_agent ) next_agent_index = current_agent_index + 1 if next_agent_index < len ( agents_sequence ): return agents_sequence [ next_agent_index ] return None def get_agent_phase_assignments ( self , chat_uuid : str ) -> List [ List [ str ]]: \"\"\" Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. An empty list is returned if no phases have been set for the given chat uuid \"\"\" if ( self . _use_redis == True ): agent_phase = self . _redis_db . hget ( \"agent_phase_assignments\" , key = chat_uuid ) if ( agent_phase is not None ): return pickle . loads ( agent_phase ) else : return [] else : if chat_uuid in self . _agent_phase_assignments : return self . _agent_phase_assignments . get ( chat_uuid ) return [] def set_agent_phase_assignments ( self , chat_uuid : str , agent_phase_assignments : List [ List [ str ]]): \"\"\" Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_phase_assignments (List[List[str]]): The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agent_phase_assignments\" , key = chat_uuid , value = pickle . dumps ( agent_phase_assignments )) else : self . _agent_phase_assignments [ chat_uuid ] = agent_phase_assignments def get_current_phase ( self , chat_uuid : str ) -> int : \"\"\" Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: int: the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): cur_phase = self . _redis_db . hget ( \"current_phase\" , key = chat_uuid ) if ( cur_phase is not None ): return pickle . loads ( cur_phase ) else : return None else : return self . _current_phase . get ( chat_uuid ) def set_current_phase ( self , chat_uuid : str , phase : int ): \"\"\" Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid phase (int): the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): self . _redis_db . pipeline ( transaction = True ) \\ . hset ( \"current_phase\" , key = chat_uuid , value = pickle . dumps ( phase )) \\ . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( self . get_agent_phase_assignments ( chat_uuid )[ phase ])) \\ . execute () else : self . _current_phase [ chat_uuid ] = phase self . _required_agents_for_current_phase [ chat_uuid ] = copy . deepcopy ( self . _agent_phase_assignments [ chat_uuid ][ phase ]) def get_agents_for_next_phase ( self , chat_uuid : str ) -> Optional [ List ]: \"\"\" Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases \"\"\" current_phase = self . get_current_phase ( chat_uuid ) next_phase = current_phase + 1 if next_phase < len ( self . get_agent_phase_assignments ( chat_uuid )): self . set_current_phase ( chat_uuid , next_phase ) return self . get_agent_phase_assignments ( chat_uuid )[ next_phase ] return None def get_required_agents_for_current_phase ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[str]: the list of agent names that still need to be executed for the current phase or an empty list if there are no remaining agents that need to be executed for the current phase \"\"\" if ( self . _use_redis == True ): req_agent = self . _redis_db . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) if ( req_agent is not None ): return pickle . loads ( req_agent ) else : return [] else : if chat_uuid in self . _required_agents_for_current_phase : return self . _required_agents_for_current_phase . get ( chat_uuid ) return [] def remove_required_agent_for_current_phase ( self , chat_uuid : str , agent_name : str ): \"\"\" Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_name (str): the name of the agent to remove \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"required_agents_for_current_phase\" ) if ( pipe . hexists ( \"required_agents_for_current_phase\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_agents = pipe . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) stored_agents : List [ str ] = pickle . loads ( redis_stored_agents ) stored_agents . remove ( agent_name ) pipe . multi () if len ( stored_agents ) == 0 : pipe . hdel ( \"required_agents_for_current_phase\" , chat_uuid ) else : pipe . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( stored_agents )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to remove agent\" ) continue else : if chat_uuid in self . _required_agents_for_current_phase : self . _required_agents_for_current_phase . get ( chat_uuid ) . remove ( agent_name ) def get_current_query ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[str]: the current query or None if there is no current query \"\"\" if ( self . _use_redis == True ): queries = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( queries is not None ): return_list : List [ str ] = pickle . loads ( queries ) return return_list [ - 1 ] else : return None else : if chat_uuid in self . _queries : if self . _queries . get ( chat_uuid ): # return the last query return self . _queries . get ( chat_uuid )[ - 1 ] else : return None def add_query ( self , chat_uuid : str , query : str ): \"\"\" Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid query (str): the current query \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"queries\" ) if ( pipe . hexists ( \"queries\" , key = chat_uuid ) == False ): pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ([ query ])) else : redis_stored_queries = pipe . hget ( \"queries\" , key = chat_uuid ) stored_queries : List [ str ] = pickle . loads ( redis_stored_queries ) stored_queries . append ( query ) pipe . multi () pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ( stored_queries )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to add query\" ) continue else : if chat_uuid not in self . _queries : self . _queries [ chat_uuid ] = [] self . _queries [ chat_uuid ] . append ( query ) def get_queries ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List[str]: the queries attempted for the given chat uuid for this context \"\"\" if ( self . _use_redis == True ): query = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( query is not None ): return pickle . loads ( query ) else : return [] if chat_uuid in self . _queries : return self . _queries . get ( chat_uuid ) else : return [] @property def collaboration_type ( self ) -> Dict [ str , WiseAgentCollaborationType ]: \"\"\"Get the collaboration type for chat uuids for this context.\"\"\" if ( self . _use_redis == True ): return_dict : Dict [ str , WiseAgentCollaborationType ] = {} redis_dict = self . _redis_db . hgetall ( \"collaboration_type\" ) for key in redis_dict : return_dict [ key . decode ( 'utf-8' )] = pickle . loads ( redis_dict [ key ]) return return_dict else : return self . _collaboration_type def get_collaboration_type ( self , chat_uuid : str ) -> WiseAgentCollaborationType : \"\"\" Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type \"\"\" if ( self . _use_redis == True ): if chat_uuid is not None : collaboration_type = self . _redis_db . hget ( \"collaboration_type\" , key = chat_uuid ) if ( collaboration_type is not None ): return pickle . loads ( collaboration_type ) else : return WiseAgentCollaborationType . INDEPENDENT else : if chat_uuid in self . _collaboration_type : return self . _collaboration_type . get ( chat_uuid ) else : return WiseAgentCollaborationType . INDEPENDENT def set_collaboration_type ( self , chat_uuid : str , collaboration_type : WiseAgentCollaborationType ): \"\"\" Set the collaboration type for the given chat uuid for this context. Args: chat_uuid (str): the chat uuid collaboration_type (WiseAgentCollaborationType): the collaboration type \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"collaboration_type\" , key = chat_uuid , value = pickle . dumps ( collaboration_type )) else : self . _collaboration_type [ chat_uuid ] = collaboration_type","title":"WiseAgentContext"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.collaboration_type","text":"Get the collaboration type for chat uuids for this context.","title":"collaboration_type"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.llm_available_tools_in_chat","text":"Get the LLM available tools in chat of the context.","title":"llm_available_tools_in_chat"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.llm_chat_completion","text":"Get the LLM chat completion of the context.","title":"llm_chat_completion"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.llm_required_tool_call","text":"Get the LLM required tool call of the context. return Dict[str, List[str]]","title":"llm_required_tool_call"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.message_trace","text":"Get the message trace of the context.","title":"message_trace"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.name","text":"Get the name of the context.","title":"name"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.participants","text":"Get the participants of the context.","title":"participants"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.__getstate__","text":"Get the state of the context. Source code in wiseagents/core.py 183 184 185 186 187 188 189 def __getstate__ ( self ) -> object : '''Get the state of the context.''' state = self . __dict__ . copy () if '_redis_db' in state : del state [ '_redis_db' ] del state [ '_use_redis' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.__init__","text":"Initialize the context with the given name. Parameters: name ( str ) \u2013 the name of the context Source code in wiseagents/core.py 159 160 161 162 163 164 165 166 167 168 169 170 def __init__ ( self , name : str , config : Optional [ Dict [ str , Any ]] = { \"use_redis\" : False }): ''' Initialize the context with the given name. Args: name (str): the name of the context''' self . _name = name self . _config = config if config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True WiseAgentRegistry . register_context ( self )","title":"__init__"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.__repr__","text":"Return a string representation of the context. Source code in wiseagents/core.py 172 173 174 175 176 177 178 179 def __repr__ ( self ) -> str : '''Return a string representation of the context.''' return ( f \" { self . __class__ . __name__ } (name= { self . name } , message_trace= { self . message_trace } ,\" f \"participants= { self . participants } , llm_chat_completion= { self . llm_chat_completion } ,\" f \"llm_required_tool_call= { self . llm_required_tool_call } , llm_available_tools_in_chat= { self . llm_available_tools_in_chat } ,\" f \"agents_sequence= { self . _agents_sequence } , route_response_to= { self . _route_response_to } ,\" f \"agent_phase_assignments= { self . _agent_phase_assignments } , current_phase= { self . _current_phase } ,\" f \"required_agents_for_current_phase= { self . _required_agents_for_current_phase } , queries= { self . _queries } )\" )","title":"__repr__"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.__setstate__","text":"Set the state of the context. Source code in wiseagents/core.py 191 192 193 194 195 196 def __setstate__ ( self , state : object ): '''Set the state of the context.''' self . __dict__ . update ( state ) if self . _config . get ( \"use_redis\" ) == True and self . _redis_db is None : self . _redis_db = redis . Redis ( host = self . _config [ \"redis_host\" ], port = self . _config [ \"redis_port\" ]) self . _use_redis = True","title":"__setstate__"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.add_participant","text":"Add a participant to the context. Parameters: agent ( WiseAgent ) \u2013 the agent to add Source code in wiseagents/core.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 def add_participant ( self , agent_name : str ): '''Add a participant to the context. Args: agent (WiseAgent): the agent to add''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"participants\" ) try : if ( pipe . exists ( \"participants\" ) == False ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : if agent_name not in pipe . lrange ( \"participants\" , 0 , - 1 ): pipe . multi () pipe . rpush ( \"participants\" , agent_name ) pipe . execute () return else : pipe . unwatch () return except redis . WatchError : logging . debug ( \"WatchError in add_participant\" ) continue else : if agent_name not in self . participants : self . _participants . append ( agent_name )","title":"add_participant"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.add_query","text":"Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid query ( str ) \u2013 the current query Source code in wiseagents/core.py 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 def add_query ( self , chat_uuid : str , query : str ): \"\"\" Add the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid query (str): the current query \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"queries\" ) if ( pipe . hexists ( \"queries\" , key = chat_uuid ) == False ): pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ([ query ])) else : redis_stored_queries = pipe . hget ( \"queries\" , key = chat_uuid ) stored_queries : List [ str ] = pickle . loads ( redis_stored_queries ) stored_queries . append ( query ) pipe . multi () pipe . hset ( \"queries\" , key = chat_uuid , value = pickle . dumps ( stored_queries )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to add query\" ) continue else : if chat_uuid not in self . _queries : self . _queries [ chat_uuid ] = [] self . _queries [ chat_uuid ] . append ( query )","title":"add_query"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.append_available_tool_in_chat","text":"Append available tool in chat to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to append Source code in wiseagents/core.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 def append_available_tool_in_chat ( self , chat_uuid : str , tools : Iterable [ ChatCompletionToolParam ]): '''Append available tool in chat to the context. Args: chat_uuid (str): the chat uuid tools (Iterable[ChatCompletionToolParam]): the tools to append''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_available_tools_in_chat\" ) if ( pipe . hexists ( \"llm_available_tools_in_chat\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ([ tools ])) pipe . execute () break else : redis_stored_tools = pipe . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) stored_tools : List [ ChatCompletionToolParam ] = pickle . loads ( redis_stored_tools ) stored_tools . append ( tools ) pipe . multi () pipe . hset ( \"llm_available_tools_in_chat\" , key = chat_uuid , value = pickle . dumps ( stored_tools )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_available_tool_in_chat\" ) continue else : if chat_uuid not in self . _llm_available_tools_in_chat : self . _llm_available_tools_in_chat [ chat_uuid ] = [] self . _llm_available_tools_in_chat [ chat_uuid ] . append ( tools )","title":"append_available_tool_in_chat"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.append_chat_completion","text":"Append chat completion to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to append Source code in wiseagents/core.py 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 def append_chat_completion ( self , chat_uuid : str , messages : Iterable [ ChatCompletionMessageParam ]): '''Append chat completion to the context. Args: chat_uuid (str): the chat uuid messages (Iterable[ChatCompletionMessageParam]): the messages to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"llm_chat_completion\" ) try : if ( pipe . hexists ( \"llm_chat_completion\" , key = chat_uuid ) == False ): pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ([ messages ])) pipe . execute () return else : redis_stored_messages = pipe . hget ( \"llm_chat_completion\" , key = chat_uuid ) stored_messages : List [ ChatCompletionMessageParam ] = pickle . loads ( redis_stored_messages ) stored_messages . append ( messages ) pipe . multi () pipe . hset ( \"llm_chat_completion\" , key = chat_uuid , value = pickle . dumps ( stored_messages )) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in append_chat_completion\" ) continue else : if chat_uuid not in self . _llm_chat_completion : self . _llm_chat_completion [ chat_uuid ] = [] self . _llm_chat_completion [ chat_uuid ] . append ( messages )","title":"append_chat_completion"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.append_required_tool_call","text":"Append required tool call to the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tool_name ( str ) \u2013 the tool name to append Source code in wiseagents/core.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 def append_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Append required tool call to the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to append''' if ( self . _use_redis == True ): pipe = self . _redis_db . pipeline ( transaction = True ) if ( self . _redis_db . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): self . _redis_db . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ([ tool_name ])) pipe . execute () else : while True : try : pipe . watch ( \"llm_required_tool_call\" ) redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . append ( tool_name ) pipe . multi () pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in append_required_tool_call\" ) continue else : if chat_uuid not in self . llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] = [] self . _llm_required_tool_call [ chat_uuid ] . append ( tool_name )","title":"append_required_tool_call"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_agent_phase_assignments","text":"Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ List [ str ]] \u2013 List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the List [ List [ str ]] \u2013 size of the outer list corresponds to the number of phases and each element in the list is a list of List [ List [ str ]] \u2013 agent names for that phase. An empty list is returned if no phases have been set for the List [ List [ str ]] \u2013 given chat uuid Source code in wiseagents/core.py 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 def get_agent_phase_assignments ( self , chat_uuid : str ) -> List [ List [ str ]]: \"\"\" Get the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[List[str]]: The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. An empty list is returned if no phases have been set for the given chat uuid \"\"\" if ( self . _use_redis == True ): agent_phase = self . _redis_db . hget ( \"agent_phase_assignments\" , key = chat_uuid ) if ( agent_phase is not None ): return pickle . loads ( agent_phase ) else : return [] else : if chat_uuid in self . _agent_phase_assignments : return self . _agent_phase_assignments . get ( chat_uuid ) return []","title":"get_agent_phase_assignments"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_agents_for_next_phase","text":"Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: Optional [ List ] \u2013 Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases Source code in wiseagents/core.py 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 def get_agents_for_next_phase ( self , chat_uuid : str ) -> Optional [ List ]: \"\"\" Get the list of agents to be executed for the next phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[List[str]]: the list of agent names for the next phase or None if there are no more phases \"\"\" current_phase = self . get_current_phase ( chat_uuid ) next_phase = current_phase + 1 if next_phase < len ( self . get_agent_phase_assignments ( chat_uuid )): self . set_current_phase ( chat_uuid , next_phase ) return self . get_agent_phase_assignments ( chat_uuid )[ next_phase ] return None","title":"get_agents_for_next_phase"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_agents_sequence","text":"Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ str ] \u2013 List[str]: the sequence of agents names or an empty list if no sequence has been set for this context Source code in wiseagents/core.py 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 def get_agents_sequence ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid Returns: List[str]: the sequence of agents names or an empty list if no sequence has been set for this context \"\"\" if ( self . _use_redis == True ): agent_sequence = self . _redis_db . hget ( \"agents_sequence\" , key = chat_uuid ) if ( agent_sequence is not None ): return pickle . loads ( agent_sequence ) else : return [] else : if chat_uuid in self . _agents_sequence : return self . _agents_sequence [ chat_uuid ] return []","title":"get_agents_sequence"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_available_tools_in_chat","text":"Get available tools in chat from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid Source code in wiseagents/core.py 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 def get_available_tools_in_chat ( self , chat_uuid : str ) -> List [ ChatCompletionToolParam ]: '''Get available tools in chat from the context. Args: chat_uuid (str): the chat uuid return List[ChatCompletionToolParam]''' if ( self . _use_redis == True ): llm_av_tools = self . _redis_db . hget ( \"llm_available_tools_in_chat\" , key = chat_uuid ) if ( llm_av_tools is not None ): return pickle . loads ( llm_av_tools ) else : return [] else : if chat_uuid in self . _llm_available_tools_in_chat : return self . _llm_available_tools_in_chat [ chat_uuid ] else : return []","title":"get_available_tools_in_chat"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_collaboration_type","text":"Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type Source code in wiseagents/core.py 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 def get_collaboration_type ( self , chat_uuid : str ) -> WiseAgentCollaborationType : \"\"\" Get the collaboration type for the given chat uuid for this context. Args: chat_uuid (Optional[str]): the chat uuid, may be None Returns: WiseAgentCollaborationType: the collaboration type \"\"\" if ( self . _use_redis == True ): if chat_uuid is not None : collaboration_type = self . _redis_db . hget ( \"collaboration_type\" , key = chat_uuid ) if ( collaboration_type is not None ): return pickle . loads ( collaboration_type ) else : return WiseAgentCollaborationType . INDEPENDENT else : if chat_uuid in self . _collaboration_type : return self . _collaboration_type . get ( chat_uuid ) else : return WiseAgentCollaborationType . INDEPENDENT","title":"get_collaboration_type"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_current_phase","text":"Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: int ( int ) \u2013 the current phase, represented as an integer in the zero-indexed list of phases Source code in wiseagents/core.py 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 def get_current_phase ( self , chat_uuid : str ) -> int : \"\"\" Get the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: int: the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): cur_phase = self . _redis_db . hget ( \"current_phase\" , key = chat_uuid ) if ( cur_phase is not None ): return pickle . loads ( cur_phase ) else : return None else : return self . _current_phase . get ( chat_uuid )","title":"get_current_phase"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_current_query","text":"Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: Optional [ str ] \u2013 Optional[str]: the current query or None if there is no current query Source code in wiseagents/core.py 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 def get_current_query ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the current query for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: Optional[str]: the current query or None if there is no current query \"\"\" if ( self . _use_redis == True ): queries = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( queries is not None ): return_list : List [ str ] = pickle . loads ( queries ) return return_list [ - 1 ] else : return None else : if chat_uuid in self . _queries : if self . _queries . get ( chat_uuid ): # return the last query return self . _queries . get ( chat_uuid )[ - 1 ] else : return None","title":"get_current_query"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_next_agent_in_sequence","text":"Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Parameters: chat_uuid ( str ) \u2013 the chat uuid current_agent ( str ) \u2013 the name of the current agent Returns: str \u2013 the name of the next agent in the sequence after the current agent or None if there are no remaining \u2013 agents in the sequence after the current agent Source code in wiseagents/core.py 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 def get_next_agent_in_sequence ( self , chat_uuid : str , current_agent : str ): \"\"\" Get the name of the next agent in the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to determine the name of the next agent to execute. Args: chat_uuid (str): the chat uuid current_agent (str): the name of the current agent Returns: str: the name of the next agent in the sequence after the current agent or None if there are no remaining agents in the sequence after the current agent \"\"\" agents_sequence = self . get_agents_sequence ( chat_uuid ) if current_agent in agents_sequence : current_agent_index = agents_sequence . index ( current_agent ) next_agent_index = current_agent_index + 1 if next_agent_index < len ( agents_sequence ): return agents_sequence [ next_agent_index ] return None","title":"get_next_agent_in_sequence"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_queries","text":"Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List [ str ] \u2013 List[str]: the queries attempted for the given chat uuid for this context Source code in wiseagents/core.py 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 def get_queries ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the queries attempted for the given chat uuid for this context. This is used by a phased coordinator. Returns: List[str]: the queries attempted for the given chat uuid for this context \"\"\" if ( self . _use_redis == True ): query = self . _redis_db . hget ( \"queries\" , key = chat_uuid ) if ( query is not None ): return pickle . loads ( query ) else : return [] if chat_uuid in self . _queries : return self . _queries . get ( chat_uuid ) else : return []","title":"get_queries"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_required_agents_for_current_phase","text":"Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid Returns: List [ str ] \u2013 List[str]: the list of agent names that still need to be executed for the current phase or an empty list List [ str ] \u2013 if there are no remaining agents that need to be executed for the current phase Source code in wiseagents/core.py 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 def get_required_agents_for_current_phase ( self , chat_uuid : str ) -> List [ str ]: \"\"\" Get the list of agents that still need to be executed for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid Returns: List[str]: the list of agent names that still need to be executed for the current phase or an empty list if there are no remaining agents that need to be executed for the current phase \"\"\" if ( self . _use_redis == True ): req_agent = self . _redis_db . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) if ( req_agent is not None ): return pickle . loads ( req_agent ) else : return [] else : if chat_uuid in self . _required_agents_for_current_phase : return self . _required_agents_for_current_phase . get ( chat_uuid ) return []","title":"get_required_agents_for_current_phase"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_required_tool_calls","text":"Get required tool calls from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid Source code in wiseagents/core.py 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def get_required_tool_calls ( self , chat_uuid : str ) -> List [ str ]: '''Get required tool calls from the context. Args: chat_uuid (str): the chat uuid return List[str]''' if ( self . _use_redis == True ): llm_req_tools = self . _redis_db . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( llm_req_tools is not None ): return pickle . loads ( llm_req_tools ) else : return [] if chat_uuid in self . _llm_required_tool_call : return self . _llm_required_tool_call [ chat_uuid ] else : return []","title":"get_required_tool_calls"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.get_route_response_to","text":"Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional [ str ] \u2013 Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set Source code in wiseagents/core.py 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 def get_route_response_to ( self , chat_uuid : str ) -> Optional [ str ]: \"\"\" Get the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Returns: Optional[str]: the name of the agent where the final response should be routed to or None if no agent is set \"\"\" if ( self . _use_redis == True ): route = self . _redis_db . hget ( \"route_response_to\" , key = chat_uuid ) if ( route is not None ): return pickle . loads ( route ) else : return None else : if chat_uuid in self . _route_response_to : return self . _route_response_to [ chat_uuid ] else : return None","title":"get_route_response_to"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.remove_required_agent_for_current_phase","text":"Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent_name ( str ) \u2013 the name of the agent to remove Source code in wiseagents/core.py 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 def remove_required_agent_for_current_phase ( self , chat_uuid : str , agent_name : str ): \"\"\" Remove the given agent from the list of required agents for the current phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_name (str): the name of the agent to remove \"\"\" if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"required_agents_for_current_phase\" ) if ( pipe . hexists ( \"required_agents_for_current_phase\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_agents = pipe . hget ( \"required_agents_for_current_phase\" , key = chat_uuid ) stored_agents : List [ str ] = pickle . loads ( redis_stored_agents ) stored_agents . remove ( agent_name ) pipe . multi () if len ( stored_agents ) == 0 : pipe . hdel ( \"required_agents_for_current_phase\" , chat_uuid ) else : pipe . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( stored_agents )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError: Retrying to remove agent\" ) continue else : if chat_uuid in self . _required_agents_for_current_phase : self . _required_agents_for_current_phase . get ( chat_uuid ) . remove ( agent_name )","title":"remove_required_agent_for_current_phase"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.remove_required_tool_call","text":"Remove required tool call from the context. Parameters: chat_uuid ( str ) \u2013 the chat uuid tool_name ( str ) \u2013 the tool name to remove Source code in wiseagents/core.py 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 def remove_required_tool_call ( self , chat_uuid : str , tool_name : str ): '''Remove required tool call from the context. Args: chat_uuid (str): the chat uuid tool_name (str): the tool name to remove''' if ( self . _use_redis == True ): while True : try : pipe = self . _redis_db . pipeline ( transaction = True ) pipe . watch ( \"llm_required_tool_call\" ) if ( pipe . hexists ( \"llm_required_tool_call\" , key = chat_uuid ) == False ): pipe . unwatch () return redis_stored_tool_names = pipe . hget ( \"llm_required_tool_call\" , key = chat_uuid ) if ( redis_stored_tool_names == None ): stored_tool_names : List [ str ] = [] else : stored_tool_names : List [ str ] = pickle . loads ( redis_stored_tool_names ) stored_tool_names . remove ( tool_name ) pipe . multi () if len ( stored_tool_names ) == 0 : pipe . hdel ( \"llm_required_tool_call\" , chat_uuid ) else : pipe . hset ( \"llm_required_tool_call\" , key = chat_uuid , value = pickle . dumps ( stored_tool_names )) pipe . execute () break except redis . WatchError : logging . warning ( \"WatchError in remove_required_tool_call\" ) continue if chat_uuid in self . _llm_required_tool_call : self . _llm_required_tool_call [ chat_uuid ] . remove ( tool_name ) if len ( self . _llm_required_tool_call [ chat_uuid ]) == 0 : self . _llm_required_tool_call . pop ( chat_uuid )","title":"remove_required_tool_call"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.set_agent_phase_assignments","text":"Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent_phase_assignments ( List [ List [ str ]] ) \u2013 The agents to be executed in each phase, represented as a Source code in wiseagents/core.py 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 def set_agent_phase_assignments ( self , chat_uuid : str , agent_phase_assignments : List [ List [ str ]]): \"\"\" Set the agents to be executed in each phase for the given chat uuid for this context. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid agent_phase_assignments (List[List[str]]): The agents to be executed in each phase, represented as a list of lists, where the size of the outer list corresponds to the number of phases and each element in the list is a list of agent names for that phase. \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agent_phase_assignments\" , key = chat_uuid , value = pickle . dumps ( agent_phase_assignments )) else : self . _agent_phase_assignments [ chat_uuid ] = agent_phase_assignments","title":"set_agent_phase_assignments"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.set_agents_sequence","text":"Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Parameters: chat_uuid ( str ) \u2013 the chat uuid agents_sequence ( List [ str ] ) \u2013 the sequence of agent names Source code in wiseagents/core.py 484 485 486 487 488 489 490 491 492 493 494 495 496 497 def set_agents_sequence ( self , chat_uuid : str , agents_sequence : List [ str ]): \"\"\" Set the sequence of agents for the given chat uuid for this context. This is used by a sequential coordinator to execute its agents in a specific order, passing the output from one agent in the sequence to the next agent in the sequence. Args: chat_uuid (str): the chat uuid agents_sequence (List[str]): the sequence of agent names \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"agents_sequence\" , key = chat_uuid , value = pickle . dumps ( agents_sequence )) else : self . _agents_sequence [ chat_uuid ] = agents_sequence","title":"set_agents_sequence"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.set_collaboration_type","text":"Set the collaboration type for the given chat uuid for this context. Parameters: chat_uuid ( str ) \u2013 the chat uuid collaboration_type ( WiseAgentCollaborationType ) \u2013 the collaboration type Source code in wiseagents/core.py 814 815 816 817 818 819 820 821 822 823 824 825 def set_collaboration_type ( self , chat_uuid : str , collaboration_type : WiseAgentCollaborationType ): \"\"\" Set the collaboration type for the given chat uuid for this context. Args: chat_uuid (str): the chat uuid collaboration_type (WiseAgentCollaborationType): the collaboration type \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"collaboration_type\" , key = chat_uuid , value = pickle . dumps ( collaboration_type )) else : self . _collaboration_type [ chat_uuid ] = collaboration_type","title":"set_collaboration_type"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.set_current_phase","text":"Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid phase ( int ) \u2013 the current phase, represented as an integer in the zero-indexed list of phases Source code in wiseagents/core.py 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 def set_current_phase ( self , chat_uuid : str , phase : int ): \"\"\" Set the current phase for the given chat uuid for this context. This method also sets the required agents for the current phase. This is used by a phased coordinator. Args: chat_uuid (str): the chat uuid phase (int): the current phase, represented as an integer in the zero-indexed list of phases \"\"\" if ( self . _use_redis == True ): self . _redis_db . pipeline ( transaction = True ) \\ . hset ( \"current_phase\" , key = chat_uuid , value = pickle . dumps ( phase )) \\ . hset ( \"required_agents_for_current_phase\" , key = chat_uuid , value = pickle . dumps ( self . get_agent_phase_assignments ( chat_uuid )[ phase ])) \\ . execute () else : self . _current_phase [ chat_uuid ] = phase self . _required_agents_for_current_phase [ chat_uuid ] = copy . deepcopy ( self . _agent_phase_assignments [ chat_uuid ][ phase ])","title":"set_current_phase"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.set_route_response_to","text":"Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Parameters: chat_uuid ( str ) \u2013 the chat uuid agent ( str ) \u2013 the name of the agent where the final response should be routed to Source code in wiseagents/core.py 519 520 521 522 523 524 525 526 527 528 529 530 531 def set_route_response_to ( self , chat_uuid : str , agent : str ): \"\"\" Set the name of the agent where the final response should be routed to for the given chat uuid for this context. This is used by a sequential coordinator and a phased coordinator. Args: chat_uuid (str): the chat uuid agent (str): the name of the agent where the final response should be routed to \"\"\" if ( self . _use_redis == True ): self . _redis_db . hset ( \"route_response_to\" , key = chat_uuid , value = pickle . dumps ( agent )) else : self . _route_response_to [ chat_uuid ] = agent","title":"set_route_response_to"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentContext.trace","text":"Trace the message. Source code in wiseagents/core.py 211 212 213 214 215 216 def trace ( self , message : WiseAgentMessage ): '''Trace the message.''' if ( self . _use_redis == True ): self . _redis_db . rpush ( \"message_trace\" , message . __repr__ ()) else : self . _message_trace . append ( message )","title":"trace"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry","text":"A Registry to get available agents and running contexts Source code in wiseagents/core.py 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 class WiseAgentRegistry : \"\"\" A Registry to get available agents and running contexts \"\"\" agents_descriptions_dict : dict [ str , str ] = {} contexts : dict [ str , WiseAgentContext ] = {} tools : dict [ str , WiseAgentTool ] = {} config : dict [ str , Any ] = {} redis_db : redis . Redis = None @classmethod def find_file ( cls , file_name , config_directory = \".wise-agents\" ) -> str : \"\"\" Find the file in the current directory or the home directory. \"\"\" # Step 1: Check the current directory local_path = os . path . join ( os . getcwd (), config_directory , file_name ) if os . path . isfile ( local_path ): return local_path # Step 2: Check the home directory home_dir = os . path . expanduser ( \"~\" ) home_path = os . path . join ( home_dir , config_directory , file_name ) if os . path . isfile ( home_path ): return home_path # If the file is not found in any of these locations, throw an exception raise FileNotFoundError ( f \"File ' { file_name } ' not found in current directory, home directory, as ' { config_directory } '/ { file_name } .\" ) @classmethod def get_config ( cls ) -> dict [ str , Any ]: \"\"\" Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture \"\"\" try : if cls . config is None or cls . config == {}: file_name = cls . find_file ( file_name = \"registry_config.yaml\" , config_directory = \".wise-agents\" ) cls . config : Dict [ str , Any ] = yaml . load ( open ( file_name ), Loader = yaml . FullLoader ) if cls . config . get ( \"use_redis\" ) == True and cls . redis_db is None : if ( cls . config . get ( \"redis_ssl\" ) is True ): cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ], username = cls . config [ \"redis_username\" ], # use your Redis user. More info https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/ password = cls . config [ \"redis_password\" ], # use your Redis password ssl = True , ssl_certfile = cls . config [ \"redis_ssl_certfile\" ], ssl_keyfile = cls . config [ \"redis_ssl_keyfile\" ], ssl_ca_certs = cls . config [ \"redis_ssl_ca_certs\" ]) else : cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ]) return cls . config except Exception as e : logging . error ( e ) exit ( 1 ) @classmethod def register_agent ( cls , agent_name : str , agent_description : str ): \"\"\" Register an agent with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"agents\" ) try : if ( pipe . hexists ( \"agents\" , agent_name ) == True ): pipe . unwatch () raise NameError ( f \"Agent with name { agent_name } already exists\" ) else : pipe . multi () pipe . hset ( \"agents\" , key = agent_name , value = agent_description ) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in register_agent\" ) continue else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : raise NameError ( f \"Agent with name { agent_name } already exists\" ) cls . agents_descriptions_dict [ agent_name ] = agent_description @classmethod def register_context ( cls , context : WiseAgentContext ): \"\"\" Register a context with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"contexts\" , key = context . name , value = pickle . dumps ( context )) else : cls . contexts [ context . name ] = context @classmethod def fetch_agents_descriptions_dict ( cls ) -> dict [ str , str ]: \"\"\" Get the dict with the agent names as keys and descriptions as values \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hgetall ( \"agents\" ) else : return cls . agents_descriptions_dict @classmethod def get_contexts ( cls ) -> dict [ str , WiseAgentContext ]: \"\"\" Get the list of contexts \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"contexts\" ) return_dictionary : Dict [ str , WiseAgentContext ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . contexts @classmethod def get_agent_description ( cls , agent_name : str ) -> str : \"\"\" Get the agent description for the agent with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return_byte = cls . redis_db . hget ( \"agents\" , key = agent_name ) if return_byte is not None : return return_byte . decode ( 'utf-8' ) else : return None else : return cls . agents_descriptions_dict . get ( agent_name ) @classmethod def get_or_create_context ( cls , context_name : str ) -> WiseAgentContext : \"\"\" Get the context with the given name \"\"\" context : WiseAgentContext = None if ( cls . get_config () . get ( \"use_redis\" ) == True ): ctx = cls . redis_db . hget ( \"contexts\" , key = context_name ) if ctx is not None : context : WiseAgentContext = pickle . loads ( ctx ) else : context = None else : context = cls . contexts . get ( context_name ) if context is None : # context creation will also register the context in the registry return WiseAgentContext ( context_name , cls . config ) else : return context @classmethod def does_context_exist ( cls , context_name : str ) -> bool : \"\"\" Get the context with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hexists ( \"contexts\" , key = context_name ) else : if cls . contexts . get ( context_name ) is None : return False else : return True @classmethod def unregister_agent ( cls , agent_name : str ): \"\"\" Remove the agent from the registry this should be used only on agents which already stopped transport connection \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"agents\" , agent_name ) else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : cls . agents_descriptions_dict . pop ( agent_name ) @classmethod def remove_context ( cls , context_name : str ): \"\"\" Remove the context from the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"contexts\" , context_name ) else : cls . contexts . pop ( context_name ) @classmethod def register_tool ( cls , tool : WiseAgentTool ): \"\"\" Register a tool with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"tools\" , key = tool . name , value = pickle . dumps ( tool )) else : cls . tools [ tool . name ] = tool @classmethod def get_tools ( cls ) -> dict [ str , WiseAgentTool ]: \"\"\" Get the list of tools \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"tools\" ) return_dictionary : Dict [ str , WiseAgentTool ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . tools @classmethod def get_tool ( cls , tool_name : str ) -> WiseAgentTool : \"\"\" Get the tool with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) piped_res = pipe . hexists ( \"tools\" , key = tool_name ) . hget ( \"tools\" , key = tool_name ) . execute () if piped_res [ 0 ]: return pickle . loads ( piped_res [ 1 ]) else : return None else : return cls . tools . get ( tool_name ) @classmethod def get_agent_names_and_descriptions ( cls ) -> List [ str ]: \"\"\" Get the list of agent names and descriptions. Returns: List[str]: the list of agent descriptions \"\"\" agent_descriptions = [] for agent_name , agent_description in cls . fetch_agents_descriptions_dict () . items (): agent_descriptions . append ( f \"Agent Name: { agent_name } Agent Description: { agent_description } \" ) return agent_descriptions","title":"WiseAgentRegistry"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.does_context_exist","text":"Get the context with the given name Source code in wiseagents/core.py 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 @classmethod def does_context_exist ( cls , context_name : str ) -> bool : \"\"\" Get the context with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hexists ( \"contexts\" , key = context_name ) else : if cls . contexts . get ( context_name ) is None : return False else : return True","title":"does_context_exist"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.fetch_agents_descriptions_dict","text":"Get the dict with the agent names as keys and descriptions as values Source code in wiseagents/core.py 1209 1210 1211 1212 1213 1214 1215 1216 1217 @classmethod def fetch_agents_descriptions_dict ( cls ) -> dict [ str , str ]: \"\"\" Get the dict with the agent names as keys and descriptions as values \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return cls . redis_db . hgetall ( \"agents\" ) else : return cls . agents_descriptions_dict","title":"fetch_agents_descriptions_dict"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.find_file","text":"Find the file in the current directory or the home directory. Source code in wiseagents/core.py 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 @classmethod def find_file ( cls , file_name , config_directory = \".wise-agents\" ) -> str : \"\"\" Find the file in the current directory or the home directory. \"\"\" # Step 1: Check the current directory local_path = os . path . join ( os . getcwd (), config_directory , file_name ) if os . path . isfile ( local_path ): return local_path # Step 2: Check the home directory home_dir = os . path . expanduser ( \"~\" ) home_path = os . path . join ( home_dir , config_directory , file_name ) if os . path . isfile ( home_path ): return home_path # If the file is not found in any of these locations, throw an exception raise FileNotFoundError ( f \"File ' { file_name } ' not found in current directory, home directory, as ' { config_directory } '/ { file_name } .\" )","title":"find_file"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.get_agent_description","text":"Get the agent description for the agent with the given name Source code in wiseagents/core.py 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 @classmethod def get_agent_description ( cls , agent_name : str ) -> str : \"\"\" Get the agent description for the agent with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): return_byte = cls . redis_db . hget ( \"agents\" , key = agent_name ) if return_byte is not None : return return_byte . decode ( 'utf-8' ) else : return None else : return cls . agents_descriptions_dict . get ( agent_name )","title":"get_agent_description"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.get_agent_names_and_descriptions","text":"Get the list of agent names and descriptions. Returns: List [ str ] \u2013 List[str]: the list of agent descriptions Source code in wiseagents/core.py 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 @classmethod def get_agent_names_and_descriptions ( cls ) -> List [ str ]: \"\"\" Get the list of agent names and descriptions. Returns: List[str]: the list of agent descriptions \"\"\" agent_descriptions = [] for agent_name , agent_description in cls . fetch_agents_descriptions_dict () . items (): agent_descriptions . append ( f \"Agent Name: { agent_name } Agent Description: { agent_description } \" ) return agent_descriptions","title":"get_agent_names_and_descriptions"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.get_config","text":"Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture Source code in wiseagents/core.py 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 @classmethod def get_config ( cls ) -> dict [ str , Any ]: \"\"\" Get the configuration and initialize the redis database for more information see https://wise-agents.github.io/wise_agents_architecture/#distributed-architecture \"\"\" try : if cls . config is None or cls . config == {}: file_name = cls . find_file ( file_name = \"registry_config.yaml\" , config_directory = \".wise-agents\" ) cls . config : Dict [ str , Any ] = yaml . load ( open ( file_name ), Loader = yaml . FullLoader ) if cls . config . get ( \"use_redis\" ) == True and cls . redis_db is None : if ( cls . config . get ( \"redis_ssl\" ) is True ): cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ], username = cls . config [ \"redis_username\" ], # use your Redis user. More info https://redis.io/docs/latest/operate/oss_and_stack/management/security/acl/ password = cls . config [ \"redis_password\" ], # use your Redis password ssl = True , ssl_certfile = cls . config [ \"redis_ssl_certfile\" ], ssl_keyfile = cls . config [ \"redis_ssl_keyfile\" ], ssl_ca_certs = cls . config [ \"redis_ssl_ca_certs\" ]) else : cls . redis_db = redis . Redis ( host = cls . config [ \"redis_host\" ], port = cls . config [ \"redis_port\" ]) return cls . config except Exception as e : logging . error ( e ) exit ( 1 )","title":"get_config"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.get_contexts","text":"Get the list of contexts Source code in wiseagents/core.py 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 @classmethod def get_contexts ( cls ) -> dict [ str , WiseAgentContext ]: \"\"\" Get the list of contexts \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"contexts\" ) return_dictionary : Dict [ str , WiseAgentContext ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . contexts","title":"get_contexts"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.get_or_create_context","text":"Get the context with the given name Source code in wiseagents/core.py 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 @classmethod def get_or_create_context ( cls , context_name : str ) -> WiseAgentContext : \"\"\" Get the context with the given name \"\"\" context : WiseAgentContext = None if ( cls . get_config () . get ( \"use_redis\" ) == True ): ctx = cls . redis_db . hget ( \"contexts\" , key = context_name ) if ctx is not None : context : WiseAgentContext = pickle . loads ( ctx ) else : context = None else : context = cls . contexts . get ( context_name ) if context is None : # context creation will also register the context in the registry return WiseAgentContext ( context_name , cls . config ) else : return context","title":"get_or_create_context"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.get_tool","text":"Get the tool with the given name Source code in wiseagents/core.py 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 @classmethod def get_tool ( cls , tool_name : str ) -> WiseAgentTool : \"\"\" Get the tool with the given name \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) piped_res = pipe . hexists ( \"tools\" , key = tool_name ) . hget ( \"tools\" , key = tool_name ) . execute () if piped_res [ 0 ]: return pickle . loads ( piped_res [ 1 ]) else : return None else : return cls . tools . get ( tool_name )","title":"get_tool"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.get_tools","text":"Get the list of tools Source code in wiseagents/core.py 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 @classmethod def get_tools ( cls ) -> dict [ str , WiseAgentTool ]: \"\"\" Get the list of tools \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): dictionary = cls . redis_db . hgetall ( \"tools\" ) return_dictionary : Dict [ str , WiseAgentTool ] = {} for key in dictionary : return_dictionary [ key ] = pickle . loads ( dictionary . get ( key )) return return_dictionary else : return cls . tools","title":"get_tools"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.register_agent","text":"Register an agent with the registry Source code in wiseagents/core.py 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 @classmethod def register_agent ( cls , agent_name : str , agent_description : str ): \"\"\" Register an agent with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): pipe = cls . redis_db . pipeline ( transaction = True ) while True : pipe . watch ( \"agents\" ) try : if ( pipe . hexists ( \"agents\" , agent_name ) == True ): pipe . unwatch () raise NameError ( f \"Agent with name { agent_name } already exists\" ) else : pipe . multi () pipe . hset ( \"agents\" , key = agent_name , value = agent_description ) pipe . execute () return except redis . WatchError : logging . debug ( \"WatchError in register_agent\" ) continue else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : raise NameError ( f \"Agent with name { agent_name } already exists\" ) cls . agents_descriptions_dict [ agent_name ] = agent_description","title":"register_agent"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.register_context","text":"Register a context with the registry Source code in wiseagents/core.py 1200 1201 1202 1203 1204 1205 1206 1207 1208 @classmethod def register_context ( cls , context : WiseAgentContext ): \"\"\" Register a context with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"contexts\" , key = context . name , value = pickle . dumps ( context )) else : cls . contexts [ context . name ] = context","title":"register_context"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.register_tool","text":"Register a tool with the registry Source code in wiseagents/core.py 1299 1300 1301 1302 1303 1304 1305 1306 1307 @classmethod def register_tool ( cls , tool : WiseAgentTool ): \"\"\" Register a tool with the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hset ( \"tools\" , key = tool . name , value = pickle . dumps ( tool )) else : cls . tools [ tool . name ] = tool","title":"register_tool"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.remove_context","text":"Remove the context from the registry Source code in wiseagents/core.py 1289 1290 1291 1292 1293 1294 1295 1296 1297 @classmethod def remove_context ( cls , context_name : str ): \"\"\" Remove the context from the registry \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"contexts\" , context_name ) else : cls . contexts . pop ( context_name )","title":"remove_context"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentRegistry.unregister_agent","text":"Remove the agent from the registry this should be used only on agents which already stopped transport connection Source code in wiseagents/core.py 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 @classmethod def unregister_agent ( cls , agent_name : str ): \"\"\" Remove the agent from the registry this should be used only on agents which already stopped transport connection \"\"\" if ( cls . get_config () . get ( \"use_redis\" ) == True ): cls . redis_db . hdel ( \"agents\" , agent_name ) else : if cls . agents_descriptions_dict . get ( agent_name ) is not None : cls . agents_descriptions_dict . pop ( agent_name )","title":"unregister_agent"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool","text":"Bases: YAMLObject A WiseAgentTool is an abstract class that represents a tool that can be used by an agent to perform a specific task. Source code in wiseagents/core.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class WiseAgentTool ( yaml . YAMLObject ): ''' A WiseAgentTool is an abstract class that represents a tool that can be used by an agent to perform a specific task.''' yaml_tag = u '!wiseagents.WiseAgentTool' yaml_loader = WiseAgentsLoader def __init__ ( self , name : str , description : str , agent_tool : bool , parameters_json_schema : dict = {}, call_back : Optional [ Callable [ ... , str ]] = None ): ''' Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Args: name (str): the name of the tool description (str): a description of what the tool does agent_tool (bool): whether the tool is an agent tool parameters_json_schema (dict): the json schema for the parameters of the tool call_back Optional(Callable[...,str]): the callback function to execute the tool''' self . _name = name self . _description = description self . _parameters_json_schema = parameters_json_schema self . _agent_tool = agent_tool self . _call_back = call_back WiseAgentRegistry . register_tool ( self ) @classmethod def from_yaml ( cls , loader , node ): '''Load the tool from a YAML node. Args: loader (yaml.Loader): the YAML loader node (yaml.Node): the YAML node''' data = loader . construct_mapping ( node , deep = True ) return cls ( name = data . get ( '_name' ), description = data . get ( '_description' ), parameters_json_schema = data . get ( '_parameters_json_schema' ), call_back = data . get ( '_call_back' )) @property def name ( self ) -> str : \"\"\"Get the name of the tool.\"\"\" return self . _name @property def description ( self ) -> str : \"\"\"Get the description of the tool.\"\"\" return self . _description @property def call_back ( self ) -> Callable [ ... , str ]: \"\"\"Get the callback function of the tool.\"\"\" return self . _call_back @property def json_schema ( self ) -> dict : \"\"\"Get the json schema of the tool.\"\"\" return self . _parameters_json_schema @property def is_agent_tool ( self ) -> bool : \"\"\"Get the agent tool of the tool.\"\"\" return self . _agent_tool def get_tool_OpenAI_format ( self ) -> ChatCompletionToolParam : '''The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam''' return { \"type\" : \"function\" , \"function\" : { \"name\" : self . name , \"description\" : self . description , \"parameters\" : self . json_schema } } def default_call_back ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' return json . dumps ( kwargs ) def exec ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' if self . call_back is None : return self . default_call_back ( ** kwargs ) return self . call_back ( ** kwargs )","title":"WiseAgentTool"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.call_back","text":"Get the callback function of the tool.","title":"call_back"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.description","text":"Get the description of the tool.","title":"description"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.is_agent_tool","text":"Get the agent tool of the tool.","title":"is_agent_tool"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.json_schema","text":"Get the json schema of the tool.","title":"json_schema"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.name","text":"Get the name of the tool.","title":"name"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.__init__","text":"Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Parameters: name ( str ) \u2013 the name of the tool description ( str ) \u2013 a description of what the tool does agent_tool ( bool ) \u2013 whether the tool is an agent tool parameters_json_schema ( dict , default: {} ) \u2013 the json schema for the parameters of the tool call_back ( Optional(Callable[...,str] , default: None ) \u2013 the callback function to execute the tool Source code in wiseagents/core.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , name : str , description : str , agent_tool : bool , parameters_json_schema : dict = {}, call_back : Optional [ Callable [ ... , str ]] = None ): ''' Initialize the tool with the given name, description, agent tool, parameters json schema, and call back. Args: name (str): the name of the tool description (str): a description of what the tool does agent_tool (bool): whether the tool is an agent tool parameters_json_schema (dict): the json schema for the parameters of the tool call_back Optional(Callable[...,str]): the callback function to execute the tool''' self . _name = name self . _description = description self . _parameters_json_schema = parameters_json_schema self . _agent_tool = agent_tool self . _call_back = call_back WiseAgentRegistry . register_tool ( self )","title":"__init__"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.default_call_back","text":"The tool should be able to execute the function with the given parameters Source code in wiseagents/core.py 100 101 102 def default_call_back ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' return json . dumps ( kwargs )","title":"default_call_back"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.exec","text":"The tool should be able to execute the function with the given parameters Source code in wiseagents/core.py 104 105 106 107 108 def exec ( self , ** kwargs ) -> str : '''The tool should be able to execute the function with the given parameters''' if self . call_back is None : return self . default_call_back ( ** kwargs ) return self . call_back ( ** kwargs )","title":"exec"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.from_yaml","text":"Load the tool from a YAML node. Parameters: loader ( Loader ) \u2013 the YAML loader node ( Node ) \u2013 the YAML node Source code in wiseagents/core.py 51 52 53 54 55 56 57 58 59 60 61 @classmethod def from_yaml ( cls , loader , node ): '''Load the tool from a YAML node. Args: loader (yaml.Loader): the YAML loader node (yaml.Node): the YAML node''' data = loader . construct_mapping ( node , deep = True ) return cls ( name = data . get ( '_name' ), description = data . get ( '_description' ), parameters_json_schema = data . get ( '_parameters_json_schema' ), call_back = data . get ( '_call_back' ))","title":"from_yaml"},{"location":"reference/wiseagents/core/#wiseagents.core.WiseAgentTool.get_tool_OpenAI_format","text":"The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam \u2013 ChatCompletionToolParam Source code in wiseagents/core.py 87 88 89 90 91 92 93 94 95 96 97 98 def get_tool_OpenAI_format ( self ) -> ChatCompletionToolParam : '''The tool should be able to return itself in the form of a ChatCompletionToolParam Returns: ChatCompletionToolParam''' return { \"type\" : \"function\" , \"function\" : { \"name\" : self . name , \"description\" : self . description , \"parameters\" : self . json_schema } }","title":"get_tool_OpenAI_format"},{"location":"reference/wiseagents/wise_agent_messaging/","text":"WiseAgentEvent TODO Source code in wiseagents/wise_agent_messaging.py 17 18 19 20 class WiseAgentEvent : \"\"\" TODO \"\"\" WiseAgentMessage Bases: YAMLObject A message that can be sent between agents. Source code in wiseagents/wise_agent_messaging.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 class WiseAgentMessage ( YAMLObject ): ''' A message that can be sent between agents. ''' yaml_tag = u '!wiseagents.WiseAgentMessage' def __init__ ( self , message : str , sender : Optional [ str ] = None , message_type : Optional [ WiseAgentMessageType ] = None , chat_id : Optional [ str ] = None , tool_id : Optional [ str ] = None , context_name : Optional [ str ] = None , route_response_to : Optional [ str ] = None ): '''Initialize the message. Args: message (str): the message contents (a natural language string) sender Optional(str): the sender of the message (or None if the sender was not specified) message_type Optional(WiseAgentMessageType): the type of the message (or None if the type was not specified) chat_id Optional(str): the id of the message tool_id Optional(str): the id of the tool context_name Optional(str): the context name of the message route_response_to Optional(str): the id of the tool to route the response to ''' self . _message = message self . _sender = sender self . _message_type = message_type self . _chat_id = chat_id self . _tool_id = tool_id self . _route_response_to = route_response_to if context_name is not None : self . _context_name = context_name else : self . _context_name = 'default' def __repr__ ( self ) -> str : return f \" { self . __class__ . __name__ } (message= { self . message } , sender= { self . sender } , message_type= { self . message_type } , id= { self . chat_id } , tool_id= { self . tool_id } , context_name= { self . context_name } , route_response_to= { self . route_response_to } , route_response_to= { self . route_response_to } )\" @property def context_name ( self ) -> str : \"\"\"Get the context name of the message.\"\"\" return self . _context_name @property def message ( self ) -> str : \"\"\"Get the message contents (a natural language string).\"\"\" return self . _message @property def sender ( self ) -> str : \"\"\"Get the sender of the message (or None if the sender was not specified).\"\"\" return self . _sender @sender . setter def sender ( self , sender : str ): '''Set the sender of the message. Args: sender (str): the sender of the message ''' self . _sender = sender @property def message_type ( self ) -> WiseAgentMessageType : \"\"\"Get the type of the message (or None if the type was not specified).\"\"\" return self . _message_type @property def chat_id ( self ) -> str : \"\"\"Get the id of the message.\"\"\" return self . _chat_id @property def tool_id ( self ) -> str : \"\"\"Get the id of the tool.\"\"\" return self . _tool_id @property def route_response_to ( self ) -> str : \"\"\"Get the id of the tool.\"\"\" return self . _route_response_to chat_id : str property Get the id of the message. context_name : str property Get the context name of the message. message : str property Get the message contents (a natural language string). message_type : WiseAgentMessageType property Get the type of the message (or None if the type was not specified). route_response_to : str property Get the id of the tool. sender : str property writable Get the sender of the message (or None if the sender was not specified). tool_id : str property Get the id of the tool. __init__ ( message , sender = None , message_type = None , chat_id = None , tool_id = None , context_name = None , route_response_to = None ) Initialize the message. Parameters: message ( str ) \u2013 the message contents (a natural language string) sender ( Optional(str , default: None ) \u2013 the sender of the message (or None if the sender was not specified) message_type ( Optional(WiseAgentMessageType , default: None ) \u2013 the type of the message (or None if the type was not specified) chat_id ( Optional(str , default: None ) \u2013 the id of the message tool_id ( Optional(str , default: None ) \u2013 the id of the tool context_name ( Optional(str , default: None ) \u2013 the context name of the message route_response_to ( Optional(str , default: None ) \u2013 the id of the tool to route the response to Source code in wiseagents/wise_agent_messaging.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , message : str , sender : Optional [ str ] = None , message_type : Optional [ WiseAgentMessageType ] = None , chat_id : Optional [ str ] = None , tool_id : Optional [ str ] = None , context_name : Optional [ str ] = None , route_response_to : Optional [ str ] = None ): '''Initialize the message. Args: message (str): the message contents (a natural language string) sender Optional(str): the sender of the message (or None if the sender was not specified) message_type Optional(WiseAgentMessageType): the type of the message (or None if the type was not specified) chat_id Optional(str): the id of the message tool_id Optional(str): the id of the tool context_name Optional(str): the context name of the message route_response_to Optional(str): the id of the tool to route the response to ''' self . _message = message self . _sender = sender self . _message_type = message_type self . _chat_id = chat_id self . _tool_id = tool_id self . _route_response_to = route_response_to if context_name is not None : self . _context_name = context_name else : self . _context_name = 'default' WiseAgentTransport Bases: YAMLObject Source code in wiseagents/wise_agent_messaging.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 class WiseAgentTransport ( YAMLObject ): yaml_loader = WiseAgentsLoader ''' A transport for sending messages between agents. ''' def set_call_backs ( self , request_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , event_receiver : Optional [ Callable [[], WiseAgentEvent ]] = None , error_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , response_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None ): '''Set the call back functions for the transport. Args: request_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving requests event_receiver Optional(Callable[[], WiseAgentEvent]): the call back function for receiving events error_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving errors response_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving responses ''' self . _request_receiver = request_receiver self . _event_receiver = event_receiver self . _error_receiver = error_receiver self . _response_receiver = response_receiver def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () del state [ '_request_receiver' ] del state [ '_response_receiver' ] del state [ '_event_receiver' ] del state [ '_error_receiver' ] return state @abstractmethod def start ( self ): \"\"\" Start the transport. \"\"\" pass @abstractmethod def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass @abstractmethod def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass @abstractmethod def stop ( self ): \"\"\" Stop the transport. \"\"\" pass @property def request_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the message receiver callback.\"\"\" return self . _request_receiver @property def event_receiver ( self ) -> Optional [ Callable [[], WiseAgentEvent ]]: \"\"\"Get the event receiver callback.\"\"\" return self . _event_receiver @property def error_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the error receiver callback.\"\"\" return self . _error_receiver @property def response_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the response receiver callback.\"\"\" return self . _response_receiver error_receiver : Optional [ Callable [[], WiseAgentMessage ]] property Get the error receiver callback. event_receiver : Optional [ Callable [[], WiseAgentEvent ]] property Get the event receiver callback. request_receiver : Optional [ Callable [[], WiseAgentMessage ]] property Get the message receiver callback. response_receiver : Optional [ Callable [[], WiseAgentMessage ]] property Get the response receiver callback. yaml_loader = WiseAgentsLoader class-attribute instance-attribute A transport for sending messages between agents. __getstate__ () Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/wise_agent_messaging.py 117 118 119 120 121 122 123 124 def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () del state [ '_request_receiver' ] del state [ '_response_receiver' ] del state [ '_event_receiver' ] del state [ '_error_receiver' ] return state send_request ( message , dest_agent_name ) Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send Source code in wiseagents/wise_agent_messaging.py 134 135 136 137 138 139 140 141 142 143 @abstractmethod def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass send_response ( message , dest_agent_name ) Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send Source code in wiseagents/wise_agent_messaging.py 145 146 147 148 149 150 151 152 153 154 @abstractmethod def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass set_call_backs ( request_receiver = None , event_receiver = None , error_receiver = None , response_receiver = None ) Set the call back functions for the transport. Parameters: request_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving requests event_receiver ( Optional(Callable[[], WiseAgentEvent] , default: None ) \u2013 the call back function for receiving events error_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving errors response_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving responses Source code in wiseagents/wise_agent_messaging.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def set_call_backs ( self , request_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , event_receiver : Optional [ Callable [[], WiseAgentEvent ]] = None , error_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , response_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None ): '''Set the call back functions for the transport. Args: request_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving requests event_receiver Optional(Callable[[], WiseAgentEvent]): the call back function for receiving events error_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving errors response_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving responses ''' self . _request_receiver = request_receiver self . _event_receiver = event_receiver self . _error_receiver = error_receiver self . _response_receiver = response_receiver start () Start the transport. Source code in wiseagents/wise_agent_messaging.py 127 128 129 130 131 132 @abstractmethod def start ( self ): \"\"\" Start the transport. \"\"\" pass stop () Stop the transport. Source code in wiseagents/wise_agent_messaging.py 156 157 158 159 160 161 @abstractmethod def stop ( self ): \"\"\" Stop the transport. \"\"\" pass","title":"wise_agent_messaging"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentEvent","text":"TODO Source code in wiseagents/wise_agent_messaging.py 17 18 19 20 class WiseAgentEvent : \"\"\" TODO \"\"\"","title":"WiseAgentEvent"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentMessage","text":"Bases: YAMLObject A message that can be sent between agents. Source code in wiseagents/wise_agent_messaging.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 class WiseAgentMessage ( YAMLObject ): ''' A message that can be sent between agents. ''' yaml_tag = u '!wiseagents.WiseAgentMessage' def __init__ ( self , message : str , sender : Optional [ str ] = None , message_type : Optional [ WiseAgentMessageType ] = None , chat_id : Optional [ str ] = None , tool_id : Optional [ str ] = None , context_name : Optional [ str ] = None , route_response_to : Optional [ str ] = None ): '''Initialize the message. Args: message (str): the message contents (a natural language string) sender Optional(str): the sender of the message (or None if the sender was not specified) message_type Optional(WiseAgentMessageType): the type of the message (or None if the type was not specified) chat_id Optional(str): the id of the message tool_id Optional(str): the id of the tool context_name Optional(str): the context name of the message route_response_to Optional(str): the id of the tool to route the response to ''' self . _message = message self . _sender = sender self . _message_type = message_type self . _chat_id = chat_id self . _tool_id = tool_id self . _route_response_to = route_response_to if context_name is not None : self . _context_name = context_name else : self . _context_name = 'default' def __repr__ ( self ) -> str : return f \" { self . __class__ . __name__ } (message= { self . message } , sender= { self . sender } , message_type= { self . message_type } , id= { self . chat_id } , tool_id= { self . tool_id } , context_name= { self . context_name } , route_response_to= { self . route_response_to } , route_response_to= { self . route_response_to } )\" @property def context_name ( self ) -> str : \"\"\"Get the context name of the message.\"\"\" return self . _context_name @property def message ( self ) -> str : \"\"\"Get the message contents (a natural language string).\"\"\" return self . _message @property def sender ( self ) -> str : \"\"\"Get the sender of the message (or None if the sender was not specified).\"\"\" return self . _sender @sender . setter def sender ( self , sender : str ): '''Set the sender of the message. Args: sender (str): the sender of the message ''' self . _sender = sender @property def message_type ( self ) -> WiseAgentMessageType : \"\"\"Get the type of the message (or None if the type was not specified).\"\"\" return self . _message_type @property def chat_id ( self ) -> str : \"\"\"Get the id of the message.\"\"\" return self . _chat_id @property def tool_id ( self ) -> str : \"\"\"Get the id of the tool.\"\"\" return self . _tool_id @property def route_response_to ( self ) -> str : \"\"\"Get the id of the tool.\"\"\" return self . _route_response_to","title":"WiseAgentMessage"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentMessage.chat_id","text":"Get the id of the message.","title":"chat_id"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentMessage.context_name","text":"Get the context name of the message.","title":"context_name"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentMessage.message","text":"Get the message contents (a natural language string).","title":"message"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentMessage.message_type","text":"Get the type of the message (or None if the type was not specified).","title":"message_type"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentMessage.route_response_to","text":"Get the id of the tool.","title":"route_response_to"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentMessage.sender","text":"Get the sender of the message (or None if the sender was not specified).","title":"sender"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentMessage.tool_id","text":"Get the id of the tool.","title":"tool_id"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentMessage.__init__","text":"Initialize the message. Parameters: message ( str ) \u2013 the message contents (a natural language string) sender ( Optional(str , default: None ) \u2013 the sender of the message (or None if the sender was not specified) message_type ( Optional(WiseAgentMessageType , default: None ) \u2013 the type of the message (or None if the type was not specified) chat_id ( Optional(str , default: None ) \u2013 the id of the message tool_id ( Optional(str , default: None ) \u2013 the id of the tool context_name ( Optional(str , default: None ) \u2013 the context name of the message route_response_to ( Optional(str , default: None ) \u2013 the id of the tool to route the response to Source code in wiseagents/wise_agent_messaging.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , message : str , sender : Optional [ str ] = None , message_type : Optional [ WiseAgentMessageType ] = None , chat_id : Optional [ str ] = None , tool_id : Optional [ str ] = None , context_name : Optional [ str ] = None , route_response_to : Optional [ str ] = None ): '''Initialize the message. Args: message (str): the message contents (a natural language string) sender Optional(str): the sender of the message (or None if the sender was not specified) message_type Optional(WiseAgentMessageType): the type of the message (or None if the type was not specified) chat_id Optional(str): the id of the message tool_id Optional(str): the id of the tool context_name Optional(str): the context name of the message route_response_to Optional(str): the id of the tool to route the response to ''' self . _message = message self . _sender = sender self . _message_type = message_type self . _chat_id = chat_id self . _tool_id = tool_id self . _route_response_to = route_response_to if context_name is not None : self . _context_name = context_name else : self . _context_name = 'default'","title":"__init__"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport","text":"Bases: YAMLObject Source code in wiseagents/wise_agent_messaging.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 class WiseAgentTransport ( YAMLObject ): yaml_loader = WiseAgentsLoader ''' A transport for sending messages between agents. ''' def set_call_backs ( self , request_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , event_receiver : Optional [ Callable [[], WiseAgentEvent ]] = None , error_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , response_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None ): '''Set the call back functions for the transport. Args: request_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving requests event_receiver Optional(Callable[[], WiseAgentEvent]): the call back function for receiving events error_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving errors response_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving responses ''' self . _request_receiver = request_receiver self . _event_receiver = event_receiver self . _error_receiver = error_receiver self . _response_receiver = response_receiver def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () del state [ '_request_receiver' ] del state [ '_response_receiver' ] del state [ '_event_receiver' ] del state [ '_error_receiver' ] return state @abstractmethod def start ( self ): \"\"\" Start the transport. \"\"\" pass @abstractmethod def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass @abstractmethod def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass @abstractmethod def stop ( self ): \"\"\" Stop the transport. \"\"\" pass @property def request_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the message receiver callback.\"\"\" return self . _request_receiver @property def event_receiver ( self ) -> Optional [ Callable [[], WiseAgentEvent ]]: \"\"\"Get the event receiver callback.\"\"\" return self . _event_receiver @property def error_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the error receiver callback.\"\"\" return self . _error_receiver @property def response_receiver ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the response receiver callback.\"\"\" return self . _response_receiver","title":"WiseAgentTransport"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.error_receiver","text":"Get the error receiver callback.","title":"error_receiver"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.event_receiver","text":"Get the event receiver callback.","title":"event_receiver"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.request_receiver","text":"Get the message receiver callback.","title":"request_receiver"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.response_receiver","text":"Get the response receiver callback.","title":"response_receiver"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.yaml_loader","text":"A transport for sending messages between agents.","title":"yaml_loader"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.__getstate__","text":"Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/wise_agent_messaging.py 117 118 119 120 121 122 123 124 def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () del state [ '_request_receiver' ] del state [ '_response_receiver' ] del state [ '_event_receiver' ] del state [ '_error_receiver' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.send_request","text":"Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send Source code in wiseagents/wise_agent_messaging.py 134 135 136 137 138 139 140 141 142 143 @abstractmethod def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass","title":"send_request"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.send_response","text":"Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send Source code in wiseagents/wise_agent_messaging.py 145 146 147 148 149 150 151 152 153 154 @abstractmethod def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): \"\"\" Send a request message to an agent. Args: message (WiseAgentMessage): the message to send \"\"\" pass","title":"send_response"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.set_call_backs","text":"Set the call back functions for the transport. Parameters: request_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving requests event_receiver ( Optional(Callable[[], WiseAgentEvent] , default: None ) \u2013 the call back function for receiving events error_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving errors response_receiver ( Optional(Callable[[], WiseAgentMessage] , default: None ) \u2013 the call back function for receiving responses Source code in wiseagents/wise_agent_messaging.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def set_call_backs ( self , request_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , event_receiver : Optional [ Callable [[], WiseAgentEvent ]] = None , error_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None , response_receiver : Optional [ Callable [[], WiseAgentMessage ]] = None ): '''Set the call back functions for the transport. Args: request_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving requests event_receiver Optional(Callable[[], WiseAgentEvent]): the call back function for receiving events error_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving errors response_receiver Optional(Callable[[], WiseAgentMessage]): the call back function for receiving responses ''' self . _request_receiver = request_receiver self . _event_receiver = event_receiver self . _error_receiver = error_receiver self . _response_receiver = response_receiver","title":"set_call_backs"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.start","text":"Start the transport. Source code in wiseagents/wise_agent_messaging.py 127 128 129 130 131 132 @abstractmethod def start ( self ): \"\"\" Start the transport. \"\"\" pass","title":"start"},{"location":"reference/wiseagents/wise_agent_messaging/#wiseagents.wise_agent_messaging.WiseAgentTransport.stop","text":"Stop the transport. Source code in wiseagents/wise_agent_messaging.py 156 157 158 159 160 161 @abstractmethod def stop ( self ): \"\"\" Stop the transport. \"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/","text":"AssistantAgent Bases: WiseAgent This utility agent start a web interface and pass the user input to another agent. The web interface will be running at http://127.0.0.1:7860 Source code in wiseagents/agents/assistant.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 class AssistantAgent ( WiseAgent ): \"\"\" This utility agent start a web interface and pass the user input to another agent. The web interface will be running at http://127.0.0.1:7860 \"\"\" yaml_tag = u '!wiseagents.agents.AssistantAgent' _response_delivery = None _cond = threading . Condition () _response : WiseAgentMessage = None _chat_id = None def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : str ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" def start_agent ( self ): super () . start_agent () self . _chat_id = str ( uuid . uuid4 ()) WiseAgentRegistry . get_or_create_context ( \"default\" ) . set_collaboration_type ( self . _chat_id , WiseAgentCollaborationType . CHAT ) gradio . ChatInterface ( self . slow_echo ) . launch ( prevent_thread_lock = True ) def slow_echo ( self , message , history ): with self . _cond : self . handle_request ( WiseAgentMessage ( message = message , sender = self . name , chat_id = self . _chat_id )) self . _cond . wait () return self . _response . message def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by just passing it to another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" print ( f \"AssistantAgent: process_request: { request } \" ) WiseAgentRegistry . get_or_create_context ( \"default\" ) . append_chat_completion ( self . _chat_id , { \"role\" : \"user\" , \"content\" : request . message }) self . send_request ( request , self . destination_agent_name ) return None def process_response ( self , response : WiseAgentMessage ): \"\"\"Process a response message just sending it back to the client.\"\"\" print ( f \"AssistantAgent: process_response: { response } \" ) with self . _cond : self . _response = response self . _cond . notify () return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def destination_agent_name ( self ) -> str : \"\"\"Get the name of the agent to send requests to.\"\"\" return self . _destination_agent_name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client\"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery destination_agent_name : str property Get the name of the agent to send requests to. name : str property Get the name of the agent. response_delivery : Optional [ Callable [[], WiseAgentMessage ]] property Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client __init__ ( name , description , transport , destination_agent_name ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication destination_agent_name ( str ) \u2013 the name of the agent to send requests to Source code in wiseagents/agents/assistant.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : str ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/assistant.py 26 27 28 29 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/assistant.py 46 47 48 49 50 51 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" process_error ( error ) Do nothing Source code in wiseagents/agents/assistant.py 98 99 100 def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True process_event ( event ) Do nothing Source code in wiseagents/agents/assistant.py 94 95 96 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by just passing it to another agent. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/assistant.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by just passing it to another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" print ( f \"AssistantAgent: process_request: { request } \" ) WiseAgentRegistry . get_or_create_context ( \"default\" ) . append_chat_completion ( self . _chat_id , { \"role\" : \"user\" , \"content\" : request . message }) self . send_request ( request , self . destination_agent_name ) return None process_response ( response ) Process a response message just sending it back to the client. Source code in wiseagents/agents/assistant.py 86 87 88 89 90 91 92 def process_response ( self , response : WiseAgentMessage ): \"\"\"Process a response message just sending it back to the client.\"\"\" print ( f \"AssistantAgent: process_response: { response } \" ) with self . _cond : self . _response = response self . _cond . notify () return True set_response_delivery ( response_delivery ) Set the function to deliver the response to the client. Parameters: response_delivery ( Callable [[], WiseAgentMessage ] ) \u2013 the function to deliver the response to the client Source code in wiseagents/agents/assistant.py 122 123 124 125 126 127 128 129 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery stop () Do nothing Source code in wiseagents/agents/assistant.py 102 103 104 def stop ( self ): \"\"\"Do nothing\"\"\" pass BaseCoVeChallengerWiseAgent Bases: WiseAgent This abstract agent implementation is used to challenge the response from a RAG or Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 class BaseCoVeChallengerWiseAgent ( WiseAgent ): \"\"\" This abstract agent implementation is used to challenge the response from a RAG or Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.BaseCoVeChallengerWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = 4 obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _vector_db = None obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _graph_db = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication k Optional(int): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions Optional(int): the number of verification questions to generate, defaults to 4 vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent (to be used for challenging RAG results) collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _k = k self . _num_verification_questions = num_verification_questions self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , vector_db = vector_db , collection_name = collection_name , graph_db = graph_db , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"k= { self . k } , num_verification_questions= { self . _num_verification_questions } ,\" f \"transport= { self . transport } , vector_db= { self . vector_db } , collection_name= { self . collection_name } ,\" f \"graph_db= { self . graph_db } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" return self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve.\"\"\" return self . _k @property def num_verification_questions ( self ) -> int : \"\"\"Get the number of verification questions to generate.\"\"\" return self . _num_verification_questions def create_and_process_chain_of_verification_prompts ( self , message : str , conversation_history : List [ ChatCompletionMessageParam ]) -> str : \"\"\" Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Args: message (str): the message containing the question and baseline response conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. \"\"\" # plan verifications, taking into account the baseline response and conversation history prompt = ( f \"Given the following question and baseline response, generate a list of { self . num_verification_questions } \" f \" verification questions that could help determine if there are any mistakes in the baseline response:\" f \" \\n { message } \\n \" f \"Your response should contain only the list of questions, one per line. \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) # execute verifications, answering questions independently, without the baseline response verification_questions = llm_response . choices [ 0 ] . message . content . splitlines () verification_responses = \"\" for question in verification_questions : retrieved_documents = self . retrieve_documents ( question ) llm_response = create_and_process_rag_prompt ( retrieved_documents , question , self . llm , False , [], self . system_message ) verification_responses = ( verification_responses + \"Verification Question: \" + question + \" \\n \" + \"Verification Result: \" + llm_response + \" \\n \" ) # generate the final revised response, conditioned on the baseline response and verification results complete_info = message + \" \\n \" + verification_responses prompt = ( f \"Given the following question, baseline response, and a list of verification questions and results,\" f \" generate a revised response incorporating the verification results: \\n { complete_info } \\n \" f \"Your response must contain only the revised response to the question in the JSON format shown below: \\n \" f \" {{ 'revised': 'Your revised response to the question.' }}\\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content @abstractmethod def retrieve_documents ( self , question : str ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Args: question (str): the question to be used to retrieve the documents Returns: List[Document]: the list of documents retrieved for the question \"\"\" ... k : int property Get the number of documents to retrieve. name : str property Get the name of the agent. num_verification_questions : int property Get the number of verification questions to generate. __init__ ( name , description , llm , transport , k = DEFAULT_NUM_DOCUMENTS , num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db = None , collection_name = DEFAULT_COLLECTION_NAME , graph_db = None , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional(int , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional(int , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 vector_db ( Optional [ WiseAgentVectorDB ] , default: None ) \u2013 the vector DB associated with the agent (to be used for challenging RAG results) collection_name ( Optional[str]) = \"wise-agent-collection\" , default: DEFAULT_COLLECTION_NAME ) \u2013 the vector DB collection name associated with the agent graph_db ( Optional [ WiseAgentGraphDB ] , default: None ) \u2013 the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication k Optional(int): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions Optional(int): the number of verification questions to generate, defaults to 4 vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent (to be used for challenging RAG results) collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _k = k self . _num_verification_questions = num_verification_questions self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , vector_db = vector_db , collection_name = collection_name , graph_db = graph_db , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 265 266 267 268 269 270 271 272 273 274 275 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = 4 obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _vector_db = None obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _graph_db = None obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 311 312 313 314 315 316 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"k= { self . k } , num_verification_questions= { self . _num_verification_questions } ,\" f \"transport= { self . transport } , vector_db= { self . vector_db } , collection_name= { self . collection_name } ,\" f \"graph_db= { self . graph_db } , system_message= { self . system_message } )\" ) create_and_process_chain_of_verification_prompts ( message , conversation_history ) Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Parameters: message ( str ) \u2013 the message containing the question and baseline response conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Source code in wiseagents/agents/rag_wise_agents.py 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 def create_and_process_chain_of_verification_prompts ( self , message : str , conversation_history : List [ ChatCompletionMessageParam ]) -> str : \"\"\" Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Args: message (str): the message containing the question and baseline response conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. \"\"\" # plan verifications, taking into account the baseline response and conversation history prompt = ( f \"Given the following question and baseline response, generate a list of { self . num_verification_questions } \" f \" verification questions that could help determine if there are any mistakes in the baseline response:\" f \" \\n { message } \\n \" f \"Your response should contain only the list of questions, one per line. \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) # execute verifications, answering questions independently, without the baseline response verification_questions = llm_response . choices [ 0 ] . message . content . splitlines () verification_responses = \"\" for question in verification_questions : retrieved_documents = self . retrieve_documents ( question ) llm_response = create_and_process_rag_prompt ( retrieved_documents , question , self . llm , False , [], self . system_message ) verification_responses = ( verification_responses + \"Verification Question: \" + question + \" \\n \" + \"Verification Result: \" + llm_response + \" \\n \" ) # generate the final revised response, conditioned on the baseline response and verification results complete_info = message + \" \\n \" + verification_responses prompt = ( f \"Given the following question, baseline response, and a list of verification questions and results,\" f \" generate a revised response incorporating the verification results: \\n { complete_info } \\n \" f \"Your response must contain only the revised response to the question in the JSON format shown below: \\n \" f \" {{ 'revised': 'Your revised response to the question.' }}\\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content process_error ( error ) Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 322 323 324 325 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 318 319 320 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" return self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) process_response ( response ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 344 345 346 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True retrieve_documents ( question ) abstractmethod Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Parameters: question ( str ) \u2013 the question to be used to retrieve the documents Returns: List [ Document ] \u2013 List[Document]: the list of documents retrieved for the question Source code in wiseagents/agents/rag_wise_agents.py 411 412 413 414 415 416 417 418 419 420 421 422 @abstractmethod def retrieve_documents ( self , question : str ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Args: question (str): the question to be used to retrieve the documents Returns: List[Document]: the list of documents retrieved for the question \"\"\" ... stop () Do nothing Source code in wiseagents/agents/rag_wise_agents.py 348 349 350 def stop ( self ): \"\"\"Do nothing\"\"\" pass CoVeChallengerRAGWiseAgent Bases: BaseCoVeChallengerWiseAgent This agent implementation is used to challenge the response from a RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 class CoVeChallengerRAGWiseAgent ( BaseCoVeChallengerWiseAgent ): \"\"\" This agent implementation is used to challenge the response from a RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.CoVeChallengerRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name (Optional[str]): the name of the collection to use in the vector database, defaults to wise-agents-collection k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _num_verification_questions = num_verification_questions llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , vector_db = vector_db , collection_name = collection_name , k = k , num_verification_questions = num_verification_questions ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , k= { self . k } ,\" f \"num_verification_questions= { self . _num_verification_questions } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass def retrieve_documents ( self , question : str ) -> List [ Document ]: return retrieve_documents_for_rag ( question , self . vector_db , self . collection_name , self . k ) __init__ ( name , description , llm , vector_db , transport , collection_name = DEFAULT_COLLECTION_NAME , k = DEFAULT_NUM_DOCUMENTS , num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication collection_name ( Optional [ str ] , default: DEFAULT_COLLECTION_NAME ) \u2013 the name of the collection to use in the vector database, defaults to wise-agents-collection k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional [ int ] , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name (Optional[str]): the name of the collection to use in the vector database, defaults to wise-agents-collection k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _num_verification_questions = num_verification_questions llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , vector_db = vector_db , collection_name = collection_name , k = k , num_verification_questions = num_verification_questions ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 433 434 435 436 437 438 439 440 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 474 475 476 477 478 479 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , k= { self . k } ,\" f \"num_verification_questions= { self . _num_verification_questions } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 485 486 487 488 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 481 482 483 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response process_response ( response ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 507 508 509 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True stop () Do nothing Source code in wiseagents/agents/rag_wise_agents.py 511 512 513 def stop ( self ): \"\"\"Do nothing\"\"\" pass GraphRAGWiseAgent Bases: WiseAgent This agent implementation makes use of Graph Retrieval Augmented Generation (Graph RAG) to answer questions. Source code in wiseagents/agents/rag_wise_agents.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 class GraphRAGWiseAgent ( WiseAgent ): \"\"\" This agent implementation makes use of Graph Retrieval Augmented Generation (Graph RAG) to answer questions. \"\"\" yaml_tag = u '!wiseagents.agents.GraphRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _include_sources = include_sources self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , graph_db = graph_db , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , transport= { self . transport } , k= { self . k } ,\" f \"include_sources= { self . include_sources } ), retrieval_query= { self . retrieval_query } ,\" f \"params= { self . params } , metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the RAG agent and sending the response back to the client. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_graph_rag ( request . message , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve for each query.\"\"\" return self . _k @property def include_sources ( self ) -> bool : \"\"\"Get whether to include the sources of the documents that were consulted to produce the response.\"\"\" return self . _include_sources @property def retrieval_query ( self ) -> str : \"\"\"Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search.\"\"\" return self . _retrieval_query @property def params ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional parameters for the query.\"\"\" return self . _params @property def metadata_filter ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional metadata filter to use with similarity search.\"\"\" return self . _metadata_filter include_sources : bool property Get whether to include the sources of the documents that were consulted to produce the response. k : int property Get the number of documents to retrieve for each query. metadata_filter : Optional [ Dict [ str , Any ]] property Get the optional metadata filter to use with similarity search. name : str property Get the name of the agent. params : Optional [ Dict [ str , Any ]] property Get the optional parameters for the query. retrieval_query : str property Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search. __init__ ( name , description , llm , graph_db , transport , k = DEFAULT_NUM_DOCUMENTS , include_sources = DEFAULT_INCLUDE_SOURCES , retrieval_query = '' , params = None , metadata_filter = None , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM to use for processing requests graph_db ( WiseAgentGraphDB ) \u2013 the graph database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve for each query, defaults to 4 include_sources ( Optional(bool , default: DEFAULT_INCLUDE_SOURCES ) \u2013 whether to include the sources of the documents that were consulted to retrieval_query ( Optional [ str ] , default: '' ) \u2013 the optional retrieval query to use to obtain sub-graphs connected to nodes params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _include_sources = include_sources self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , graph_db = graph_db , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 135 136 137 138 139 140 141 142 143 144 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 182 183 184 185 186 187 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , transport= { self . transport } , k= { self . k } ,\" f \"include_sources= { self . include_sources } ), retrieval_query= { self . retrieval_query } ,\" f \"params= { self . params } , metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 193 194 195 196 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 189 190 191 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by passing it to the RAG agent and sending the response back to the client. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/rag_wise_agents.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the RAG agent and sending the response back to the client. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_graph_rag ( request . message , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources process_response ( response ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 218 219 220 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True stop () Do nothing Source code in wiseagents/agents/rag_wise_agents.py 222 223 224 def stop ( self ): \"\"\"Do nothing\"\"\" pass LLMOnlyWiseAgent Bases: WiseAgent This utility agent simply passes a request that it receives to an LLM for processing and returns the response received from the LLM. Source code in wiseagents/agents/utility_wise_agents.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 class LLMOnlyWiseAgent ( WiseAgent ): \"\"\" This utility agent simply passes a request that it receives to an LLM for processing and returns the response received from the LLM. \"\"\" yaml_tag = u '!wiseagents.agents.LLMOnlyWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name name : str property Get the name of the agent. __init__ ( name , description , llm , transport , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/utility_wise_agents.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 108 109 110 111 112 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 134 135 136 137 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 143 144 145 146 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 139 140 141 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by passing it to the LLM. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/utility_wise_agents.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content process_response ( response ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 167 168 169 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True LLMWiseAgentWithTools Bases: WiseAgent This utility agent makes use of an LLM along with tools to process a request and determine the response to send back to the client. Source code in wiseagents/agents/utility_wise_agents.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 class LLMWiseAgentWithTools ( WiseAgent ): \"\"\" This utility agent makes use of an LLM along with tools to process a request and determine the response to send back to the client. \"\"\" yaml_tag = u '!wiseagents.agents.LLMWiseAgentWithTools' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , tools : List [ str ], system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm self . _tools = tools super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" logging . debug ( f \"IA Request received: { request } \" ) chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : request . message }) for tool in self . _tools : ctx . append_available_tool_in_chat ( chat_uuid = chat_id , tools = WiseAgentRegistry . get_tool ( tool ) . get_tool_OpenAI_format ()) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } , Tools: { ctx . get_available_tools_in_chat ( chat_uuid = chat_id ) } \" ) # TODO: https://github.com/wise-agents/wise-agents/issues/205 llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) ##calling tool response_message = llm_response . choices [ 0 ] . message tool_calls = response_message . tool_calls logging . debug ( f \"Tool calls: { tool_calls } \" ) logging . debug ( f \"Response message: { response_message } \" ) # Step 2: check if the model wanted to call a function if tool_calls is not None : # Step 3: call the function # TODO: the JSON response may not always be valid; be sure to handle errors ctx . append_chat_completion ( chat_uuid = chat_id , messages = response_message ) # extend conversation with assistant's reply # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls : #record the required tool call in the context/chatid ctx . append_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) for tool_call in tool_calls : function_name = tool_call . function . name wise_agent_tool : WiseAgentTool = WiseAgentRegistry . get_tool ( function_name ) if wise_agent_tool . is_agent_tool : #call the agent with correlation ID and complete the chat on response self . send_request ( WiseAgentMessage ( message = tool_call . function . arguments , sender = self . name , chat_id = chat_id , tool_id = tool_call . id , context_name = request . context_name , route_response_to = request . sender ), dest_agent_name = function_name ) else : function_args = json . loads ( tool_call . function . arguments ) function_response = wise_agent_tool . exec ( ** function_args ) logging . debug ( f \"Function response: { function_response } \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : tool_call . id , \"role\" : \"tool\" , \"name\" : function_name , \"content\" : function_response , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) #SEND THE RESPONSE IF NOT ASYNC, OTHERWISE WE WILL DO LATER IN PROCESS_RESPONSE if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { request . sender } \" ) ctx . llm_chat_completion . pop ( chat_id ) return response_message . content def process_response ( self , response : WiseAgentMessage ): \"\"\" Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Args: response (WiseAgentMessage): the response message to process \"\"\" print ( f \"Response received: { response } \" ) chat_id = response . chat_id ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : response . tool_id , \"role\" : \"tool\" , \"name\" : response . sender , \"content\" : response . message , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = response . sender ) if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { response . route_response_to } \" ) self . send_response ( WiseAgentMessage ( response_message . content , self . name ), response . route_response_to ) ctx . llm_chat_completion . pop ( chat_id ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name name : str property Get the name of the agent. __init__ ( name , description , llm , transport , tools , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/utility_wise_agents.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , tools : List [ str ], system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm self . _tools = tools super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 187 188 189 190 191 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 213 214 215 216 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 222 223 224 225 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 218 219 220 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Optional[str]: the response to the request message as a string or None if there is no string response yet Source code in wiseagents/agents/utility_wise_agents.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" logging . debug ( f \"IA Request received: { request } \" ) chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : request . message }) for tool in self . _tools : ctx . append_available_tool_in_chat ( chat_uuid = chat_id , tools = WiseAgentRegistry . get_tool ( tool ) . get_tool_OpenAI_format ()) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } , Tools: { ctx . get_available_tools_in_chat ( chat_uuid = chat_id ) } \" ) # TODO: https://github.com/wise-agents/wise-agents/issues/205 llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) ##calling tool response_message = llm_response . choices [ 0 ] . message tool_calls = response_message . tool_calls logging . debug ( f \"Tool calls: { tool_calls } \" ) logging . debug ( f \"Response message: { response_message } \" ) # Step 2: check if the model wanted to call a function if tool_calls is not None : # Step 3: call the function # TODO: the JSON response may not always be valid; be sure to handle errors ctx . append_chat_completion ( chat_uuid = chat_id , messages = response_message ) # extend conversation with assistant's reply # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls : #record the required tool call in the context/chatid ctx . append_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) for tool_call in tool_calls : function_name = tool_call . function . name wise_agent_tool : WiseAgentTool = WiseAgentRegistry . get_tool ( function_name ) if wise_agent_tool . is_agent_tool : #call the agent with correlation ID and complete the chat on response self . send_request ( WiseAgentMessage ( message = tool_call . function . arguments , sender = self . name , chat_id = chat_id , tool_id = tool_call . id , context_name = request . context_name , route_response_to = request . sender ), dest_agent_name = function_name ) else : function_args = json . loads ( tool_call . function . arguments ) function_response = wise_agent_tool . exec ( ** function_args ) logging . debug ( f \"Function response: { function_response } \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : tool_call . id , \"role\" : \"tool\" , \"name\" : function_name , \"content\" : function_response , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) #SEND THE RESPONSE IF NOT ASYNC, OTHERWISE WE WILL DO LATER IN PROCESS_RESPONSE if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { request . sender } \" ) ctx . llm_chat_completion . pop ( chat_id ) return response_message . content process_response ( response ) Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/utility_wise_agents.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def process_response ( self , response : WiseAgentMessage ): \"\"\" Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Args: response (WiseAgentMessage): the response message to process \"\"\" print ( f \"Response received: { response } \" ) chat_id = response . chat_id ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : response . tool_id , \"role\" : \"tool\" , \"name\" : response . sender , \"content\" : response . message , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = response . sender ) if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { response . route_response_to } \" ) self . send_response ( WiseAgentMessage ( response_message . content , self . name ), response . route_response_to ) ctx . llm_chat_completion . pop ( chat_id ) return True stop () Do nothing Source code in wiseagents/agents/utility_wise_agents.py 334 335 336 def stop ( self ): \"\"\"Do nothing\"\"\" pass PassThroughClientAgent Bases: WiseAgent This utility agent simply passes a request that it receives to another agent and sends the response back to the client. Source code in wiseagents/agents/utility_wise_agents.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class PassThroughClientAgent ( WiseAgent ): \"\"\" This utility agent simply passes a request that it receives to another agent and sends the response back to the client. \"\"\" yaml_tag = u '!wiseagents.agents.PassThroughClientAgent' _response_delivery = None _destination_agent_name = None def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _destination_agent_name = \"WiseIntelligentAgent\" return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : Optional [ str ] = \"WiseIntelligentAgent\" ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\"Process a request message by just passing it to another agent.\"\"\" self . send_request ( WiseAgentMessage ( request , self . name ), self . destination_agent_name ) return None def process_response ( self , response ): \"\"\"Process a response message just sending it back to the client.\"\"\" if self . response_delivery is not None : self . response_delivery ( response ) else : logging . debug ( f \"############################### Not sending response { response } \" ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def destination_agent_name ( self ) -> str : \"\"\"Get the name of the agent to send requests to.\"\"\" return self . _destination_agent_name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client\"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery destination_agent_name : str property Get the name of the agent to send requests to. name : str property Get the name of the agent. response_delivery : Optional [ Callable [[], WiseAgentMessage ]] property Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client __init__ ( name , description , transport , destination_agent_name = 'WiseIntelligentAgent' ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication destination_agent_name ( str , default: 'WiseIntelligentAgent' ) \u2013 the name of the agent to send requests to Source code in wiseagents/agents/utility_wise_agents.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : Optional [ str ] = \"WiseIntelligentAgent\" ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/utility_wise_agents.py 22 23 24 25 26 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _destination_agent_name = \"WiseIntelligentAgent\" return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 43 44 45 46 47 48 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" process_error ( error ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 68 69 70 def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True process_event ( event ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 64 65 66 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by just passing it to another agent. Source code in wiseagents/agents/utility_wise_agents.py 50 51 52 53 54 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\"Process a request message by just passing it to another agent.\"\"\" self . send_request ( WiseAgentMessage ( request , self . name ), self . destination_agent_name ) return None process_response ( response ) Process a response message just sending it back to the client. Source code in wiseagents/agents/utility_wise_agents.py 56 57 58 59 60 61 62 def process_response ( self , response ): \"\"\"Process a response message just sending it back to the client.\"\"\" if self . response_delivery is not None : self . response_delivery ( response ) else : logging . debug ( f \"############################### Not sending response { response } \" ) return True set_response_delivery ( response_delivery ) Set the function to deliver the response to the client. Parameters: response_delivery ( Callable [[], WiseAgentMessage ] ) \u2013 the function to deliver the response to the client Source code in wiseagents/agents/utility_wise_agents.py 92 93 94 95 96 97 98 99 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery stop () Do nothing Source code in wiseagents/agents/utility_wise_agents.py 72 73 74 def stop ( self ): \"\"\"Do nothing\"\"\" pass PhasedCoordinatorWiseAgent Bases: WiseAgent This agent will coordinate the execution of a group of agents in order to determine the response to a query. The agents will be executed in phases, where agents within a phase will be executed in parallel. After the phases have completed, the coordinator may choose to repeat the phases until it is satisfied with the final response or determines it's not possible to answer the query. Source code in wiseagents/agents/coordinator_wise_agents.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 class PhasedCoordinatorWiseAgent ( WiseAgent ): \"\"\" This agent will coordinate the execution of a group of agents in order to determine the response to a query. The agents will be executed in phases, where agents within a phase will be executed in parallel. After the phases have completed, the coordinator may choose to repeat the phases until it is satisfied with the final response or determines it's not possible to answer the query. \"\"\" yaml_tag = u '!wiseagents.agents.PhasedCoordinatorWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _phases = [ \"Data Collection\" , \"Data Analysis\" ] obj . _max_iterations = MAX_ITERATIONS_FOR_COORDINATOR obj . _confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD obj . _system_message = None return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : WiseAgentLLM , phases : Optional [ List [ str ]] = None , max_iterations : Optional [ int ] = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold : Optional [ int ] = CONFIDENCE_SCORE_THRESHOLD , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication llm (WiseAgentLLM): the LLM to use for coordinating the collaboration phases (Optional[List[str]]): the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations (Optional[int]): the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold (Optional[int]): the confidence score threshold to determine if the final answer is acceptable, defaults to 85 system_message (Optional[str]): the optional system message to be used by the coordinator when processing chat completions using its LLM \"\"\" self . _name = name self . _phases = phases if phases is not None else [ \"Data Collection\" , \"Data Analysis\" ] self . _max_iterations = max_iterations self . _confidence_score_threshold = confidence_score_threshold self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = transport , llm = llm , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , transport= { self . transport } ,\" f \"llm= { self . llm } , phases= { self . phases } ,max_iterations= { self . max_iterations } , system_message= { self . system_message } \" ) @property def phases ( self ) -> List [ str ]: \"\"\"Get the list of phases.\"\"\" return self . _phases @property def max_iterations ( self ) -> int : \"\"\"Get the maximum number of iterations.\"\"\" return self . _max_iterations @property def confidence_score_threshold ( self ) -> int : \"\"\"Get the confidence score threshold.\"\"\" return self . _confidence_score_threshold def handle_request ( self , request ): \"\"\" Process a request message by kicking off the collaboration in phases. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . PHASED ) ctx . set_route_response_to ( chat_id , request . sender ) # Determine the agents required to answer the query agent_selection_prompt = ( \"Given the following query and a description of the agents that are available,\" + \" determine all of the agents that could be required to solve the query.\" + \" Format the response as a space separated list of agent names and don't include \" + \" anything else in the response. \\n \" + \" Query: \" + request . message + \" \\n \" + \"Available agents: \\n \" + \" \\n \" . join ( WiseAgentRegistry . get_agent_names_and_descriptions ()) + \" \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_selection_prompt }) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } \" ) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) # Assign the agents to phases agent_assignment_prompt = ( \"Assign each of the agents that will be required to solve the query to one of the following phases: \\n \" + \", \" . join ( self . phases ) + \" \\n \" + \"Assume that agents within a phase will be executed in parallel.\" + \" Format the response as a space separated list of agents for each phase, where the first\" \" line contains the list of agents for the first phase and second line contains the list of\" \" agents for the second phase and so on. Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_assignment_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) phases = [ phase . split () for phase in llm_response . choices [ 0 ] . message . content . splitlines ()] ctx . set_agent_phase_assignments ( chat_id , phases ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , request . message ) # Kick off the first phase for agent in phases [ 0 ]: self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), agent ) def process_response ( self , response ): \"\"\" Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Args: response (WiseAgentMessage): the response message to process \"\"\" ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) chat_id = response . chat_id if response . message_type != WiseAgentMessageType . ACK : raise ValueError ( f \"Unexpected response message: { response . message } \" ) # Remove the agent from the required agents for this phase ctx . remove_required_agent_for_current_phase ( chat_id , response . sender ) # If there are no more agents remaining in this phase, move on to the next phase, # return the final answer, or iterate if len ( ctx . get_required_agents_for_current_phase ( chat_id )) == 0 : next_phase = ctx . get_agents_for_next_phase ( chat_id ) if next_phase is None : # Determine the final answer final_answer_prompt = ( \"What is the final answer for the original query? Provide the answer followed\" + \" by a confidence score from 0 to 100 to indicate how certain you are of the\" + \" answer. Format the response with just the answer first followed by just\" + \" the confidence score on the next line. For example: \\n \" + \" Your answer goes here. \\n \" \" 85 \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : final_answer_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) final_answer_and_score = llm_response . choices [ 0 ] . message . content . splitlines () final_answer = \" \\n \" . join ( final_answer_and_score [: - 1 ]) if final_answer_and_score [ - 1 ] . strip () . isnumeric (): score = int ( final_answer_and_score [ - 1 ]) else : # A score could not be determined score = 0 # Determine if we should return the final answer or iterate if score >= self . confidence_score_threshold : self . send_response ( WiseAgentMessage ( message = final_answer , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) elif len ( ctx . get_queries ( chat_id )) == self . max_iterations : self . send_response ( WiseAgentMessage ( message = CANNOT_ANSWER , message_type = WiseAgentMessageType . CANNOT_ANSWER , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) else : # Rephrase the query and iterate if len ( ctx . get_queries ( chat_id )) < self . max_iterations : rephrase_query_prompt = ( \"The final answer was not considered good enough to respond to the original query. \\n \" + \" The original query was: \" + ctx . get_queries ( chat_id )[ 0 ] + \" \\n \" + \" Your task is to analyze the original query for its intent along with the conversation\" + \" history and final answer to rephrase the original query to yield a better final answer.\" + \" The response should contain only the rephrased query.\" \" Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : rephrase_query_prompt }) # Note that llm_chat_completion[chat_id] is being used here so we have the full history llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) rephrased_query = llm_response . choices [ 0 ] . message . content ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , rephrased_query ) for agent in ctx . get_required_agents_for_current_phase ( chat_id ): self . send_request ( WiseAgentMessage ( message = rephrased_query , sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) else : # Kick off the next phase for agent in next_phase : self . send_request ( WiseAgentMessage ( message = ctx . get_current_query ( chat_id ), sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\" Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the \"\"\" self . _response_delivery = response_delivery confidence_score_threshold : int property Get the confidence score threshold. max_iterations : int property Get the maximum number of iterations. name : str property Get the name of the agent. phases : List [ str ] property Get the list of phases. response_delivery : Optional [ Callable [[], WiseAgentMessage ]] property Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client __init__ ( name , description , transport , llm , phases = None , max_iterations = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication llm ( WiseAgentLLM ) \u2013 the LLM to use for coordinating the collaboration phases ( Optional [ List [ str ]] , default: None ) \u2013 the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations ( Optional [ int ] , default: MAX_ITERATIONS_FOR_COORDINATOR ) \u2013 the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold ( Optional [ int ] , default: CONFIDENCE_SCORE_THRESHOLD ) \u2013 the confidence score threshold to determine if the final answer system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the coordinator when processing Source code in wiseagents/agents/coordinator_wise_agents.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : WiseAgentLLM , phases : Optional [ List [ str ]] = None , max_iterations : Optional [ int ] = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold : Optional [ int ] = CONFIDENCE_SCORE_THRESHOLD , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication llm (WiseAgentLLM): the LLM to use for coordinating the collaboration phases (Optional[List[str]]): the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations (Optional[int]): the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold (Optional[int]): the confidence score threshold to determine if the final answer is acceptable, defaults to 85 system_message (Optional[str]): the optional system message to be used by the coordinator when processing chat completions using its LLM \"\"\" self . _name = name self . _phases = phases if phases is not None else [ \"Data Collection\" , \"Data Analysis\" ] self . _max_iterations = max_iterations self . _confidence_score_threshold = confidence_score_threshold self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = transport , llm = llm , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/coordinator_wise_agents.py 114 115 116 117 118 119 120 121 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _phases = [ \"Data Collection\" , \"Data Analysis\" ] obj . _max_iterations = MAX_ITERATIONS_FOR_COORDINATOR obj . _confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/coordinator_wise_agents.py 148 149 150 151 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , transport= { self . transport } ,\" f \"llm= { self . llm } , phases= { self . phases } ,max_iterations= { self . max_iterations } , system_message= { self . system_message } \" ) handle_request ( request ) Process a request message by kicking off the collaboration in phases. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process Source code in wiseagents/agents/coordinator_wise_agents.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def handle_request ( self , request ): \"\"\" Process a request message by kicking off the collaboration in phases. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . PHASED ) ctx . set_route_response_to ( chat_id , request . sender ) # Determine the agents required to answer the query agent_selection_prompt = ( \"Given the following query and a description of the agents that are available,\" + \" determine all of the agents that could be required to solve the query.\" + \" Format the response as a space separated list of agent names and don't include \" + \" anything else in the response. \\n \" + \" Query: \" + request . message + \" \\n \" + \"Available agents: \\n \" + \" \\n \" . join ( WiseAgentRegistry . get_agent_names_and_descriptions ()) + \" \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_selection_prompt }) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } \" ) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) # Assign the agents to phases agent_assignment_prompt = ( \"Assign each of the agents that will be required to solve the query to one of the following phases: \\n \" + \", \" . join ( self . phases ) + \" \\n \" + \"Assume that agents within a phase will be executed in parallel.\" + \" Format the response as a space separated list of agents for each phase, where the first\" \" line contains the list of agents for the first phase and second line contains the list of\" \" agents for the second phase and so on. Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_assignment_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) phases = [ phase . split () for phase in llm_response . choices [ 0 ] . message . content . splitlines ()] ctx . set_agent_phase_assignments ( chat_id , phases ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , request . message ) # Kick off the first phase for agent in phases [ 0 ]: self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), agent ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/coordinator_wise_agents.py 299 300 301 302 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 295 296 297 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_response ( response ) Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/coordinator_wise_agents.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 def process_response ( self , response ): \"\"\" Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Args: response (WiseAgentMessage): the response message to process \"\"\" ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) chat_id = response . chat_id if response . message_type != WiseAgentMessageType . ACK : raise ValueError ( f \"Unexpected response message: { response . message } \" ) # Remove the agent from the required agents for this phase ctx . remove_required_agent_for_current_phase ( chat_id , response . sender ) # If there are no more agents remaining in this phase, move on to the next phase, # return the final answer, or iterate if len ( ctx . get_required_agents_for_current_phase ( chat_id )) == 0 : next_phase = ctx . get_agents_for_next_phase ( chat_id ) if next_phase is None : # Determine the final answer final_answer_prompt = ( \"What is the final answer for the original query? Provide the answer followed\" + \" by a confidence score from 0 to 100 to indicate how certain you are of the\" + \" answer. Format the response with just the answer first followed by just\" + \" the confidence score on the next line. For example: \\n \" + \" Your answer goes here. \\n \" \" 85 \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : final_answer_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) final_answer_and_score = llm_response . choices [ 0 ] . message . content . splitlines () final_answer = \" \\n \" . join ( final_answer_and_score [: - 1 ]) if final_answer_and_score [ - 1 ] . strip () . isnumeric (): score = int ( final_answer_and_score [ - 1 ]) else : # A score could not be determined score = 0 # Determine if we should return the final answer or iterate if score >= self . confidence_score_threshold : self . send_response ( WiseAgentMessage ( message = final_answer , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) elif len ( ctx . get_queries ( chat_id )) == self . max_iterations : self . send_response ( WiseAgentMessage ( message = CANNOT_ANSWER , message_type = WiseAgentMessageType . CANNOT_ANSWER , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) else : # Rephrase the query and iterate if len ( ctx . get_queries ( chat_id )) < self . max_iterations : rephrase_query_prompt = ( \"The final answer was not considered good enough to respond to the original query. \\n \" + \" The original query was: \" + ctx . get_queries ( chat_id )[ 0 ] + \" \\n \" + \" Your task is to analyze the original query for its intent along with the conversation\" + \" history and final answer to rephrase the original query to yield a better final answer.\" + \" The response should contain only the rephrased query.\" \" Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : rephrase_query_prompt }) # Note that llm_chat_completion[chat_id] is being used here so we have the full history llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) rephrased_query = llm_response . choices [ 0 ] . message . content ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , rephrased_query ) for agent in ctx . get_required_agents_for_current_phase ( chat_id ): self . send_request ( WiseAgentMessage ( message = rephrased_query , sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) else : # Kick off the next phase for agent in next_phase : self . send_request ( WiseAgentMessage ( message = ctx . get_current_query ( chat_id ), sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) return True set_response_delivery ( response_delivery ) Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the Source code in wiseagents/agents/coordinator_wise_agents.py 322 323 324 325 326 327 328 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the \"\"\" self . _response_delivery = response_delivery stop () Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 304 305 306 def stop ( self ): \"\"\"Do nothing\"\"\" pass RAGWiseAgent Bases: WiseAgent This agent makes use of retrieval augmented generation (RAG) to answer questions. Source code in wiseagents/agents/rag_wise_agents.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class RAGWiseAgent ( WiseAgent ): \"\"\" This agent makes use of retrieval augmented generation (RAG) to answer questions. \"\"\" yaml_tag = u '!wiseagents.agents.RAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name Optional(str): the name of the collection within the vector database to use for retrieving documents, defaults to wise-agent-collection k Optional(int): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _include_sources = include_sources super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , vector_db = vector_db , collection_name = collection_name , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , transport= { self . transport } ,\" f \"k= { self . k } , include_sources= { self . include_sources } ), system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message using retrieval augmented generation (RAG). Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_rag ( request . message , self . vector_db , self . collection_name , self . k ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve for each query.\"\"\" return self . _k @property def include_sources ( self ) -> bool : \"\"\"Get whether to include the sources of the documents that were consulted to produce the response.\"\"\" return self . _include_sources include_sources : bool property Get whether to include the sources of the documents that were consulted to produce the response. k : int property Get the number of documents to retrieve for each query. name : str property Get the name of the agent. __init__ ( name , description , llm , vector_db , transport , collection_name = DEFAULT_COLLECTION_NAME , k = DEFAULT_NUM_DOCUMENTS , include_sources = DEFAULT_INCLUDE_SOURCES , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM to use for processing requests vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication collection_name ( Optional(str , default: DEFAULT_COLLECTION_NAME ) \u2013 the name of the collection within the vector database to use for k ( Optional(int , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve for each query, defaults to 4 include_sources ( Optional(bool , default: DEFAULT_INCLUDE_SOURCES ) \u2013 whether to include the sources of the documents that were consulted to Source code in wiseagents/agents/rag_wise_agents.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name Optional(str): the name of the collection within the vector database to use for retrieving documents, defaults to wise-agent-collection k Optional(int): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _include_sources = include_sources super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , vector_db = vector_db , collection_name = collection_name , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 32 33 34 35 36 37 38 39 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 70 71 72 73 74 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , transport= { self . transport } ,\" f \"k= { self . k } , include_sources= { self . include_sources } ), system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 80 81 82 83 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 76 77 78 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message using retrieval augmented generation (RAG). Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/rag_wise_agents.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message using retrieval augmented generation (RAG). Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_rag ( request . message , self . vector_db , self . collection_name , self . k ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources process_response ( response ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 105 106 107 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True stop () Do nothing Source code in wiseagents/agents/rag_wise_agents.py 109 110 111 def stop ( self ): \"\"\"Do nothing\"\"\" pass SequentialCoordinatorWiseAgent Bases: WiseAgent This agent will coordinate the execution of a sequence of agents. Use Stomp protocol. Source code in wiseagents/agents/coordinator_wise_agents.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 class SequentialCoordinatorWiseAgent ( WiseAgent ): \"\"\" This agent will coordinate the execution of a sequence of agents. Use Stomp protocol. \"\"\" yaml_tag = u '!wiseagents.agents.SequentialCoordinatorWiseAgent' def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , agents : List [ str ]): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication agents (List[str]): the list of agents to coordinate \"\"\" self . _name = name self . _agents = agents super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , agents= { self . agents } )\" def handle_request ( self , request ): \"\"\" Process a request message by passing it to the first agent in the sequence. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Sequential coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . SEQUENTIAL ) ctx . set_agents_sequence ( chat_id , self . _agents ) ctx . set_route_response_to ( chat_id , request . sender ) self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), self . _agents [ 0 ]) def process_response ( self , response ): \"\"\" Process a response message by passing it to the next agent in the sequence. Args: response (WiseAgentMessage): the response message to process \"\"\" if response . message : raise ValueError ( f \"Unexpected response message: { response . message } \" ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def agents ( self ) -> List [ str ]: \"\"\"Get the list of agents.\"\"\" return self . _agents @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\" Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\"Set the function to deliver the response to the client.\"\"\" self . _response_delivery = response_delivery agents : List [ str ] property Get the list of agents. name : str property Get the name of the agent. response_delivery : Optional [ Callable [[], WiseAgentMessage ]] property Get the function to deliver the response to the client. Returns: Callable [[], WiseAgentMessage ] \u2013 the function to deliver the response to the client __init__ ( name , description , transport , agents ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication agents ( List [ str ] ) \u2013 the list of agents to coordinate Source code in wiseagents/agents/coordinator_wise_agents.py 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , agents : List [ str ]): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication agents (List[str]): the list of agents to coordinate \"\"\" self . _name = name self . _agents = agents super () . __init__ ( name = name , description = description , transport = transport , llm = None ) __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/coordinator_wise_agents.py 33 34 35 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , agents= { self . agents } )\" handle_request ( request ) Process a request message by passing it to the first agent in the sequence. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process Source code in wiseagents/agents/coordinator_wise_agents.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def handle_request ( self , request ): \"\"\" Process a request message by passing it to the first agent in the sequence. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Sequential coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . SEQUENTIAL ) ctx . set_agents_sequence ( chat_id , self . _agents ) ctx . set_route_response_to ( chat_id , request . sender ) self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), self . _agents [ 0 ]) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/coordinator_wise_agents.py 71 72 73 74 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 67 68 69 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_response ( response ) Process a response message by passing it to the next agent in the sequence. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/coordinator_wise_agents.py 56 57 58 59 60 61 62 63 64 65 def process_response ( self , response ): \"\"\" Process a response message by passing it to the next agent in the sequence. Args: response (WiseAgentMessage): the response message to process \"\"\" if response . message : raise ValueError ( f \"Unexpected response message: { response . message } \" ) return True set_response_delivery ( response_delivery ) Set the function to deliver the response to the client. Source code in wiseagents/agents/coordinator_wise_agents.py 100 101 102 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\"Set the function to deliver the response to the client.\"\"\" self . _response_delivery = response_delivery stop () Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 76 77 78 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"agents"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent","text":"Bases: WiseAgent This utility agent start a web interface and pass the user input to another agent. The web interface will be running at http://127.0.0.1:7860 Source code in wiseagents/agents/assistant.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 class AssistantAgent ( WiseAgent ): \"\"\" This utility agent start a web interface and pass the user input to another agent. The web interface will be running at http://127.0.0.1:7860 \"\"\" yaml_tag = u '!wiseagents.agents.AssistantAgent' _response_delivery = None _cond = threading . Condition () _response : WiseAgentMessage = None _chat_id = None def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : str ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" def start_agent ( self ): super () . start_agent () self . _chat_id = str ( uuid . uuid4 ()) WiseAgentRegistry . get_or_create_context ( \"default\" ) . set_collaboration_type ( self . _chat_id , WiseAgentCollaborationType . CHAT ) gradio . ChatInterface ( self . slow_echo ) . launch ( prevent_thread_lock = True ) def slow_echo ( self , message , history ): with self . _cond : self . handle_request ( WiseAgentMessage ( message = message , sender = self . name , chat_id = self . _chat_id )) self . _cond . wait () return self . _response . message def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by just passing it to another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" print ( f \"AssistantAgent: process_request: { request } \" ) WiseAgentRegistry . get_or_create_context ( \"default\" ) . append_chat_completion ( self . _chat_id , { \"role\" : \"user\" , \"content\" : request . message }) self . send_request ( request , self . destination_agent_name ) return None def process_response ( self , response : WiseAgentMessage ): \"\"\"Process a response message just sending it back to the client.\"\"\" print ( f \"AssistantAgent: process_response: { response } \" ) with self . _cond : self . _response = response self . _cond . notify () return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def destination_agent_name ( self ) -> str : \"\"\"Get the name of the agent to send requests to.\"\"\" return self . _destination_agent_name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client\"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery","title":"AssistantAgent"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.destination_agent_name","text":"Get the name of the agent to send requests to.","title":"destination_agent_name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.response_delivery","text":"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client","title":"response_delivery"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication destination_agent_name ( str ) \u2013 the name of the agent to send requests to Source code in wiseagents/agents/assistant.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : str ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/assistant.py 26 27 28 29 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) return obj","title":"__new__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/assistant.py 46 47 48 49 50 51 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \"","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.process_error","text":"Do nothing Source code in wiseagents/agents/assistant.py 98 99 100 def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.process_event","text":"Do nothing Source code in wiseagents/agents/assistant.py 94 95 96 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.process_request","text":"Process a request message by just passing it to another agent. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/assistant.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by just passing it to another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" print ( f \"AssistantAgent: process_request: { request } \" ) WiseAgentRegistry . get_or_create_context ( \"default\" ) . append_chat_completion ( self . _chat_id , { \"role\" : \"user\" , \"content\" : request . message }) self . send_request ( request , self . destination_agent_name ) return None","title":"process_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.process_response","text":"Process a response message just sending it back to the client. Source code in wiseagents/agents/assistant.py 86 87 88 89 90 91 92 def process_response ( self , response : WiseAgentMessage ): \"\"\"Process a response message just sending it back to the client.\"\"\" print ( f \"AssistantAgent: process_response: { response } \" ) with self . _cond : self . _response = response self . _cond . notify () return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.set_response_delivery","text":"Set the function to deliver the response to the client. Parameters: response_delivery ( Callable [[], WiseAgentMessage ] ) \u2013 the function to deliver the response to the client Source code in wiseagents/agents/assistant.py 122 123 124 125 126 127 128 129 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery","title":"set_response_delivery"},{"location":"reference/wiseagents/agents/#wiseagents.agents.AssistantAgent.stop","text":"Do nothing Source code in wiseagents/agents/assistant.py 102 103 104 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent","text":"Bases: WiseAgent This abstract agent implementation is used to challenge the response from a RAG or Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 class BaseCoVeChallengerWiseAgent ( WiseAgent ): \"\"\" This abstract agent implementation is used to challenge the response from a RAG or Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.BaseCoVeChallengerWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = 4 obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _vector_db = None obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _graph_db = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication k Optional(int): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions Optional(int): the number of verification questions to generate, defaults to 4 vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent (to be used for challenging RAG results) collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _k = k self . _num_verification_questions = num_verification_questions self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , vector_db = vector_db , collection_name = collection_name , graph_db = graph_db , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"k= { self . k } , num_verification_questions= { self . _num_verification_questions } ,\" f \"transport= { self . transport } , vector_db= { self . vector_db } , collection_name= { self . collection_name } ,\" f \"graph_db= { self . graph_db } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" return self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve.\"\"\" return self . _k @property def num_verification_questions ( self ) -> int : \"\"\"Get the number of verification questions to generate.\"\"\" return self . _num_verification_questions def create_and_process_chain_of_verification_prompts ( self , message : str , conversation_history : List [ ChatCompletionMessageParam ]) -> str : \"\"\" Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Args: message (str): the message containing the question and baseline response conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. \"\"\" # plan verifications, taking into account the baseline response and conversation history prompt = ( f \"Given the following question and baseline response, generate a list of { self . num_verification_questions } \" f \" verification questions that could help determine if there are any mistakes in the baseline response:\" f \" \\n { message } \\n \" f \"Your response should contain only the list of questions, one per line. \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) # execute verifications, answering questions independently, without the baseline response verification_questions = llm_response . choices [ 0 ] . message . content . splitlines () verification_responses = \"\" for question in verification_questions : retrieved_documents = self . retrieve_documents ( question ) llm_response = create_and_process_rag_prompt ( retrieved_documents , question , self . llm , False , [], self . system_message ) verification_responses = ( verification_responses + \"Verification Question: \" + question + \" \\n \" + \"Verification Result: \" + llm_response + \" \\n \" ) # generate the final revised response, conditioned on the baseline response and verification results complete_info = message + \" \\n \" + verification_responses prompt = ( f \"Given the following question, baseline response, and a list of verification questions and results,\" f \" generate a revised response incorporating the verification results: \\n { complete_info } \\n \" f \"Your response must contain only the revised response to the question in the JSON format shown below: \\n \" f \" {{ 'revised': 'Your revised response to the question.' }}\\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content @abstractmethod def retrieve_documents ( self , question : str ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Args: question (str): the question to be used to retrieve the documents Returns: List[Document]: the list of documents retrieved for the question \"\"\" ...","title":"BaseCoVeChallengerWiseAgent"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.k","text":"Get the number of documents to retrieve.","title":"k"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.num_verification_questions","text":"Get the number of verification questions to generate.","title":"num_verification_questions"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional(int , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional(int , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 vector_db ( Optional [ WiseAgentVectorDB ] , default: None ) \u2013 the vector DB associated with the agent (to be used for challenging RAG results) collection_name ( Optional[str]) = \"wise-agent-collection\" , default: DEFAULT_COLLECTION_NAME ) \u2013 the vector DB collection name associated with the agent graph_db ( Optional [ WiseAgentGraphDB ] , default: None ) \u2013 the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication k Optional(int): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions Optional(int): the number of verification questions to generate, defaults to 4 vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent (to be used for challenging RAG results) collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _k = k self . _num_verification_questions = num_verification_questions self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , vector_db = vector_db , collection_name = collection_name , graph_db = graph_db , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 265 266 267 268 269 270 271 272 273 274 275 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = 4 obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _vector_db = None obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _graph_db = None obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 311 312 313 314 315 316 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"k= { self . k } , num_verification_questions= { self . _num_verification_questions } ,\" f \"transport= { self . transport } , vector_db= { self . vector_db } , collection_name= { self . collection_name } ,\" f \"graph_db= { self . graph_db } , system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.create_and_process_chain_of_verification_prompts","text":"Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Parameters: message ( str ) \u2013 the message containing the question and baseline response conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Source code in wiseagents/agents/rag_wise_agents.py 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 def create_and_process_chain_of_verification_prompts ( self , message : str , conversation_history : List [ ChatCompletionMessageParam ]) -> str : \"\"\" Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Args: message (str): the message containing the question and baseline response conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. \"\"\" # plan verifications, taking into account the baseline response and conversation history prompt = ( f \"Given the following question and baseline response, generate a list of { self . num_verification_questions } \" f \" verification questions that could help determine if there are any mistakes in the baseline response:\" f \" \\n { message } \\n \" f \"Your response should contain only the list of questions, one per line. \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) # execute verifications, answering questions independently, without the baseline response verification_questions = llm_response . choices [ 0 ] . message . content . splitlines () verification_responses = \"\" for question in verification_questions : retrieved_documents = self . retrieve_documents ( question ) llm_response = create_and_process_rag_prompt ( retrieved_documents , question , self . llm , False , [], self . system_message ) verification_responses = ( verification_responses + \"Verification Question: \" + question + \" \\n \" + \"Verification Result: \" + llm_response + \" \\n \" ) # generate the final revised response, conditioned on the baseline response and verification results complete_info = message + \" \\n \" + verification_responses prompt = ( f \"Given the following question, baseline response, and a list of verification questions and results,\" f \" generate a revised response incorporating the verification results: \\n { complete_info } \\n \" f \"Your response must contain only the revised response to the question in the JSON format shown below: \\n \" f \" {{ 'revised': 'Your revised response to the question.' }}\\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content","title":"create_and_process_chain_of_verification_prompts"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 322 323 324 325 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 318 319 320 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.process_request","text":"Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" return self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history )","title":"process_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 344 345 346 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.retrieve_documents","text":"Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Parameters: question ( str ) \u2013 the question to be used to retrieve the documents Returns: List [ Document ] \u2013 List[Document]: the list of documents retrieved for the question Source code in wiseagents/agents/rag_wise_agents.py 411 412 413 414 415 416 417 418 419 420 421 422 @abstractmethod def retrieve_documents ( self , question : str ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Args: question (str): the question to be used to retrieve the documents Returns: List[Document]: the list of documents retrieved for the question \"\"\" ...","title":"retrieve_documents"},{"location":"reference/wiseagents/agents/#wiseagents.agents.BaseCoVeChallengerWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 348 349 350 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/#wiseagents.agents.CoVeChallengerRAGWiseAgent","text":"Bases: BaseCoVeChallengerWiseAgent This agent implementation is used to challenge the response from a RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 class CoVeChallengerRAGWiseAgent ( BaseCoVeChallengerWiseAgent ): \"\"\" This agent implementation is used to challenge the response from a RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.CoVeChallengerRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name (Optional[str]): the name of the collection to use in the vector database, defaults to wise-agents-collection k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _num_verification_questions = num_verification_questions llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , vector_db = vector_db , collection_name = collection_name , k = k , num_verification_questions = num_verification_questions ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , k= { self . k } ,\" f \"num_verification_questions= { self . _num_verification_questions } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass def retrieve_documents ( self , question : str ) -> List [ Document ]: return retrieve_documents_for_rag ( question , self . vector_db , self . collection_name , self . k )","title":"CoVeChallengerRAGWiseAgent"},{"location":"reference/wiseagents/agents/#wiseagents.agents.CoVeChallengerRAGWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication collection_name ( Optional [ str ] , default: DEFAULT_COLLECTION_NAME ) \u2013 the name of the collection to use in the vector database, defaults to wise-agents-collection k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional [ int ] , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name (Optional[str]): the name of the collection to use in the vector database, defaults to wise-agents-collection k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _num_verification_questions = num_verification_questions llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , vector_db = vector_db , collection_name = collection_name , k = k , num_verification_questions = num_verification_questions )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.CoVeChallengerRAGWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 433 434 435 436 437 438 439 440 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.CoVeChallengerRAGWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 474 475 476 477 478 479 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , k= { self . k } ,\" f \"num_verification_questions= { self . _num_verification_questions } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.CoVeChallengerRAGWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 485 486 487 488 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.CoVeChallengerRAGWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 481 482 483 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.CoVeChallengerRAGWiseAgent.process_request","text":"Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response","title":"process_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.CoVeChallengerRAGWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 507 508 509 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.CoVeChallengerRAGWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 511 512 513 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent","text":"Bases: WiseAgent This agent implementation makes use of Graph Retrieval Augmented Generation (Graph RAG) to answer questions. Source code in wiseagents/agents/rag_wise_agents.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 class GraphRAGWiseAgent ( WiseAgent ): \"\"\" This agent implementation makes use of Graph Retrieval Augmented Generation (Graph RAG) to answer questions. \"\"\" yaml_tag = u '!wiseagents.agents.GraphRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _include_sources = include_sources self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , graph_db = graph_db , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , transport= { self . transport } , k= { self . k } ,\" f \"include_sources= { self . include_sources } ), retrieval_query= { self . retrieval_query } ,\" f \"params= { self . params } , metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the RAG agent and sending the response back to the client. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_graph_rag ( request . message , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve for each query.\"\"\" return self . _k @property def include_sources ( self ) -> bool : \"\"\"Get whether to include the sources of the documents that were consulted to produce the response.\"\"\" return self . _include_sources @property def retrieval_query ( self ) -> str : \"\"\"Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search.\"\"\" return self . _retrieval_query @property def params ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional parameters for the query.\"\"\" return self . _params @property def metadata_filter ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional metadata filter to use with similarity search.\"\"\" return self . _metadata_filter","title":"GraphRAGWiseAgent"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.include_sources","text":"Get whether to include the sources of the documents that were consulted to produce the response.","title":"include_sources"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.k","text":"Get the number of documents to retrieve for each query.","title":"k"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.metadata_filter","text":"Get the optional metadata filter to use with similarity search.","title":"metadata_filter"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.params","text":"Get the optional parameters for the query.","title":"params"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.retrieval_query","text":"Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search.","title":"retrieval_query"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM to use for processing requests graph_db ( WiseAgentGraphDB ) \u2013 the graph database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve for each query, defaults to 4 include_sources ( Optional(bool , default: DEFAULT_INCLUDE_SOURCES ) \u2013 whether to include the sources of the documents that were consulted to retrieval_query ( Optional [ str ] , default: '' ) \u2013 the optional retrieval query to use to obtain sub-graphs connected to nodes params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _include_sources = include_sources self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , graph_db = graph_db , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 135 136 137 138 139 140 141 142 143 144 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 182 183 184 185 186 187 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , transport= { self . transport } , k= { self . k } ,\" f \"include_sources= { self . include_sources } ), retrieval_query= { self . retrieval_query } ,\" f \"params= { self . params } , metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 193 194 195 196 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 189 190 191 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.process_request","text":"Process a request message by passing it to the RAG agent and sending the response back to the client. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/rag_wise_agents.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the RAG agent and sending the response back to the client. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_graph_rag ( request . message , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources","title":"process_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 218 219 220 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.GraphRAGWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 222 223 224 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMOnlyWiseAgent","text":"Bases: WiseAgent This utility agent simply passes a request that it receives to an LLM for processing and returns the response received from the LLM. Source code in wiseagents/agents/utility_wise_agents.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 class LLMOnlyWiseAgent ( WiseAgent ): \"\"\" This utility agent simply passes a request that it receives to an LLM for processing and returns the response received from the LLM. \"\"\" yaml_tag = u '!wiseagents.agents.LLMOnlyWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name","title":"LLMOnlyWiseAgent"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMOnlyWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMOnlyWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/utility_wise_agents.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMOnlyWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 108 109 110 111 112 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMOnlyWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 134 135 136 137 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMOnlyWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 143 144 145 146 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMOnlyWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 139 140 141 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMOnlyWiseAgent.process_request","text":"Process a request message by passing it to the LLM. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/utility_wise_agents.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content","title":"process_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMOnlyWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 167 168 169 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools","text":"Bases: WiseAgent This utility agent makes use of an LLM along with tools to process a request and determine the response to send back to the client. Source code in wiseagents/agents/utility_wise_agents.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 class LLMWiseAgentWithTools ( WiseAgent ): \"\"\" This utility agent makes use of an LLM along with tools to process a request and determine the response to send back to the client. \"\"\" yaml_tag = u '!wiseagents.agents.LLMWiseAgentWithTools' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , tools : List [ str ], system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm self . _tools = tools super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" logging . debug ( f \"IA Request received: { request } \" ) chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : request . message }) for tool in self . _tools : ctx . append_available_tool_in_chat ( chat_uuid = chat_id , tools = WiseAgentRegistry . get_tool ( tool ) . get_tool_OpenAI_format ()) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } , Tools: { ctx . get_available_tools_in_chat ( chat_uuid = chat_id ) } \" ) # TODO: https://github.com/wise-agents/wise-agents/issues/205 llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) ##calling tool response_message = llm_response . choices [ 0 ] . message tool_calls = response_message . tool_calls logging . debug ( f \"Tool calls: { tool_calls } \" ) logging . debug ( f \"Response message: { response_message } \" ) # Step 2: check if the model wanted to call a function if tool_calls is not None : # Step 3: call the function # TODO: the JSON response may not always be valid; be sure to handle errors ctx . append_chat_completion ( chat_uuid = chat_id , messages = response_message ) # extend conversation with assistant's reply # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls : #record the required tool call in the context/chatid ctx . append_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) for tool_call in tool_calls : function_name = tool_call . function . name wise_agent_tool : WiseAgentTool = WiseAgentRegistry . get_tool ( function_name ) if wise_agent_tool . is_agent_tool : #call the agent with correlation ID and complete the chat on response self . send_request ( WiseAgentMessage ( message = tool_call . function . arguments , sender = self . name , chat_id = chat_id , tool_id = tool_call . id , context_name = request . context_name , route_response_to = request . sender ), dest_agent_name = function_name ) else : function_args = json . loads ( tool_call . function . arguments ) function_response = wise_agent_tool . exec ( ** function_args ) logging . debug ( f \"Function response: { function_response } \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : tool_call . id , \"role\" : \"tool\" , \"name\" : function_name , \"content\" : function_response , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) #SEND THE RESPONSE IF NOT ASYNC, OTHERWISE WE WILL DO LATER IN PROCESS_RESPONSE if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { request . sender } \" ) ctx . llm_chat_completion . pop ( chat_id ) return response_message . content def process_response ( self , response : WiseAgentMessage ): \"\"\" Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Args: response (WiseAgentMessage): the response message to process \"\"\" print ( f \"Response received: { response } \" ) chat_id = response . chat_id ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : response . tool_id , \"role\" : \"tool\" , \"name\" : response . sender , \"content\" : response . message , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = response . sender ) if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { response . route_response_to } \" ) self . send_response ( WiseAgentMessage ( response_message . content , self . name ), response . route_response_to ) ctx . llm_chat_completion . pop ( chat_id ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name","title":"LLMWiseAgentWithTools"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/utility_wise_agents.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , tools : List [ str ], system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm self . _tools = tools super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 187 188 189 190 191 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 213 214 215 216 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools.process_error","text":"Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 222 223 224 225 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools.process_event","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 218 219 220 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools.process_request","text":"Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Optional[str]: the response to the request message as a string or None if there is no string response yet Source code in wiseagents/agents/utility_wise_agents.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" logging . debug ( f \"IA Request received: { request } \" ) chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : request . message }) for tool in self . _tools : ctx . append_available_tool_in_chat ( chat_uuid = chat_id , tools = WiseAgentRegistry . get_tool ( tool ) . get_tool_OpenAI_format ()) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } , Tools: { ctx . get_available_tools_in_chat ( chat_uuid = chat_id ) } \" ) # TODO: https://github.com/wise-agents/wise-agents/issues/205 llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) ##calling tool response_message = llm_response . choices [ 0 ] . message tool_calls = response_message . tool_calls logging . debug ( f \"Tool calls: { tool_calls } \" ) logging . debug ( f \"Response message: { response_message } \" ) # Step 2: check if the model wanted to call a function if tool_calls is not None : # Step 3: call the function # TODO: the JSON response may not always be valid; be sure to handle errors ctx . append_chat_completion ( chat_uuid = chat_id , messages = response_message ) # extend conversation with assistant's reply # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls : #record the required tool call in the context/chatid ctx . append_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) for tool_call in tool_calls : function_name = tool_call . function . name wise_agent_tool : WiseAgentTool = WiseAgentRegistry . get_tool ( function_name ) if wise_agent_tool . is_agent_tool : #call the agent with correlation ID and complete the chat on response self . send_request ( WiseAgentMessage ( message = tool_call . function . arguments , sender = self . name , chat_id = chat_id , tool_id = tool_call . id , context_name = request . context_name , route_response_to = request . sender ), dest_agent_name = function_name ) else : function_args = json . loads ( tool_call . function . arguments ) function_response = wise_agent_tool . exec ( ** function_args ) logging . debug ( f \"Function response: { function_response } \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : tool_call . id , \"role\" : \"tool\" , \"name\" : function_name , \"content\" : function_response , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) #SEND THE RESPONSE IF NOT ASYNC, OTHERWISE WE WILL DO LATER IN PROCESS_RESPONSE if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { request . sender } \" ) ctx . llm_chat_completion . pop ( chat_id ) return response_message . content","title":"process_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools.process_response","text":"Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/utility_wise_agents.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def process_response ( self , response : WiseAgentMessage ): \"\"\" Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Args: response (WiseAgentMessage): the response message to process \"\"\" print ( f \"Response received: { response } \" ) chat_id = response . chat_id ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : response . tool_id , \"role\" : \"tool\" , \"name\" : response . sender , \"content\" : response . message , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = response . sender ) if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { response . route_response_to } \" ) self . send_response ( WiseAgentMessage ( response_message . content , self . name ), response . route_response_to ) ctx . llm_chat_completion . pop ( chat_id ) return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.LLMWiseAgentWithTools.stop","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 334 335 336 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent","text":"Bases: WiseAgent This utility agent simply passes a request that it receives to another agent and sends the response back to the client. Source code in wiseagents/agents/utility_wise_agents.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class PassThroughClientAgent ( WiseAgent ): \"\"\" This utility agent simply passes a request that it receives to another agent and sends the response back to the client. \"\"\" yaml_tag = u '!wiseagents.agents.PassThroughClientAgent' _response_delivery = None _destination_agent_name = None def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _destination_agent_name = \"WiseIntelligentAgent\" return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : Optional [ str ] = \"WiseIntelligentAgent\" ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\"Process a request message by just passing it to another agent.\"\"\" self . send_request ( WiseAgentMessage ( request , self . name ), self . destination_agent_name ) return None def process_response ( self , response ): \"\"\"Process a response message just sending it back to the client.\"\"\" if self . response_delivery is not None : self . response_delivery ( response ) else : logging . debug ( f \"############################### Not sending response { response } \" ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def destination_agent_name ( self ) -> str : \"\"\"Get the name of the agent to send requests to.\"\"\" return self . _destination_agent_name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client\"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery","title":"PassThroughClientAgent"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.destination_agent_name","text":"Get the name of the agent to send requests to.","title":"destination_agent_name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.response_delivery","text":"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client","title":"response_delivery"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication destination_agent_name ( str , default: 'WiseIntelligentAgent' ) \u2013 the name of the agent to send requests to Source code in wiseagents/agents/utility_wise_agents.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : Optional [ str ] = \"WiseIntelligentAgent\" ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/utility_wise_agents.py 22 23 24 25 26 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _destination_agent_name = \"WiseIntelligentAgent\" return obj","title":"__new__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 43 44 45 46 47 48 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \"","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.process_error","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 68 69 70 def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.process_event","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 64 65 66 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.process_request","text":"Process a request message by just passing it to another agent. Source code in wiseagents/agents/utility_wise_agents.py 50 51 52 53 54 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\"Process a request message by just passing it to another agent.\"\"\" self . send_request ( WiseAgentMessage ( request , self . name ), self . destination_agent_name ) return None","title":"process_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.process_response","text":"Process a response message just sending it back to the client. Source code in wiseagents/agents/utility_wise_agents.py 56 57 58 59 60 61 62 def process_response ( self , response ): \"\"\"Process a response message just sending it back to the client.\"\"\" if self . response_delivery is not None : self . response_delivery ( response ) else : logging . debug ( f \"############################### Not sending response { response } \" ) return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.set_response_delivery","text":"Set the function to deliver the response to the client. Parameters: response_delivery ( Callable [[], WiseAgentMessage ] ) \u2013 the function to deliver the response to the client Source code in wiseagents/agents/utility_wise_agents.py 92 93 94 95 96 97 98 99 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery","title":"set_response_delivery"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PassThroughClientAgent.stop","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 72 73 74 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent","text":"Bases: WiseAgent This agent will coordinate the execution of a group of agents in order to determine the response to a query. The agents will be executed in phases, where agents within a phase will be executed in parallel. After the phases have completed, the coordinator may choose to repeat the phases until it is satisfied with the final response or determines it's not possible to answer the query. Source code in wiseagents/agents/coordinator_wise_agents.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 class PhasedCoordinatorWiseAgent ( WiseAgent ): \"\"\" This agent will coordinate the execution of a group of agents in order to determine the response to a query. The agents will be executed in phases, where agents within a phase will be executed in parallel. After the phases have completed, the coordinator may choose to repeat the phases until it is satisfied with the final response or determines it's not possible to answer the query. \"\"\" yaml_tag = u '!wiseagents.agents.PhasedCoordinatorWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _phases = [ \"Data Collection\" , \"Data Analysis\" ] obj . _max_iterations = MAX_ITERATIONS_FOR_COORDINATOR obj . _confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD obj . _system_message = None return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : WiseAgentLLM , phases : Optional [ List [ str ]] = None , max_iterations : Optional [ int ] = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold : Optional [ int ] = CONFIDENCE_SCORE_THRESHOLD , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication llm (WiseAgentLLM): the LLM to use for coordinating the collaboration phases (Optional[List[str]]): the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations (Optional[int]): the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold (Optional[int]): the confidence score threshold to determine if the final answer is acceptable, defaults to 85 system_message (Optional[str]): the optional system message to be used by the coordinator when processing chat completions using its LLM \"\"\" self . _name = name self . _phases = phases if phases is not None else [ \"Data Collection\" , \"Data Analysis\" ] self . _max_iterations = max_iterations self . _confidence_score_threshold = confidence_score_threshold self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = transport , llm = llm , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , transport= { self . transport } ,\" f \"llm= { self . llm } , phases= { self . phases } ,max_iterations= { self . max_iterations } , system_message= { self . system_message } \" ) @property def phases ( self ) -> List [ str ]: \"\"\"Get the list of phases.\"\"\" return self . _phases @property def max_iterations ( self ) -> int : \"\"\"Get the maximum number of iterations.\"\"\" return self . _max_iterations @property def confidence_score_threshold ( self ) -> int : \"\"\"Get the confidence score threshold.\"\"\" return self . _confidence_score_threshold def handle_request ( self , request ): \"\"\" Process a request message by kicking off the collaboration in phases. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . PHASED ) ctx . set_route_response_to ( chat_id , request . sender ) # Determine the agents required to answer the query agent_selection_prompt = ( \"Given the following query and a description of the agents that are available,\" + \" determine all of the agents that could be required to solve the query.\" + \" Format the response as a space separated list of agent names and don't include \" + \" anything else in the response. \\n \" + \" Query: \" + request . message + \" \\n \" + \"Available agents: \\n \" + \" \\n \" . join ( WiseAgentRegistry . get_agent_names_and_descriptions ()) + \" \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_selection_prompt }) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } \" ) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) # Assign the agents to phases agent_assignment_prompt = ( \"Assign each of the agents that will be required to solve the query to one of the following phases: \\n \" + \", \" . join ( self . phases ) + \" \\n \" + \"Assume that agents within a phase will be executed in parallel.\" + \" Format the response as a space separated list of agents for each phase, where the first\" \" line contains the list of agents for the first phase and second line contains the list of\" \" agents for the second phase and so on. Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_assignment_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) phases = [ phase . split () for phase in llm_response . choices [ 0 ] . message . content . splitlines ()] ctx . set_agent_phase_assignments ( chat_id , phases ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , request . message ) # Kick off the first phase for agent in phases [ 0 ]: self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), agent ) def process_response ( self , response ): \"\"\" Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Args: response (WiseAgentMessage): the response message to process \"\"\" ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) chat_id = response . chat_id if response . message_type != WiseAgentMessageType . ACK : raise ValueError ( f \"Unexpected response message: { response . message } \" ) # Remove the agent from the required agents for this phase ctx . remove_required_agent_for_current_phase ( chat_id , response . sender ) # If there are no more agents remaining in this phase, move on to the next phase, # return the final answer, or iterate if len ( ctx . get_required_agents_for_current_phase ( chat_id )) == 0 : next_phase = ctx . get_agents_for_next_phase ( chat_id ) if next_phase is None : # Determine the final answer final_answer_prompt = ( \"What is the final answer for the original query? Provide the answer followed\" + \" by a confidence score from 0 to 100 to indicate how certain you are of the\" + \" answer. Format the response with just the answer first followed by just\" + \" the confidence score on the next line. For example: \\n \" + \" Your answer goes here. \\n \" \" 85 \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : final_answer_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) final_answer_and_score = llm_response . choices [ 0 ] . message . content . splitlines () final_answer = \" \\n \" . join ( final_answer_and_score [: - 1 ]) if final_answer_and_score [ - 1 ] . strip () . isnumeric (): score = int ( final_answer_and_score [ - 1 ]) else : # A score could not be determined score = 0 # Determine if we should return the final answer or iterate if score >= self . confidence_score_threshold : self . send_response ( WiseAgentMessage ( message = final_answer , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) elif len ( ctx . get_queries ( chat_id )) == self . max_iterations : self . send_response ( WiseAgentMessage ( message = CANNOT_ANSWER , message_type = WiseAgentMessageType . CANNOT_ANSWER , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) else : # Rephrase the query and iterate if len ( ctx . get_queries ( chat_id )) < self . max_iterations : rephrase_query_prompt = ( \"The final answer was not considered good enough to respond to the original query. \\n \" + \" The original query was: \" + ctx . get_queries ( chat_id )[ 0 ] + \" \\n \" + \" Your task is to analyze the original query for its intent along with the conversation\" + \" history and final answer to rephrase the original query to yield a better final answer.\" + \" The response should contain only the rephrased query.\" \" Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : rephrase_query_prompt }) # Note that llm_chat_completion[chat_id] is being used here so we have the full history llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) rephrased_query = llm_response . choices [ 0 ] . message . content ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , rephrased_query ) for agent in ctx . get_required_agents_for_current_phase ( chat_id ): self . send_request ( WiseAgentMessage ( message = rephrased_query , sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) else : # Kick off the next phase for agent in next_phase : self . send_request ( WiseAgentMessage ( message = ctx . get_current_query ( chat_id ), sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\" Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the \"\"\" self . _response_delivery = response_delivery","title":"PhasedCoordinatorWiseAgent"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.confidence_score_threshold","text":"Get the confidence score threshold.","title":"confidence_score_threshold"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.max_iterations","text":"Get the maximum number of iterations.","title":"max_iterations"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.phases","text":"Get the list of phases.","title":"phases"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.response_delivery","text":"Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client","title":"response_delivery"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication llm ( WiseAgentLLM ) \u2013 the LLM to use for coordinating the collaboration phases ( Optional [ List [ str ]] , default: None ) \u2013 the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations ( Optional [ int ] , default: MAX_ITERATIONS_FOR_COORDINATOR ) \u2013 the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold ( Optional [ int ] , default: CONFIDENCE_SCORE_THRESHOLD ) \u2013 the confidence score threshold to determine if the final answer system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the coordinator when processing Source code in wiseagents/agents/coordinator_wise_agents.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : WiseAgentLLM , phases : Optional [ List [ str ]] = None , max_iterations : Optional [ int ] = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold : Optional [ int ] = CONFIDENCE_SCORE_THRESHOLD , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication llm (WiseAgentLLM): the LLM to use for coordinating the collaboration phases (Optional[List[str]]): the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations (Optional[int]): the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold (Optional[int]): the confidence score threshold to determine if the final answer is acceptable, defaults to 85 system_message (Optional[str]): the optional system message to be used by the coordinator when processing chat completions using its LLM \"\"\" self . _name = name self . _phases = phases if phases is not None else [ \"Data Collection\" , \"Data Analysis\" ] self . _max_iterations = max_iterations self . _confidence_score_threshold = confidence_score_threshold self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = transport , llm = llm , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/coordinator_wise_agents.py 114 115 116 117 118 119 120 121 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _phases = [ \"Data Collection\" , \"Data Analysis\" ] obj . _max_iterations = MAX_ITERATIONS_FOR_COORDINATOR obj . _confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/coordinator_wise_agents.py 148 149 150 151 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , transport= { self . transport } ,\" f \"llm= { self . llm } , phases= { self . phases } ,max_iterations= { self . max_iterations } , system_message= { self . system_message } \" )","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.handle_request","text":"Process a request message by kicking off the collaboration in phases. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process Source code in wiseagents/agents/coordinator_wise_agents.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def handle_request ( self , request ): \"\"\" Process a request message by kicking off the collaboration in phases. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . PHASED ) ctx . set_route_response_to ( chat_id , request . sender ) # Determine the agents required to answer the query agent_selection_prompt = ( \"Given the following query and a description of the agents that are available,\" + \" determine all of the agents that could be required to solve the query.\" + \" Format the response as a space separated list of agent names and don't include \" + \" anything else in the response. \\n \" + \" Query: \" + request . message + \" \\n \" + \"Available agents: \\n \" + \" \\n \" . join ( WiseAgentRegistry . get_agent_names_and_descriptions ()) + \" \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_selection_prompt }) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } \" ) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) # Assign the agents to phases agent_assignment_prompt = ( \"Assign each of the agents that will be required to solve the query to one of the following phases: \\n \" + \", \" . join ( self . phases ) + \" \\n \" + \"Assume that agents within a phase will be executed in parallel.\" + \" Format the response as a space separated list of agents for each phase, where the first\" \" line contains the list of agents for the first phase and second line contains the list of\" \" agents for the second phase and so on. Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_assignment_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) phases = [ phase . split () for phase in llm_response . choices [ 0 ] . message . content . splitlines ()] ctx . set_agent_phase_assignments ( chat_id , phases ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , request . message ) # Kick off the first phase for agent in phases [ 0 ]: self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), agent )","title":"handle_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/coordinator_wise_agents.py 299 300 301 302 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 295 296 297 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.process_response","text":"Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/coordinator_wise_agents.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 def process_response ( self , response ): \"\"\" Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Args: response (WiseAgentMessage): the response message to process \"\"\" ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) chat_id = response . chat_id if response . message_type != WiseAgentMessageType . ACK : raise ValueError ( f \"Unexpected response message: { response . message } \" ) # Remove the agent from the required agents for this phase ctx . remove_required_agent_for_current_phase ( chat_id , response . sender ) # If there are no more agents remaining in this phase, move on to the next phase, # return the final answer, or iterate if len ( ctx . get_required_agents_for_current_phase ( chat_id )) == 0 : next_phase = ctx . get_agents_for_next_phase ( chat_id ) if next_phase is None : # Determine the final answer final_answer_prompt = ( \"What is the final answer for the original query? Provide the answer followed\" + \" by a confidence score from 0 to 100 to indicate how certain you are of the\" + \" answer. Format the response with just the answer first followed by just\" + \" the confidence score on the next line. For example: \\n \" + \" Your answer goes here. \\n \" \" 85 \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : final_answer_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) final_answer_and_score = llm_response . choices [ 0 ] . message . content . splitlines () final_answer = \" \\n \" . join ( final_answer_and_score [: - 1 ]) if final_answer_and_score [ - 1 ] . strip () . isnumeric (): score = int ( final_answer_and_score [ - 1 ]) else : # A score could not be determined score = 0 # Determine if we should return the final answer or iterate if score >= self . confidence_score_threshold : self . send_response ( WiseAgentMessage ( message = final_answer , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) elif len ( ctx . get_queries ( chat_id )) == self . max_iterations : self . send_response ( WiseAgentMessage ( message = CANNOT_ANSWER , message_type = WiseAgentMessageType . CANNOT_ANSWER , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) else : # Rephrase the query and iterate if len ( ctx . get_queries ( chat_id )) < self . max_iterations : rephrase_query_prompt = ( \"The final answer was not considered good enough to respond to the original query. \\n \" + \" The original query was: \" + ctx . get_queries ( chat_id )[ 0 ] + \" \\n \" + \" Your task is to analyze the original query for its intent along with the conversation\" + \" history and final answer to rephrase the original query to yield a better final answer.\" + \" The response should contain only the rephrased query.\" \" Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : rephrase_query_prompt }) # Note that llm_chat_completion[chat_id] is being used here so we have the full history llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) rephrased_query = llm_response . choices [ 0 ] . message . content ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , rephrased_query ) for agent in ctx . get_required_agents_for_current_phase ( chat_id ): self . send_request ( WiseAgentMessage ( message = rephrased_query , sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) else : # Kick off the next phase for agent in next_phase : self . send_request ( WiseAgentMessage ( message = ctx . get_current_query ( chat_id ), sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.set_response_delivery","text":"Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the Source code in wiseagents/agents/coordinator_wise_agents.py 322 323 324 325 326 327 328 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the \"\"\" self . _response_delivery = response_delivery","title":"set_response_delivery"},{"location":"reference/wiseagents/agents/#wiseagents.agents.PhasedCoordinatorWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 304 305 306 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent","text":"Bases: WiseAgent This agent makes use of retrieval augmented generation (RAG) to answer questions. Source code in wiseagents/agents/rag_wise_agents.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class RAGWiseAgent ( WiseAgent ): \"\"\" This agent makes use of retrieval augmented generation (RAG) to answer questions. \"\"\" yaml_tag = u '!wiseagents.agents.RAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name Optional(str): the name of the collection within the vector database to use for retrieving documents, defaults to wise-agent-collection k Optional(int): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _include_sources = include_sources super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , vector_db = vector_db , collection_name = collection_name , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , transport= { self . transport } ,\" f \"k= { self . k } , include_sources= { self . include_sources } ), system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message using retrieval augmented generation (RAG). Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_rag ( request . message , self . vector_db , self . collection_name , self . k ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve for each query.\"\"\" return self . _k @property def include_sources ( self ) -> bool : \"\"\"Get whether to include the sources of the documents that were consulted to produce the response.\"\"\" return self . _include_sources","title":"RAGWiseAgent"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.include_sources","text":"Get whether to include the sources of the documents that were consulted to produce the response.","title":"include_sources"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.k","text":"Get the number of documents to retrieve for each query.","title":"k"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM to use for processing requests vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication collection_name ( Optional(str , default: DEFAULT_COLLECTION_NAME ) \u2013 the name of the collection within the vector database to use for k ( Optional(int , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve for each query, defaults to 4 include_sources ( Optional(bool , default: DEFAULT_INCLUDE_SOURCES ) \u2013 whether to include the sources of the documents that were consulted to Source code in wiseagents/agents/rag_wise_agents.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name Optional(str): the name of the collection within the vector database to use for retrieving documents, defaults to wise-agent-collection k Optional(int): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _include_sources = include_sources super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , vector_db = vector_db , collection_name = collection_name , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 32 33 34 35 36 37 38 39 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 70 71 72 73 74 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , transport= { self . transport } ,\" f \"k= { self . k } , include_sources= { self . include_sources } ), system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 80 81 82 83 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 76 77 78 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.process_request","text":"Process a request message using retrieval augmented generation (RAG). Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/rag_wise_agents.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message using retrieval augmented generation (RAG). Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_rag ( request . message , self . vector_db , self . collection_name , self . k ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources","title":"process_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 105 106 107 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.RAGWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 109 110 111 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent","text":"Bases: WiseAgent This agent will coordinate the execution of a sequence of agents. Use Stomp protocol. Source code in wiseagents/agents/coordinator_wise_agents.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 class SequentialCoordinatorWiseAgent ( WiseAgent ): \"\"\" This agent will coordinate the execution of a sequence of agents. Use Stomp protocol. \"\"\" yaml_tag = u '!wiseagents.agents.SequentialCoordinatorWiseAgent' def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , agents : List [ str ]): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication agents (List[str]): the list of agents to coordinate \"\"\" self . _name = name self . _agents = agents super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , agents= { self . agents } )\" def handle_request ( self , request ): \"\"\" Process a request message by passing it to the first agent in the sequence. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Sequential coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . SEQUENTIAL ) ctx . set_agents_sequence ( chat_id , self . _agents ) ctx . set_route_response_to ( chat_id , request . sender ) self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), self . _agents [ 0 ]) def process_response ( self , response ): \"\"\" Process a response message by passing it to the next agent in the sequence. Args: response (WiseAgentMessage): the response message to process \"\"\" if response . message : raise ValueError ( f \"Unexpected response message: { response . message } \" ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def agents ( self ) -> List [ str ]: \"\"\"Get the list of agents.\"\"\" return self . _agents @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\" Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\"Set the function to deliver the response to the client.\"\"\" self . _response_delivery = response_delivery","title":"SequentialCoordinatorWiseAgent"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.agents","text":"Get the list of agents.","title":"agents"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.response_delivery","text":"Get the function to deliver the response to the client. Returns: Callable [[], WiseAgentMessage ] \u2013 the function to deliver the response to the client","title":"response_delivery"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication agents ( List [ str ] ) \u2013 the list of agents to coordinate Source code in wiseagents/agents/coordinator_wise_agents.py 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , agents : List [ str ]): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication agents (List[str]): the list of agents to coordinate \"\"\" self . _name = name self . _agents = agents super () . __init__ ( name = name , description = description , transport = transport , llm = None )","title":"__init__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/coordinator_wise_agents.py 33 34 35 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , agents= { self . agents } )\"","title":"__repr__"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.handle_request","text":"Process a request message by passing it to the first agent in the sequence. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process Source code in wiseagents/agents/coordinator_wise_agents.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def handle_request ( self , request ): \"\"\" Process a request message by passing it to the first agent in the sequence. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Sequential coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . SEQUENTIAL ) ctx . set_agents_sequence ( chat_id , self . _agents ) ctx . set_route_response_to ( chat_id , request . sender ) self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), self . _agents [ 0 ])","title":"handle_request"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/coordinator_wise_agents.py 71 72 73 74 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 67 68 69 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.process_response","text":"Process a response message by passing it to the next agent in the sequence. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/coordinator_wise_agents.py 56 57 58 59 60 61 62 63 64 65 def process_response ( self , response ): \"\"\" Process a response message by passing it to the next agent in the sequence. Args: response (WiseAgentMessage): the response message to process \"\"\" if response . message : raise ValueError ( f \"Unexpected response message: { response . message } \" ) return True","title":"process_response"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.set_response_delivery","text":"Set the function to deliver the response to the client. Source code in wiseagents/agents/coordinator_wise_agents.py 100 101 102 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\"Set the function to deliver the response to the client.\"\"\" self . _response_delivery = response_delivery","title":"set_response_delivery"},{"location":"reference/wiseagents/agents/#wiseagents.agents.SequentialCoordinatorWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 76 77 78 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/assistant/","text":"AssistantAgent Bases: WiseAgent This utility agent start a web interface and pass the user input to another agent. The web interface will be running at http://127.0.0.1:7860 Source code in wiseagents/agents/assistant.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 class AssistantAgent ( WiseAgent ): \"\"\" This utility agent start a web interface and pass the user input to another agent. The web interface will be running at http://127.0.0.1:7860 \"\"\" yaml_tag = u '!wiseagents.agents.AssistantAgent' _response_delivery = None _cond = threading . Condition () _response : WiseAgentMessage = None _chat_id = None def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : str ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" def start_agent ( self ): super () . start_agent () self . _chat_id = str ( uuid . uuid4 ()) WiseAgentRegistry . get_or_create_context ( \"default\" ) . set_collaboration_type ( self . _chat_id , WiseAgentCollaborationType . CHAT ) gradio . ChatInterface ( self . slow_echo ) . launch ( prevent_thread_lock = True ) def slow_echo ( self , message , history ): with self . _cond : self . handle_request ( WiseAgentMessage ( message = message , sender = self . name , chat_id = self . _chat_id )) self . _cond . wait () return self . _response . message def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by just passing it to another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" print ( f \"AssistantAgent: process_request: { request } \" ) WiseAgentRegistry . get_or_create_context ( \"default\" ) . append_chat_completion ( self . _chat_id , { \"role\" : \"user\" , \"content\" : request . message }) self . send_request ( request , self . destination_agent_name ) return None def process_response ( self , response : WiseAgentMessage ): \"\"\"Process a response message just sending it back to the client.\"\"\" print ( f \"AssistantAgent: process_response: { response } \" ) with self . _cond : self . _response = response self . _cond . notify () return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def destination_agent_name ( self ) -> str : \"\"\"Get the name of the agent to send requests to.\"\"\" return self . _destination_agent_name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client\"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery destination_agent_name : str property Get the name of the agent to send requests to. name : str property Get the name of the agent. response_delivery : Optional [ Callable [[], WiseAgentMessage ]] property Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client __init__ ( name , description , transport , destination_agent_name ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication destination_agent_name ( str ) \u2013 the name of the agent to send requests to Source code in wiseagents/agents/assistant.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : str ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/assistant.py 26 27 28 29 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/assistant.py 46 47 48 49 50 51 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" process_error ( error ) Do nothing Source code in wiseagents/agents/assistant.py 98 99 100 def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True process_event ( event ) Do nothing Source code in wiseagents/agents/assistant.py 94 95 96 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by just passing it to another agent. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/assistant.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by just passing it to another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" print ( f \"AssistantAgent: process_request: { request } \" ) WiseAgentRegistry . get_or_create_context ( \"default\" ) . append_chat_completion ( self . _chat_id , { \"role\" : \"user\" , \"content\" : request . message }) self . send_request ( request , self . destination_agent_name ) return None process_response ( response ) Process a response message just sending it back to the client. Source code in wiseagents/agents/assistant.py 86 87 88 89 90 91 92 def process_response ( self , response : WiseAgentMessage ): \"\"\"Process a response message just sending it back to the client.\"\"\" print ( f \"AssistantAgent: process_response: { response } \" ) with self . _cond : self . _response = response self . _cond . notify () return True set_response_delivery ( response_delivery ) Set the function to deliver the response to the client. Parameters: response_delivery ( Callable [[], WiseAgentMessage ] ) \u2013 the function to deliver the response to the client Source code in wiseagents/agents/assistant.py 122 123 124 125 126 127 128 129 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery stop () Do nothing Source code in wiseagents/agents/assistant.py 102 103 104 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"assistant"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent","text":"Bases: WiseAgent This utility agent start a web interface and pass the user input to another agent. The web interface will be running at http://127.0.0.1:7860 Source code in wiseagents/agents/assistant.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 class AssistantAgent ( WiseAgent ): \"\"\" This utility agent start a web interface and pass the user input to another agent. The web interface will be running at http://127.0.0.1:7860 \"\"\" yaml_tag = u '!wiseagents.agents.AssistantAgent' _response_delivery = None _cond = threading . Condition () _response : WiseAgentMessage = None _chat_id = None def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : str ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" def start_agent ( self ): super () . start_agent () self . _chat_id = str ( uuid . uuid4 ()) WiseAgentRegistry . get_or_create_context ( \"default\" ) . set_collaboration_type ( self . _chat_id , WiseAgentCollaborationType . CHAT ) gradio . ChatInterface ( self . slow_echo ) . launch ( prevent_thread_lock = True ) def slow_echo ( self , message , history ): with self . _cond : self . handle_request ( WiseAgentMessage ( message = message , sender = self . name , chat_id = self . _chat_id )) self . _cond . wait () return self . _response . message def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by just passing it to another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" print ( f \"AssistantAgent: process_request: { request } \" ) WiseAgentRegistry . get_or_create_context ( \"default\" ) . append_chat_completion ( self . _chat_id , { \"role\" : \"user\" , \"content\" : request . message }) self . send_request ( request , self . destination_agent_name ) return None def process_response ( self , response : WiseAgentMessage ): \"\"\"Process a response message just sending it back to the client.\"\"\" print ( f \"AssistantAgent: process_response: { response } \" ) with self . _cond : self . _response = response self . _cond . notify () return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def destination_agent_name ( self ) -> str : \"\"\"Get the name of the agent to send requests to.\"\"\" return self . _destination_agent_name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client\"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery","title":"AssistantAgent"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.destination_agent_name","text":"Get the name of the agent to send requests to.","title":"destination_agent_name"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.response_delivery","text":"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client","title":"response_delivery"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication destination_agent_name ( str ) \u2013 the name of the agent to send requests to Source code in wiseagents/agents/assistant.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : str ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None )","title":"__init__"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/assistant.py 26 27 28 29 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) return obj","title":"__new__"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/assistant.py 46 47 48 49 50 51 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \"","title":"__repr__"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.process_error","text":"Do nothing Source code in wiseagents/agents/assistant.py 98 99 100 def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True","title":"process_error"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.process_event","text":"Do nothing Source code in wiseagents/agents/assistant.py 94 95 96 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.process_request","text":"Process a request message by just passing it to another agent. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/assistant.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by just passing it to another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" print ( f \"AssistantAgent: process_request: { request } \" ) WiseAgentRegistry . get_or_create_context ( \"default\" ) . append_chat_completion ( self . _chat_id , { \"role\" : \"user\" , \"content\" : request . message }) self . send_request ( request , self . destination_agent_name ) return None","title":"process_request"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.process_response","text":"Process a response message just sending it back to the client. Source code in wiseagents/agents/assistant.py 86 87 88 89 90 91 92 def process_response ( self , response : WiseAgentMessage ): \"\"\"Process a response message just sending it back to the client.\"\"\" print ( f \"AssistantAgent: process_response: { response } \" ) with self . _cond : self . _response = response self . _cond . notify () return True","title":"process_response"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.set_response_delivery","text":"Set the function to deliver the response to the client. Parameters: response_delivery ( Callable [[], WiseAgentMessage ] ) \u2013 the function to deliver the response to the client Source code in wiseagents/agents/assistant.py 122 123 124 125 126 127 128 129 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery","title":"set_response_delivery"},{"location":"reference/wiseagents/agents/assistant/#wiseagents.agents.assistant.AssistantAgent.stop","text":"Do nothing Source code in wiseagents/agents/assistant.py 102 103 104 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/","text":"PhasedCoordinatorWiseAgent Bases: WiseAgent This agent will coordinate the execution of a group of agents in order to determine the response to a query. The agents will be executed in phases, where agents within a phase will be executed in parallel. After the phases have completed, the coordinator may choose to repeat the phases until it is satisfied with the final response or determines it's not possible to answer the query. Source code in wiseagents/agents/coordinator_wise_agents.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 class PhasedCoordinatorWiseAgent ( WiseAgent ): \"\"\" This agent will coordinate the execution of a group of agents in order to determine the response to a query. The agents will be executed in phases, where agents within a phase will be executed in parallel. After the phases have completed, the coordinator may choose to repeat the phases until it is satisfied with the final response or determines it's not possible to answer the query. \"\"\" yaml_tag = u '!wiseagents.agents.PhasedCoordinatorWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _phases = [ \"Data Collection\" , \"Data Analysis\" ] obj . _max_iterations = MAX_ITERATIONS_FOR_COORDINATOR obj . _confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD obj . _system_message = None return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : WiseAgentLLM , phases : Optional [ List [ str ]] = None , max_iterations : Optional [ int ] = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold : Optional [ int ] = CONFIDENCE_SCORE_THRESHOLD , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication llm (WiseAgentLLM): the LLM to use for coordinating the collaboration phases (Optional[List[str]]): the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations (Optional[int]): the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold (Optional[int]): the confidence score threshold to determine if the final answer is acceptable, defaults to 85 system_message (Optional[str]): the optional system message to be used by the coordinator when processing chat completions using its LLM \"\"\" self . _name = name self . _phases = phases if phases is not None else [ \"Data Collection\" , \"Data Analysis\" ] self . _max_iterations = max_iterations self . _confidence_score_threshold = confidence_score_threshold self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = transport , llm = llm , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , transport= { self . transport } ,\" f \"llm= { self . llm } , phases= { self . phases } ,max_iterations= { self . max_iterations } , system_message= { self . system_message } \" ) @property def phases ( self ) -> List [ str ]: \"\"\"Get the list of phases.\"\"\" return self . _phases @property def max_iterations ( self ) -> int : \"\"\"Get the maximum number of iterations.\"\"\" return self . _max_iterations @property def confidence_score_threshold ( self ) -> int : \"\"\"Get the confidence score threshold.\"\"\" return self . _confidence_score_threshold def handle_request ( self , request ): \"\"\" Process a request message by kicking off the collaboration in phases. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . PHASED ) ctx . set_route_response_to ( chat_id , request . sender ) # Determine the agents required to answer the query agent_selection_prompt = ( \"Given the following query and a description of the agents that are available,\" + \" determine all of the agents that could be required to solve the query.\" + \" Format the response as a space separated list of agent names and don't include \" + \" anything else in the response. \\n \" + \" Query: \" + request . message + \" \\n \" + \"Available agents: \\n \" + \" \\n \" . join ( WiseAgentRegistry . get_agent_names_and_descriptions ()) + \" \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_selection_prompt }) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } \" ) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) # Assign the agents to phases agent_assignment_prompt = ( \"Assign each of the agents that will be required to solve the query to one of the following phases: \\n \" + \", \" . join ( self . phases ) + \" \\n \" + \"Assume that agents within a phase will be executed in parallel.\" + \" Format the response as a space separated list of agents for each phase, where the first\" \" line contains the list of agents for the first phase and second line contains the list of\" \" agents for the second phase and so on. Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_assignment_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) phases = [ phase . split () for phase in llm_response . choices [ 0 ] . message . content . splitlines ()] ctx . set_agent_phase_assignments ( chat_id , phases ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , request . message ) # Kick off the first phase for agent in phases [ 0 ]: self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), agent ) def process_response ( self , response ): \"\"\" Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Args: response (WiseAgentMessage): the response message to process \"\"\" ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) chat_id = response . chat_id if response . message_type != WiseAgentMessageType . ACK : raise ValueError ( f \"Unexpected response message: { response . message } \" ) # Remove the agent from the required agents for this phase ctx . remove_required_agent_for_current_phase ( chat_id , response . sender ) # If there are no more agents remaining in this phase, move on to the next phase, # return the final answer, or iterate if len ( ctx . get_required_agents_for_current_phase ( chat_id )) == 0 : next_phase = ctx . get_agents_for_next_phase ( chat_id ) if next_phase is None : # Determine the final answer final_answer_prompt = ( \"What is the final answer for the original query? Provide the answer followed\" + \" by a confidence score from 0 to 100 to indicate how certain you are of the\" + \" answer. Format the response with just the answer first followed by just\" + \" the confidence score on the next line. For example: \\n \" + \" Your answer goes here. \\n \" \" 85 \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : final_answer_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) final_answer_and_score = llm_response . choices [ 0 ] . message . content . splitlines () final_answer = \" \\n \" . join ( final_answer_and_score [: - 1 ]) if final_answer_and_score [ - 1 ] . strip () . isnumeric (): score = int ( final_answer_and_score [ - 1 ]) else : # A score could not be determined score = 0 # Determine if we should return the final answer or iterate if score >= self . confidence_score_threshold : self . send_response ( WiseAgentMessage ( message = final_answer , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) elif len ( ctx . get_queries ( chat_id )) == self . max_iterations : self . send_response ( WiseAgentMessage ( message = CANNOT_ANSWER , message_type = WiseAgentMessageType . CANNOT_ANSWER , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) else : # Rephrase the query and iterate if len ( ctx . get_queries ( chat_id )) < self . max_iterations : rephrase_query_prompt = ( \"The final answer was not considered good enough to respond to the original query. \\n \" + \" The original query was: \" + ctx . get_queries ( chat_id )[ 0 ] + \" \\n \" + \" Your task is to analyze the original query for its intent along with the conversation\" + \" history and final answer to rephrase the original query to yield a better final answer.\" + \" The response should contain only the rephrased query.\" \" Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : rephrase_query_prompt }) # Note that llm_chat_completion[chat_id] is being used here so we have the full history llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) rephrased_query = llm_response . choices [ 0 ] . message . content ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , rephrased_query ) for agent in ctx . get_required_agents_for_current_phase ( chat_id ): self . send_request ( WiseAgentMessage ( message = rephrased_query , sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) else : # Kick off the next phase for agent in next_phase : self . send_request ( WiseAgentMessage ( message = ctx . get_current_query ( chat_id ), sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\" Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the \"\"\" self . _response_delivery = response_delivery confidence_score_threshold : int property Get the confidence score threshold. max_iterations : int property Get the maximum number of iterations. name : str property Get the name of the agent. phases : List [ str ] property Get the list of phases. response_delivery : Optional [ Callable [[], WiseAgentMessage ]] property Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client __init__ ( name , description , transport , llm , phases = None , max_iterations = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication llm ( WiseAgentLLM ) \u2013 the LLM to use for coordinating the collaboration phases ( Optional [ List [ str ]] , default: None ) \u2013 the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations ( Optional [ int ] , default: MAX_ITERATIONS_FOR_COORDINATOR ) \u2013 the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold ( Optional [ int ] , default: CONFIDENCE_SCORE_THRESHOLD ) \u2013 the confidence score threshold to determine if the final answer system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the coordinator when processing Source code in wiseagents/agents/coordinator_wise_agents.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : WiseAgentLLM , phases : Optional [ List [ str ]] = None , max_iterations : Optional [ int ] = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold : Optional [ int ] = CONFIDENCE_SCORE_THRESHOLD , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication llm (WiseAgentLLM): the LLM to use for coordinating the collaboration phases (Optional[List[str]]): the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations (Optional[int]): the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold (Optional[int]): the confidence score threshold to determine if the final answer is acceptable, defaults to 85 system_message (Optional[str]): the optional system message to be used by the coordinator when processing chat completions using its LLM \"\"\" self . _name = name self . _phases = phases if phases is not None else [ \"Data Collection\" , \"Data Analysis\" ] self . _max_iterations = max_iterations self . _confidence_score_threshold = confidence_score_threshold self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = transport , llm = llm , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/coordinator_wise_agents.py 114 115 116 117 118 119 120 121 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _phases = [ \"Data Collection\" , \"Data Analysis\" ] obj . _max_iterations = MAX_ITERATIONS_FOR_COORDINATOR obj . _confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/coordinator_wise_agents.py 148 149 150 151 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , transport= { self . transport } ,\" f \"llm= { self . llm } , phases= { self . phases } ,max_iterations= { self . max_iterations } , system_message= { self . system_message } \" ) handle_request ( request ) Process a request message by kicking off the collaboration in phases. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process Source code in wiseagents/agents/coordinator_wise_agents.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def handle_request ( self , request ): \"\"\" Process a request message by kicking off the collaboration in phases. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . PHASED ) ctx . set_route_response_to ( chat_id , request . sender ) # Determine the agents required to answer the query agent_selection_prompt = ( \"Given the following query and a description of the agents that are available,\" + \" determine all of the agents that could be required to solve the query.\" + \" Format the response as a space separated list of agent names and don't include \" + \" anything else in the response. \\n \" + \" Query: \" + request . message + \" \\n \" + \"Available agents: \\n \" + \" \\n \" . join ( WiseAgentRegistry . get_agent_names_and_descriptions ()) + \" \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_selection_prompt }) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } \" ) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) # Assign the agents to phases agent_assignment_prompt = ( \"Assign each of the agents that will be required to solve the query to one of the following phases: \\n \" + \", \" . join ( self . phases ) + \" \\n \" + \"Assume that agents within a phase will be executed in parallel.\" + \" Format the response as a space separated list of agents for each phase, where the first\" \" line contains the list of agents for the first phase and second line contains the list of\" \" agents for the second phase and so on. Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_assignment_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) phases = [ phase . split () for phase in llm_response . choices [ 0 ] . message . content . splitlines ()] ctx . set_agent_phase_assignments ( chat_id , phases ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , request . message ) # Kick off the first phase for agent in phases [ 0 ]: self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), agent ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/coordinator_wise_agents.py 299 300 301 302 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 295 296 297 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_response ( response ) Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/coordinator_wise_agents.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 def process_response ( self , response ): \"\"\" Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Args: response (WiseAgentMessage): the response message to process \"\"\" ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) chat_id = response . chat_id if response . message_type != WiseAgentMessageType . ACK : raise ValueError ( f \"Unexpected response message: { response . message } \" ) # Remove the agent from the required agents for this phase ctx . remove_required_agent_for_current_phase ( chat_id , response . sender ) # If there are no more agents remaining in this phase, move on to the next phase, # return the final answer, or iterate if len ( ctx . get_required_agents_for_current_phase ( chat_id )) == 0 : next_phase = ctx . get_agents_for_next_phase ( chat_id ) if next_phase is None : # Determine the final answer final_answer_prompt = ( \"What is the final answer for the original query? Provide the answer followed\" + \" by a confidence score from 0 to 100 to indicate how certain you are of the\" + \" answer. Format the response with just the answer first followed by just\" + \" the confidence score on the next line. For example: \\n \" + \" Your answer goes here. \\n \" \" 85 \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : final_answer_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) final_answer_and_score = llm_response . choices [ 0 ] . message . content . splitlines () final_answer = \" \\n \" . join ( final_answer_and_score [: - 1 ]) if final_answer_and_score [ - 1 ] . strip () . isnumeric (): score = int ( final_answer_and_score [ - 1 ]) else : # A score could not be determined score = 0 # Determine if we should return the final answer or iterate if score >= self . confidence_score_threshold : self . send_response ( WiseAgentMessage ( message = final_answer , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) elif len ( ctx . get_queries ( chat_id )) == self . max_iterations : self . send_response ( WiseAgentMessage ( message = CANNOT_ANSWER , message_type = WiseAgentMessageType . CANNOT_ANSWER , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) else : # Rephrase the query and iterate if len ( ctx . get_queries ( chat_id )) < self . max_iterations : rephrase_query_prompt = ( \"The final answer was not considered good enough to respond to the original query. \\n \" + \" The original query was: \" + ctx . get_queries ( chat_id )[ 0 ] + \" \\n \" + \" Your task is to analyze the original query for its intent along with the conversation\" + \" history and final answer to rephrase the original query to yield a better final answer.\" + \" The response should contain only the rephrased query.\" \" Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : rephrase_query_prompt }) # Note that llm_chat_completion[chat_id] is being used here so we have the full history llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) rephrased_query = llm_response . choices [ 0 ] . message . content ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , rephrased_query ) for agent in ctx . get_required_agents_for_current_phase ( chat_id ): self . send_request ( WiseAgentMessage ( message = rephrased_query , sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) else : # Kick off the next phase for agent in next_phase : self . send_request ( WiseAgentMessage ( message = ctx . get_current_query ( chat_id ), sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) return True set_response_delivery ( response_delivery ) Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the Source code in wiseagents/agents/coordinator_wise_agents.py 322 323 324 325 326 327 328 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the \"\"\" self . _response_delivery = response_delivery stop () Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 304 305 306 def stop ( self ): \"\"\"Do nothing\"\"\" pass SequentialCoordinatorWiseAgent Bases: WiseAgent This agent will coordinate the execution of a sequence of agents. Use Stomp protocol. Source code in wiseagents/agents/coordinator_wise_agents.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 class SequentialCoordinatorWiseAgent ( WiseAgent ): \"\"\" This agent will coordinate the execution of a sequence of agents. Use Stomp protocol. \"\"\" yaml_tag = u '!wiseagents.agents.SequentialCoordinatorWiseAgent' def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , agents : List [ str ]): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication agents (List[str]): the list of agents to coordinate \"\"\" self . _name = name self . _agents = agents super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , agents= { self . agents } )\" def handle_request ( self , request ): \"\"\" Process a request message by passing it to the first agent in the sequence. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Sequential coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . SEQUENTIAL ) ctx . set_agents_sequence ( chat_id , self . _agents ) ctx . set_route_response_to ( chat_id , request . sender ) self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), self . _agents [ 0 ]) def process_response ( self , response ): \"\"\" Process a response message by passing it to the next agent in the sequence. Args: response (WiseAgentMessage): the response message to process \"\"\" if response . message : raise ValueError ( f \"Unexpected response message: { response . message } \" ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def agents ( self ) -> List [ str ]: \"\"\"Get the list of agents.\"\"\" return self . _agents @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\" Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\"Set the function to deliver the response to the client.\"\"\" self . _response_delivery = response_delivery agents : List [ str ] property Get the list of agents. name : str property Get the name of the agent. response_delivery : Optional [ Callable [[], WiseAgentMessage ]] property Get the function to deliver the response to the client. Returns: Callable [[], WiseAgentMessage ] \u2013 the function to deliver the response to the client __init__ ( name , description , transport , agents ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication agents ( List [ str ] ) \u2013 the list of agents to coordinate Source code in wiseagents/agents/coordinator_wise_agents.py 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , agents : List [ str ]): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication agents (List[str]): the list of agents to coordinate \"\"\" self . _name = name self . _agents = agents super () . __init__ ( name = name , description = description , transport = transport , llm = None ) __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/coordinator_wise_agents.py 33 34 35 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , agents= { self . agents } )\" handle_request ( request ) Process a request message by passing it to the first agent in the sequence. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process Source code in wiseagents/agents/coordinator_wise_agents.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def handle_request ( self , request ): \"\"\" Process a request message by passing it to the first agent in the sequence. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Sequential coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . SEQUENTIAL ) ctx . set_agents_sequence ( chat_id , self . _agents ) ctx . set_route_response_to ( chat_id , request . sender ) self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), self . _agents [ 0 ]) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/coordinator_wise_agents.py 71 72 73 74 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 67 68 69 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_response ( response ) Process a response message by passing it to the next agent in the sequence. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/coordinator_wise_agents.py 56 57 58 59 60 61 62 63 64 65 def process_response ( self , response ): \"\"\" Process a response message by passing it to the next agent in the sequence. Args: response (WiseAgentMessage): the response message to process \"\"\" if response . message : raise ValueError ( f \"Unexpected response message: { response . message } \" ) return True set_response_delivery ( response_delivery ) Set the function to deliver the response to the client. Source code in wiseagents/agents/coordinator_wise_agents.py 100 101 102 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\"Set the function to deliver the response to the client.\"\"\" self . _response_delivery = response_delivery stop () Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 76 77 78 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"coordinator_wise_agents"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent","text":"Bases: WiseAgent This agent will coordinate the execution of a group of agents in order to determine the response to a query. The agents will be executed in phases, where agents within a phase will be executed in parallel. After the phases have completed, the coordinator may choose to repeat the phases until it is satisfied with the final response or determines it's not possible to answer the query. Source code in wiseagents/agents/coordinator_wise_agents.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 class PhasedCoordinatorWiseAgent ( WiseAgent ): \"\"\" This agent will coordinate the execution of a group of agents in order to determine the response to a query. The agents will be executed in phases, where agents within a phase will be executed in parallel. After the phases have completed, the coordinator may choose to repeat the phases until it is satisfied with the final response or determines it's not possible to answer the query. \"\"\" yaml_tag = u '!wiseagents.agents.PhasedCoordinatorWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _phases = [ \"Data Collection\" , \"Data Analysis\" ] obj . _max_iterations = MAX_ITERATIONS_FOR_COORDINATOR obj . _confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD obj . _system_message = None return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : WiseAgentLLM , phases : Optional [ List [ str ]] = None , max_iterations : Optional [ int ] = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold : Optional [ int ] = CONFIDENCE_SCORE_THRESHOLD , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication llm (WiseAgentLLM): the LLM to use for coordinating the collaboration phases (Optional[List[str]]): the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations (Optional[int]): the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold (Optional[int]): the confidence score threshold to determine if the final answer is acceptable, defaults to 85 system_message (Optional[str]): the optional system message to be used by the coordinator when processing chat completions using its LLM \"\"\" self . _name = name self . _phases = phases if phases is not None else [ \"Data Collection\" , \"Data Analysis\" ] self . _max_iterations = max_iterations self . _confidence_score_threshold = confidence_score_threshold self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = transport , llm = llm , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , transport= { self . transport } ,\" f \"llm= { self . llm } , phases= { self . phases } ,max_iterations= { self . max_iterations } , system_message= { self . system_message } \" ) @property def phases ( self ) -> List [ str ]: \"\"\"Get the list of phases.\"\"\" return self . _phases @property def max_iterations ( self ) -> int : \"\"\"Get the maximum number of iterations.\"\"\" return self . _max_iterations @property def confidence_score_threshold ( self ) -> int : \"\"\"Get the confidence score threshold.\"\"\" return self . _confidence_score_threshold def handle_request ( self , request ): \"\"\" Process a request message by kicking off the collaboration in phases. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . PHASED ) ctx . set_route_response_to ( chat_id , request . sender ) # Determine the agents required to answer the query agent_selection_prompt = ( \"Given the following query and a description of the agents that are available,\" + \" determine all of the agents that could be required to solve the query.\" + \" Format the response as a space separated list of agent names and don't include \" + \" anything else in the response. \\n \" + \" Query: \" + request . message + \" \\n \" + \"Available agents: \\n \" + \" \\n \" . join ( WiseAgentRegistry . get_agent_names_and_descriptions ()) + \" \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_selection_prompt }) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } \" ) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) # Assign the agents to phases agent_assignment_prompt = ( \"Assign each of the agents that will be required to solve the query to one of the following phases: \\n \" + \", \" . join ( self . phases ) + \" \\n \" + \"Assume that agents within a phase will be executed in parallel.\" + \" Format the response as a space separated list of agents for each phase, where the first\" \" line contains the list of agents for the first phase and second line contains the list of\" \" agents for the second phase and so on. Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_assignment_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) phases = [ phase . split () for phase in llm_response . choices [ 0 ] . message . content . splitlines ()] ctx . set_agent_phase_assignments ( chat_id , phases ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , request . message ) # Kick off the first phase for agent in phases [ 0 ]: self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), agent ) def process_response ( self , response ): \"\"\" Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Args: response (WiseAgentMessage): the response message to process \"\"\" ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) chat_id = response . chat_id if response . message_type != WiseAgentMessageType . ACK : raise ValueError ( f \"Unexpected response message: { response . message } \" ) # Remove the agent from the required agents for this phase ctx . remove_required_agent_for_current_phase ( chat_id , response . sender ) # If there are no more agents remaining in this phase, move on to the next phase, # return the final answer, or iterate if len ( ctx . get_required_agents_for_current_phase ( chat_id )) == 0 : next_phase = ctx . get_agents_for_next_phase ( chat_id ) if next_phase is None : # Determine the final answer final_answer_prompt = ( \"What is the final answer for the original query? Provide the answer followed\" + \" by a confidence score from 0 to 100 to indicate how certain you are of the\" + \" answer. Format the response with just the answer first followed by just\" + \" the confidence score on the next line. For example: \\n \" + \" Your answer goes here. \\n \" \" 85 \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : final_answer_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) final_answer_and_score = llm_response . choices [ 0 ] . message . content . splitlines () final_answer = \" \\n \" . join ( final_answer_and_score [: - 1 ]) if final_answer_and_score [ - 1 ] . strip () . isnumeric (): score = int ( final_answer_and_score [ - 1 ]) else : # A score could not be determined score = 0 # Determine if we should return the final answer or iterate if score >= self . confidence_score_threshold : self . send_response ( WiseAgentMessage ( message = final_answer , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) elif len ( ctx . get_queries ( chat_id )) == self . max_iterations : self . send_response ( WiseAgentMessage ( message = CANNOT_ANSWER , message_type = WiseAgentMessageType . CANNOT_ANSWER , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) else : # Rephrase the query and iterate if len ( ctx . get_queries ( chat_id )) < self . max_iterations : rephrase_query_prompt = ( \"The final answer was not considered good enough to respond to the original query. \\n \" + \" The original query was: \" + ctx . get_queries ( chat_id )[ 0 ] + \" \\n \" + \" Your task is to analyze the original query for its intent along with the conversation\" + \" history and final answer to rephrase the original query to yield a better final answer.\" + \" The response should contain only the rephrased query.\" \" Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : rephrase_query_prompt }) # Note that llm_chat_completion[chat_id] is being used here so we have the full history llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) rephrased_query = llm_response . choices [ 0 ] . message . content ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , rephrased_query ) for agent in ctx . get_required_agents_for_current_phase ( chat_id ): self . send_request ( WiseAgentMessage ( message = rephrased_query , sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) else : # Kick off the next phase for agent in next_phase : self . send_request ( WiseAgentMessage ( message = ctx . get_current_query ( chat_id ), sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\" Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the \"\"\" self . _response_delivery = response_delivery","title":"PhasedCoordinatorWiseAgent"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.confidence_score_threshold","text":"Get the confidence score threshold.","title":"confidence_score_threshold"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.max_iterations","text":"Get the maximum number of iterations.","title":"max_iterations"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.phases","text":"Get the list of phases.","title":"phases"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.response_delivery","text":"Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client","title":"response_delivery"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication llm ( WiseAgentLLM ) \u2013 the LLM to use for coordinating the collaboration phases ( Optional [ List [ str ]] , default: None ) \u2013 the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations ( Optional [ int ] , default: MAX_ITERATIONS_FOR_COORDINATOR ) \u2013 the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold ( Optional [ int ] , default: CONFIDENCE_SCORE_THRESHOLD ) \u2013 the confidence score threshold to determine if the final answer system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the coordinator when processing Source code in wiseagents/agents/coordinator_wise_agents.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , llm : WiseAgentLLM , phases : Optional [ List [ str ]] = None , max_iterations : Optional [ int ] = MAX_ITERATIONS_FOR_COORDINATOR , confidence_score_threshold : Optional [ int ] = CONFIDENCE_SCORE_THRESHOLD , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication llm (WiseAgentLLM): the LLM to use for coordinating the collaboration phases (Optional[List[str]]): the optional list of phase names, defaults to \"Data Collection\" and \"Data Analysis\" max_iterations (Optional[int]): the maximum number of iterations to run the phases, defaults to 5 confidence_score_threshold (Optional[int]): the confidence score threshold to determine if the final answer is acceptable, defaults to 85 system_message (Optional[str]): the optional system message to be used by the coordinator when processing chat completions using its LLM \"\"\" self . _name = name self . _phases = phases if phases is not None else [ \"Data Collection\" , \"Data Analysis\" ] self . _max_iterations = max_iterations self . _confidence_score_threshold = confidence_score_threshold self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = transport , llm = llm , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/coordinator_wise_agents.py 114 115 116 117 118 119 120 121 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _phases = [ \"Data Collection\" , \"Data Analysis\" ] obj . _max_iterations = MAX_ITERATIONS_FOR_COORDINATOR obj . _confidence_score_threshold = CONFIDENCE_SCORE_THRESHOLD obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/coordinator_wise_agents.py 148 149 150 151 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , transport= { self . transport } ,\" f \"llm= { self . llm } , phases= { self . phases } ,max_iterations= { self . max_iterations } , system_message= { self . system_message } \" )","title":"__repr__"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.handle_request","text":"Process a request message by kicking off the collaboration in phases. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process Source code in wiseagents/agents/coordinator_wise_agents.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def handle_request ( self , request ): \"\"\" Process a request message by kicking off the collaboration in phases. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . PHASED ) ctx . set_route_response_to ( chat_id , request . sender ) # Determine the agents required to answer the query agent_selection_prompt = ( \"Given the following query and a description of the agents that are available,\" + \" determine all of the agents that could be required to solve the query.\" + \" Format the response as a space separated list of agent names and don't include \" + \" anything else in the response. \\n \" + \" Query: \" + request . message + \" \\n \" + \"Available agents: \\n \" + \" \\n \" . join ( WiseAgentRegistry . get_agent_names_and_descriptions ()) + \" \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_selection_prompt }) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } \" ) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) # Assign the agents to phases agent_assignment_prompt = ( \"Assign each of the agents that will be required to solve the query to one of the following phases: \\n \" + \", \" . join ( self . phases ) + \" \\n \" + \"Assume that agents within a phase will be executed in parallel.\" + \" Format the response as a space separated list of agents for each phase, where the first\" \" line contains the list of agents for the first phase and second line contains the list of\" \" agents for the second phase and so on. Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : agent_assignment_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) phases = [ phase . split () for phase in llm_response . choices [ 0 ] . message . content . splitlines ()] ctx . set_agent_phase_assignments ( chat_id , phases ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , request . message ) # Kick off the first phase for agent in phases [ 0 ]: self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), agent )","title":"handle_request"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/coordinator_wise_agents.py 299 300 301 302 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 295 296 297 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.process_response","text":"Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/coordinator_wise_agents.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 def process_response ( self , response ): \"\"\" Process a response message. If this message is from the last agent remaining in the current phase, then kick off the next phase of collaboration if there are more phases. Otherwise, determine if we should return the final answer or if we need to go back to the first phase and repeat with a rephrased query. Args: response (WiseAgentMessage): the response message to process \"\"\" ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) chat_id = response . chat_id if response . message_type != WiseAgentMessageType . ACK : raise ValueError ( f \"Unexpected response message: { response . message } \" ) # Remove the agent from the required agents for this phase ctx . remove_required_agent_for_current_phase ( chat_id , response . sender ) # If there are no more agents remaining in this phase, move on to the next phase, # return the final answer, or iterate if len ( ctx . get_required_agents_for_current_phase ( chat_id )) == 0 : next_phase = ctx . get_agents_for_next_phase ( chat_id ) if next_phase is None : # Determine the final answer final_answer_prompt = ( \"What is the final answer for the original query? Provide the answer followed\" + \" by a confidence score from 0 to 100 to indicate how certain you are of the\" + \" answer. Format the response with just the answer first followed by just\" + \" the confidence score on the next line. For example: \\n \" + \" Your answer goes here. \\n \" \" 85 \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : final_answer_prompt }) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) final_answer_and_score = llm_response . choices [ 0 ] . message . content . splitlines () final_answer = \" \\n \" . join ( final_answer_and_score [: - 1 ]) if final_answer_and_score [ - 1 ] . strip () . isnumeric (): score = int ( final_answer_and_score [ - 1 ]) else : # A score could not be determined score = 0 # Determine if we should return the final answer or iterate if score >= self . confidence_score_threshold : self . send_response ( WiseAgentMessage ( message = final_answer , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) elif len ( ctx . get_queries ( chat_id )) == self . max_iterations : self . send_response ( WiseAgentMessage ( message = CANNOT_ANSWER , message_type = WiseAgentMessageType . CANNOT_ANSWER , sender = self . name , context_name = response . context_name , chat_id = chat_id ), ctx . get_route_response_to ( chat_id )) else : # Rephrase the query and iterate if len ( ctx . get_queries ( chat_id )) < self . max_iterations : rephrase_query_prompt = ( \"The final answer was not considered good enough to respond to the original query. \\n \" + \" The original query was: \" + ctx . get_queries ( chat_id )[ 0 ] + \" \\n \" + \" Your task is to analyze the original query for its intent along with the conversation\" + \" history and final answer to rephrase the original query to yield a better final answer.\" + \" The response should contain only the rephrased query.\" \" Don't include anything else in the response. \\n \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : rephrase_query_prompt }) # Note that llm_chat_completion[chat_id] is being used here so we have the full history llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], tools = []) rephrased_query = llm_response . choices [ 0 ] . message . content ctx . append_chat_completion ( chat_uuid = chat_id , messages = llm_response . choices [ 0 ] . message ) ctx . set_current_phase ( chat_id , 0 ) ctx . add_query ( chat_id , rephrased_query ) for agent in ctx . get_required_agents_for_current_phase ( chat_id ): self . send_request ( WiseAgentMessage ( message = rephrased_query , sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) else : # Kick off the next phase for agent in next_phase : self . send_request ( WiseAgentMessage ( message = ctx . get_current_query ( chat_id ), sender = self . name , context_name = response . context_name , chat_id = chat_id ), agent ) return True","title":"process_response"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.set_response_delivery","text":"Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the Source code in wiseagents/agents/coordinator_wise_agents.py 322 323 324 325 326 327 328 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the \"\"\" self . _response_delivery = response_delivery","title":"set_response_delivery"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.PhasedCoordinatorWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 304 305 306 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent","text":"Bases: WiseAgent This agent will coordinate the execution of a sequence of agents. Use Stomp protocol. Source code in wiseagents/agents/coordinator_wise_agents.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 class SequentialCoordinatorWiseAgent ( WiseAgent ): \"\"\" This agent will coordinate the execution of a sequence of agents. Use Stomp protocol. \"\"\" yaml_tag = u '!wiseagents.agents.SequentialCoordinatorWiseAgent' def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , agents : List [ str ]): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication agents (List[str]): the list of agents to coordinate \"\"\" self . _name = name self . _agents = agents super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , agents= { self . agents } )\" def handle_request ( self , request ): \"\"\" Process a request message by passing it to the first agent in the sequence. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Sequential coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . SEQUENTIAL ) ctx . set_agents_sequence ( chat_id , self . _agents ) ctx . set_route_response_to ( chat_id , request . sender ) self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), self . _agents [ 0 ]) def process_response ( self , response ): \"\"\" Process a response message by passing it to the next agent in the sequence. Args: response (WiseAgentMessage): the response message to process \"\"\" if response . message : raise ValueError ( f \"Unexpected response message: { response . message } \" ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def agents ( self ) -> List [ str ]: \"\"\"Get the list of agents.\"\"\" return self . _agents @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\" Get the function to deliver the response to the client. Returns: (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\"Set the function to deliver the response to the client.\"\"\" self . _response_delivery = response_delivery","title":"SequentialCoordinatorWiseAgent"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.agents","text":"Get the list of agents.","title":"agents"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.response_delivery","text":"Get the function to deliver the response to the client. Returns: Callable [[], WiseAgentMessage ] \u2013 the function to deliver the response to the client","title":"response_delivery"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication agents ( List [ str ] ) \u2013 the list of agents to coordinate Source code in wiseagents/agents/coordinator_wise_agents.py 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , agents : List [ str ]): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication agents (List[str]): the list of agents to coordinate \"\"\" self . _name = name self . _agents = agents super () . __init__ ( name = name , description = description , transport = transport , llm = None )","title":"__init__"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/coordinator_wise_agents.py 33 34 35 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , agents= { self . agents } )\"","title":"__repr__"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.handle_request","text":"Process a request message by passing it to the first agent in the sequence. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process Source code in wiseagents/agents/coordinator_wise_agents.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def handle_request ( self , request ): \"\"\" Process a request message by passing it to the first agent in the sequence. Args: request (WiseAgentMessage): the request message to process \"\"\" logging . debug ( f \"Sequential coordinator received request: { request } \" ) # Generate a chat ID that will be used to collaborate on this query chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . set_collaboration_type ( chat_id , WiseAgentCollaborationType . SEQUENTIAL ) ctx . set_agents_sequence ( chat_id , self . _agents ) ctx . set_route_response_to ( chat_id , request . sender ) self . send_request ( WiseAgentMessage ( message = request . message , sender = self . name , context_name = request . context_name , chat_id = chat_id ), self . _agents [ 0 ])","title":"handle_request"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/coordinator_wise_agents.py 71 72 73 74 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 67 68 69 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.process_response","text":"Process a response message by passing it to the next agent in the sequence. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/coordinator_wise_agents.py 56 57 58 59 60 61 62 63 64 65 def process_response ( self , response ): \"\"\" Process a response message by passing it to the next agent in the sequence. Args: response (WiseAgentMessage): the response message to process \"\"\" if response . message : raise ValueError ( f \"Unexpected response message: { response . message } \" ) return True","title":"process_response"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.set_response_delivery","text":"Set the function to deliver the response to the client. Source code in wiseagents/agents/coordinator_wise_agents.py 100 101 102 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\"Set the function to deliver the response to the client.\"\"\" self . _response_delivery = response_delivery","title":"set_response_delivery"},{"location":"reference/wiseagents/agents/coordinator_wise_agents/#wiseagents.agents.coordinator_wise_agents.SequentialCoordinatorWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/coordinator_wise_agents.py 76 77 78 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/rag_wise_agents/","text":"DEFAULT_COLLECTION_NAME = 'wise-agents-collection' module-attribute The default value for whether to include the sources of the documents that were consulted to produce the response when using retrieval augmented generation (RAG). DEFAULT_INCLUDE_SOURCES = False module-attribute The default number of verification questions to use when challenging the results retrieved from retrieval augmented generation (RAG). DEFAULT_NUM_DOCUMENTS = 4 module-attribute The default collection name to use during retrieval augmented generation (RAG). BaseCoVeChallengerWiseAgent Bases: WiseAgent This abstract agent implementation is used to challenge the response from a RAG or Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 class BaseCoVeChallengerWiseAgent ( WiseAgent ): \"\"\" This abstract agent implementation is used to challenge the response from a RAG or Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.BaseCoVeChallengerWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = 4 obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _vector_db = None obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _graph_db = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication k Optional(int): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions Optional(int): the number of verification questions to generate, defaults to 4 vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent (to be used for challenging RAG results) collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _k = k self . _num_verification_questions = num_verification_questions self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , vector_db = vector_db , collection_name = collection_name , graph_db = graph_db , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"k= { self . k } , num_verification_questions= { self . _num_verification_questions } ,\" f \"transport= { self . transport } , vector_db= { self . vector_db } , collection_name= { self . collection_name } ,\" f \"graph_db= { self . graph_db } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" return self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve.\"\"\" return self . _k @property def num_verification_questions ( self ) -> int : \"\"\"Get the number of verification questions to generate.\"\"\" return self . _num_verification_questions def create_and_process_chain_of_verification_prompts ( self , message : str , conversation_history : List [ ChatCompletionMessageParam ]) -> str : \"\"\" Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Args: message (str): the message containing the question and baseline response conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. \"\"\" # plan verifications, taking into account the baseline response and conversation history prompt = ( f \"Given the following question and baseline response, generate a list of { self . num_verification_questions } \" f \" verification questions that could help determine if there are any mistakes in the baseline response:\" f \" \\n { message } \\n \" f \"Your response should contain only the list of questions, one per line. \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) # execute verifications, answering questions independently, without the baseline response verification_questions = llm_response . choices [ 0 ] . message . content . splitlines () verification_responses = \"\" for question in verification_questions : retrieved_documents = self . retrieve_documents ( question ) llm_response = create_and_process_rag_prompt ( retrieved_documents , question , self . llm , False , [], self . system_message ) verification_responses = ( verification_responses + \"Verification Question: \" + question + \" \\n \" + \"Verification Result: \" + llm_response + \" \\n \" ) # generate the final revised response, conditioned on the baseline response and verification results complete_info = message + \" \\n \" + verification_responses prompt = ( f \"Given the following question, baseline response, and a list of verification questions and results,\" f \" generate a revised response incorporating the verification results: \\n { complete_info } \\n \" f \"Your response must contain only the revised response to the question in the JSON format shown below: \\n \" f \" {{ 'revised': 'Your revised response to the question.' }}\\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content @abstractmethod def retrieve_documents ( self , question : str ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Args: question (str): the question to be used to retrieve the documents Returns: List[Document]: the list of documents retrieved for the question \"\"\" ... k : int property Get the number of documents to retrieve. name : str property Get the name of the agent. num_verification_questions : int property Get the number of verification questions to generate. __init__ ( name , description , llm , transport , k = DEFAULT_NUM_DOCUMENTS , num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db = None , collection_name = DEFAULT_COLLECTION_NAME , graph_db = None , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional(int , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional(int , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 vector_db ( Optional [ WiseAgentVectorDB ] , default: None ) \u2013 the vector DB associated with the agent (to be used for challenging RAG results) collection_name ( Optional[str]) = \"wise-agent-collection\" , default: DEFAULT_COLLECTION_NAME ) \u2013 the vector DB collection name associated with the agent graph_db ( Optional [ WiseAgentGraphDB ] , default: None ) \u2013 the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication k Optional(int): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions Optional(int): the number of verification questions to generate, defaults to 4 vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent (to be used for challenging RAG results) collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _k = k self . _num_verification_questions = num_verification_questions self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , vector_db = vector_db , collection_name = collection_name , graph_db = graph_db , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 265 266 267 268 269 270 271 272 273 274 275 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = 4 obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _vector_db = None obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _graph_db = None obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 311 312 313 314 315 316 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"k= { self . k } , num_verification_questions= { self . _num_verification_questions } ,\" f \"transport= { self . transport } , vector_db= { self . vector_db } , collection_name= { self . collection_name } ,\" f \"graph_db= { self . graph_db } , system_message= { self . system_message } )\" ) create_and_process_chain_of_verification_prompts ( message , conversation_history ) Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Parameters: message ( str ) \u2013 the message containing the question and baseline response conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Source code in wiseagents/agents/rag_wise_agents.py 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 def create_and_process_chain_of_verification_prompts ( self , message : str , conversation_history : List [ ChatCompletionMessageParam ]) -> str : \"\"\" Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Args: message (str): the message containing the question and baseline response conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. \"\"\" # plan verifications, taking into account the baseline response and conversation history prompt = ( f \"Given the following question and baseline response, generate a list of { self . num_verification_questions } \" f \" verification questions that could help determine if there are any mistakes in the baseline response:\" f \" \\n { message } \\n \" f \"Your response should contain only the list of questions, one per line. \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) # execute verifications, answering questions independently, without the baseline response verification_questions = llm_response . choices [ 0 ] . message . content . splitlines () verification_responses = \"\" for question in verification_questions : retrieved_documents = self . retrieve_documents ( question ) llm_response = create_and_process_rag_prompt ( retrieved_documents , question , self . llm , False , [], self . system_message ) verification_responses = ( verification_responses + \"Verification Question: \" + question + \" \\n \" + \"Verification Result: \" + llm_response + \" \\n \" ) # generate the final revised response, conditioned on the baseline response and verification results complete_info = message + \" \\n \" + verification_responses prompt = ( f \"Given the following question, baseline response, and a list of verification questions and results,\" f \" generate a revised response incorporating the verification results: \\n { complete_info } \\n \" f \"Your response must contain only the revised response to the question in the JSON format shown below: \\n \" f \" {{ 'revised': 'Your revised response to the question.' }}\\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content process_error ( error ) Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 322 323 324 325 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 318 319 320 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" return self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) process_response ( response ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 344 345 346 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True retrieve_documents ( question ) abstractmethod Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Parameters: question ( str ) \u2013 the question to be used to retrieve the documents Returns: List [ Document ] \u2013 List[Document]: the list of documents retrieved for the question Source code in wiseagents/agents/rag_wise_agents.py 411 412 413 414 415 416 417 418 419 420 421 422 @abstractmethod def retrieve_documents ( self , question : str ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Args: question (str): the question to be used to retrieve the documents Returns: List[Document]: the list of documents retrieved for the question \"\"\" ... stop () Do nothing Source code in wiseagents/agents/rag_wise_agents.py 348 349 350 def stop ( self ): \"\"\"Do nothing\"\"\" pass CoVeChallengerGraphRAGWiseAgent Bases: BaseCoVeChallengerWiseAgent This agent implementation is used to challenge the response from a Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 class CoVeChallengerGraphRAGWiseAgent ( BaseCoVeChallengerWiseAgent ): \"\"\" This agent implementation is used to challenge the response from a Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.CoVeChallengerGraphRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests graph_db (Optional[WiseAgentGraphDB]): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _num_verification_questions = num_verification_questions self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , graph_db = graph_db , k = k , num_verification_questions = num_verification_questions ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , k= { self . k } ,num_verification_questions= { self . _num_verification_questions } \" f \"transport= { self . transport } , retrieval_query= { self . retrieval_query } , params= { self . params } \" f \"metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def retrieval_query ( self ) -> str : \"\"\"Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search.\"\"\" return self . _retrieval_query @property def params ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional parameters for the query.\"\"\" return self . _params @property def metadata_filter ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional metadata filter to use with similarity search.\"\"\" return self . _metadata_filter def retrieve_documents ( self , question : str ) -> List [ Document ]: return retrieve_documents_for_graph_rag ( question , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter ) metadata_filter : Optional [ Dict [ str , Any ]] property Get the optional metadata filter to use with similarity search. params : Optional [ Dict [ str , Any ]] property Get the optional parameters for the query. retrieval_query : str property Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search. __init__ ( name , description , llm , graph_db , transport , k = DEFAULT_NUM_DOCUMENTS , num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS , retrieval_query = '' , params = None , metadata_filter = None , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests graph_db ( Optional [ WiseAgentGraphDB ] ) \u2013 the graph database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional [ int ] , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 retrieval_query ( Optional [ str ] , default: '' ) \u2013 the optional retrieval query to use to obtain sub-graphs connected to nodes params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests graph_db (Optional[WiseAgentGraphDB]): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _num_verification_questions = num_verification_questions self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , graph_db = graph_db , k = k , num_verification_questions = num_verification_questions ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 527 528 529 530 531 532 533 534 535 536 537 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 577 578 579 580 581 582 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , k= { self . k } ,num_verification_questions= { self . _num_verification_questions } \" f \"transport= { self . transport } , retrieval_query= { self . retrieval_query } , params= { self . params } \" f \"metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 588 589 590 591 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 584 585 586 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response process_response ( response ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 610 611 612 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True stop () Do nothing Source code in wiseagents/agents/rag_wise_agents.py 614 615 616 def stop ( self ): \"\"\"Do nothing\"\"\" pass CoVeChallengerRAGWiseAgent Bases: BaseCoVeChallengerWiseAgent This agent implementation is used to challenge the response from a RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 class CoVeChallengerRAGWiseAgent ( BaseCoVeChallengerWiseAgent ): \"\"\" This agent implementation is used to challenge the response from a RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.CoVeChallengerRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name (Optional[str]): the name of the collection to use in the vector database, defaults to wise-agents-collection k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _num_verification_questions = num_verification_questions llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , vector_db = vector_db , collection_name = collection_name , k = k , num_verification_questions = num_verification_questions ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , k= { self . k } ,\" f \"num_verification_questions= { self . _num_verification_questions } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass def retrieve_documents ( self , question : str ) -> List [ Document ]: return retrieve_documents_for_rag ( question , self . vector_db , self . collection_name , self . k ) __init__ ( name , description , llm , vector_db , transport , collection_name = DEFAULT_COLLECTION_NAME , k = DEFAULT_NUM_DOCUMENTS , num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication collection_name ( Optional [ str ] , default: DEFAULT_COLLECTION_NAME ) \u2013 the name of the collection to use in the vector database, defaults to wise-agents-collection k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional [ int ] , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name (Optional[str]): the name of the collection to use in the vector database, defaults to wise-agents-collection k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _num_verification_questions = num_verification_questions llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , vector_db = vector_db , collection_name = collection_name , k = k , num_verification_questions = num_verification_questions ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 433 434 435 436 437 438 439 440 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 474 475 476 477 478 479 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , k= { self . k } ,\" f \"num_verification_questions= { self . _num_verification_questions } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 485 486 487 488 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 481 482 483 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response process_response ( response ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 507 508 509 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True stop () Do nothing Source code in wiseagents/agents/rag_wise_agents.py 511 512 513 def stop ( self ): \"\"\"Do nothing\"\"\" pass GraphRAGWiseAgent Bases: WiseAgent This agent implementation makes use of Graph Retrieval Augmented Generation (Graph RAG) to answer questions. Source code in wiseagents/agents/rag_wise_agents.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 class GraphRAGWiseAgent ( WiseAgent ): \"\"\" This agent implementation makes use of Graph Retrieval Augmented Generation (Graph RAG) to answer questions. \"\"\" yaml_tag = u '!wiseagents.agents.GraphRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _include_sources = include_sources self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , graph_db = graph_db , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , transport= { self . transport } , k= { self . k } ,\" f \"include_sources= { self . include_sources } ), retrieval_query= { self . retrieval_query } ,\" f \"params= { self . params } , metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the RAG agent and sending the response back to the client. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_graph_rag ( request . message , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve for each query.\"\"\" return self . _k @property def include_sources ( self ) -> bool : \"\"\"Get whether to include the sources of the documents that were consulted to produce the response.\"\"\" return self . _include_sources @property def retrieval_query ( self ) -> str : \"\"\"Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search.\"\"\" return self . _retrieval_query @property def params ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional parameters for the query.\"\"\" return self . _params @property def metadata_filter ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional metadata filter to use with similarity search.\"\"\" return self . _metadata_filter include_sources : bool property Get whether to include the sources of the documents that were consulted to produce the response. k : int property Get the number of documents to retrieve for each query. metadata_filter : Optional [ Dict [ str , Any ]] property Get the optional metadata filter to use with similarity search. name : str property Get the name of the agent. params : Optional [ Dict [ str , Any ]] property Get the optional parameters for the query. retrieval_query : str property Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search. __init__ ( name , description , llm , graph_db , transport , k = DEFAULT_NUM_DOCUMENTS , include_sources = DEFAULT_INCLUDE_SOURCES , retrieval_query = '' , params = None , metadata_filter = None , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM to use for processing requests graph_db ( WiseAgentGraphDB ) \u2013 the graph database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve for each query, defaults to 4 include_sources ( Optional(bool , default: DEFAULT_INCLUDE_SOURCES ) \u2013 whether to include the sources of the documents that were consulted to retrieval_query ( Optional [ str ] , default: '' ) \u2013 the optional retrieval query to use to obtain sub-graphs connected to nodes params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _include_sources = include_sources self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , graph_db = graph_db , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 135 136 137 138 139 140 141 142 143 144 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 182 183 184 185 186 187 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , transport= { self . transport } , k= { self . k } ,\" f \"include_sources= { self . include_sources } ), retrieval_query= { self . retrieval_query } ,\" f \"params= { self . params } , metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 193 194 195 196 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 189 190 191 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by passing it to the RAG agent and sending the response back to the client. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/rag_wise_agents.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the RAG agent and sending the response back to the client. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_graph_rag ( request . message , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources process_response ( response ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 218 219 220 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True stop () Do nothing Source code in wiseagents/agents/rag_wise_agents.py 222 223 224 def stop ( self ): \"\"\"Do nothing\"\"\" pass RAGWiseAgent Bases: WiseAgent This agent makes use of retrieval augmented generation (RAG) to answer questions. Source code in wiseagents/agents/rag_wise_agents.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class RAGWiseAgent ( WiseAgent ): \"\"\" This agent makes use of retrieval augmented generation (RAG) to answer questions. \"\"\" yaml_tag = u '!wiseagents.agents.RAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name Optional(str): the name of the collection within the vector database to use for retrieving documents, defaults to wise-agent-collection k Optional(int): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _include_sources = include_sources super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , vector_db = vector_db , collection_name = collection_name , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , transport= { self . transport } ,\" f \"k= { self . k } , include_sources= { self . include_sources } ), system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message using retrieval augmented generation (RAG). Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_rag ( request . message , self . vector_db , self . collection_name , self . k ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve for each query.\"\"\" return self . _k @property def include_sources ( self ) -> bool : \"\"\"Get whether to include the sources of the documents that were consulted to produce the response.\"\"\" return self . _include_sources include_sources : bool property Get whether to include the sources of the documents that were consulted to produce the response. k : int property Get the number of documents to retrieve for each query. name : str property Get the name of the agent. __init__ ( name , description , llm , vector_db , transport , collection_name = DEFAULT_COLLECTION_NAME , k = DEFAULT_NUM_DOCUMENTS , include_sources = DEFAULT_INCLUDE_SOURCES , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM to use for processing requests vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication collection_name ( Optional(str , default: DEFAULT_COLLECTION_NAME ) \u2013 the name of the collection within the vector database to use for k ( Optional(int , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve for each query, defaults to 4 include_sources ( Optional(bool , default: DEFAULT_INCLUDE_SOURCES ) \u2013 whether to include the sources of the documents that were consulted to Source code in wiseagents/agents/rag_wise_agents.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name Optional(str): the name of the collection within the vector database to use for retrieving documents, defaults to wise-agent-collection k Optional(int): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _include_sources = include_sources super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , vector_db = vector_db , collection_name = collection_name , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 32 33 34 35 36 37 38 39 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 70 71 72 73 74 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , transport= { self . transport } ,\" f \"k= { self . k } , include_sources= { self . include_sources } ), system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 80 81 82 83 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 76 77 78 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message using retrieval augmented generation (RAG). Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/rag_wise_agents.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message using retrieval augmented generation (RAG). Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_rag ( request . message , self . vector_db , self . collection_name , self . k ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources process_response ( response ) Do nothing Source code in wiseagents/agents/rag_wise_agents.py 105 106 107 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True stop () Do nothing Source code in wiseagents/agents/rag_wise_agents.py 109 110 111 def stop ( self ): \"\"\"Do nothing\"\"\" pass create_and_process_rag_prompt ( retrieved_documents , question , llm , include_sources , conversation_history , system_message ) Create a RAG prompt and process it with the LLM agent. Parameters: retrieved_documents ( List [ Document ] ) \u2013 the list of retrieved documents question ( str ) \u2013 the question to ask llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing the prompt conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. system_message ( str ) \u2013 the optional system message to use Source code in wiseagents/agents/rag_wise_agents.py 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 def create_and_process_rag_prompt ( retrieved_documents : List [ Document ], question : str , llm : WiseAgentLLM , include_sources : bool , conversation_history : List [ ChatCompletionMessageParam ], system_message : str ) -> str : \"\"\" Create a RAG prompt and process it with the LLM agent. Args: retrieved_documents (List[Document]): the list of retrieved documents question (str): the question to ask llm (WiseAgentLLM): the LLM agent to use for processing the prompt conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. system_message (str): the optional system message to use \"\"\" context = \" \\n \" . join ([ document . content for document in retrieved_documents ]) prompt = ( f \"Answer the question based only on the following context: \\n { context } \\n \" f \"Question: { question } \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : system_message or llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = llm . process_chat_completion ( conversation_history , []) if include_sources : source_documents = \"\" for document in retrieved_documents : source_documents += f \"Source Document: \\n Content: { document . content } \\n Metadata: { json . dumps ( document . metadata ) } \\n\\n \" return f \" { llm_response . choices [ 0 ] . message . content } \\n\\n Source Documents: \\n { source_documents } \" else : return llm_response . choices [ 0 ] . message . content retrieve_documents_for_graph_rag ( question , graph_db , k , retrieval_query = '' , params = None , metadata_filter = None ) Retrieve documents to be used as the context for graph based retrieval augmented generation (Graph RAG). Parameters: question ( str ) \u2013 the question to be used to retrieve the documents graph_db ( WiseAgentGraphDB ) \u2013 the graph database to use for retrieving documents k ( int ) \u2013 the number of documents to retrieve for a question retrieval_query ( Optional [ str ] , default: '' ) \u2013 the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search Returns: Source code in wiseagents/agents/rag_wise_agents.py 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 def retrieve_documents_for_graph_rag ( question : str , graph_db : WiseAgentGraphDB , k : int , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for graph based retrieval augmented generation (Graph RAG). Args: question (str): the question to be used to retrieve the documents graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents k (int): the number of documents to retrieve for a question retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: \"\"\" retrieved_documents = graph_db . query_with_embeddings ( query = question , k = k , retrieval_query = retrieval_query , params = params , metadata_filter = metadata_filter ) return retrieved_documents retrieve_documents_for_rag ( question , vector_db , collection_name , k ) Retrieve documents to be used as the context for retrieval augmented generation (RAG). Parameters: question ( str ) \u2013 the question to be used to retrieve the documents vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents collection_name ( str ) \u2013 the name of the collection within the vector database to use for retrieving documents k ( int ) \u2013 the number of documents to retrieve for a question Returns: Source code in wiseagents/agents/rag_wise_agents.py 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 def retrieve_documents_for_rag ( question : str , vector_db : WiseAgentVectorDB , collection_name : str , k : int ) \\ -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for retrieval augmented generation (RAG). Args: question (str): the question to be used to retrieve the documents vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents collection_name (str): the name of the collection within the vector database to use for retrieving documents k (int): the number of documents to retrieve for a question Returns: \"\"\" retrieved_documents = vector_db . query ([ question ], collection_name , k ) if retrieved_documents : return retrieved_documents [ 0 ] else : return []","title":"rag_wise_agents"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.DEFAULT_COLLECTION_NAME","text":"The default value for whether to include the sources of the documents that were consulted to produce the response when using retrieval augmented generation (RAG).","title":"DEFAULT_COLLECTION_NAME"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.DEFAULT_INCLUDE_SOURCES","text":"The default number of verification questions to use when challenging the results retrieved from retrieval augmented generation (RAG).","title":"DEFAULT_INCLUDE_SOURCES"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.DEFAULT_NUM_DOCUMENTS","text":"The default collection name to use during retrieval augmented generation (RAG).","title":"DEFAULT_NUM_DOCUMENTS"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent","text":"Bases: WiseAgent This abstract agent implementation is used to challenge the response from a RAG or Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 class BaseCoVeChallengerWiseAgent ( WiseAgent ): \"\"\" This abstract agent implementation is used to challenge the response from a RAG or Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.BaseCoVeChallengerWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = 4 obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _vector_db = None obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _graph_db = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication k Optional(int): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions Optional(int): the number of verification questions to generate, defaults to 4 vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent (to be used for challenging RAG results) collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _k = k self . _num_verification_questions = num_verification_questions self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , vector_db = vector_db , collection_name = collection_name , graph_db = graph_db , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"k= { self . k } , num_verification_questions= { self . _num_verification_questions } ,\" f \"transport= { self . transport } , vector_db= { self . vector_db } , collection_name= { self . collection_name } ,\" f \"graph_db= { self . graph_db } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" return self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve.\"\"\" return self . _k @property def num_verification_questions ( self ) -> int : \"\"\"Get the number of verification questions to generate.\"\"\" return self . _num_verification_questions def create_and_process_chain_of_verification_prompts ( self , message : str , conversation_history : List [ ChatCompletionMessageParam ]) -> str : \"\"\" Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Args: message (str): the message containing the question and baseline response conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. \"\"\" # plan verifications, taking into account the baseline response and conversation history prompt = ( f \"Given the following question and baseline response, generate a list of { self . num_verification_questions } \" f \" verification questions that could help determine if there are any mistakes in the baseline response:\" f \" \\n { message } \\n \" f \"Your response should contain only the list of questions, one per line. \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) # execute verifications, answering questions independently, without the baseline response verification_questions = llm_response . choices [ 0 ] . message . content . splitlines () verification_responses = \"\" for question in verification_questions : retrieved_documents = self . retrieve_documents ( question ) llm_response = create_and_process_rag_prompt ( retrieved_documents , question , self . llm , False , [], self . system_message ) verification_responses = ( verification_responses + \"Verification Question: \" + question + \" \\n \" + \"Verification Result: \" + llm_response + \" \\n \" ) # generate the final revised response, conditioned on the baseline response and verification results complete_info = message + \" \\n \" + verification_responses prompt = ( f \"Given the following question, baseline response, and a list of verification questions and results,\" f \" generate a revised response incorporating the verification results: \\n { complete_info } \\n \" f \"Your response must contain only the revised response to the question in the JSON format shown below: \\n \" f \" {{ 'revised': 'Your revised response to the question.' }}\\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content @abstractmethod def retrieve_documents ( self , question : str ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Args: question (str): the question to be used to retrieve the documents Returns: List[Document]: the list of documents retrieved for the question \"\"\" ...","title":"BaseCoVeChallengerWiseAgent"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.k","text":"Get the number of documents to retrieve.","title":"k"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.num_verification_questions","text":"Get the number of verification questions to generate.","title":"num_verification_questions"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional(int , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional(int , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 vector_db ( Optional [ WiseAgentVectorDB ] , default: None ) \u2013 the vector DB associated with the agent (to be used for challenging RAG results) collection_name ( Optional[str]) = \"wise-agent-collection\" , default: DEFAULT_COLLECTION_NAME ) \u2013 the vector DB collection name associated with the agent graph_db ( Optional [ WiseAgentGraphDB ] , default: None ) \u2013 the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , vector_db : Optional [ WiseAgentVectorDB ] = None , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , graph_db : Optional [ WiseAgentGraphDB ] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication k Optional(int): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions Optional(int): the number of verification questions to generate, defaults to 4 vector_db (Optional[WiseAgentVectorDB]): the vector DB associated with the agent (to be used for challenging RAG results) collection_name (Optional[str]) = \"wise-agent-collection\": the vector DB collection name associated with the agent graph_db (Optional[WiseAgentGraphDB]): the graph DB associated with the agent (to be used for challenging Graph RAG results) system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _k = k self . _num_verification_questions = num_verification_questions self . _vector_db = vector_db self . _collection_name = collection_name self . _graph_db = graph_db llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , vector_db = vector_db , collection_name = collection_name , graph_db = graph_db , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 265 266 267 268 269 270 271 272 273 274 275 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = 4 obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _vector_db = None obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _graph_db = None obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 311 312 313 314 315 316 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"k= { self . k } , num_verification_questions= { self . _num_verification_questions } ,\" f \"transport= { self . transport } , vector_db= { self . vector_db } , collection_name= { self . collection_name } ,\" f \"graph_db= { self . graph_db } , system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.create_and_process_chain_of_verification_prompts","text":"Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Parameters: message ( str ) \u2013 the message containing the question and baseline response conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Source code in wiseagents/agents/rag_wise_agents.py 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 def create_and_process_chain_of_verification_prompts ( self , message : str , conversation_history : List [ ChatCompletionMessageParam ]) -> str : \"\"\" Create prompts to challenge the baseline response to a question to try to generate a revised response to the original question. Args: message (str): the message containing the question and baseline response conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. \"\"\" # plan verifications, taking into account the baseline response and conversation history prompt = ( f \"Given the following question and baseline response, generate a list of { self . num_verification_questions } \" f \" verification questions that could help determine if there are any mistakes in the baseline response:\" f \" \\n { message } \\n \" f \"Your response should contain only the list of questions, one per line. \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) # execute verifications, answering questions independently, without the baseline response verification_questions = llm_response . choices [ 0 ] . message . content . splitlines () verification_responses = \"\" for question in verification_questions : retrieved_documents = self . retrieve_documents ( question ) llm_response = create_and_process_rag_prompt ( retrieved_documents , question , self . llm , False , [], self . system_message ) verification_responses = ( verification_responses + \"Verification Question: \" + question + \" \\n \" + \"Verification Result: \" + llm_response + \" \\n \" ) # generate the final revised response, conditioned on the baseline response and verification results complete_info = message + \" \\n \" + verification_responses prompt = ( f \"Given the following question, baseline response, and a list of verification questions and results,\" f \" generate a revised response incorporating the verification results: \\n { complete_info } \\n \" f \"Your response must contain only the revised response to the question in the JSON format shown below: \\n \" f \" {{ 'revised': 'Your revised response to the question.' }}\\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content","title":"create_and_process_chain_of_verification_prompts"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 322 323 324 325 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 318 319 320 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.process_request","text":"Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" return self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history )","title":"process_request"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 344 345 346 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.retrieve_documents","text":"Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Parameters: question ( str ) \u2013 the question to be used to retrieve the documents Returns: List [ Document ] \u2013 List[Document]: the list of documents retrieved for the question Source code in wiseagents/agents/rag_wise_agents.py 411 412 413 414 415 416 417 418 419 420 421 422 @abstractmethod def retrieve_documents ( self , question : str ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for a RAG or Graph RAG prompt. Args: question (str): the question to be used to retrieve the documents Returns: List[Document]: the list of documents retrieved for the question \"\"\" ...","title":"retrieve_documents"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.BaseCoVeChallengerWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 348 349 350 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent","text":"Bases: BaseCoVeChallengerWiseAgent This agent implementation is used to challenge the response from a Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 class CoVeChallengerGraphRAGWiseAgent ( BaseCoVeChallengerWiseAgent ): \"\"\" This agent implementation is used to challenge the response from a Graph RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.CoVeChallengerGraphRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests graph_db (Optional[WiseAgentGraphDB]): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _num_verification_questions = num_verification_questions self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , graph_db = graph_db , k = k , num_verification_questions = num_verification_questions ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , k= { self . k } ,num_verification_questions= { self . _num_verification_questions } \" f \"transport= { self . transport } , retrieval_query= { self . retrieval_query } , params= { self . params } \" f \"metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def retrieval_query ( self ) -> str : \"\"\"Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search.\"\"\" return self . _retrieval_query @property def params ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional parameters for the query.\"\"\" return self . _params @property def metadata_filter ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional metadata filter to use with similarity search.\"\"\" return self . _metadata_filter def retrieve_documents ( self , question : str ) -> List [ Document ]: return retrieve_documents_for_graph_rag ( question , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter )","title":"CoVeChallengerGraphRAGWiseAgent"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.metadata_filter","text":"Get the optional metadata filter to use with similarity search.","title":"metadata_filter"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.params","text":"Get the optional parameters for the query.","title":"params"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.retrieval_query","text":"Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search.","title":"retrieval_query"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests graph_db ( Optional [ WiseAgentGraphDB ] ) \u2013 the graph database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional [ int ] , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 retrieval_query ( Optional [ str ] , default: '' ) \u2013 the optional retrieval query to use to obtain sub-graphs connected to nodes params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests graph_db (Optional[WiseAgentGraphDB]): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _num_verification_questions = num_verification_questions self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , graph_db = graph_db , k = k , num_verification_questions = num_verification_questions )","title":"__init__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 527 528 529 530 531 532 533 534 535 536 537 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 577 578 579 580 581 582 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , k= { self . k } ,num_verification_questions= { self . _num_verification_questions } \" f \"transport= { self . transport } , retrieval_query= { self . retrieval_query } , params= { self . params } \" f \"metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 588 589 590 591 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 584 585 586 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.process_request","text":"Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response","title":"process_request"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 610 611 612 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerGraphRAGWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 614 615 616 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerRAGWiseAgent","text":"Bases: BaseCoVeChallengerWiseAgent This agent implementation is used to challenge the response from a RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. Source code in wiseagents/agents/rag_wise_agents.py 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 class CoVeChallengerRAGWiseAgent ( BaseCoVeChallengerWiseAgent ): \"\"\" This agent implementation is used to challenge the response from a RAG agent using the Chain-of-Verification (CoVe) method (https://arxiv.org/pdf/2309.11495) to try to prevent hallucinations. \"\"\" yaml_tag = u '!wiseagents.agents.CoVeChallengerRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name (Optional[str]): the name of the collection to use in the vector database, defaults to wise-agents-collection k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _num_verification_questions = num_verification_questions llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , vector_db = vector_db , collection_name = collection_name , k = k , num_verification_questions = num_verification_questions ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , k= { self . k } ,\" f \"num_verification_questions= { self . _num_verification_questions } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass def retrieve_documents ( self , question : str ) -> List [ Document ]: return retrieve_documents_for_rag ( question , self . vector_db , self . collection_name , self . k )","title":"CoVeChallengerRAGWiseAgent"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerRAGWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication collection_name ( Optional [ str ] , default: DEFAULT_COLLECTION_NAME ) \u2013 the name of the collection to use in the vector database, defaults to wise-agents-collection k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions ( Optional [ int ] , default: DEFAULT_NUM_VERIFICATION_QUESTIONS ) \u2013 the number of verification questions to generate, defaults to 4 system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , num_verification_questions : Optional [ int ] = DEFAULT_NUM_VERIFICATION_QUESTIONS , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name (Optional[str]): the name of the collection to use in the vector database, defaults to wise-agents-collection k (Optional[int]): the number of documents to retrieve from the vector database, defaults to 4 num_verification_questions (Optional[int]): the number of verification questions to generate, defaults to 4 system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _num_verification_questions = num_verification_questions llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message , vector_db = vector_db , collection_name = collection_name , k = k , num_verification_questions = num_verification_questions )","title":"__init__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerRAGWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 433 434 435 436 437 438 439 440 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _num_verification_questions = DEFAULT_NUM_VERIFICATION_QUESTIONS obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerRAGWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 474 475 476 477 478 479 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , k= { self . k } ,\" f \"num_verification_questions= { self . _num_verification_questions } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerRAGWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 485 486 487 488 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerRAGWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 481 482 483 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerRAGWiseAgent.process_request","text":"Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: str ( Optional [ str ] ) \u2013 the response to the request message as a string Source code in wiseagents/agents/rag_wise_agents.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a message containing a question and a baseline response to the question by challenging the baseline response to generate a revised response to the original question. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: str: the response to the request message as a string \"\"\" llm_response = self . create_and_process_chain_of_verification_prompts ( request . message , conversation_history ) return llm_response","title":"process_request"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerRAGWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 507 508 509 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.CoVeChallengerRAGWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 511 512 513 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent","text":"Bases: WiseAgent This agent implementation makes use of Graph Retrieval Augmented Generation (Graph RAG) to answer questions. Source code in wiseagents/agents/rag_wise_agents.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 class GraphRAGWiseAgent ( WiseAgent ): \"\"\" This agent implementation makes use of Graph Retrieval Augmented Generation (Graph RAG) to answer questions. \"\"\" yaml_tag = u '!wiseagents.agents.GraphRAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _include_sources = include_sources self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , graph_db = graph_db , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , transport= { self . transport } , k= { self . k } ,\" f \"include_sources= { self . include_sources } ), retrieval_query= { self . retrieval_query } ,\" f \"params= { self . params } , metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the RAG agent and sending the response back to the client. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_graph_rag ( request . message , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve for each query.\"\"\" return self . _k @property def include_sources ( self ) -> bool : \"\"\"Get whether to include the sources of the documents that were consulted to produce the response.\"\"\" return self . _include_sources @property def retrieval_query ( self ) -> str : \"\"\"Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search.\"\"\" return self . _retrieval_query @property def params ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional parameters for the query.\"\"\" return self . _params @property def metadata_filter ( self ) -> Optional [ Dict [ str , Any ]]: \"\"\"Get the optional metadata filter to use with similarity search.\"\"\" return self . _metadata_filter","title":"GraphRAGWiseAgent"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.include_sources","text":"Get whether to include the sources of the documents that were consulted to produce the response.","title":"include_sources"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.k","text":"Get the number of documents to retrieve for each query.","title":"k"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.metadata_filter","text":"Get the optional metadata filter to use with similarity search.","title":"metadata_filter"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.params","text":"Get the optional parameters for the query.","title":"params"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.retrieval_query","text":"Get the Cypher query to use to obtain sub-graphs connected to nodes retrieved from a similarity search.","title":"retrieval_query"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM to use for processing requests graph_db ( WiseAgentGraphDB ) \u2013 the graph database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication k ( Optional [ int ] , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve for each query, defaults to 4 include_sources ( Optional(bool , default: DEFAULT_INCLUDE_SOURCES ) \u2013 whether to include the sources of the documents that were consulted to retrieval_query ( Optional [ str ] , default: '' ) \u2013 the optional retrieval query to use to obtain sub-graphs connected to nodes params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/rag_wise_agents.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , graph_db : WiseAgentGraphDB , transport : WiseAgentTransport , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication k (Optional[int]): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _graph_db = graph_db self . _k = k self . _include_sources = include_sources self . _retrieval_query = retrieval_query self . _params = params self . _metadata_filter = metadata_filter super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , graph_db = graph_db , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 135 136 137 138 139 140 141 142 143 144 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _retrieval_query = \"\" obj . _params = None obj . _metadata_filter = None obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 182 183 184 185 186 187 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"graph_db= { self . graph_db } , transport= { self . transport } , k= { self . k } ,\" f \"include_sources= { self . include_sources } ), retrieval_query= { self . retrieval_query } ,\" f \"params= { self . params } , metadata_filter= { self . metadata_filter } , system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 193 194 195 196 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 189 190 191 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.process_request","text":"Process a request message by passing it to the RAG agent and sending the response back to the client. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/rag_wise_agents.py 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the RAG agent and sending the response back to the client. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_graph_rag ( request . message , self . graph_db , self . k , self . retrieval_query , self . params , self . metadata_filter ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources","title":"process_request"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 218 219 220 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.GraphRAGWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 222 223 224 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent","text":"Bases: WiseAgent This agent makes use of retrieval augmented generation (RAG) to answer questions. Source code in wiseagents/agents/rag_wise_agents.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class RAGWiseAgent ( WiseAgent ): \"\"\" This agent makes use of retrieval augmented generation (RAG) to answer questions. \"\"\" yaml_tag = u '!wiseagents.agents.RAGWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name Optional(str): the name of the collection within the vector database to use for retrieving documents, defaults to wise-agent-collection k Optional(int): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _include_sources = include_sources super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , vector_db = vector_db , collection_name = collection_name , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , transport= { self . transport } ,\" f \"k= { self . k } , include_sources= { self . include_sources } ), system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message using retrieval augmented generation (RAG). Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_rag ( request . message , self . vector_db , self . collection_name , self . k ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def k ( self ) -> int : \"\"\"Get the number of documents to retrieve for each query.\"\"\" return self . _k @property def include_sources ( self ) -> bool : \"\"\"Get whether to include the sources of the documents that were consulted to produce the response.\"\"\" return self . _include_sources","title":"RAGWiseAgent"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.include_sources","text":"Get whether to include the sources of the documents that were consulted to produce the response.","title":"include_sources"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.k","text":"Get the number of documents to retrieve for each query.","title":"k"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM to use for processing requests vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents transport ( WiseAgentTransport ) \u2013 the transport to use for communication collection_name ( Optional(str , default: DEFAULT_COLLECTION_NAME ) \u2013 the name of the collection within the vector database to use for k ( Optional(int , default: DEFAULT_NUM_DOCUMENTS ) \u2013 the number of documents to retrieve for each query, defaults to 4 include_sources ( Optional(bool , default: DEFAULT_INCLUDE_SOURCES ) \u2013 whether to include the sources of the documents that were consulted to Source code in wiseagents/agents/rag_wise_agents.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , vector_db : WiseAgentVectorDB , transport : WiseAgentTransport , collection_name : Optional [ str ] = DEFAULT_COLLECTION_NAME , k : Optional [ int ] = DEFAULT_NUM_DOCUMENTS , include_sources : Optional [ bool ] = DEFAULT_INCLUDE_SOURCES , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM to use for processing requests vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents transport (WiseAgentTransport): the transport to use for communication collection_name Optional(str): the name of the collection within the vector database to use for retrieving documents, defaults to wise-agent-collection k Optional(int): the number of documents to retrieve for each query, defaults to 4 include_sources Optional(bool): whether to include the sources of the documents that were consulted to produce the response, defaults to False \"\"\" self . _name = name self . _description = description self . _transport = transport self . _vector_db = vector_db self . _collection_name = collection_name self . _k = k self . _include_sources = include_sources super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , vector_db = vector_db , collection_name = collection_name , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/rag_wise_agents.py 32 33 34 35 36 37 38 39 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _collection_name = DEFAULT_COLLECTION_NAME obj . _k = DEFAULT_NUM_DOCUMENTS obj . _include_sources = DEFAULT_INCLUDE_SOURCES obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/rag_wise_agents.py 70 71 72 73 74 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"vector_db= { self . vector_db } , collection_name= { self . collection_name } , transport= { self . transport } ,\" f \"k= { self . k } , include_sources= { self . include_sources } ), system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/rag_wise_agents.py 80 81 82 83 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 76 77 78 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.process_request","text":"Process a request message using retrieval augmented generation (RAG). Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/rag_wise_agents.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message using retrieval augmented generation (RAG). Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" retrieved_documents = retrieve_documents_for_rag ( request . message , self . vector_db , self . collection_name , self . k ) llm_response_with_sources = create_and_process_rag_prompt ( retrieved_documents , request . message , self . llm , self . include_sources , conversation_history , self . system_message ) return llm_response_with_sources","title":"process_request"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 105 106 107 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.RAGWiseAgent.stop","text":"Do nothing Source code in wiseagents/agents/rag_wise_agents.py 109 110 111 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.create_and_process_rag_prompt","text":"Create a RAG prompt and process it with the LLM agent. Parameters: retrieved_documents ( List [ Document ] ) \u2013 the list of retrieved documents question ( str ) \u2013 the question to ask llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing the prompt conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. system_message ( str ) \u2013 the optional system message to use Source code in wiseagents/agents/rag_wise_agents.py 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 def create_and_process_rag_prompt ( retrieved_documents : List [ Document ], question : str , llm : WiseAgentLLM , include_sources : bool , conversation_history : List [ ChatCompletionMessageParam ], system_message : str ) -> str : \"\"\" Create a RAG prompt and process it with the LLM agent. Args: retrieved_documents (List[Document]): the list of retrieved documents question (str): the question to ask llm (WiseAgentLLM): the LLM agent to use for processing the prompt conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. system_message (str): the optional system message to use \"\"\" context = \" \\n \" . join ([ document . content for document in retrieved_documents ]) prompt = ( f \"Answer the question based only on the following context: \\n { context } \\n \" f \"Question: { question } \\n \" ) conversation_history . append ({ \"role\" : \"system\" , \"content\" : system_message or llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : prompt }) llm_response = llm . process_chat_completion ( conversation_history , []) if include_sources : source_documents = \"\" for document in retrieved_documents : source_documents += f \"Source Document: \\n Content: { document . content } \\n Metadata: { json . dumps ( document . metadata ) } \\n\\n \" return f \" { llm_response . choices [ 0 ] . message . content } \\n\\n Source Documents: \\n { source_documents } \" else : return llm_response . choices [ 0 ] . message . content","title":"create_and_process_rag_prompt"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.retrieve_documents_for_graph_rag","text":"Retrieve documents to be used as the context for graph based retrieval augmented generation (Graph RAG). Parameters: question ( str ) \u2013 the question to be used to retrieve the documents graph_db ( WiseAgentGraphDB ) \u2013 the graph database to use for retrieving documents k ( int ) \u2013 the number of documents to retrieve for a question retrieval_query ( Optional [ str ] , default: '' ) \u2013 the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search Returns: Source code in wiseagents/agents/rag_wise_agents.py 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 def retrieve_documents_for_graph_rag ( question : str , graph_db : WiseAgentGraphDB , k : int , retrieval_query : Optional [ str ] = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for graph based retrieval augmented generation (Graph RAG). Args: question (str): the question to be used to retrieve the documents graph_db (WiseAgentGraphDB): the graph database to use for retrieving documents k (int): the number of documents to retrieve for a question retrieval_query (Optional[str]): the optional retrieval query to use to obtain sub-graphs connected to nodes retrieved from a similarity search params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: \"\"\" retrieved_documents = graph_db . query_with_embeddings ( query = question , k = k , retrieval_query = retrieval_query , params = params , metadata_filter = metadata_filter ) return retrieved_documents","title":"retrieve_documents_for_graph_rag"},{"location":"reference/wiseagents/agents/rag_wise_agents/#wiseagents.agents.rag_wise_agents.retrieve_documents_for_rag","text":"Retrieve documents to be used as the context for retrieval augmented generation (RAG). Parameters: question ( str ) \u2013 the question to be used to retrieve the documents vector_db ( WiseAgentVectorDB ) \u2013 the vector database to use for retrieving documents collection_name ( str ) \u2013 the name of the collection within the vector database to use for retrieving documents k ( int ) \u2013 the number of documents to retrieve for a question Returns: Source code in wiseagents/agents/rag_wise_agents.py 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 def retrieve_documents_for_rag ( question : str , vector_db : WiseAgentVectorDB , collection_name : str , k : int ) \\ -> List [ Document ]: \"\"\" Retrieve documents to be used as the context for retrieval augmented generation (RAG). Args: question (str): the question to be used to retrieve the documents vector_db (WiseAgentVectorDB): the vector database to use for retrieving documents collection_name (str): the name of the collection within the vector database to use for retrieving documents k (int): the number of documents to retrieve for a question Returns: \"\"\" retrieved_documents = vector_db . query ([ question ], collection_name , k ) if retrieved_documents : return retrieved_documents [ 0 ] else : return []","title":"retrieve_documents_for_rag"},{"location":"reference/wiseagents/agents/utility_wise_agents/","text":"ChatWiseAgent Bases: WiseAgent This agent implementation is meant to be used in conjunction with an Assistant. A ChatWiseAgent agent will receive a request from an assistant agent and will process the request, adding its response to the shared context. The chatAgent agent will then send the assistant agent a message to let the assistant know that it has finished executing its work. Source code in wiseagents/agents/utility_wise_agents.py 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 class ChatWiseAgent ( WiseAgent ): \"\"\" This agent implementation is meant to be used in conjunction with an Assistant. A ChatWiseAgent agent will receive a request from an assistant agent and will process the request, adding its response to the shared context. The chatAgent agent will then send the assistant agent a message to let the assistant know that it has finished executing its work. \"\"\" yaml_tag = u '!wiseagents.agents.ChatWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the agent when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _llm = llm self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"transport= { self . transport } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM and then send a response back to the sender to let them know the request has been processed. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name name : str property Get the name of the agent. __init__ ( name , description , llm , transport , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the agent when processing Source code in wiseagents/agents/utility_wise_agents.py 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the agent when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _llm = llm self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 353 354 355 356 357 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 379 380 381 382 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"transport= { self . transport } , system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 388 389 390 391 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 384 385 386 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by passing it to the LLM and then send a response back to the sender to let them know the request has been processed. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/utility_wise_agents.py 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM and then send a response back to the sender to let them know the request has been processed. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content process_response ( response ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 414 415 416 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True LLMOnlyWiseAgent Bases: WiseAgent This utility agent simply passes a request that it receives to an LLM for processing and returns the response received from the LLM. Source code in wiseagents/agents/utility_wise_agents.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 class LLMOnlyWiseAgent ( WiseAgent ): \"\"\" This utility agent simply passes a request that it receives to an LLM for processing and returns the response received from the LLM. \"\"\" yaml_tag = u '!wiseagents.agents.LLMOnlyWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name name : str property Get the name of the agent. __init__ ( name , description , llm , transport , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/utility_wise_agents.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 108 109 110 111 112 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 134 135 136 137 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 143 144 145 146 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 139 140 141 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by passing it to the LLM. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/utility_wise_agents.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content process_response ( response ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 167 168 169 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True LLMWiseAgentWithTools Bases: WiseAgent This utility agent makes use of an LLM along with tools to process a request and determine the response to send back to the client. Source code in wiseagents/agents/utility_wise_agents.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 class LLMWiseAgentWithTools ( WiseAgent ): \"\"\" This utility agent makes use of an LLM along with tools to process a request and determine the response to send back to the client. \"\"\" yaml_tag = u '!wiseagents.agents.LLMWiseAgentWithTools' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , tools : List [ str ], system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm self . _tools = tools super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" logging . debug ( f \"IA Request received: { request } \" ) chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : request . message }) for tool in self . _tools : ctx . append_available_tool_in_chat ( chat_uuid = chat_id , tools = WiseAgentRegistry . get_tool ( tool ) . get_tool_OpenAI_format ()) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } , Tools: { ctx . get_available_tools_in_chat ( chat_uuid = chat_id ) } \" ) # TODO: https://github.com/wise-agents/wise-agents/issues/205 llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) ##calling tool response_message = llm_response . choices [ 0 ] . message tool_calls = response_message . tool_calls logging . debug ( f \"Tool calls: { tool_calls } \" ) logging . debug ( f \"Response message: { response_message } \" ) # Step 2: check if the model wanted to call a function if tool_calls is not None : # Step 3: call the function # TODO: the JSON response may not always be valid; be sure to handle errors ctx . append_chat_completion ( chat_uuid = chat_id , messages = response_message ) # extend conversation with assistant's reply # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls : #record the required tool call in the context/chatid ctx . append_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) for tool_call in tool_calls : function_name = tool_call . function . name wise_agent_tool : WiseAgentTool = WiseAgentRegistry . get_tool ( function_name ) if wise_agent_tool . is_agent_tool : #call the agent with correlation ID and complete the chat on response self . send_request ( WiseAgentMessage ( message = tool_call . function . arguments , sender = self . name , chat_id = chat_id , tool_id = tool_call . id , context_name = request . context_name , route_response_to = request . sender ), dest_agent_name = function_name ) else : function_args = json . loads ( tool_call . function . arguments ) function_response = wise_agent_tool . exec ( ** function_args ) logging . debug ( f \"Function response: { function_response } \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : tool_call . id , \"role\" : \"tool\" , \"name\" : function_name , \"content\" : function_response , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) #SEND THE RESPONSE IF NOT ASYNC, OTHERWISE WE WILL DO LATER IN PROCESS_RESPONSE if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { request . sender } \" ) ctx . llm_chat_completion . pop ( chat_id ) return response_message . content def process_response ( self , response : WiseAgentMessage ): \"\"\" Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Args: response (WiseAgentMessage): the response message to process \"\"\" print ( f \"Response received: { response } \" ) chat_id = response . chat_id ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : response . tool_id , \"role\" : \"tool\" , \"name\" : response . sender , \"content\" : response . message , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = response . sender ) if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { response . route_response_to } \" ) self . send_response ( WiseAgentMessage ( response_message . content , self . name ), response . route_response_to ) ctx . llm_chat_completion . pop ( chat_id ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name name : str property Get the name of the agent. __init__ ( name , description , llm , transport , tools , system_message = None ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/utility_wise_agents.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , tools : List [ str ], system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm self . _tools = tools super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 187 188 189 190 191 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 213 214 215 216 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) process_error ( error ) Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 222 223 224 225 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True process_event ( event ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 218 219 220 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Optional[str]: the response to the request message as a string or None if there is no string response yet Source code in wiseagents/agents/utility_wise_agents.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" logging . debug ( f \"IA Request received: { request } \" ) chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : request . message }) for tool in self . _tools : ctx . append_available_tool_in_chat ( chat_uuid = chat_id , tools = WiseAgentRegistry . get_tool ( tool ) . get_tool_OpenAI_format ()) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } , Tools: { ctx . get_available_tools_in_chat ( chat_uuid = chat_id ) } \" ) # TODO: https://github.com/wise-agents/wise-agents/issues/205 llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) ##calling tool response_message = llm_response . choices [ 0 ] . message tool_calls = response_message . tool_calls logging . debug ( f \"Tool calls: { tool_calls } \" ) logging . debug ( f \"Response message: { response_message } \" ) # Step 2: check if the model wanted to call a function if tool_calls is not None : # Step 3: call the function # TODO: the JSON response may not always be valid; be sure to handle errors ctx . append_chat_completion ( chat_uuid = chat_id , messages = response_message ) # extend conversation with assistant's reply # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls : #record the required tool call in the context/chatid ctx . append_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) for tool_call in tool_calls : function_name = tool_call . function . name wise_agent_tool : WiseAgentTool = WiseAgentRegistry . get_tool ( function_name ) if wise_agent_tool . is_agent_tool : #call the agent with correlation ID and complete the chat on response self . send_request ( WiseAgentMessage ( message = tool_call . function . arguments , sender = self . name , chat_id = chat_id , tool_id = tool_call . id , context_name = request . context_name , route_response_to = request . sender ), dest_agent_name = function_name ) else : function_args = json . loads ( tool_call . function . arguments ) function_response = wise_agent_tool . exec ( ** function_args ) logging . debug ( f \"Function response: { function_response } \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : tool_call . id , \"role\" : \"tool\" , \"name\" : function_name , \"content\" : function_response , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) #SEND THE RESPONSE IF NOT ASYNC, OTHERWISE WE WILL DO LATER IN PROCESS_RESPONSE if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { request . sender } \" ) ctx . llm_chat_completion . pop ( chat_id ) return response_message . content process_response ( response ) Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/utility_wise_agents.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def process_response ( self , response : WiseAgentMessage ): \"\"\" Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Args: response (WiseAgentMessage): the response message to process \"\"\" print ( f \"Response received: { response } \" ) chat_id = response . chat_id ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : response . tool_id , \"role\" : \"tool\" , \"name\" : response . sender , \"content\" : response . message , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = response . sender ) if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { response . route_response_to } \" ) self . send_response ( WiseAgentMessage ( response_message . content , self . name ), response . route_response_to ) ctx . llm_chat_completion . pop ( chat_id ) return True stop () Do nothing Source code in wiseagents/agents/utility_wise_agents.py 334 335 336 def stop ( self ): \"\"\"Do nothing\"\"\" pass PassThroughClientAgent Bases: WiseAgent This utility agent simply passes a request that it receives to another agent and sends the response back to the client. Source code in wiseagents/agents/utility_wise_agents.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class PassThroughClientAgent ( WiseAgent ): \"\"\" This utility agent simply passes a request that it receives to another agent and sends the response back to the client. \"\"\" yaml_tag = u '!wiseagents.agents.PassThroughClientAgent' _response_delivery = None _destination_agent_name = None def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _destination_agent_name = \"WiseIntelligentAgent\" return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : Optional [ str ] = \"WiseIntelligentAgent\" ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\"Process a request message by just passing it to another agent.\"\"\" self . send_request ( WiseAgentMessage ( request , self . name ), self . destination_agent_name ) return None def process_response ( self , response ): \"\"\"Process a response message just sending it back to the client.\"\"\" if self . response_delivery is not None : self . response_delivery ( response ) else : logging . debug ( f \"############################### Not sending response { response } \" ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def destination_agent_name ( self ) -> str : \"\"\"Get the name of the agent to send requests to.\"\"\" return self . _destination_agent_name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client\"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery destination_agent_name : str property Get the name of the agent to send requests to. name : str property Get the name of the agent. response_delivery : Optional [ Callable [[], WiseAgentMessage ]] property Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client __init__ ( name , description , transport , destination_agent_name = 'WiseIntelligentAgent' ) Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication destination_agent_name ( str , default: 'WiseIntelligentAgent' ) \u2013 the name of the agent to send requests to Source code in wiseagents/agents/utility_wise_agents.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : Optional [ str ] = \"WiseIntelligentAgent\" ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/utility_wise_agents.py 22 23 24 25 26 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _destination_agent_name = \"WiseIntelligentAgent\" return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 43 44 45 46 47 48 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" process_error ( error ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 68 69 70 def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True process_event ( event ) Do nothing Source code in wiseagents/agents/utility_wise_agents.py 64 65 66 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True process_request ( request , conversation_history ) Process a request message by just passing it to another agent. Source code in wiseagents/agents/utility_wise_agents.py 50 51 52 53 54 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\"Process a request message by just passing it to another agent.\"\"\" self . send_request ( WiseAgentMessage ( request , self . name ), self . destination_agent_name ) return None process_response ( response ) Process a response message just sending it back to the client. Source code in wiseagents/agents/utility_wise_agents.py 56 57 58 59 60 61 62 def process_response ( self , response ): \"\"\"Process a response message just sending it back to the client.\"\"\" if self . response_delivery is not None : self . response_delivery ( response ) else : logging . debug ( f \"############################### Not sending response { response } \" ) return True set_response_delivery ( response_delivery ) Set the function to deliver the response to the client. Parameters: response_delivery ( Callable [[], WiseAgentMessage ] ) \u2013 the function to deliver the response to the client Source code in wiseagents/agents/utility_wise_agents.py 92 93 94 95 96 97 98 99 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery stop () Do nothing Source code in wiseagents/agents/utility_wise_agents.py 72 73 74 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"utility_wise_agents"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.ChatWiseAgent","text":"Bases: WiseAgent This agent implementation is meant to be used in conjunction with an Assistant. A ChatWiseAgent agent will receive a request from an assistant agent and will process the request, adding its response to the shared context. The chatAgent agent will then send the assistant agent a message to let the assistant know that it has finished executing its work. Source code in wiseagents/agents/utility_wise_agents.py 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 class ChatWiseAgent ( WiseAgent ): \"\"\" This agent implementation is meant to be used in conjunction with an Assistant. A ChatWiseAgent agent will receive a request from an assistant agent and will process the request, adding its response to the shared context. The chatAgent agent will then send the assistant agent a message to let the assistant know that it has finished executing its work. \"\"\" yaml_tag = u '!wiseagents.agents.ChatWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the agent when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _llm = llm self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"transport= { self . transport } , system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM and then send a response back to the sender to let them know the request has been processed. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name","title":"ChatWiseAgent"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.ChatWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.ChatWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the agent when processing Source code in wiseagents/agents/utility_wise_agents.py 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the agent when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport self . _llm = llm self . _system_message = system_message super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.ChatWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 353 354 355 356 357 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.ChatWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 379 380 381 382 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } ,\" f \"transport= { self . transport } , system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.ChatWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 388 389 390 391 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.ChatWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 384 385 386 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.ChatWiseAgent.process_request","text":"Process a request message by passing it to the LLM and then send a response back to the sender to let them know the request has been processed. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/utility_wise_agents.py 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM and then send a response back to the sender to let them know the request has been processed. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content","title":"process_request"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.ChatWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 414 415 416 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMOnlyWiseAgent","text":"Bases: WiseAgent This utility agent simply passes a request that it receives to an LLM for processing and returns the response received from the LLM. Source code in wiseagents/agents/utility_wise_agents.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 class LLMOnlyWiseAgent ( WiseAgent ): \"\"\" This utility agent simply passes a request that it receives to an LLM for processing and returns the response received from the LLM. \"\"\" yaml_tag = u '!wiseagents.agents.LLMOnlyWiseAgent' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True def stop ( self ): pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name","title":"LLMOnlyWiseAgent"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMOnlyWiseAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMOnlyWiseAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/utility_wise_agents.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMOnlyWiseAgent.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 108 109 110 111 112 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMOnlyWiseAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 134 135 136 137 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMOnlyWiseAgent.process_error","text":"Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 143 144 145 146 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMOnlyWiseAgent.process_event","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 139 140 141 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMOnlyWiseAgent.process_request","text":"Process a request message by passing it to the LLM. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Returns: Optional [ str ] \u2013 Optional[str]: the response to the request message as a string or None if there is Optional [ str ] \u2013 no string response yet Source code in wiseagents/agents/utility_wise_agents.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Returns: Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" conversation_history . append ({ \"role\" : \"system\" , \"content\" : self . system_message or self . llm . system_message }) conversation_history . append ({ \"role\" : \"user\" , \"content\" : request . message }) llm_response = self . llm . process_chat_completion ( conversation_history , []) return llm_response . choices [ 0 ] . message . content","title":"process_request"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMOnlyWiseAgent.process_response","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 167 168 169 def process_response ( self , response : WiseAgentMessage ): \"\"\"Do nothing\"\"\" return True","title":"process_response"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools","text":"Bases: WiseAgent This utility agent makes use of an LLM along with tools to process a request and determine the response to send back to the client. Source code in wiseagents/agents/utility_wise_agents.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 class LLMWiseAgentWithTools ( WiseAgent ): \"\"\" This utility agent makes use of an LLM along with tools to process a request and determine the response to send back to the client. \"\"\" yaml_tag = u '!wiseagents.agents.LLMWiseAgentWithTools' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , tools : List [ str ], system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm self . _tools = tools super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" ) def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" logging . debug ( f \"IA Request received: { request } \" ) chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : request . message }) for tool in self . _tools : ctx . append_available_tool_in_chat ( chat_uuid = chat_id , tools = WiseAgentRegistry . get_tool ( tool ) . get_tool_OpenAI_format ()) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } , Tools: { ctx . get_available_tools_in_chat ( chat_uuid = chat_id ) } \" ) # TODO: https://github.com/wise-agents/wise-agents/issues/205 llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) ##calling tool response_message = llm_response . choices [ 0 ] . message tool_calls = response_message . tool_calls logging . debug ( f \"Tool calls: { tool_calls } \" ) logging . debug ( f \"Response message: { response_message } \" ) # Step 2: check if the model wanted to call a function if tool_calls is not None : # Step 3: call the function # TODO: the JSON response may not always be valid; be sure to handle errors ctx . append_chat_completion ( chat_uuid = chat_id , messages = response_message ) # extend conversation with assistant's reply # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls : #record the required tool call in the context/chatid ctx . append_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) for tool_call in tool_calls : function_name = tool_call . function . name wise_agent_tool : WiseAgentTool = WiseAgentRegistry . get_tool ( function_name ) if wise_agent_tool . is_agent_tool : #call the agent with correlation ID and complete the chat on response self . send_request ( WiseAgentMessage ( message = tool_call . function . arguments , sender = self . name , chat_id = chat_id , tool_id = tool_call . id , context_name = request . context_name , route_response_to = request . sender ), dest_agent_name = function_name ) else : function_args = json . loads ( tool_call . function . arguments ) function_response = wise_agent_tool . exec ( ** function_args ) logging . debug ( f \"Function response: { function_response } \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : tool_call . id , \"role\" : \"tool\" , \"name\" : function_name , \"content\" : function_response , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) #SEND THE RESPONSE IF NOT ASYNC, OTHERWISE WE WILL DO LATER IN PROCESS_RESPONSE if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { request . sender } \" ) ctx . llm_chat_completion . pop ( chat_id ) return response_message . content def process_response ( self , response : WiseAgentMessage ): \"\"\" Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Args: response (WiseAgentMessage): the response message to process \"\"\" print ( f \"Response received: { response } \" ) chat_id = response . chat_id ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : response . tool_id , \"role\" : \"tool\" , \"name\" : response . sender , \"content\" : response . message , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = response . sender ) if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { response . route_response_to } \" ) self . send_response ( WiseAgentMessage ( response_message . content , self . name ), response . route_response_to ) ctx . llm_chat_completion . pop ( chat_id ) return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name","title":"LLMWiseAgentWithTools"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent llm ( WiseAgentLLM ) \u2013 the LLM agent to use for processing requests transport ( WiseAgentTransport ) \u2013 the transport to use for communication system_message ( Optional [ str ] , default: None ) \u2013 the optional system message to be used by the collaborator when processing Source code in wiseagents/agents/utility_wise_agents.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 def __init__ ( self , name : str , description : str , llm : WiseAgentLLM , transport : WiseAgentTransport , tools : List [ str ], system_message : Optional [ str ] = None ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent llm (WiseAgentLLM): the LLM agent to use for processing requests transport (WiseAgentTransport): the transport to use for communication system_message (Optional[str]): the optional system message to be used by the collaborator when processing chat completions using its LLM \"\"\" self . _name = name self . _description = description self . _transport = transport llm_agent = llm self . _tools = tools super () . __init__ ( name = name , description = description , transport = self . transport , llm = llm_agent , system_message = system_message )","title":"__init__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/agents/utility_wise_agents.py 187 188 189 190 191 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _system_message = None return obj","title":"__new__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 213 214 215 216 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return ( f \" { self . __class__ . __name__ } (name= { self . name } , description= { self . description } , llm= { self . llm } , transport= { self . transport } ,\" f \"system_message= { self . system_message } )\" )","title":"__repr__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools.process_error","text":"Log the error and return True. Source code in wiseagents/agents/utility_wise_agents.py 222 223 224 225 def process_error ( self , error ): \"\"\"Log the error and return True.\"\"\" logging . error ( error ) return True","title":"process_error"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools.process_event","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 218 219 220 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools.process_request","text":"Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Parameters: request ( WiseAgentMessage ) \u2013 the request message to process conversation_history ( List [ ChatCompletionMessageParam ] ) \u2013 The conversation history that Optional[str]: the response to the request message as a string or None if there is no string response yet Source code in wiseagents/agents/utility_wise_agents.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\" Process a request message by passing it to the LLM agent. It also invokes tool(s) if required. Tool(s) could be a callback function or another agent. Args: request (WiseAgentMessage): the request message to process conversation_history (List[ChatCompletionMessageParam]): The conversation history that can be used while processing the request. If this agent isn't involved in a type of collaboration that makes use of the conversation history, this will be an empty list. Optional[str]: the response to the request message as a string or None if there is no string response yet \"\"\" logging . debug ( f \"IA Request received: { request } \" ) chat_id = str ( uuid . uuid4 ()) ctx = WiseAgentRegistry . get_or_create_context ( request . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"system\" , \"content\" : self . llm . system_message }) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"role\" : \"user\" , \"content\" : request . message }) for tool in self . _tools : ctx . append_available_tool_in_chat ( chat_uuid = chat_id , tools = WiseAgentRegistry . get_tool ( tool ) . get_tool_OpenAI_format ()) logging . debug ( f \"messages: { ctx . llm_chat_completion [ chat_id ] } , Tools: { ctx . get_available_tools_in_chat ( chat_uuid = chat_id ) } \" ) # TODO: https://github.com/wise-agents/wise-agents/issues/205 llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) ##calling tool response_message = llm_response . choices [ 0 ] . message tool_calls = response_message . tool_calls logging . debug ( f \"Tool calls: { tool_calls } \" ) logging . debug ( f \"Response message: { response_message } \" ) # Step 2: check if the model wanted to call a function if tool_calls is not None : # Step 3: call the function # TODO: the JSON response may not always be valid; be sure to handle errors ctx . append_chat_completion ( chat_uuid = chat_id , messages = response_message ) # extend conversation with assistant's reply # Step 4: send the info for each function call and function response to the model for tool_call in tool_calls : #record the required tool call in the context/chatid ctx . append_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) for tool_call in tool_calls : function_name = tool_call . function . name wise_agent_tool : WiseAgentTool = WiseAgentRegistry . get_tool ( function_name ) if wise_agent_tool . is_agent_tool : #call the agent with correlation ID and complete the chat on response self . send_request ( WiseAgentMessage ( message = tool_call . function . arguments , sender = self . name , chat_id = chat_id , tool_id = tool_call . id , context_name = request . context_name , route_response_to = request . sender ), dest_agent_name = function_name ) else : function_args = json . loads ( tool_call . function . arguments ) function_response = wise_agent_tool . exec ( ** function_args ) logging . debug ( f \"Function response: { function_response } \" ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : tool_call . id , \"role\" : \"tool\" , \"name\" : function_name , \"content\" : function_response , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = tool_call . function . name ) #SEND THE RESPONSE IF NOT ASYNC, OTHERWISE WE WILL DO LATER IN PROCESS_RESPONSE if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { request . sender } \" ) ctx . llm_chat_completion . pop ( chat_id ) return response_message . content","title":"process_request"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools.process_response","text":"Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Parameters: response ( WiseAgentMessage ) \u2013 the response message to process Source code in wiseagents/agents/utility_wise_agents.py 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def process_response ( self , response : WiseAgentMessage ): \"\"\" Process a response message and sending the response back to the client. It invoke also the tool if required. Tool could be a callback function or another agent. Args: response (WiseAgentMessage): the response message to process \"\"\" print ( f \"Response received: { response } \" ) chat_id = response . chat_id ctx = WiseAgentRegistry . get_or_create_context ( response . context_name ) ctx . append_chat_completion ( chat_uuid = chat_id , messages = { \"tool_call_id\" : response . tool_id , \"role\" : \"tool\" , \"name\" : response . sender , \"content\" : response . message , } ) # extend conversation with function response ctx . remove_required_tool_call ( chat_uuid = chat_id , tool_name = response . sender ) if ctx . get_required_tool_calls ( chat_uuid = chat_id ) == []: # if all tool calls have been completed (no asynch needed) llm_response = self . llm . process_chat_completion ( ctx . llm_chat_completion [ chat_id ], ctx . get_available_tools_in_chat ( chat_uuid = chat_id )) response_message = llm_response . choices [ 0 ] . message logging . debug ( f \"sending response { response_message . content } to: { response . route_response_to } \" ) self . send_response ( WiseAgentMessage ( response_message . content , self . name ), response . route_response_to ) ctx . llm_chat_completion . pop ( chat_id ) return True","title":"process_response"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.LLMWiseAgentWithTools.stop","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 334 335 336 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent","text":"Bases: WiseAgent This utility agent simply passes a request that it receives to another agent and sends the response back to the client. Source code in wiseagents/agents/utility_wise_agents.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class PassThroughClientAgent ( WiseAgent ): \"\"\" This utility agent simply passes a request that it receives to another agent and sends the response back to the client. \"\"\" yaml_tag = u '!wiseagents.agents.PassThroughClientAgent' _response_delivery = None _destination_agent_name = None def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _destination_agent_name = \"WiseIntelligentAgent\" return obj def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : Optional [ str ] = \"WiseIntelligentAgent\" ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None ) def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \" def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\"Process a request message by just passing it to another agent.\"\"\" self . send_request ( WiseAgentMessage ( request , self . name ), self . destination_agent_name ) return None def process_response ( self , response ): \"\"\"Process a response message just sending it back to the client.\"\"\" if self . response_delivery is not None : self . response_delivery ( response ) else : logging . debug ( f \"############################### Not sending response { response } \" ) return True def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True def stop ( self ): \"\"\"Do nothing\"\"\" pass @property def name ( self ) -> str : \"\"\"Get the name of the agent.\"\"\" return self . _name @property def destination_agent_name ( self ) -> str : \"\"\"Get the name of the agent to send requests to.\"\"\" return self . _destination_agent_name @property def response_delivery ( self ) -> Optional [ Callable [[], WiseAgentMessage ]]: \"\"\"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client\"\"\" return self . _response_delivery def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery","title":"PassThroughClientAgent"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.destination_agent_name","text":"Get the name of the agent to send requests to.","title":"destination_agent_name"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.name","text":"Get the name of the agent.","title":"name"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.response_delivery","text":"Get the function to deliver the response to the client. return (Callable[[], WiseAgentMessage]): the function to deliver the response to the client","title":"response_delivery"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.__init__","text":"Initialize the agent. Parameters: name ( str ) \u2013 the name of the agent description ( str ) \u2013 a description of the agent transport ( WiseAgentTransport ) \u2013 the transport to use for communication destination_agent_name ( str , default: 'WiseIntelligentAgent' ) \u2013 the name of the agent to send requests to Source code in wiseagents/agents/utility_wise_agents.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def __init__ ( self , name : str , description : str , transport : WiseAgentTransport , destination_agent_name : Optional [ str ] = \"WiseIntelligentAgent\" ): \"\"\" Initialize the agent. Args: name (str): the name of the agent description (str): a description of the agent transport (WiseAgentTransport): the transport to use for communication destination_agent_name (str): the name of the agent to send requests to \"\"\" self . _name = name self . _destination_agent_name = destination_agent_name super () . __init__ ( name = name , description = description , transport = transport , llm = None )","title":"__init__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.__new__","text":"Create a new instance of the class, setting default values for the optional instance variables. Source code in wiseagents/agents/utility_wise_agents.py 22 23 24 25 26 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the optional instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _destination_agent_name = \"WiseIntelligentAgent\" return obj","title":"__new__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/agents/utility_wise_agents.py 43 44 45 46 47 48 def __repr__ ( self ): \"\"\"Return a string representation of the agent.\"\"\" return f \" { self . __class__ . __name__ } (name= { self . name } , \\ description= { self . description } , transport= { self . transport } , \\ destination_agent_name= { self . destination_agent_name } , \\ response_delivery= { self . response_delivery } \"","title":"__repr__"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.process_error","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 68 69 70 def process_error ( self , error ): \"\"\"Do nothing\"\"\" return True","title":"process_error"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.process_event","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 64 65 66 def process_event ( self , event ): \"\"\"Do nothing\"\"\" return True","title":"process_event"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.process_request","text":"Process a request message by just passing it to another agent. Source code in wiseagents/agents/utility_wise_agents.py 50 51 52 53 54 def process_request ( self , request : WiseAgentMessage , conversation_history : List [ ChatCompletionMessageParam ]) -> Optional [ str ]: \"\"\"Process a request message by just passing it to another agent.\"\"\" self . send_request ( WiseAgentMessage ( request , self . name ), self . destination_agent_name ) return None","title":"process_request"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.process_response","text":"Process a response message just sending it back to the client. Source code in wiseagents/agents/utility_wise_agents.py 56 57 58 59 60 61 62 def process_response ( self , response ): \"\"\"Process a response message just sending it back to the client.\"\"\" if self . response_delivery is not None : self . response_delivery ( response ) else : logging . debug ( f \"############################### Not sending response { response } \" ) return True","title":"process_response"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.set_response_delivery","text":"Set the function to deliver the response to the client. Parameters: response_delivery ( Callable [[], WiseAgentMessage ] ) \u2013 the function to deliver the response to the client Source code in wiseagents/agents/utility_wise_agents.py 92 93 94 95 96 97 98 99 def set_response_delivery ( self , response_delivery : Callable [[], WiseAgentMessage ]): \"\"\" Set the function to deliver the response to the client. Args: response_delivery (Callable[[], WiseAgentMessage]): the function to deliver the response to the client \"\"\" self . _response_delivery = response_delivery","title":"set_response_delivery"},{"location":"reference/wiseagents/agents/utility_wise_agents/#wiseagents.agents.utility_wise_agents.PassThroughClientAgent.stop","text":"Do nothing Source code in wiseagents/agents/utility_wise_agents.py 72 73 74 def stop ( self ): \"\"\"Do nothing\"\"\" pass","title":"stop"},{"location":"reference/wiseagents/cli/","text":"","title":"cli"},{"location":"reference/wiseagents/cli/wise_agent_cli/","text":"","title":"wise_agent_cli"},{"location":"reference/wiseagents/graphdb/","text":"Entity Bases: BaseModel An entity (node) in a knowledge graph. Attributes: id ( Optional [ str ] ) \u2013 the unique id for the entity label ( Optional [ str ] ) \u2013 an optional label for the entity metadata ( Optional [ dict ] ) \u2013 optional information about the entity Source code in wiseagents/graphdb/wise_agent_graph_db.py 10 11 12 13 14 15 16 17 18 19 20 21 class Entity ( BaseModel ): \"\"\" An entity (node) in a knowledge graph. Attributes: id (Optional[str]): the unique id for the entity label (Optional[str]): an optional label for the entity metadata (Optional[dict]): optional information about the entity \"\"\" id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) label : Optional [ str ] = \"entity\" metadata : Optional [ dict ] = Field ( default_factory = dict ) GraphDocument Bases: BaseModel A graph document is a collection of entities and relationships that are part of a knowledge graph. Attributes: entities ( List [ Entity ] ) \u2013 the entities in the graph document relationships ( List [ Relationship ] ) \u2013 the relationships in the graph document source ( Source ) \u2013 the source that contains the entities and relationships Source code in wiseagents/graphdb/wise_agent_graph_db.py 54 55 56 57 58 59 60 61 62 63 64 65 class GraphDocument ( BaseModel ): \"\"\" A graph document is a collection of entities and relationships that are part of a knowledge graph. Attributes: entities (List[Entity]): the entities in the graph document relationships (List[Relationship]): the relationships in the graph document source (Source): the source that contains the entities and relationships \"\"\" entities : List [ Entity ] relationships : List [ Relationship ] source : Source LangChainWiseAgentGraphDB Bases: WiseAgentGraphDB An abstract class that makes use of a LangChain graph database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 class LangChainWiseAgentGraphDB ( WiseAgentGraphDB ): \"\"\" An abstract class that makes use of a LangChain graph database. \"\"\" def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentGraphDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) @property def embedding_model_name ( self ): \"\"\"Get the name of the embedding model.\"\"\" return self . _embedding_model_name def convert_to_lang_chain_node ( self , entity : Entity ) -> Node : return Node ( id = entity . id , type = entity . label , properties = entity . metadata ) def convert_to_lang_chain_relationship ( self , relationship : Relationship ) -> LangChainRelationship : return LangChainRelationship ( source = self . convert_to_lang_chain_node ( relationship . source ), target = self . convert_to_lang_chain_node ( relationship . target ), type = relationship . label , properties = relationship . metadata ) def convert_to_lang_chain_graph_document ( self , graph_document : GraphDocument ) -> LangChainGraphDocument : return LangChainGraphDocument ( nodes = [ self . convert_to_lang_chain_node ( entity ) for entity in graph_document . entities ], relationships = [ self . convert_to_lang_chain_relationship ( relationship ) for relationship in graph_document . relationships ], source = self . convert_to_lang_chain_document ( graph_document . source )) def convert_to_lang_chain_document ( self , source : Source ) -> LangChainDocument : return LangChainDocument ( id = source . id , page_content = source . content , metadata = source . metadata ) @abstractmethod def get_schema ( self ) -> str : ... @abstractmethod def refresh_schema ( self ): ... @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ): ... @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): ... @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): ... @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): ... @abstractmethod def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): ... embedding_model_name property Get the name of the embedding model. __init__ ( embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME ) Initialize a new instance of LangChainWiseAgentGraphDB. Parameters: embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentGraphDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 21 22 23 24 25 26 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj Neo4jLangChainWiseAgentGraphDB Bases: LangChainWiseAgentGraphDB A LangChainWiseAgentGraphDB implementation that makes use of a LangChain Neo4j graph database and a corresponding Neo4j vector database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 class Neo4jLangChainWiseAgentGraphDB ( LangChainWiseAgentGraphDB ): \"\"\" A LangChainWiseAgentGraphDB implementation that makes use of a LangChain Neo4j graph database and a corresponding Neo4j vector database. \"\"\" yaml_tag = u '!wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _url = None obj . _refresh_graph_schema = True obj . _entity_label = \"entity\" obj . _neo4j_graph_db = None obj . _neo4j_vector_db = None return obj def __init__ ( self , properties : List [ str ], collection_name : str , url : Optional [ str ] = None , refresh_graph_schema : Optional [ bool ] = True , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME , entity_label : Optional [ str ] = \"entity\" ): \"\"\" Initialize a new instance of Neo4jLangChainWiseAgent Args: properties (List[str]): the properties to be used as text node properties for the graph database collection_name (str): the collection name to use for the vector database url (Optional[str]): the URL of the Neo4j database (the username, password, and database name to be used will be obtained from the NEO4J_USERNAME, NEO4J_PASSWORD, and NEO4J_DATABASE environment variables) refresh_graph_schema (Optional[bool]): whether to refresh the graph schema embedding_model_name (Optional[str]): the optional name of the embedding model to use entity_label (Optional[str]): the label to use for entities in the graph database \"\"\" super () . __init__ ( embedding_model_name ) self . _properties = properties self . _collection_name = collection_name self . _url = url self . _refresh_graph_schema = refresh_graph_schema self . _entity_label = entity_label self . _neo4j_graph_db = None self . _neo4j_vector_db = None def __repr__ ( self ): \"\"\"Return a string representation of the graph DB.\"\"\" return ( f \" { self . __class__ . __name__ } (properties= { self . properties } , url= { self . url } , refresh_schema= { self . refresh_graph_schema } ,\" f \"embedding_model_name= { self . embedding_model_name } , collection_name= { self . collection_name } ,\" f \"entity_label= { self . _entity_label } \" ) def __getstate__ ( self ) -> object : \"\"\"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_neo4j_graph_db' ] del state [ '_neo4j_vector_db' ] del state [ '_embedding_function' ] return state @property def properties ( self ): \"\"\"Get the properties to be used as text node properties for the graph database.\"\"\" return self . _properties @property def collection_name ( self ): \"\"\"Get the collection name to use for the vector database.\"\"\" return self . _collection_name @property def entity_label ( self ): \"\"\"Get the label to use for entities in the graph database.\"\"\" return self . _entity_label @property def url ( self ): \"\"\"Get the URL of the Neo4j database.\"\"\" return self . _url @property def refresh_graph_schema ( self ): \"\"\"Get whether to refresh the graph schema.\"\"\" return self . _refresh_graph_schema def connect ( self ): if self . _neo4j_graph_db is None : self . _neo4j_graph_db = Neo4jGraph ( url = self . url , refresh_schema = self . refresh_graph_schema ) def get_schema ( self ) -> str : self . connect () return self . _neo4j_graph_db . get_schema def refresh_schema ( self ): self . connect () self . _neo4j_graph_db . refresh_schema () def query ( self , query : str , params : Optional [ dict ] = None ): self . connect () return self . _neo4j_graph_db . query ( query = query , params = params ) def insert_entity ( self , entity : Entity , source : Source ): self . connect () self . insert_graph_documents ([ GraphDocument ( entities = [ entity ], relationships = [], source = source )]) def insert_relationship ( self , relationship : Relationship , source : Source ): self . connect () self . insert_graph_documents ([ GraphDocument ( entities = [], relationships = [ relationship ], source = source )]) def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): self . connect () self . _neo4j_graph_db . add_graph_documents ([ self . convert_to_lang_chain_graph_document ( graph_document ) for graph_document in graph_documents ]) def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): \"\"\" Create a vector database from the graph database. Args: retrieval_query (str): the retrieval query to use for the vector database \"\"\" self . connect () self . _neo4j_vector_db = Neo4jVector . from_existing_graph ( embedding = self . _embedding_function , node_label = self . entity_label , embedding_node_property = \"embedding\" , text_node_properties = self . properties , url = self . url , index_name = self . collection_name , retrieval_query = retrieval_query ) def query_with_embeddings ( self , query : str , k : int , retrieval_query : str = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Args: query (str): the query to execute k (int): the number of documents to retrieve retrieval_query (str): the retrieval query to use for the vector database params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: List[Document]: the list of documents retrieved from the vector database \"\"\" if self . _neo4j_vector_db is None : self . create_vector_db_from_graph_db ( retrieval_query = retrieval_query ) return [ Document ( content = doc . page_content , metadata = doc . metadata ) for doc in self . _neo4j_vector_db . similarity_search ( query = query , k = k , params = params if params else {}, filter = metadata_filter if metadata_filter else {})] def delete_vector_db ( self ): \"\"\" Delete the vector database that corresponds to this graph database. \"\"\" if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . delete_index () self . _neo4j_vector_db = None def close ( self ): \"\"\" Close the Neo4j driver. \"\"\" if self . _neo4j_graph_db is not None : self . _neo4j_graph_db . _driver . close () if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . _driver . close () collection_name property Get the collection name to use for the vector database. entity_label property Get the label to use for entities in the graph database. properties property Get the properties to be used as text node properties for the graph database. refresh_graph_schema property Get whether to refresh the graph schema. url property Get the URL of the Neo4j database. __getstate__ () Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 141 142 143 144 145 146 147 def __getstate__ ( self ) -> object : \"\"\"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_neo4j_graph_db' ] del state [ '_neo4j_vector_db' ] del state [ '_embedding_function' ] return state __init__ ( properties , collection_name , url = None , refresh_graph_schema = True , embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME , entity_label = 'entity' ) Initialize a new instance of Neo4jLangChainWiseAgent Parameters: properties ( List [ str ] ) \u2013 the properties to be used as text node properties for the graph database collection_name ( str ) \u2013 the collection name to use for the vector database url ( Optional [ str ] , default: None ) \u2013 the URL of the Neo4j database (the username, password, and database name to be used refresh_graph_schema ( Optional [ bool ] , default: True ) \u2013 whether to refresh the graph schema embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use entity_label ( Optional [ str ] , default: 'entity' ) \u2013 the label to use for entities in the graph database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def __init__ ( self , properties : List [ str ], collection_name : str , url : Optional [ str ] = None , refresh_graph_schema : Optional [ bool ] = True , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME , entity_label : Optional [ str ] = \"entity\" ): \"\"\" Initialize a new instance of Neo4jLangChainWiseAgent Args: properties (List[str]): the properties to be used as text node properties for the graph database collection_name (str): the collection name to use for the vector database url (Optional[str]): the URL of the Neo4j database (the username, password, and database name to be used will be obtained from the NEO4J_USERNAME, NEO4J_PASSWORD, and NEO4J_DATABASE environment variables) refresh_graph_schema (Optional[bool]): whether to refresh the graph schema embedding_model_name (Optional[str]): the optional name of the embedding model to use entity_label (Optional[str]): the label to use for entities in the graph database \"\"\" super () . __init__ ( embedding_model_name ) self . _properties = properties self . _collection_name = collection_name self . _url = url self . _refresh_graph_schema = refresh_graph_schema self . _entity_label = entity_label self . _neo4j_graph_db = None self . _neo4j_vector_db = None __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 99 100 101 102 103 104 105 106 107 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _url = None obj . _refresh_graph_schema = True obj . _entity_label = \"entity\" obj . _neo4j_graph_db = None obj . _neo4j_vector_db = None return obj __repr__ () Return a string representation of the graph DB. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 135 136 137 138 139 def __repr__ ( self ): \"\"\"Return a string representation of the graph DB.\"\"\" return ( f \" { self . __class__ . __name__ } (properties= { self . properties } , url= { self . url } , refresh_schema= { self . refresh_graph_schema } ,\" f \"embedding_model_name= { self . embedding_model_name } , collection_name= { self . collection_name } ,\" f \"entity_label= { self . _entity_label } \" ) close () Close the Neo4j driver. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 256 257 258 259 260 261 262 263 def close ( self ): \"\"\" Close the Neo4j driver. \"\"\" if self . _neo4j_graph_db is not None : self . _neo4j_graph_db . _driver . close () if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . _driver . close () create_vector_db_from_graph_db ( retrieval_query = '' ) Create a vector database from the graph database. Parameters: retrieval_query ( str , default: '' ) \u2013 the retrieval query to use for the vector database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): \"\"\" Create a vector database from the graph database. Args: retrieval_query (str): the retrieval query to use for the vector database \"\"\" self . connect () self . _neo4j_vector_db = Neo4jVector . from_existing_graph ( embedding = self . _embedding_function , node_label = self . entity_label , embedding_node_property = \"embedding\" , text_node_properties = self . properties , url = self . url , index_name = self . collection_name , retrieval_query = retrieval_query ) delete_vector_db () Delete the vector database that corresponds to this graph database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 248 249 250 251 252 253 254 def delete_vector_db ( self ): \"\"\" Delete the vector database that corresponds to this graph database. \"\"\" if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . delete_index () self . _neo4j_vector_db = None query_with_embeddings ( query , k , retrieval_query = '' , params = None , metadata_filter = None ) Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Parameters: query ( str ) \u2013 the query to execute k ( int ) \u2013 the number of documents to retrieve retrieval_query ( str , default: '' ) \u2013 the retrieval query to use for the vector database params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search Returns: List [ Document ] \u2013 List[Document]: the list of documents retrieved from the vector database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def query_with_embeddings ( self , query : str , k : int , retrieval_query : str = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Args: query (str): the query to execute k (int): the number of documents to retrieve retrieval_query (str): the retrieval query to use for the vector database params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: List[Document]: the list of documents retrieved from the vector database \"\"\" if self . _neo4j_vector_db is None : self . create_vector_db_from_graph_db ( retrieval_query = retrieval_query ) return [ Document ( content = doc . page_content , metadata = doc . metadata ) for doc in self . _neo4j_vector_db . similarity_search ( query = query , k = k , params = params if params else {}, filter = metadata_filter if metadata_filter else {})] Relationship Bases: BaseModel A relationship (edge) in a knowledge graph. Attributes: label ( str ) \u2013 a description of the relationship source ( Entity ) \u2013 the source entity target ( Entity ) \u2013 the target entity metadata ( Optional [ dict ] ) \u2013 optional information about the relationship Source code in wiseagents/graphdb/wise_agent_graph_db.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class Relationship ( BaseModel ): \"\"\" A relationship (edge) in a knowledge graph. Attributes: label (str): a description of the relationship source (Entity): the source entity target (Entity): the target entity metadata (Optional[dict]): optional information about the relationship \"\"\" label : str source : Entity target : Entity metadata : Optional [ dict ] = Field ( default_factory = dict ) Source Bases: BaseModel Information about a source from which entities and relationships have been derived from. Attributes: content ( str ) \u2013 the content of the source id ( str ) \u2013 the optional id associated with the source metadata ( Optional [ dict ] ) \u2013 optional information about the source Source code in wiseagents/graphdb/wise_agent_graph_db.py 40 41 42 43 44 45 46 47 48 49 50 51 class Source ( BaseModel ): \"\"\" Information about a source from which entities and relationships have been derived from. Attributes: content (str): the content of the source id (str): the optional id associated with the source metadata (Optional[dict]): optional information about the source \"\"\" content : str id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) metadata : Optional [ dict ] = {} WiseAgentGraphDB Bases: YAMLObject Abstract class to define the interface for a WiseAgentGraphDB. Source code in wiseagents/graphdb/wise_agent_graph_db.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 class WiseAgentGraphDB ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentGraphDB.\"\"\" yaml_tag = u '!WiseAgentGraphDB' yaml_loader = WiseAgentsLoader @abstractmethod def get_schema ( self ) -> str : \"\"\" Get the schema of the graph DB. Returns: str: the schema of the graph DB \"\"\" ... @abstractmethod def refresh_schema ( self ): \"\"\" Refresh the schema of the graph DB. \"\"\" ... @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ) -> Any : \"\"\" Query the graph DB. Args: query (str): the query to execute params (dict): the optional parameters for the query Returns: Any: the result of the query \"\"\" ... @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): \"\"\" Insert an entity into the graph DB. Args: entity (Entity): the entity to insert source (Source): information about the source from which the entity has been derived from \"\"\" ... @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): \"\"\" Insert a relationship into the graph DB. Args: relationship (Relationship): the relationship to insert source (Source): information about the source from which the relationship has been derived from \"\"\" ... @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): \"\"\" Insert a list of graph documents into the graph DB. Args: graph_documents (List[GraphDocuments]): the graph documents to insert \"\"\" ... get_schema () abstractmethod Get the schema of the graph DB. Returns: str ( str ) \u2013 the schema of the graph DB Source code in wiseagents/graphdb/wise_agent_graph_db.py 74 75 76 77 78 79 80 81 82 @abstractmethod def get_schema ( self ) -> str : \"\"\" Get the schema of the graph DB. Returns: str: the schema of the graph DB \"\"\" ... insert_entity ( entity , source ) abstractmethod Insert an entity into the graph DB. Parameters: entity ( Entity ) \u2013 the entity to insert source ( Source ) \u2013 information about the source from which the entity has been derived from Source code in wiseagents/graphdb/wise_agent_graph_db.py 106 107 108 109 110 111 112 113 114 115 116 @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): \"\"\" Insert an entity into the graph DB. Args: entity (Entity): the entity to insert source (Source): information about the source from which the entity has been derived from \"\"\" ... insert_graph_documents ( graph_documents ) abstractmethod Insert a list of graph documents into the graph DB. Parameters: graph_documents ( List [ GraphDocuments ] ) \u2013 the graph documents to insert Source code in wiseagents/graphdb/wise_agent_graph_db.py 130 131 132 133 134 135 136 137 138 139 @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): \"\"\" Insert a list of graph documents into the graph DB. Args: graph_documents (List[GraphDocuments]): the graph documents to insert \"\"\" ... insert_relationship ( relationship , source ) abstractmethod Insert a relationship into the graph DB. Parameters: relationship ( Relationship ) \u2013 the relationship to insert source ( Source ) \u2013 information about the source from which the relationship has been derived from Source code in wiseagents/graphdb/wise_agent_graph_db.py 118 119 120 121 122 123 124 125 126 127 128 @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): \"\"\" Insert a relationship into the graph DB. Args: relationship (Relationship): the relationship to insert source (Source): information about the source from which the relationship has been derived from \"\"\" ... query ( query , params = None ) abstractmethod Query the graph DB. Parameters: query ( str ) \u2013 the query to execute params ( dict , default: None ) \u2013 the optional parameters for the query Returns: Any ( Any ) \u2013 the result of the query Source code in wiseagents/graphdb/wise_agent_graph_db.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ) -> Any : \"\"\" Query the graph DB. Args: query (str): the query to execute params (dict): the optional parameters for the query Returns: Any: the result of the query \"\"\" ... refresh_schema () abstractmethod Refresh the schema of the graph DB. Source code in wiseagents/graphdb/wise_agent_graph_db.py 84 85 86 87 88 89 @abstractmethod def refresh_schema ( self ): \"\"\" Refresh the schema of the graph DB. \"\"\" ...","title":"graphdb"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Entity","text":"Bases: BaseModel An entity (node) in a knowledge graph. Attributes: id ( Optional [ str ] ) \u2013 the unique id for the entity label ( Optional [ str ] ) \u2013 an optional label for the entity metadata ( Optional [ dict ] ) \u2013 optional information about the entity Source code in wiseagents/graphdb/wise_agent_graph_db.py 10 11 12 13 14 15 16 17 18 19 20 21 class Entity ( BaseModel ): \"\"\" An entity (node) in a knowledge graph. Attributes: id (Optional[str]): the unique id for the entity label (Optional[str]): an optional label for the entity metadata (Optional[dict]): optional information about the entity \"\"\" id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) label : Optional [ str ] = \"entity\" metadata : Optional [ dict ] = Field ( default_factory = dict )","title":"Entity"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.GraphDocument","text":"Bases: BaseModel A graph document is a collection of entities and relationships that are part of a knowledge graph. Attributes: entities ( List [ Entity ] ) \u2013 the entities in the graph document relationships ( List [ Relationship ] ) \u2013 the relationships in the graph document source ( Source ) \u2013 the source that contains the entities and relationships Source code in wiseagents/graphdb/wise_agent_graph_db.py 54 55 56 57 58 59 60 61 62 63 64 65 class GraphDocument ( BaseModel ): \"\"\" A graph document is a collection of entities and relationships that are part of a knowledge graph. Attributes: entities (List[Entity]): the entities in the graph document relationships (List[Relationship]): the relationships in the graph document source (Source): the source that contains the entities and relationships \"\"\" entities : List [ Entity ] relationships : List [ Relationship ] source : Source","title":"GraphDocument"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.LangChainWiseAgentGraphDB","text":"Bases: WiseAgentGraphDB An abstract class that makes use of a LangChain graph database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 class LangChainWiseAgentGraphDB ( WiseAgentGraphDB ): \"\"\" An abstract class that makes use of a LangChain graph database. \"\"\" def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentGraphDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) @property def embedding_model_name ( self ): \"\"\"Get the name of the embedding model.\"\"\" return self . _embedding_model_name def convert_to_lang_chain_node ( self , entity : Entity ) -> Node : return Node ( id = entity . id , type = entity . label , properties = entity . metadata ) def convert_to_lang_chain_relationship ( self , relationship : Relationship ) -> LangChainRelationship : return LangChainRelationship ( source = self . convert_to_lang_chain_node ( relationship . source ), target = self . convert_to_lang_chain_node ( relationship . target ), type = relationship . label , properties = relationship . metadata ) def convert_to_lang_chain_graph_document ( self , graph_document : GraphDocument ) -> LangChainGraphDocument : return LangChainGraphDocument ( nodes = [ self . convert_to_lang_chain_node ( entity ) for entity in graph_document . entities ], relationships = [ self . convert_to_lang_chain_relationship ( relationship ) for relationship in graph_document . relationships ], source = self . convert_to_lang_chain_document ( graph_document . source )) def convert_to_lang_chain_document ( self , source : Source ) -> LangChainDocument : return LangChainDocument ( id = source . id , page_content = source . content , metadata = source . metadata ) @abstractmethod def get_schema ( self ) -> str : ... @abstractmethod def refresh_schema ( self ): ... @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ): ... @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): ... @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): ... @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): ... @abstractmethod def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): ...","title":"LangChainWiseAgentGraphDB"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.LangChainWiseAgentGraphDB.embedding_model_name","text":"Get the name of the embedding model.","title":"embedding_model_name"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.LangChainWiseAgentGraphDB.__init__","text":"Initialize a new instance of LangChainWiseAgentGraphDB. Parameters: embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentGraphDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name )","title":"__init__"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.LangChainWiseAgentGraphDB.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 21 22 23 24 25 26 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj","title":"__new__"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB","text":"Bases: LangChainWiseAgentGraphDB A LangChainWiseAgentGraphDB implementation that makes use of a LangChain Neo4j graph database and a corresponding Neo4j vector database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 class Neo4jLangChainWiseAgentGraphDB ( LangChainWiseAgentGraphDB ): \"\"\" A LangChainWiseAgentGraphDB implementation that makes use of a LangChain Neo4j graph database and a corresponding Neo4j vector database. \"\"\" yaml_tag = u '!wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _url = None obj . _refresh_graph_schema = True obj . _entity_label = \"entity\" obj . _neo4j_graph_db = None obj . _neo4j_vector_db = None return obj def __init__ ( self , properties : List [ str ], collection_name : str , url : Optional [ str ] = None , refresh_graph_schema : Optional [ bool ] = True , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME , entity_label : Optional [ str ] = \"entity\" ): \"\"\" Initialize a new instance of Neo4jLangChainWiseAgent Args: properties (List[str]): the properties to be used as text node properties for the graph database collection_name (str): the collection name to use for the vector database url (Optional[str]): the URL of the Neo4j database (the username, password, and database name to be used will be obtained from the NEO4J_USERNAME, NEO4J_PASSWORD, and NEO4J_DATABASE environment variables) refresh_graph_schema (Optional[bool]): whether to refresh the graph schema embedding_model_name (Optional[str]): the optional name of the embedding model to use entity_label (Optional[str]): the label to use for entities in the graph database \"\"\" super () . __init__ ( embedding_model_name ) self . _properties = properties self . _collection_name = collection_name self . _url = url self . _refresh_graph_schema = refresh_graph_schema self . _entity_label = entity_label self . _neo4j_graph_db = None self . _neo4j_vector_db = None def __repr__ ( self ): \"\"\"Return a string representation of the graph DB.\"\"\" return ( f \" { self . __class__ . __name__ } (properties= { self . properties } , url= { self . url } , refresh_schema= { self . refresh_graph_schema } ,\" f \"embedding_model_name= { self . embedding_model_name } , collection_name= { self . collection_name } ,\" f \"entity_label= { self . _entity_label } \" ) def __getstate__ ( self ) -> object : \"\"\"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_neo4j_graph_db' ] del state [ '_neo4j_vector_db' ] del state [ '_embedding_function' ] return state @property def properties ( self ): \"\"\"Get the properties to be used as text node properties for the graph database.\"\"\" return self . _properties @property def collection_name ( self ): \"\"\"Get the collection name to use for the vector database.\"\"\" return self . _collection_name @property def entity_label ( self ): \"\"\"Get the label to use for entities in the graph database.\"\"\" return self . _entity_label @property def url ( self ): \"\"\"Get the URL of the Neo4j database.\"\"\" return self . _url @property def refresh_graph_schema ( self ): \"\"\"Get whether to refresh the graph schema.\"\"\" return self . _refresh_graph_schema def connect ( self ): if self . _neo4j_graph_db is None : self . _neo4j_graph_db = Neo4jGraph ( url = self . url , refresh_schema = self . refresh_graph_schema ) def get_schema ( self ) -> str : self . connect () return self . _neo4j_graph_db . get_schema def refresh_schema ( self ): self . connect () self . _neo4j_graph_db . refresh_schema () def query ( self , query : str , params : Optional [ dict ] = None ): self . connect () return self . _neo4j_graph_db . query ( query = query , params = params ) def insert_entity ( self , entity : Entity , source : Source ): self . connect () self . insert_graph_documents ([ GraphDocument ( entities = [ entity ], relationships = [], source = source )]) def insert_relationship ( self , relationship : Relationship , source : Source ): self . connect () self . insert_graph_documents ([ GraphDocument ( entities = [], relationships = [ relationship ], source = source )]) def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): self . connect () self . _neo4j_graph_db . add_graph_documents ([ self . convert_to_lang_chain_graph_document ( graph_document ) for graph_document in graph_documents ]) def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): \"\"\" Create a vector database from the graph database. Args: retrieval_query (str): the retrieval query to use for the vector database \"\"\" self . connect () self . _neo4j_vector_db = Neo4jVector . from_existing_graph ( embedding = self . _embedding_function , node_label = self . entity_label , embedding_node_property = \"embedding\" , text_node_properties = self . properties , url = self . url , index_name = self . collection_name , retrieval_query = retrieval_query ) def query_with_embeddings ( self , query : str , k : int , retrieval_query : str = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Args: query (str): the query to execute k (int): the number of documents to retrieve retrieval_query (str): the retrieval query to use for the vector database params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: List[Document]: the list of documents retrieved from the vector database \"\"\" if self . _neo4j_vector_db is None : self . create_vector_db_from_graph_db ( retrieval_query = retrieval_query ) return [ Document ( content = doc . page_content , metadata = doc . metadata ) for doc in self . _neo4j_vector_db . similarity_search ( query = query , k = k , params = params if params else {}, filter = metadata_filter if metadata_filter else {})] def delete_vector_db ( self ): \"\"\" Delete the vector database that corresponds to this graph database. \"\"\" if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . delete_index () self . _neo4j_vector_db = None def close ( self ): \"\"\" Close the Neo4j driver. \"\"\" if self . _neo4j_graph_db is not None : self . _neo4j_graph_db . _driver . close () if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . _driver . close ()","title":"Neo4jLangChainWiseAgentGraphDB"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.collection_name","text":"Get the collection name to use for the vector database.","title":"collection_name"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.entity_label","text":"Get the label to use for entities in the graph database.","title":"entity_label"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.properties","text":"Get the properties to be used as text node properties for the graph database.","title":"properties"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.refresh_graph_schema","text":"Get whether to refresh the graph schema.","title":"refresh_graph_schema"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.url","text":"Get the URL of the Neo4j database.","title":"url"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.__getstate__","text":"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 141 142 143 144 145 146 147 def __getstate__ ( self ) -> object : \"\"\"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_neo4j_graph_db' ] del state [ '_neo4j_vector_db' ] del state [ '_embedding_function' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.__init__","text":"Initialize a new instance of Neo4jLangChainWiseAgent Parameters: properties ( List [ str ] ) \u2013 the properties to be used as text node properties for the graph database collection_name ( str ) \u2013 the collection name to use for the vector database url ( Optional [ str ] , default: None ) \u2013 the URL of the Neo4j database (the username, password, and database name to be used refresh_graph_schema ( Optional [ bool ] , default: True ) \u2013 whether to refresh the graph schema embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use entity_label ( Optional [ str ] , default: 'entity' ) \u2013 the label to use for entities in the graph database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def __init__ ( self , properties : List [ str ], collection_name : str , url : Optional [ str ] = None , refresh_graph_schema : Optional [ bool ] = True , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME , entity_label : Optional [ str ] = \"entity\" ): \"\"\" Initialize a new instance of Neo4jLangChainWiseAgent Args: properties (List[str]): the properties to be used as text node properties for the graph database collection_name (str): the collection name to use for the vector database url (Optional[str]): the URL of the Neo4j database (the username, password, and database name to be used will be obtained from the NEO4J_USERNAME, NEO4J_PASSWORD, and NEO4J_DATABASE environment variables) refresh_graph_schema (Optional[bool]): whether to refresh the graph schema embedding_model_name (Optional[str]): the optional name of the embedding model to use entity_label (Optional[str]): the label to use for entities in the graph database \"\"\" super () . __init__ ( embedding_model_name ) self . _properties = properties self . _collection_name = collection_name self . _url = url self . _refresh_graph_schema = refresh_graph_schema self . _entity_label = entity_label self . _neo4j_graph_db = None self . _neo4j_vector_db = None","title":"__init__"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 99 100 101 102 103 104 105 106 107 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _url = None obj . _refresh_graph_schema = True obj . _entity_label = \"entity\" obj . _neo4j_graph_db = None obj . _neo4j_vector_db = None return obj","title":"__new__"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.__repr__","text":"Return a string representation of the graph DB. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 135 136 137 138 139 def __repr__ ( self ): \"\"\"Return a string representation of the graph DB.\"\"\" return ( f \" { self . __class__ . __name__ } (properties= { self . properties } , url= { self . url } , refresh_schema= { self . refresh_graph_schema } ,\" f \"embedding_model_name= { self . embedding_model_name } , collection_name= { self . collection_name } ,\" f \"entity_label= { self . _entity_label } \" )","title":"__repr__"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.close","text":"Close the Neo4j driver. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 256 257 258 259 260 261 262 263 def close ( self ): \"\"\" Close the Neo4j driver. \"\"\" if self . _neo4j_graph_db is not None : self . _neo4j_graph_db . _driver . close () if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . _driver . close ()","title":"close"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.create_vector_db_from_graph_db","text":"Create a vector database from the graph database. Parameters: retrieval_query ( str , default: '' ) \u2013 the retrieval query to use for the vector database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): \"\"\" Create a vector database from the graph database. Args: retrieval_query (str): the retrieval query to use for the vector database \"\"\" self . connect () self . _neo4j_vector_db = Neo4jVector . from_existing_graph ( embedding = self . _embedding_function , node_label = self . entity_label , embedding_node_property = \"embedding\" , text_node_properties = self . properties , url = self . url , index_name = self . collection_name , retrieval_query = retrieval_query )","title":"create_vector_db_from_graph_db"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.delete_vector_db","text":"Delete the vector database that corresponds to this graph database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 248 249 250 251 252 253 254 def delete_vector_db ( self ): \"\"\" Delete the vector database that corresponds to this graph database. \"\"\" if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . delete_index () self . _neo4j_vector_db = None","title":"delete_vector_db"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB.query_with_embeddings","text":"Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Parameters: query ( str ) \u2013 the query to execute k ( int ) \u2013 the number of documents to retrieve retrieval_query ( str , default: '' ) \u2013 the retrieval query to use for the vector database params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search Returns: List [ Document ] \u2013 List[Document]: the list of documents retrieved from the vector database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def query_with_embeddings ( self , query : str , k : int , retrieval_query : str = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Args: query (str): the query to execute k (int): the number of documents to retrieve retrieval_query (str): the retrieval query to use for the vector database params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: List[Document]: the list of documents retrieved from the vector database \"\"\" if self . _neo4j_vector_db is None : self . create_vector_db_from_graph_db ( retrieval_query = retrieval_query ) return [ Document ( content = doc . page_content , metadata = doc . metadata ) for doc in self . _neo4j_vector_db . similarity_search ( query = query , k = k , params = params if params else {}, filter = metadata_filter if metadata_filter else {})]","title":"query_with_embeddings"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Relationship","text":"Bases: BaseModel A relationship (edge) in a knowledge graph. Attributes: label ( str ) \u2013 a description of the relationship source ( Entity ) \u2013 the source entity target ( Entity ) \u2013 the target entity metadata ( Optional [ dict ] ) \u2013 optional information about the relationship Source code in wiseagents/graphdb/wise_agent_graph_db.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class Relationship ( BaseModel ): \"\"\" A relationship (edge) in a knowledge graph. Attributes: label (str): a description of the relationship source (Entity): the source entity target (Entity): the target entity metadata (Optional[dict]): optional information about the relationship \"\"\" label : str source : Entity target : Entity metadata : Optional [ dict ] = Field ( default_factory = dict )","title":"Relationship"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.Source","text":"Bases: BaseModel Information about a source from which entities and relationships have been derived from. Attributes: content ( str ) \u2013 the content of the source id ( str ) \u2013 the optional id associated with the source metadata ( Optional [ dict ] ) \u2013 optional information about the source Source code in wiseagents/graphdb/wise_agent_graph_db.py 40 41 42 43 44 45 46 47 48 49 50 51 class Source ( BaseModel ): \"\"\" Information about a source from which entities and relationships have been derived from. Attributes: content (str): the content of the source id (str): the optional id associated with the source metadata (Optional[dict]): optional information about the source \"\"\" content : str id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) metadata : Optional [ dict ] = {}","title":"Source"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.WiseAgentGraphDB","text":"Bases: YAMLObject Abstract class to define the interface for a WiseAgentGraphDB. Source code in wiseagents/graphdb/wise_agent_graph_db.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 class WiseAgentGraphDB ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentGraphDB.\"\"\" yaml_tag = u '!WiseAgentGraphDB' yaml_loader = WiseAgentsLoader @abstractmethod def get_schema ( self ) -> str : \"\"\" Get the schema of the graph DB. Returns: str: the schema of the graph DB \"\"\" ... @abstractmethod def refresh_schema ( self ): \"\"\" Refresh the schema of the graph DB. \"\"\" ... @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ) -> Any : \"\"\" Query the graph DB. Args: query (str): the query to execute params (dict): the optional parameters for the query Returns: Any: the result of the query \"\"\" ... @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): \"\"\" Insert an entity into the graph DB. Args: entity (Entity): the entity to insert source (Source): information about the source from which the entity has been derived from \"\"\" ... @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): \"\"\" Insert a relationship into the graph DB. Args: relationship (Relationship): the relationship to insert source (Source): information about the source from which the relationship has been derived from \"\"\" ... @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): \"\"\" Insert a list of graph documents into the graph DB. Args: graph_documents (List[GraphDocuments]): the graph documents to insert \"\"\" ...","title":"WiseAgentGraphDB"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.WiseAgentGraphDB.get_schema","text":"Get the schema of the graph DB. Returns: str ( str ) \u2013 the schema of the graph DB Source code in wiseagents/graphdb/wise_agent_graph_db.py 74 75 76 77 78 79 80 81 82 @abstractmethod def get_schema ( self ) -> str : \"\"\" Get the schema of the graph DB. Returns: str: the schema of the graph DB \"\"\" ...","title":"get_schema"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.WiseAgentGraphDB.insert_entity","text":"Insert an entity into the graph DB. Parameters: entity ( Entity ) \u2013 the entity to insert source ( Source ) \u2013 information about the source from which the entity has been derived from Source code in wiseagents/graphdb/wise_agent_graph_db.py 106 107 108 109 110 111 112 113 114 115 116 @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): \"\"\" Insert an entity into the graph DB. Args: entity (Entity): the entity to insert source (Source): information about the source from which the entity has been derived from \"\"\" ...","title":"insert_entity"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.WiseAgentGraphDB.insert_graph_documents","text":"Insert a list of graph documents into the graph DB. Parameters: graph_documents ( List [ GraphDocuments ] ) \u2013 the graph documents to insert Source code in wiseagents/graphdb/wise_agent_graph_db.py 130 131 132 133 134 135 136 137 138 139 @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): \"\"\" Insert a list of graph documents into the graph DB. Args: graph_documents (List[GraphDocuments]): the graph documents to insert \"\"\" ...","title":"insert_graph_documents"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.WiseAgentGraphDB.insert_relationship","text":"Insert a relationship into the graph DB. Parameters: relationship ( Relationship ) \u2013 the relationship to insert source ( Source ) \u2013 information about the source from which the relationship has been derived from Source code in wiseagents/graphdb/wise_agent_graph_db.py 118 119 120 121 122 123 124 125 126 127 128 @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): \"\"\" Insert a relationship into the graph DB. Args: relationship (Relationship): the relationship to insert source (Source): information about the source from which the relationship has been derived from \"\"\" ...","title":"insert_relationship"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.WiseAgentGraphDB.query","text":"Query the graph DB. Parameters: query ( str ) \u2013 the query to execute params ( dict , default: None ) \u2013 the optional parameters for the query Returns: Any ( Any ) \u2013 the result of the query Source code in wiseagents/graphdb/wise_agent_graph_db.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ) -> Any : \"\"\" Query the graph DB. Args: query (str): the query to execute params (dict): the optional parameters for the query Returns: Any: the result of the query \"\"\" ...","title":"query"},{"location":"reference/wiseagents/graphdb/#wiseagents.graphdb.WiseAgentGraphDB.refresh_schema","text":"Refresh the schema of the graph DB. Source code in wiseagents/graphdb/wise_agent_graph_db.py 84 85 86 87 88 89 @abstractmethod def refresh_schema ( self ): \"\"\" Refresh the schema of the graph DB. \"\"\" ...","title":"refresh_schema"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/","text":"LangChainWiseAgentGraphDB Bases: WiseAgentGraphDB An abstract class that makes use of a LangChain graph database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 class LangChainWiseAgentGraphDB ( WiseAgentGraphDB ): \"\"\" An abstract class that makes use of a LangChain graph database. \"\"\" def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentGraphDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) @property def embedding_model_name ( self ): \"\"\"Get the name of the embedding model.\"\"\" return self . _embedding_model_name def convert_to_lang_chain_node ( self , entity : Entity ) -> Node : return Node ( id = entity . id , type = entity . label , properties = entity . metadata ) def convert_to_lang_chain_relationship ( self , relationship : Relationship ) -> LangChainRelationship : return LangChainRelationship ( source = self . convert_to_lang_chain_node ( relationship . source ), target = self . convert_to_lang_chain_node ( relationship . target ), type = relationship . label , properties = relationship . metadata ) def convert_to_lang_chain_graph_document ( self , graph_document : GraphDocument ) -> LangChainGraphDocument : return LangChainGraphDocument ( nodes = [ self . convert_to_lang_chain_node ( entity ) for entity in graph_document . entities ], relationships = [ self . convert_to_lang_chain_relationship ( relationship ) for relationship in graph_document . relationships ], source = self . convert_to_lang_chain_document ( graph_document . source )) def convert_to_lang_chain_document ( self , source : Source ) -> LangChainDocument : return LangChainDocument ( id = source . id , page_content = source . content , metadata = source . metadata ) @abstractmethod def get_schema ( self ) -> str : ... @abstractmethod def refresh_schema ( self ): ... @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ): ... @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): ... @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): ... @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): ... @abstractmethod def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): ... embedding_model_name property Get the name of the embedding model. __init__ ( embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME ) Initialize a new instance of LangChainWiseAgentGraphDB. Parameters: embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentGraphDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 21 22 23 24 25 26 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj Neo4jLangChainWiseAgentGraphDB Bases: LangChainWiseAgentGraphDB A LangChainWiseAgentGraphDB implementation that makes use of a LangChain Neo4j graph database and a corresponding Neo4j vector database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 class Neo4jLangChainWiseAgentGraphDB ( LangChainWiseAgentGraphDB ): \"\"\" A LangChainWiseAgentGraphDB implementation that makes use of a LangChain Neo4j graph database and a corresponding Neo4j vector database. \"\"\" yaml_tag = u '!wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _url = None obj . _refresh_graph_schema = True obj . _entity_label = \"entity\" obj . _neo4j_graph_db = None obj . _neo4j_vector_db = None return obj def __init__ ( self , properties : List [ str ], collection_name : str , url : Optional [ str ] = None , refresh_graph_schema : Optional [ bool ] = True , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME , entity_label : Optional [ str ] = \"entity\" ): \"\"\" Initialize a new instance of Neo4jLangChainWiseAgent Args: properties (List[str]): the properties to be used as text node properties for the graph database collection_name (str): the collection name to use for the vector database url (Optional[str]): the URL of the Neo4j database (the username, password, and database name to be used will be obtained from the NEO4J_USERNAME, NEO4J_PASSWORD, and NEO4J_DATABASE environment variables) refresh_graph_schema (Optional[bool]): whether to refresh the graph schema embedding_model_name (Optional[str]): the optional name of the embedding model to use entity_label (Optional[str]): the label to use for entities in the graph database \"\"\" super () . __init__ ( embedding_model_name ) self . _properties = properties self . _collection_name = collection_name self . _url = url self . _refresh_graph_schema = refresh_graph_schema self . _entity_label = entity_label self . _neo4j_graph_db = None self . _neo4j_vector_db = None def __repr__ ( self ): \"\"\"Return a string representation of the graph DB.\"\"\" return ( f \" { self . __class__ . __name__ } (properties= { self . properties } , url= { self . url } , refresh_schema= { self . refresh_graph_schema } ,\" f \"embedding_model_name= { self . embedding_model_name } , collection_name= { self . collection_name } ,\" f \"entity_label= { self . _entity_label } \" ) def __getstate__ ( self ) -> object : \"\"\"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_neo4j_graph_db' ] del state [ '_neo4j_vector_db' ] del state [ '_embedding_function' ] return state @property def properties ( self ): \"\"\"Get the properties to be used as text node properties for the graph database.\"\"\" return self . _properties @property def collection_name ( self ): \"\"\"Get the collection name to use for the vector database.\"\"\" return self . _collection_name @property def entity_label ( self ): \"\"\"Get the label to use for entities in the graph database.\"\"\" return self . _entity_label @property def url ( self ): \"\"\"Get the URL of the Neo4j database.\"\"\" return self . _url @property def refresh_graph_schema ( self ): \"\"\"Get whether to refresh the graph schema.\"\"\" return self . _refresh_graph_schema def connect ( self ): if self . _neo4j_graph_db is None : self . _neo4j_graph_db = Neo4jGraph ( url = self . url , refresh_schema = self . refresh_graph_schema ) def get_schema ( self ) -> str : self . connect () return self . _neo4j_graph_db . get_schema def refresh_schema ( self ): self . connect () self . _neo4j_graph_db . refresh_schema () def query ( self , query : str , params : Optional [ dict ] = None ): self . connect () return self . _neo4j_graph_db . query ( query = query , params = params ) def insert_entity ( self , entity : Entity , source : Source ): self . connect () self . insert_graph_documents ([ GraphDocument ( entities = [ entity ], relationships = [], source = source )]) def insert_relationship ( self , relationship : Relationship , source : Source ): self . connect () self . insert_graph_documents ([ GraphDocument ( entities = [], relationships = [ relationship ], source = source )]) def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): self . connect () self . _neo4j_graph_db . add_graph_documents ([ self . convert_to_lang_chain_graph_document ( graph_document ) for graph_document in graph_documents ]) def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): \"\"\" Create a vector database from the graph database. Args: retrieval_query (str): the retrieval query to use for the vector database \"\"\" self . connect () self . _neo4j_vector_db = Neo4jVector . from_existing_graph ( embedding = self . _embedding_function , node_label = self . entity_label , embedding_node_property = \"embedding\" , text_node_properties = self . properties , url = self . url , index_name = self . collection_name , retrieval_query = retrieval_query ) def query_with_embeddings ( self , query : str , k : int , retrieval_query : str = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Args: query (str): the query to execute k (int): the number of documents to retrieve retrieval_query (str): the retrieval query to use for the vector database params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: List[Document]: the list of documents retrieved from the vector database \"\"\" if self . _neo4j_vector_db is None : self . create_vector_db_from_graph_db ( retrieval_query = retrieval_query ) return [ Document ( content = doc . page_content , metadata = doc . metadata ) for doc in self . _neo4j_vector_db . similarity_search ( query = query , k = k , params = params if params else {}, filter = metadata_filter if metadata_filter else {})] def delete_vector_db ( self ): \"\"\" Delete the vector database that corresponds to this graph database. \"\"\" if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . delete_index () self . _neo4j_vector_db = None def close ( self ): \"\"\" Close the Neo4j driver. \"\"\" if self . _neo4j_graph_db is not None : self . _neo4j_graph_db . _driver . close () if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . _driver . close () collection_name property Get the collection name to use for the vector database. entity_label property Get the label to use for entities in the graph database. properties property Get the properties to be used as text node properties for the graph database. refresh_graph_schema property Get whether to refresh the graph schema. url property Get the URL of the Neo4j database. __getstate__ () Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 141 142 143 144 145 146 147 def __getstate__ ( self ) -> object : \"\"\"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_neo4j_graph_db' ] del state [ '_neo4j_vector_db' ] del state [ '_embedding_function' ] return state __init__ ( properties , collection_name , url = None , refresh_graph_schema = True , embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME , entity_label = 'entity' ) Initialize a new instance of Neo4jLangChainWiseAgent Parameters: properties ( List [ str ] ) \u2013 the properties to be used as text node properties for the graph database collection_name ( str ) \u2013 the collection name to use for the vector database url ( Optional [ str ] , default: None ) \u2013 the URL of the Neo4j database (the username, password, and database name to be used refresh_graph_schema ( Optional [ bool ] , default: True ) \u2013 whether to refresh the graph schema embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use entity_label ( Optional [ str ] , default: 'entity' ) \u2013 the label to use for entities in the graph database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def __init__ ( self , properties : List [ str ], collection_name : str , url : Optional [ str ] = None , refresh_graph_schema : Optional [ bool ] = True , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME , entity_label : Optional [ str ] = \"entity\" ): \"\"\" Initialize a new instance of Neo4jLangChainWiseAgent Args: properties (List[str]): the properties to be used as text node properties for the graph database collection_name (str): the collection name to use for the vector database url (Optional[str]): the URL of the Neo4j database (the username, password, and database name to be used will be obtained from the NEO4J_USERNAME, NEO4J_PASSWORD, and NEO4J_DATABASE environment variables) refresh_graph_schema (Optional[bool]): whether to refresh the graph schema embedding_model_name (Optional[str]): the optional name of the embedding model to use entity_label (Optional[str]): the label to use for entities in the graph database \"\"\" super () . __init__ ( embedding_model_name ) self . _properties = properties self . _collection_name = collection_name self . _url = url self . _refresh_graph_schema = refresh_graph_schema self . _entity_label = entity_label self . _neo4j_graph_db = None self . _neo4j_vector_db = None __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 99 100 101 102 103 104 105 106 107 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _url = None obj . _refresh_graph_schema = True obj . _entity_label = \"entity\" obj . _neo4j_graph_db = None obj . _neo4j_vector_db = None return obj __repr__ () Return a string representation of the graph DB. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 135 136 137 138 139 def __repr__ ( self ): \"\"\"Return a string representation of the graph DB.\"\"\" return ( f \" { self . __class__ . __name__ } (properties= { self . properties } , url= { self . url } , refresh_schema= { self . refresh_graph_schema } ,\" f \"embedding_model_name= { self . embedding_model_name } , collection_name= { self . collection_name } ,\" f \"entity_label= { self . _entity_label } \" ) close () Close the Neo4j driver. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 256 257 258 259 260 261 262 263 def close ( self ): \"\"\" Close the Neo4j driver. \"\"\" if self . _neo4j_graph_db is not None : self . _neo4j_graph_db . _driver . close () if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . _driver . close () create_vector_db_from_graph_db ( retrieval_query = '' ) Create a vector database from the graph database. Parameters: retrieval_query ( str , default: '' ) \u2013 the retrieval query to use for the vector database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): \"\"\" Create a vector database from the graph database. Args: retrieval_query (str): the retrieval query to use for the vector database \"\"\" self . connect () self . _neo4j_vector_db = Neo4jVector . from_existing_graph ( embedding = self . _embedding_function , node_label = self . entity_label , embedding_node_property = \"embedding\" , text_node_properties = self . properties , url = self . url , index_name = self . collection_name , retrieval_query = retrieval_query ) delete_vector_db () Delete the vector database that corresponds to this graph database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 248 249 250 251 252 253 254 def delete_vector_db ( self ): \"\"\" Delete the vector database that corresponds to this graph database. \"\"\" if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . delete_index () self . _neo4j_vector_db = None query_with_embeddings ( query , k , retrieval_query = '' , params = None , metadata_filter = None ) Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Parameters: query ( str ) \u2013 the query to execute k ( int ) \u2013 the number of documents to retrieve retrieval_query ( str , default: '' ) \u2013 the retrieval query to use for the vector database params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search Returns: List [ Document ] \u2013 List[Document]: the list of documents retrieved from the vector database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def query_with_embeddings ( self , query : str , k : int , retrieval_query : str = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Args: query (str): the query to execute k (int): the number of documents to retrieve retrieval_query (str): the retrieval query to use for the vector database params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: List[Document]: the list of documents retrieved from the vector database \"\"\" if self . _neo4j_vector_db is None : self . create_vector_db_from_graph_db ( retrieval_query = retrieval_query ) return [ Document ( content = doc . page_content , metadata = doc . metadata ) for doc in self . _neo4j_vector_db . similarity_search ( query = query , k = k , params = params if params else {}, filter = metadata_filter if metadata_filter else {})]","title":"lang_chain_wise_agent_graph_db"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.LangChainWiseAgentGraphDB","text":"Bases: WiseAgentGraphDB An abstract class that makes use of a LangChain graph database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 class LangChainWiseAgentGraphDB ( WiseAgentGraphDB ): \"\"\" An abstract class that makes use of a LangChain graph database. \"\"\" def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentGraphDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) @property def embedding_model_name ( self ): \"\"\"Get the name of the embedding model.\"\"\" return self . _embedding_model_name def convert_to_lang_chain_node ( self , entity : Entity ) -> Node : return Node ( id = entity . id , type = entity . label , properties = entity . metadata ) def convert_to_lang_chain_relationship ( self , relationship : Relationship ) -> LangChainRelationship : return LangChainRelationship ( source = self . convert_to_lang_chain_node ( relationship . source ), target = self . convert_to_lang_chain_node ( relationship . target ), type = relationship . label , properties = relationship . metadata ) def convert_to_lang_chain_graph_document ( self , graph_document : GraphDocument ) -> LangChainGraphDocument : return LangChainGraphDocument ( nodes = [ self . convert_to_lang_chain_node ( entity ) for entity in graph_document . entities ], relationships = [ self . convert_to_lang_chain_relationship ( relationship ) for relationship in graph_document . relationships ], source = self . convert_to_lang_chain_document ( graph_document . source )) def convert_to_lang_chain_document ( self , source : Source ) -> LangChainDocument : return LangChainDocument ( id = source . id , page_content = source . content , metadata = source . metadata ) @abstractmethod def get_schema ( self ) -> str : ... @abstractmethod def refresh_schema ( self ): ... @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ): ... @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): ... @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): ... @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): ... @abstractmethod def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): ...","title":"LangChainWiseAgentGraphDB"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.LangChainWiseAgentGraphDB.embedding_model_name","text":"Get the name of the embedding model.","title":"embedding_model_name"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.LangChainWiseAgentGraphDB.__init__","text":"Initialize a new instance of LangChainWiseAgentGraphDB. Parameters: embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 28 29 30 31 32 33 34 35 36 37 def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentGraphDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name )","title":"__init__"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.LangChainWiseAgentGraphDB.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 21 22 23 24 25 26 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj","title":"__new__"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB","text":"Bases: LangChainWiseAgentGraphDB A LangChainWiseAgentGraphDB implementation that makes use of a LangChain Neo4j graph database and a corresponding Neo4j vector database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 class Neo4jLangChainWiseAgentGraphDB ( LangChainWiseAgentGraphDB ): \"\"\" A LangChainWiseAgentGraphDB implementation that makes use of a LangChain Neo4j graph database and a corresponding Neo4j vector database. \"\"\" yaml_tag = u '!wiseagents.graphdb.Neo4jLangChainWiseAgentGraphDB' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _url = None obj . _refresh_graph_schema = True obj . _entity_label = \"entity\" obj . _neo4j_graph_db = None obj . _neo4j_vector_db = None return obj def __init__ ( self , properties : List [ str ], collection_name : str , url : Optional [ str ] = None , refresh_graph_schema : Optional [ bool ] = True , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME , entity_label : Optional [ str ] = \"entity\" ): \"\"\" Initialize a new instance of Neo4jLangChainWiseAgent Args: properties (List[str]): the properties to be used as text node properties for the graph database collection_name (str): the collection name to use for the vector database url (Optional[str]): the URL of the Neo4j database (the username, password, and database name to be used will be obtained from the NEO4J_USERNAME, NEO4J_PASSWORD, and NEO4J_DATABASE environment variables) refresh_graph_schema (Optional[bool]): whether to refresh the graph schema embedding_model_name (Optional[str]): the optional name of the embedding model to use entity_label (Optional[str]): the label to use for entities in the graph database \"\"\" super () . __init__ ( embedding_model_name ) self . _properties = properties self . _collection_name = collection_name self . _url = url self . _refresh_graph_schema = refresh_graph_schema self . _entity_label = entity_label self . _neo4j_graph_db = None self . _neo4j_vector_db = None def __repr__ ( self ): \"\"\"Return a string representation of the graph DB.\"\"\" return ( f \" { self . __class__ . __name__ } (properties= { self . properties } , url= { self . url } , refresh_schema= { self . refresh_graph_schema } ,\" f \"embedding_model_name= { self . embedding_model_name } , collection_name= { self . collection_name } ,\" f \"entity_label= { self . _entity_label } \" ) def __getstate__ ( self ) -> object : \"\"\"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_neo4j_graph_db' ] del state [ '_neo4j_vector_db' ] del state [ '_embedding_function' ] return state @property def properties ( self ): \"\"\"Get the properties to be used as text node properties for the graph database.\"\"\" return self . _properties @property def collection_name ( self ): \"\"\"Get the collection name to use for the vector database.\"\"\" return self . _collection_name @property def entity_label ( self ): \"\"\"Get the label to use for entities in the graph database.\"\"\" return self . _entity_label @property def url ( self ): \"\"\"Get the URL of the Neo4j database.\"\"\" return self . _url @property def refresh_graph_schema ( self ): \"\"\"Get whether to refresh the graph schema.\"\"\" return self . _refresh_graph_schema def connect ( self ): if self . _neo4j_graph_db is None : self . _neo4j_graph_db = Neo4jGraph ( url = self . url , refresh_schema = self . refresh_graph_schema ) def get_schema ( self ) -> str : self . connect () return self . _neo4j_graph_db . get_schema def refresh_schema ( self ): self . connect () self . _neo4j_graph_db . refresh_schema () def query ( self , query : str , params : Optional [ dict ] = None ): self . connect () return self . _neo4j_graph_db . query ( query = query , params = params ) def insert_entity ( self , entity : Entity , source : Source ): self . connect () self . insert_graph_documents ([ GraphDocument ( entities = [ entity ], relationships = [], source = source )]) def insert_relationship ( self , relationship : Relationship , source : Source ): self . connect () self . insert_graph_documents ([ GraphDocument ( entities = [], relationships = [ relationship ], source = source )]) def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): self . connect () self . _neo4j_graph_db . add_graph_documents ([ self . convert_to_lang_chain_graph_document ( graph_document ) for graph_document in graph_documents ]) def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): \"\"\" Create a vector database from the graph database. Args: retrieval_query (str): the retrieval query to use for the vector database \"\"\" self . connect () self . _neo4j_vector_db = Neo4jVector . from_existing_graph ( embedding = self . _embedding_function , node_label = self . entity_label , embedding_node_property = \"embedding\" , text_node_properties = self . properties , url = self . url , index_name = self . collection_name , retrieval_query = retrieval_query ) def query_with_embeddings ( self , query : str , k : int , retrieval_query : str = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Args: query (str): the query to execute k (int): the number of documents to retrieve retrieval_query (str): the retrieval query to use for the vector database params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: List[Document]: the list of documents retrieved from the vector database \"\"\" if self . _neo4j_vector_db is None : self . create_vector_db_from_graph_db ( retrieval_query = retrieval_query ) return [ Document ( content = doc . page_content , metadata = doc . metadata ) for doc in self . _neo4j_vector_db . similarity_search ( query = query , k = k , params = params if params else {}, filter = metadata_filter if metadata_filter else {})] def delete_vector_db ( self ): \"\"\" Delete the vector database that corresponds to this graph database. \"\"\" if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . delete_index () self . _neo4j_vector_db = None def close ( self ): \"\"\" Close the Neo4j driver. \"\"\" if self . _neo4j_graph_db is not None : self . _neo4j_graph_db . _driver . close () if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . _driver . close ()","title":"Neo4jLangChainWiseAgentGraphDB"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.collection_name","text":"Get the collection name to use for the vector database.","title":"collection_name"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.entity_label","text":"Get the label to use for entities in the graph database.","title":"entity_label"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.properties","text":"Get the properties to be used as text node properties for the graph database.","title":"properties"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.refresh_graph_schema","text":"Get whether to refresh the graph schema.","title":"refresh_graph_schema"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.url","text":"Get the URL of the Neo4j database.","title":"url"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.__getstate__","text":"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 141 142 143 144 145 146 147 def __getstate__ ( self ) -> object : \"\"\"Return the state of the graph DB. Removing the instance variable neo4j_graph_db to avoid it being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_neo4j_graph_db' ] del state [ '_neo4j_vector_db' ] del state [ '_embedding_function' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.__init__","text":"Initialize a new instance of Neo4jLangChainWiseAgent Parameters: properties ( List [ str ] ) \u2013 the properties to be used as text node properties for the graph database collection_name ( str ) \u2013 the collection name to use for the vector database url ( Optional [ str ] , default: None ) \u2013 the URL of the Neo4j database (the username, password, and database name to be used refresh_graph_schema ( Optional [ bool ] , default: True ) \u2013 whether to refresh the graph schema embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use entity_label ( Optional [ str ] , default: 'entity' ) \u2013 the label to use for entities in the graph database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def __init__ ( self , properties : List [ str ], collection_name : str , url : Optional [ str ] = None , refresh_graph_schema : Optional [ bool ] = True , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME , entity_label : Optional [ str ] = \"entity\" ): \"\"\" Initialize a new instance of Neo4jLangChainWiseAgent Args: properties (List[str]): the properties to be used as text node properties for the graph database collection_name (str): the collection name to use for the vector database url (Optional[str]): the URL of the Neo4j database (the username, password, and database name to be used will be obtained from the NEO4J_USERNAME, NEO4J_PASSWORD, and NEO4J_DATABASE environment variables) refresh_graph_schema (Optional[bool]): whether to refresh the graph schema embedding_model_name (Optional[str]): the optional name of the embedding model to use entity_label (Optional[str]): the label to use for entities in the graph database \"\"\" super () . __init__ ( embedding_model_name ) self . _properties = properties self . _collection_name = collection_name self . _url = url self . _refresh_graph_schema = refresh_graph_schema self . _entity_label = entity_label self . _neo4j_graph_db = None self . _neo4j_vector_db = None","title":"__init__"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 99 100 101 102 103 104 105 106 107 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _url = None obj . _refresh_graph_schema = True obj . _entity_label = \"entity\" obj . _neo4j_graph_db = None obj . _neo4j_vector_db = None return obj","title":"__new__"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.__repr__","text":"Return a string representation of the graph DB. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 135 136 137 138 139 def __repr__ ( self ): \"\"\"Return a string representation of the graph DB.\"\"\" return ( f \" { self . __class__ . __name__ } (properties= { self . properties } , url= { self . url } , refresh_schema= { self . refresh_graph_schema } ,\" f \"embedding_model_name= { self . embedding_model_name } , collection_name= { self . collection_name } ,\" f \"entity_label= { self . _entity_label } \" )","title":"__repr__"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.close","text":"Close the Neo4j driver. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 256 257 258 259 260 261 262 263 def close ( self ): \"\"\" Close the Neo4j driver. \"\"\" if self . _neo4j_graph_db is not None : self . _neo4j_graph_db . _driver . close () if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . _driver . close ()","title":"close"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.create_vector_db_from_graph_db","text":"Create a vector database from the graph database. Parameters: retrieval_query ( str , default: '' ) \u2013 the retrieval query to use for the vector database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 def create_vector_db_from_graph_db ( self , retrieval_query : str = \"\" ): \"\"\" Create a vector database from the graph database. Args: retrieval_query (str): the retrieval query to use for the vector database \"\"\" self . connect () self . _neo4j_vector_db = Neo4jVector . from_existing_graph ( embedding = self . _embedding_function , node_label = self . entity_label , embedding_node_property = \"embedding\" , text_node_properties = self . properties , url = self . url , index_name = self . collection_name , retrieval_query = retrieval_query )","title":"create_vector_db_from_graph_db"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.delete_vector_db","text":"Delete the vector database that corresponds to this graph database. Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 248 249 250 251 252 253 254 def delete_vector_db ( self ): \"\"\" Delete the vector database that corresponds to this graph database. \"\"\" if self . _neo4j_vector_db is not None : self . _neo4j_vector_db . delete_index () self . _neo4j_vector_db = None","title":"delete_vector_db"},{"location":"reference/wiseagents/graphdb/lang_chain_wise_agent_graph_db/#wiseagents.graphdb.lang_chain_wise_agent_graph_db.Neo4jLangChainWiseAgentGraphDB.query_with_embeddings","text":"Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Parameters: query ( str ) \u2013 the query to execute k ( int ) \u2013 the number of documents to retrieve retrieval_query ( str , default: '' ) \u2013 the retrieval query to use for the vector database params ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional parameters for the query metadata_filter ( Optional [ Dict [ str , Any ]] , default: None ) \u2013 the optional metadata filter to use with similarity search Returns: List [ Document ] \u2013 List[Document]: the list of documents retrieved from the vector database Source code in wiseagents/graphdb/lang_chain_wise_agent_graph_db.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 def query_with_embeddings ( self , query : str , k : int , retrieval_query : str = \"\" , params : Optional [ Dict [ str , Any ]] = None , metadata_filter : Optional [ Dict [ str , Any ]] = None ) -> List [ Document ]: \"\"\" Query the vector database that corresponds to this graph database using the given query and retrieve the top k documents. Args: query (str): the query to execute k (int): the number of documents to retrieve retrieval_query (str): the retrieval query to use for the vector database params (Optional[Dict[str, Any]]): the optional parameters for the query metadata_filter (Optional[Dict[str, Any]]): the optional metadata filter to use with similarity search Returns: List[Document]: the list of documents retrieved from the vector database \"\"\" if self . _neo4j_vector_db is None : self . create_vector_db_from_graph_db ( retrieval_query = retrieval_query ) return [ Document ( content = doc . page_content , metadata = doc . metadata ) for doc in self . _neo4j_vector_db . similarity_search ( query = query , k = k , params = params if params else {}, filter = metadata_filter if metadata_filter else {})]","title":"query_with_embeddings"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/","text":"Entity Bases: BaseModel An entity (node) in a knowledge graph. Attributes: id ( Optional [ str ] ) \u2013 the unique id for the entity label ( Optional [ str ] ) \u2013 an optional label for the entity metadata ( Optional [ dict ] ) \u2013 optional information about the entity Source code in wiseagents/graphdb/wise_agent_graph_db.py 10 11 12 13 14 15 16 17 18 19 20 21 class Entity ( BaseModel ): \"\"\" An entity (node) in a knowledge graph. Attributes: id (Optional[str]): the unique id for the entity label (Optional[str]): an optional label for the entity metadata (Optional[dict]): optional information about the entity \"\"\" id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) label : Optional [ str ] = \"entity\" metadata : Optional [ dict ] = Field ( default_factory = dict ) GraphDocument Bases: BaseModel A graph document is a collection of entities and relationships that are part of a knowledge graph. Attributes: entities ( List [ Entity ] ) \u2013 the entities in the graph document relationships ( List [ Relationship ] ) \u2013 the relationships in the graph document source ( Source ) \u2013 the source that contains the entities and relationships Source code in wiseagents/graphdb/wise_agent_graph_db.py 54 55 56 57 58 59 60 61 62 63 64 65 class GraphDocument ( BaseModel ): \"\"\" A graph document is a collection of entities and relationships that are part of a knowledge graph. Attributes: entities (List[Entity]): the entities in the graph document relationships (List[Relationship]): the relationships in the graph document source (Source): the source that contains the entities and relationships \"\"\" entities : List [ Entity ] relationships : List [ Relationship ] source : Source Relationship Bases: BaseModel A relationship (edge) in a knowledge graph. Attributes: label ( str ) \u2013 a description of the relationship source ( Entity ) \u2013 the source entity target ( Entity ) \u2013 the target entity metadata ( Optional [ dict ] ) \u2013 optional information about the relationship Source code in wiseagents/graphdb/wise_agent_graph_db.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class Relationship ( BaseModel ): \"\"\" A relationship (edge) in a knowledge graph. Attributes: label (str): a description of the relationship source (Entity): the source entity target (Entity): the target entity metadata (Optional[dict]): optional information about the relationship \"\"\" label : str source : Entity target : Entity metadata : Optional [ dict ] = Field ( default_factory = dict ) Source Bases: BaseModel Information about a source from which entities and relationships have been derived from. Attributes: content ( str ) \u2013 the content of the source id ( str ) \u2013 the optional id associated with the source metadata ( Optional [ dict ] ) \u2013 optional information about the source Source code in wiseagents/graphdb/wise_agent_graph_db.py 40 41 42 43 44 45 46 47 48 49 50 51 class Source ( BaseModel ): \"\"\" Information about a source from which entities and relationships have been derived from. Attributes: content (str): the content of the source id (str): the optional id associated with the source metadata (Optional[dict]): optional information about the source \"\"\" content : str id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) metadata : Optional [ dict ] = {} WiseAgentGraphDB Bases: YAMLObject Abstract class to define the interface for a WiseAgentGraphDB. Source code in wiseagents/graphdb/wise_agent_graph_db.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 class WiseAgentGraphDB ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentGraphDB.\"\"\" yaml_tag = u '!WiseAgentGraphDB' yaml_loader = WiseAgentsLoader @abstractmethod def get_schema ( self ) -> str : \"\"\" Get the schema of the graph DB. Returns: str: the schema of the graph DB \"\"\" ... @abstractmethod def refresh_schema ( self ): \"\"\" Refresh the schema of the graph DB. \"\"\" ... @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ) -> Any : \"\"\" Query the graph DB. Args: query (str): the query to execute params (dict): the optional parameters for the query Returns: Any: the result of the query \"\"\" ... @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): \"\"\" Insert an entity into the graph DB. Args: entity (Entity): the entity to insert source (Source): information about the source from which the entity has been derived from \"\"\" ... @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): \"\"\" Insert a relationship into the graph DB. Args: relationship (Relationship): the relationship to insert source (Source): information about the source from which the relationship has been derived from \"\"\" ... @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): \"\"\" Insert a list of graph documents into the graph DB. Args: graph_documents (List[GraphDocuments]): the graph documents to insert \"\"\" ... get_schema () abstractmethod Get the schema of the graph DB. Returns: str ( str ) \u2013 the schema of the graph DB Source code in wiseagents/graphdb/wise_agent_graph_db.py 74 75 76 77 78 79 80 81 82 @abstractmethod def get_schema ( self ) -> str : \"\"\" Get the schema of the graph DB. Returns: str: the schema of the graph DB \"\"\" ... insert_entity ( entity , source ) abstractmethod Insert an entity into the graph DB. Parameters: entity ( Entity ) \u2013 the entity to insert source ( Source ) \u2013 information about the source from which the entity has been derived from Source code in wiseagents/graphdb/wise_agent_graph_db.py 106 107 108 109 110 111 112 113 114 115 116 @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): \"\"\" Insert an entity into the graph DB. Args: entity (Entity): the entity to insert source (Source): information about the source from which the entity has been derived from \"\"\" ... insert_graph_documents ( graph_documents ) abstractmethod Insert a list of graph documents into the graph DB. Parameters: graph_documents ( List [ GraphDocuments ] ) \u2013 the graph documents to insert Source code in wiseagents/graphdb/wise_agent_graph_db.py 130 131 132 133 134 135 136 137 138 139 @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): \"\"\" Insert a list of graph documents into the graph DB. Args: graph_documents (List[GraphDocuments]): the graph documents to insert \"\"\" ... insert_relationship ( relationship , source ) abstractmethod Insert a relationship into the graph DB. Parameters: relationship ( Relationship ) \u2013 the relationship to insert source ( Source ) \u2013 information about the source from which the relationship has been derived from Source code in wiseagents/graphdb/wise_agent_graph_db.py 118 119 120 121 122 123 124 125 126 127 128 @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): \"\"\" Insert a relationship into the graph DB. Args: relationship (Relationship): the relationship to insert source (Source): information about the source from which the relationship has been derived from \"\"\" ... query ( query , params = None ) abstractmethod Query the graph DB. Parameters: query ( str ) \u2013 the query to execute params ( dict , default: None ) \u2013 the optional parameters for the query Returns: Any ( Any ) \u2013 the result of the query Source code in wiseagents/graphdb/wise_agent_graph_db.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ) -> Any : \"\"\" Query the graph DB. Args: query (str): the query to execute params (dict): the optional parameters for the query Returns: Any: the result of the query \"\"\" ... refresh_schema () abstractmethod Refresh the schema of the graph DB. Source code in wiseagents/graphdb/wise_agent_graph_db.py 84 85 86 87 88 89 @abstractmethod def refresh_schema ( self ): \"\"\" Refresh the schema of the graph DB. \"\"\" ...","title":"wise_agent_graph_db"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.Entity","text":"Bases: BaseModel An entity (node) in a knowledge graph. Attributes: id ( Optional [ str ] ) \u2013 the unique id for the entity label ( Optional [ str ] ) \u2013 an optional label for the entity metadata ( Optional [ dict ] ) \u2013 optional information about the entity Source code in wiseagents/graphdb/wise_agent_graph_db.py 10 11 12 13 14 15 16 17 18 19 20 21 class Entity ( BaseModel ): \"\"\" An entity (node) in a knowledge graph. Attributes: id (Optional[str]): the unique id for the entity label (Optional[str]): an optional label for the entity metadata (Optional[dict]): optional information about the entity \"\"\" id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) label : Optional [ str ] = \"entity\" metadata : Optional [ dict ] = Field ( default_factory = dict )","title":"Entity"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.GraphDocument","text":"Bases: BaseModel A graph document is a collection of entities and relationships that are part of a knowledge graph. Attributes: entities ( List [ Entity ] ) \u2013 the entities in the graph document relationships ( List [ Relationship ] ) \u2013 the relationships in the graph document source ( Source ) \u2013 the source that contains the entities and relationships Source code in wiseagents/graphdb/wise_agent_graph_db.py 54 55 56 57 58 59 60 61 62 63 64 65 class GraphDocument ( BaseModel ): \"\"\" A graph document is a collection of entities and relationships that are part of a knowledge graph. Attributes: entities (List[Entity]): the entities in the graph document relationships (List[Relationship]): the relationships in the graph document source (Source): the source that contains the entities and relationships \"\"\" entities : List [ Entity ] relationships : List [ Relationship ] source : Source","title":"GraphDocument"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.Relationship","text":"Bases: BaseModel A relationship (edge) in a knowledge graph. Attributes: label ( str ) \u2013 a description of the relationship source ( Entity ) \u2013 the source entity target ( Entity ) \u2013 the target entity metadata ( Optional [ dict ] ) \u2013 optional information about the relationship Source code in wiseagents/graphdb/wise_agent_graph_db.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class Relationship ( BaseModel ): \"\"\" A relationship (edge) in a knowledge graph. Attributes: label (str): a description of the relationship source (Entity): the source entity target (Entity): the target entity metadata (Optional[dict]): optional information about the relationship \"\"\" label : str source : Entity target : Entity metadata : Optional [ dict ] = Field ( default_factory = dict )","title":"Relationship"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.Source","text":"Bases: BaseModel Information about a source from which entities and relationships have been derived from. Attributes: content ( str ) \u2013 the content of the source id ( str ) \u2013 the optional id associated with the source metadata ( Optional [ dict ] ) \u2013 optional information about the source Source code in wiseagents/graphdb/wise_agent_graph_db.py 40 41 42 43 44 45 46 47 48 49 50 51 class Source ( BaseModel ): \"\"\" Information about a source from which entities and relationships have been derived from. Attributes: content (str): the content of the source id (str): the optional id associated with the source metadata (Optional[dict]): optional information about the source \"\"\" content : str id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) metadata : Optional [ dict ] = {}","title":"Source"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.WiseAgentGraphDB","text":"Bases: YAMLObject Abstract class to define the interface for a WiseAgentGraphDB. Source code in wiseagents/graphdb/wise_agent_graph_db.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 class WiseAgentGraphDB ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentGraphDB.\"\"\" yaml_tag = u '!WiseAgentGraphDB' yaml_loader = WiseAgentsLoader @abstractmethod def get_schema ( self ) -> str : \"\"\" Get the schema of the graph DB. Returns: str: the schema of the graph DB \"\"\" ... @abstractmethod def refresh_schema ( self ): \"\"\" Refresh the schema of the graph DB. \"\"\" ... @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ) -> Any : \"\"\" Query the graph DB. Args: query (str): the query to execute params (dict): the optional parameters for the query Returns: Any: the result of the query \"\"\" ... @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): \"\"\" Insert an entity into the graph DB. Args: entity (Entity): the entity to insert source (Source): information about the source from which the entity has been derived from \"\"\" ... @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): \"\"\" Insert a relationship into the graph DB. Args: relationship (Relationship): the relationship to insert source (Source): information about the source from which the relationship has been derived from \"\"\" ... @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): \"\"\" Insert a list of graph documents into the graph DB. Args: graph_documents (List[GraphDocuments]): the graph documents to insert \"\"\" ...","title":"WiseAgentGraphDB"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.WiseAgentGraphDB.get_schema","text":"Get the schema of the graph DB. Returns: str ( str ) \u2013 the schema of the graph DB Source code in wiseagents/graphdb/wise_agent_graph_db.py 74 75 76 77 78 79 80 81 82 @abstractmethod def get_schema ( self ) -> str : \"\"\" Get the schema of the graph DB. Returns: str: the schema of the graph DB \"\"\" ...","title":"get_schema"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.WiseAgentGraphDB.insert_entity","text":"Insert an entity into the graph DB. Parameters: entity ( Entity ) \u2013 the entity to insert source ( Source ) \u2013 information about the source from which the entity has been derived from Source code in wiseagents/graphdb/wise_agent_graph_db.py 106 107 108 109 110 111 112 113 114 115 116 @abstractmethod def insert_entity ( self , entity : Entity , source : Source ): \"\"\" Insert an entity into the graph DB. Args: entity (Entity): the entity to insert source (Source): information about the source from which the entity has been derived from \"\"\" ...","title":"insert_entity"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.WiseAgentGraphDB.insert_graph_documents","text":"Insert a list of graph documents into the graph DB. Parameters: graph_documents ( List [ GraphDocuments ] ) \u2013 the graph documents to insert Source code in wiseagents/graphdb/wise_agent_graph_db.py 130 131 132 133 134 135 136 137 138 139 @abstractmethod def insert_graph_documents ( self , graph_documents : List [ GraphDocument ]): \"\"\" Insert a list of graph documents into the graph DB. Args: graph_documents (List[GraphDocuments]): the graph documents to insert \"\"\" ...","title":"insert_graph_documents"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.WiseAgentGraphDB.insert_relationship","text":"Insert a relationship into the graph DB. Parameters: relationship ( Relationship ) \u2013 the relationship to insert source ( Source ) \u2013 information about the source from which the relationship has been derived from Source code in wiseagents/graphdb/wise_agent_graph_db.py 118 119 120 121 122 123 124 125 126 127 128 @abstractmethod def insert_relationship ( self , relationship : Relationship , source : Source ): \"\"\" Insert a relationship into the graph DB. Args: relationship (Relationship): the relationship to insert source (Source): information about the source from which the relationship has been derived from \"\"\" ...","title":"insert_relationship"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.WiseAgentGraphDB.query","text":"Query the graph DB. Parameters: query ( str ) \u2013 the query to execute params ( dict , default: None ) \u2013 the optional parameters for the query Returns: Any ( Any ) \u2013 the result of the query Source code in wiseagents/graphdb/wise_agent_graph_db.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @abstractmethod def query ( self , query : str , params : Optional [ dict ] = None ) -> Any : \"\"\" Query the graph DB. Args: query (str): the query to execute params (dict): the optional parameters for the query Returns: Any: the result of the query \"\"\" ...","title":"query"},{"location":"reference/wiseagents/graphdb/wise_agent_graph_db/#wiseagents.graphdb.wise_agent_graph_db.WiseAgentGraphDB.refresh_schema","text":"Refresh the schema of the graph DB. Source code in wiseagents/graphdb/wise_agent_graph_db.py 84 85 86 87 88 89 @abstractmethod def refresh_schema ( self ): \"\"\" Refresh the schema of the graph DB. \"\"\" ...","title":"refresh_schema"},{"location":"reference/wiseagents/llm/","text":"OpenaiAPIWiseAgentLLM Bases: WiseAgentRemoteLLM A class to define a WiseAgentLLM that uses the OpenAI API. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 class OpenaiAPIWiseAgentLLM ( WiseAgentRemoteLLM ): '''A class to define a WiseAgentLLM that uses the OpenAI API.''' client = None yaml_tag = u '!wiseagents.llm.OpenaiAPIWiseAgentLLM' def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _api_key = \"sk-no-key-required\" obj . _remote_address = \"http://localhost:8001/v1\" obj . chain = None return obj def __init__ ( self , system_message , model_name , remote_address = \"http://localhost:8001/v1\" , api_key : Optional [ str ] = \"sk-no-key-required\" ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name remote_address (str): the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key (str): the API key. Default is \"sk-no-key-required\"''' super () . __init__ ( system_message , model_name , remote_address ) self . _api_key = api_key self . chain = None def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } ,\" f \"remote_address= { self . remote_address } , api_key= { self . api_key } )\" ) def __getstate__ ( self ) -> object : '''Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () if 'client' in state . keys (): del state [ 'client' ] return state def connect ( self ): '''Connect to the remote machine.''' self . client = openai . OpenAI ( base_url = self . remote_address , api_key = self . api_key ) def process_single_prompt ( self , prompt ): '''Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () messages = [] messages . append ({ \"role\" : \"system\" , \"content\" : self . system_message }) messages . append ({ \"role\" : \"user\" , \"content\" : prompt }) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , #tools=tools, tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response . choices [ 0 ] . message def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () #messages = [] #messages.append({\"role\": \"system\", \"content\": self.system_message}) #messages.append({\"role\": \"user\", \"content\": message}) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , tools = tools , tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response @property def api_key ( self ): '''Get the API key.''' return self . _api_key api_key property Get the API key. __getstate__ () Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 43 44 45 46 47 48 def __getstate__ ( self ) -> object : '''Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () if 'client' in state . keys (): del state [ 'client' ] return state __init__ ( system_message , model_name , remote_address = 'http://localhost:8001/v1' , api_key = 'sk-no-key-required' ) Initialize the agent. Parameters: system_message ( str ) \u2013 the system message model_name ( str ) \u2013 the model name remote_address ( str , default: 'http://localhost:8001/v1' ) \u2013 the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key ( str , default: 'sk-no-key-required' ) \u2013 the API key. Default is \"sk-no-key-required\" Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( self , system_message , model_name , remote_address = \"http://localhost:8001/v1\" , api_key : Optional [ str ] = \"sk-no-key-required\" ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name remote_address (str): the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key (str): the API key. Default is \"sk-no-key-required\"''' super () . __init__ ( system_message , model_name , remote_address ) self . _api_key = api_key self . chain = None __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 16 17 18 19 20 21 22 def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _api_key = \"sk-no-key-required\" obj . _remote_address = \"http://localhost:8001/v1\" obj . chain = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 38 39 40 41 def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } ,\" f \"remote_address= { self . remote_address } , api_key= { self . api_key } )\" ) connect () Connect to the remote machine. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 50 51 52 53 def connect ( self ): '''Connect to the remote machine.''' self . client = openai . OpenAI ( base_url = self . remote_address , api_key = self . api_key ) process_chat_completion ( messages , tools ) Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () #messages = [] #messages.append({\"role\": \"system\", \"content\": self.system_message}) #messages.append({\"role\": \"user\", \"content\": message}) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , tools = tools , tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response process_single_prompt ( prompt ) Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def process_single_prompt ( self , prompt ): '''Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () messages = [] messages . append ({ \"role\" : \"system\" , \"content\" : self . system_message }) messages . append ({ \"role\" : \"user\" , \"content\" : prompt }) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , #tools=tools, tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response . choices [ 0 ] . message WiseAgentLLM Bases: YAMLObject Abstract class to define the interface for a WiseAgentLLM. Source code in wiseagents/llm/wise_agent_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 class WiseAgentLLM ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentLLM.\"\"\" yaml_tag = u '!WiseAgentLLM' yaml_loader = WiseAgentsLoader def __init__ ( self , system_message , model_name ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name ''' super () . __init__ () self . _system_message = system_message self . _model_name = model_name def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } )\" @property def system_message ( self ): '''Get the system message.''' return self . _system_message @property def model_name ( self ): '''Get the model name.''' return self . _model_name @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ... @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ... model_name property Get the model name. system_message property Get the system message. __init__ ( system_message , model_name ) Initialize the agent. Parameters: system_message ( str ) \u2013 the system message model_name ( str ) \u2013 the model name Source code in wiseagents/llm/wise_agent_LLM.py 13 14 15 16 17 18 19 20 21 22 def __init__ ( self , system_message , model_name ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name ''' super () . __init__ () self . _system_message = system_message self . _model_name = model_name __repr__ () Return a string representation of the agent. Source code in wiseagents/llm/wise_agent_LLM.py 24 25 26 def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } )\" process_chat_completion ( messages , tools ) abstractmethod Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/wise_agent_LLM.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ... process_single_prompt ( prompt ) abstractmethod Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/wise_agent_LLM.py 38 39 40 41 42 43 44 45 46 @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ... WiseAgentRemoteLLM Bases: WiseAgentLLM Extend WiseAgentLLM to support remote execution of WiseAgentLLM on a remote machine. Source code in wiseagents/llm/wise_agent_remote_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class WiseAgentRemoteLLM ( WiseAgentLLM ): \"\"\"Extend WiseAgentLLM to support remote execution of WiseAgentLLM on a remote machine.\"\"\" yaml_tag = u '!WiseAgentRemoteLLM' def __init__ ( self , system_message , model_name , remote_address ): super () . __init__ ( system_message , model_name ) self . _remote_address = remote_address def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } , remote_address= { self . remote_address } )\" @property def remote_address ( self ): '''Get the remote address.''' return self . _remote_address @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ... @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ... remote_address property Get the remote address. __repr__ () Return a string representation of the agent. Source code in wiseagents/llm/wise_agent_remote_LLM.py 17 18 19 def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } , remote_address= { self . remote_address } )\" process_chat_completion ( messages , tools ) abstractmethod Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/wise_agent_remote_LLM.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ... process_single_prompt ( prompt ) abstractmethod Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/wise_agent_remote_LLM.py 26 27 28 29 30 31 32 33 34 @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ...","title":"llm"},{"location":"reference/wiseagents/llm/#wiseagents.llm.OpenaiAPIWiseAgentLLM","text":"Bases: WiseAgentRemoteLLM A class to define a WiseAgentLLM that uses the OpenAI API. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 class OpenaiAPIWiseAgentLLM ( WiseAgentRemoteLLM ): '''A class to define a WiseAgentLLM that uses the OpenAI API.''' client = None yaml_tag = u '!wiseagents.llm.OpenaiAPIWiseAgentLLM' def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _api_key = \"sk-no-key-required\" obj . _remote_address = \"http://localhost:8001/v1\" obj . chain = None return obj def __init__ ( self , system_message , model_name , remote_address = \"http://localhost:8001/v1\" , api_key : Optional [ str ] = \"sk-no-key-required\" ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name remote_address (str): the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key (str): the API key. Default is \"sk-no-key-required\"''' super () . __init__ ( system_message , model_name , remote_address ) self . _api_key = api_key self . chain = None def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } ,\" f \"remote_address= { self . remote_address } , api_key= { self . api_key } )\" ) def __getstate__ ( self ) -> object : '''Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () if 'client' in state . keys (): del state [ 'client' ] return state def connect ( self ): '''Connect to the remote machine.''' self . client = openai . OpenAI ( base_url = self . remote_address , api_key = self . api_key ) def process_single_prompt ( self , prompt ): '''Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () messages = [] messages . append ({ \"role\" : \"system\" , \"content\" : self . system_message }) messages . append ({ \"role\" : \"user\" , \"content\" : prompt }) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , #tools=tools, tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response . choices [ 0 ] . message def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () #messages = [] #messages.append({\"role\": \"system\", \"content\": self.system_message}) #messages.append({\"role\": \"user\", \"content\": message}) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , tools = tools , tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response @property def api_key ( self ): '''Get the API key.''' return self . _api_key","title":"OpenaiAPIWiseAgentLLM"},{"location":"reference/wiseagents/llm/#wiseagents.llm.OpenaiAPIWiseAgentLLM.api_key","text":"Get the API key.","title":"api_key"},{"location":"reference/wiseagents/llm/#wiseagents.llm.OpenaiAPIWiseAgentLLM.__getstate__","text":"Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 43 44 45 46 47 48 def __getstate__ ( self ) -> object : '''Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () if 'client' in state . keys (): del state [ 'client' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/llm/#wiseagents.llm.OpenaiAPIWiseAgentLLM.__init__","text":"Initialize the agent. Parameters: system_message ( str ) \u2013 the system message model_name ( str ) \u2013 the model name remote_address ( str , default: 'http://localhost:8001/v1' ) \u2013 the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key ( str , default: 'sk-no-key-required' ) \u2013 the API key. Default is \"sk-no-key-required\" Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( self , system_message , model_name , remote_address = \"http://localhost:8001/v1\" , api_key : Optional [ str ] = \"sk-no-key-required\" ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name remote_address (str): the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key (str): the API key. Default is \"sk-no-key-required\"''' super () . __init__ ( system_message , model_name , remote_address ) self . _api_key = api_key self . chain = None","title":"__init__"},{"location":"reference/wiseagents/llm/#wiseagents.llm.OpenaiAPIWiseAgentLLM.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 16 17 18 19 20 21 22 def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _api_key = \"sk-no-key-required\" obj . _remote_address = \"http://localhost:8001/v1\" obj . chain = None return obj","title":"__new__"},{"location":"reference/wiseagents/llm/#wiseagents.llm.OpenaiAPIWiseAgentLLM.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 38 39 40 41 def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } ,\" f \"remote_address= { self . remote_address } , api_key= { self . api_key } )\" )","title":"__repr__"},{"location":"reference/wiseagents/llm/#wiseagents.llm.OpenaiAPIWiseAgentLLM.connect","text":"Connect to the remote machine. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 50 51 52 53 def connect ( self ): '''Connect to the remote machine.''' self . client = openai . OpenAI ( base_url = self . remote_address , api_key = self . api_key )","title":"connect"},{"location":"reference/wiseagents/llm/#wiseagents.llm.OpenaiAPIWiseAgentLLM.process_chat_completion","text":"Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () #messages = [] #messages.append({\"role\": \"system\", \"content\": self.system_message}) #messages.append({\"role\": \"user\", \"content\": message}) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , tools = tools , tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response","title":"process_chat_completion"},{"location":"reference/wiseagents/llm/#wiseagents.llm.OpenaiAPIWiseAgentLLM.process_single_prompt","text":"Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def process_single_prompt ( self , prompt ): '''Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () messages = [] messages . append ({ \"role\" : \"system\" , \"content\" : self . system_message }) messages . append ({ \"role\" : \"user\" , \"content\" : prompt }) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , #tools=tools, tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response . choices [ 0 ] . message","title":"process_single_prompt"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentLLM","text":"Bases: YAMLObject Abstract class to define the interface for a WiseAgentLLM. Source code in wiseagents/llm/wise_agent_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 class WiseAgentLLM ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentLLM.\"\"\" yaml_tag = u '!WiseAgentLLM' yaml_loader = WiseAgentsLoader def __init__ ( self , system_message , model_name ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name ''' super () . __init__ () self . _system_message = system_message self . _model_name = model_name def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } )\" @property def system_message ( self ): '''Get the system message.''' return self . _system_message @property def model_name ( self ): '''Get the model name.''' return self . _model_name @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ... @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ...","title":"WiseAgentLLM"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentLLM.model_name","text":"Get the model name.","title":"model_name"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentLLM.system_message","text":"Get the system message.","title":"system_message"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentLLM.__init__","text":"Initialize the agent. Parameters: system_message ( str ) \u2013 the system message model_name ( str ) \u2013 the model name Source code in wiseagents/llm/wise_agent_LLM.py 13 14 15 16 17 18 19 20 21 22 def __init__ ( self , system_message , model_name ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name ''' super () . __init__ () self . _system_message = system_message self . _model_name = model_name","title":"__init__"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentLLM.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/llm/wise_agent_LLM.py 24 25 26 def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } )\"","title":"__repr__"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentLLM.process_chat_completion","text":"Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/wise_agent_LLM.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ...","title":"process_chat_completion"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentLLM.process_single_prompt","text":"Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/wise_agent_LLM.py 38 39 40 41 42 43 44 45 46 @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ...","title":"process_single_prompt"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentRemoteLLM","text":"Bases: WiseAgentLLM Extend WiseAgentLLM to support remote execution of WiseAgentLLM on a remote machine. Source code in wiseagents/llm/wise_agent_remote_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class WiseAgentRemoteLLM ( WiseAgentLLM ): \"\"\"Extend WiseAgentLLM to support remote execution of WiseAgentLLM on a remote machine.\"\"\" yaml_tag = u '!WiseAgentRemoteLLM' def __init__ ( self , system_message , model_name , remote_address ): super () . __init__ ( system_message , model_name ) self . _remote_address = remote_address def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } , remote_address= { self . remote_address } )\" @property def remote_address ( self ): '''Get the remote address.''' return self . _remote_address @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ... @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ...","title":"WiseAgentRemoteLLM"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentRemoteLLM.remote_address","text":"Get the remote address.","title":"remote_address"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentRemoteLLM.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/llm/wise_agent_remote_LLM.py 17 18 19 def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } , remote_address= { self . remote_address } )\"","title":"__repr__"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentRemoteLLM.process_chat_completion","text":"Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/wise_agent_remote_LLM.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ...","title":"process_chat_completion"},{"location":"reference/wiseagents/llm/#wiseagents.llm.WiseAgentRemoteLLM.process_single_prompt","text":"Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/wise_agent_remote_LLM.py 26 27 28 29 30 31 32 33 34 @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ...","title":"process_single_prompt"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/","text":"OpenaiAPIWiseAgentLLM Bases: WiseAgentRemoteLLM A class to define a WiseAgentLLM that uses the OpenAI API. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 class OpenaiAPIWiseAgentLLM ( WiseAgentRemoteLLM ): '''A class to define a WiseAgentLLM that uses the OpenAI API.''' client = None yaml_tag = u '!wiseagents.llm.OpenaiAPIWiseAgentLLM' def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _api_key = \"sk-no-key-required\" obj . _remote_address = \"http://localhost:8001/v1\" obj . chain = None return obj def __init__ ( self , system_message , model_name , remote_address = \"http://localhost:8001/v1\" , api_key : Optional [ str ] = \"sk-no-key-required\" ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name remote_address (str): the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key (str): the API key. Default is \"sk-no-key-required\"''' super () . __init__ ( system_message , model_name , remote_address ) self . _api_key = api_key self . chain = None def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } ,\" f \"remote_address= { self . remote_address } , api_key= { self . api_key } )\" ) def __getstate__ ( self ) -> object : '''Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () if 'client' in state . keys (): del state [ 'client' ] return state def connect ( self ): '''Connect to the remote machine.''' self . client = openai . OpenAI ( base_url = self . remote_address , api_key = self . api_key ) def process_single_prompt ( self , prompt ): '''Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () messages = [] messages . append ({ \"role\" : \"system\" , \"content\" : self . system_message }) messages . append ({ \"role\" : \"user\" , \"content\" : prompt }) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , #tools=tools, tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response . choices [ 0 ] . message def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () #messages = [] #messages.append({\"role\": \"system\", \"content\": self.system_message}) #messages.append({\"role\": \"user\", \"content\": message}) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , tools = tools , tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response @property def api_key ( self ): '''Get the API key.''' return self . _api_key api_key property Get the API key. __getstate__ () Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 43 44 45 46 47 48 def __getstate__ ( self ) -> object : '''Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () if 'client' in state . keys (): del state [ 'client' ] return state __init__ ( system_message , model_name , remote_address = 'http://localhost:8001/v1' , api_key = 'sk-no-key-required' ) Initialize the agent. Parameters: system_message ( str ) \u2013 the system message model_name ( str ) \u2013 the model name remote_address ( str , default: 'http://localhost:8001/v1' ) \u2013 the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key ( str , default: 'sk-no-key-required' ) \u2013 the API key. Default is \"sk-no-key-required\" Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( self , system_message , model_name , remote_address = \"http://localhost:8001/v1\" , api_key : Optional [ str ] = \"sk-no-key-required\" ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name remote_address (str): the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key (str): the API key. Default is \"sk-no-key-required\"''' super () . __init__ ( system_message , model_name , remote_address ) self . _api_key = api_key self . chain = None __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 16 17 18 19 20 21 22 def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _api_key = \"sk-no-key-required\" obj . _remote_address = \"http://localhost:8001/v1\" obj . chain = None return obj __repr__ () Return a string representation of the agent. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 38 39 40 41 def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } ,\" f \"remote_address= { self . remote_address } , api_key= { self . api_key } )\" ) connect () Connect to the remote machine. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 50 51 52 53 def connect ( self ): '''Connect to the remote machine.''' self . client = openai . OpenAI ( base_url = self . remote_address , api_key = self . api_key ) process_chat_completion ( messages , tools ) Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () #messages = [] #messages.append({\"role\": \"system\", \"content\": self.system_message}) #messages.append({\"role\": \"user\", \"content\": message}) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , tools = tools , tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response process_single_prompt ( prompt ) Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def process_single_prompt ( self , prompt ): '''Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () messages = [] messages . append ({ \"role\" : \"system\" , \"content\" : self . system_message }) messages . append ({ \"role\" : \"user\" , \"content\" : prompt }) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , #tools=tools, tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response . choices [ 0 ] . message","title":"openai_API_wise_agent_LLM"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/#wiseagents.llm.openai_API_wise_agent_LLM.OpenaiAPIWiseAgentLLM","text":"Bases: WiseAgentRemoteLLM A class to define a WiseAgentLLM that uses the OpenAI API. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 class OpenaiAPIWiseAgentLLM ( WiseAgentRemoteLLM ): '''A class to define a WiseAgentLLM that uses the OpenAI API.''' client = None yaml_tag = u '!wiseagents.llm.OpenaiAPIWiseAgentLLM' def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _api_key = \"sk-no-key-required\" obj . _remote_address = \"http://localhost:8001/v1\" obj . chain = None return obj def __init__ ( self , system_message , model_name , remote_address = \"http://localhost:8001/v1\" , api_key : Optional [ str ] = \"sk-no-key-required\" ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name remote_address (str): the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key (str): the API key. Default is \"sk-no-key-required\"''' super () . __init__ ( system_message , model_name , remote_address ) self . _api_key = api_key self . chain = None def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } ,\" f \"remote_address= { self . remote_address } , api_key= { self . api_key } )\" ) def __getstate__ ( self ) -> object : '''Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () if 'client' in state . keys (): del state [ 'client' ] return state def connect ( self ): '''Connect to the remote machine.''' self . client = openai . OpenAI ( base_url = self . remote_address , api_key = self . api_key ) def process_single_prompt ( self , prompt ): '''Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () messages = [] messages . append ({ \"role\" : \"system\" , \"content\" : self . system_message }) messages . append ({ \"role\" : \"user\" , \"content\" : prompt }) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , #tools=tools, tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response . choices [ 0 ] . message def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () #messages = [] #messages.append({\"role\": \"system\", \"content\": self.system_message}) #messages.append({\"role\": \"user\", \"content\": message}) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , tools = tools , tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response @property def api_key ( self ): '''Get the API key.''' return self . _api_key","title":"OpenaiAPIWiseAgentLLM"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/#wiseagents.llm.openai_API_wise_agent_LLM.OpenaiAPIWiseAgentLLM.api_key","text":"Get the API key.","title":"api_key"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/#wiseagents.llm.openai_API_wise_agent_LLM.OpenaiAPIWiseAgentLLM.__getstate__","text":"Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 43 44 45 46 47 48 def __getstate__ ( self ) -> object : '''Return the state of the agent. Removing the instance variable client to avoid it is serialized/deserialized by pyyaml.''' state = self . __dict__ . copy () if 'client' in state . keys (): del state [ 'client' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/#wiseagents.llm.openai_API_wise_agent_LLM.OpenaiAPIWiseAgentLLM.__init__","text":"Initialize the agent. Parameters: system_message ( str ) \u2013 the system message model_name ( str ) \u2013 the model name remote_address ( str , default: 'http://localhost:8001/v1' ) \u2013 the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key ( str , default: 'sk-no-key-required' ) \u2013 the API key. Default is \"sk-no-key-required\" Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( self , system_message , model_name , remote_address = \"http://localhost:8001/v1\" , api_key : Optional [ str ] = \"sk-no-key-required\" ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name remote_address (str): the remote address of the agent. Default is \"http://localhost:8001/v1\" api_key (str): the API key. Default is \"sk-no-key-required\"''' super () . __init__ ( system_message , model_name , remote_address ) self . _api_key = api_key self . chain = None","title":"__init__"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/#wiseagents.llm.openai_API_wise_agent_LLM.OpenaiAPIWiseAgentLLM.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 16 17 18 19 20 21 22 def __new__ ( cls , * args , ** kwargs ): '''Create a new instance of the class, setting default values for the instance variables.''' obj = super () . __new__ ( cls ) obj . _api_key = \"sk-no-key-required\" obj . _remote_address = \"http://localhost:8001/v1\" obj . chain = None return obj","title":"__new__"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/#wiseagents.llm.openai_API_wise_agent_LLM.OpenaiAPIWiseAgentLLM.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 38 39 40 41 def __repr__ ( self ): '''Return a string representation of the agent.''' return ( f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } ,\" f \"remote_address= { self . remote_address } , api_key= { self . api_key } )\" )","title":"__repr__"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/#wiseagents.llm.openai_API_wise_agent_LLM.OpenaiAPIWiseAgentLLM.connect","text":"Connect to the remote machine. Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 50 51 52 53 def connect ( self ): '''Connect to the remote machine.''' self . client = openai . OpenAI ( base_url = self . remote_address , api_key = self . api_key )","title":"connect"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/#wiseagents.llm.openai_API_wise_agent_LLM.OpenaiAPIWiseAgentLLM.process_chat_completion","text":"Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method is implemented from superclass WiseAgentLLM. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () #messages = [] #messages.append({\"role\": \"system\", \"content\": self.system_message}) #messages.append({\"role\": \"user\", \"content\": message}) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , tools = tools , tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response","title":"process_chat_completion"},{"location":"reference/wiseagents/llm/openai_API_wise_agent_LLM/#wiseagents.llm.openai_API_wise_agent_LLM.OpenaiAPIWiseAgentLLM.process_single_prompt","text":"Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/openai_API_wise_agent_LLM.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def process_single_prompt ( self , prompt ): '''Process a single prompt. This method is implemented from superclass WiseAgentLLM. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' print ( f \"Executing WiseAgentLLM on remote machine at { self . remote_address } \" ) if ( self . client is None ): self . connect () messages = [] messages . append ({ \"role\" : \"system\" , \"content\" : self . system_message }) messages . append ({ \"role\" : \"user\" , \"content\" : prompt }) response = self . client . chat . completions . create ( messages = messages , model = self . model_name , #tools=tools, tool_choice = \"auto\" , # auto is default, but we'll be explicit ) return response . choices [ 0 ] . message","title":"process_single_prompt"},{"location":"reference/wiseagents/llm/wise_agent_LLM/","text":"WiseAgentLLM Bases: YAMLObject Abstract class to define the interface for a WiseAgentLLM. Source code in wiseagents/llm/wise_agent_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 class WiseAgentLLM ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentLLM.\"\"\" yaml_tag = u '!WiseAgentLLM' yaml_loader = WiseAgentsLoader def __init__ ( self , system_message , model_name ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name ''' super () . __init__ () self . _system_message = system_message self . _model_name = model_name def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } )\" @property def system_message ( self ): '''Get the system message.''' return self . _system_message @property def model_name ( self ): '''Get the model name.''' return self . _model_name @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ... @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ... model_name property Get the model name. system_message property Get the system message. __init__ ( system_message , model_name ) Initialize the agent. Parameters: system_message ( str ) \u2013 the system message model_name ( str ) \u2013 the model name Source code in wiseagents/llm/wise_agent_LLM.py 13 14 15 16 17 18 19 20 21 22 def __init__ ( self , system_message , model_name ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name ''' super () . __init__ () self . _system_message = system_message self . _model_name = model_name __repr__ () Return a string representation of the agent. Source code in wiseagents/llm/wise_agent_LLM.py 24 25 26 def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } )\" process_chat_completion ( messages , tools ) abstractmethod Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/wise_agent_LLM.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ... process_single_prompt ( prompt ) abstractmethod Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/wise_agent_LLM.py 38 39 40 41 42 43 44 45 46 @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ...","title":"wise_agent_LLM"},{"location":"reference/wiseagents/llm/wise_agent_LLM/#wiseagents.llm.wise_agent_LLM.WiseAgentLLM","text":"Bases: YAMLObject Abstract class to define the interface for a WiseAgentLLM. Source code in wiseagents/llm/wise_agent_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 class WiseAgentLLM ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentLLM.\"\"\" yaml_tag = u '!WiseAgentLLM' yaml_loader = WiseAgentsLoader def __init__ ( self , system_message , model_name ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name ''' super () . __init__ () self . _system_message = system_message self . _model_name = model_name def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } )\" @property def system_message ( self ): '''Get the system message.''' return self . _system_message @property def model_name ( self ): '''Get the model name.''' return self . _model_name @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ... @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ...","title":"WiseAgentLLM"},{"location":"reference/wiseagents/llm/wise_agent_LLM/#wiseagents.llm.wise_agent_LLM.WiseAgentLLM.model_name","text":"Get the model name.","title":"model_name"},{"location":"reference/wiseagents/llm/wise_agent_LLM/#wiseagents.llm.wise_agent_LLM.WiseAgentLLM.system_message","text":"Get the system message.","title":"system_message"},{"location":"reference/wiseagents/llm/wise_agent_LLM/#wiseagents.llm.wise_agent_LLM.WiseAgentLLM.__init__","text":"Initialize the agent. Parameters: system_message ( str ) \u2013 the system message model_name ( str ) \u2013 the model name Source code in wiseagents/llm/wise_agent_LLM.py 13 14 15 16 17 18 19 20 21 22 def __init__ ( self , system_message , model_name ): '''Initialize the agent. Args: system_message (str): the system message model_name (str): the model name ''' super () . __init__ () self . _system_message = system_message self . _model_name = model_name","title":"__init__"},{"location":"reference/wiseagents/llm/wise_agent_LLM/#wiseagents.llm.wise_agent_LLM.WiseAgentLLM.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/llm/wise_agent_LLM.py 24 25 26 def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } )\"","title":"__repr__"},{"location":"reference/wiseagents/llm/wise_agent_LLM/#wiseagents.llm.wise_agent_LLM.WiseAgentLLM.process_chat_completion","text":"Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/wise_agent_LLM.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ...","title":"process_chat_completion"},{"location":"reference/wiseagents/llm/wise_agent_LLM/#wiseagents.llm.wise_agent_LLM.WiseAgentLLM.process_single_prompt","text":"Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/wise_agent_LLM.py 38 39 40 41 42 43 44 45 46 @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ...","title":"process_single_prompt"},{"location":"reference/wiseagents/llm/wise_agent_remote_LLM/","text":"WiseAgentRemoteLLM Bases: WiseAgentLLM Extend WiseAgentLLM to support remote execution of WiseAgentLLM on a remote machine. Source code in wiseagents/llm/wise_agent_remote_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class WiseAgentRemoteLLM ( WiseAgentLLM ): \"\"\"Extend WiseAgentLLM to support remote execution of WiseAgentLLM on a remote machine.\"\"\" yaml_tag = u '!WiseAgentRemoteLLM' def __init__ ( self , system_message , model_name , remote_address ): super () . __init__ ( system_message , model_name ) self . _remote_address = remote_address def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } , remote_address= { self . remote_address } )\" @property def remote_address ( self ): '''Get the remote address.''' return self . _remote_address @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ... @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ... remote_address property Get the remote address. __repr__ () Return a string representation of the agent. Source code in wiseagents/llm/wise_agent_remote_LLM.py 17 18 19 def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } , remote_address= { self . remote_address } )\" process_chat_completion ( messages , tools ) abstractmethod Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/wise_agent_remote_LLM.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ... process_single_prompt ( prompt ) abstractmethod Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/wise_agent_remote_LLM.py 26 27 28 29 30 31 32 33 34 @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ...","title":"wise_agent_remote_LLM"},{"location":"reference/wiseagents/llm/wise_agent_remote_LLM/#wiseagents.llm.wise_agent_remote_LLM.WiseAgentRemoteLLM","text":"Bases: WiseAgentLLM Extend WiseAgentLLM to support remote execution of WiseAgentLLM on a remote machine. Source code in wiseagents/llm/wise_agent_remote_LLM.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class WiseAgentRemoteLLM ( WiseAgentLLM ): \"\"\"Extend WiseAgentLLM to support remote execution of WiseAgentLLM on a remote machine.\"\"\" yaml_tag = u '!WiseAgentRemoteLLM' def __init__ ( self , system_message , model_name , remote_address ): super () . __init__ ( system_message , model_name ) self . _remote_address = remote_address def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } , remote_address= { self . remote_address } )\" @property def remote_address ( self ): '''Get the remote address.''' return self . _remote_address @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ... @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ...","title":"WiseAgentRemoteLLM"},{"location":"reference/wiseagents/llm/wise_agent_remote_LLM/#wiseagents.llm.wise_agent_remote_LLM.WiseAgentRemoteLLM.remote_address","text":"Get the remote address.","title":"remote_address"},{"location":"reference/wiseagents/llm/wise_agent_remote_LLM/#wiseagents.llm.wise_agent_remote_LLM.WiseAgentRemoteLLM.__repr__","text":"Return a string representation of the agent. Source code in wiseagents/llm/wise_agent_remote_LLM.py 17 18 19 def __repr__ ( self ): '''Return a string representation of the agent.''' return f \" { self . __class__ . __name__ } (system_message= { self . system_message } , model_name= { self . model_name } , remote_address= { self . remote_address } )\"","title":"__repr__"},{"location":"reference/wiseagents/llm/wise_agent_remote_LLM/#wiseagents.llm.wise_agent_remote_LLM.WiseAgentRemoteLLM.process_chat_completion","text":"Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Parameters: messages ( Iterable [ ChatCompletionMessageParam ] ) \u2013 the messages to process tools ( Iterable [ ChatCompletionToolParam ] ) \u2013 the tools to use Returns: ChatCompletion ( ChatCompletion ) \u2013 the chat completion result Source code in wiseagents/llm/wise_agent_remote_LLM.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @abstractmethod def process_chat_completion ( self , messages : Iterable [ ChatCompletionMessageParam ], tools : Iterable [ ChatCompletionToolParam ]) -> ChatCompletion : '''Process a chat completion. This method should be implemented by subclasses. The context and state is passed in input and returned as part of the output. Deal with the messages and tools is responsibility of the caller. Args: messages (Iterable[ChatCompletionMessageParam]): the messages to process tools (Iterable[ChatCompletionToolParam]): the tools to use Returns: ChatCompletion: the chat completion result''' ...","title":"process_chat_completion"},{"location":"reference/wiseagents/llm/wise_agent_remote_LLM/#wiseagents.llm.wise_agent_remote_LLM.WiseAgentRemoteLLM.process_single_prompt","text":"Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Parameters: prompt ( str ) \u2013 the prompt to process Source code in wiseagents/llm/wise_agent_remote_LLM.py 26 27 28 29 30 31 32 33 34 @abstractmethod def process_single_prompt ( self , prompt ): '''Process a single prompt. This method should be implemented by subclasses. The single prompt is processed and the result is returned, all the context and state is maintained locally in the method Args: prompt (str): the prompt to process''' ...","title":"process_single_prompt"},{"location":"reference/wiseagents/transports/","text":"StompWiseAgentTransport Bases: WiseAgentTransport A transport for sending messages between agents using the STOMP protocol. Source code in wiseagents/transports/stomp.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 class StompWiseAgentTransport ( WiseAgentTransport ): '''A transport for sending messages between agents using the STOMP protocol.''' yaml_tag = u '!wiseagents.transports.StompWiseAgentTransport' request_conn : stomp . Connection = None response_conn : stomp . Connection = None def __init__ ( self , host : str , port : int , agent_name : str ): '''Initialize the transport. Args: host (str): the host port (int): the port agent_name (str): the agent name''' self . _host = host self . _port = port self . _agent_name = agent_name def __repr__ ( self ) -> str : return f \"host= { self . _host } , port= { self . _port } , agent_name= { self . _agent_name } \" def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = super () . __getstate__ () del state [ 'request_conn' ] del state [ 'response_conn' ] return state def start ( self ): ''' Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set''' if ( self . request_conn is not None and self . request_conn . is_connected ()) and ( self . response_conn is not None and self . response_conn . is_connected ()): return hosts = [( self . host , self . port )] self . request_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . request_conn . set_listener ( 'WiseAgentRequestTopicListener' , WiseAgentRequestQueueListener ( self )) self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . request_conn . subscribe ( destination = self . request_queue , id = id ( self ), ack = 'auto' ) self . response_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . response_conn . set_listener ( 'WiseAgentResponseQueueListener' , WiseAgentResponseQueueListener ( self )) self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . response_conn . subscribe ( destination = self . response_queue , id = id ( self ) + 1 , ack = 'auto' ) def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () if self . request_conn . is_connected () == False : self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) if self . response_conn . is_connected () == False : self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) request_destination = '/queue/request/' + dest_agent_name logging . debug ( f \"Sending request { message } to { request_destination } \" ) self . request_conn . send ( body = yaml . dump ( message ), destination = request_destination ) def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a response message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () response_destination = '/queue/response/' + dest_agent_name self . response_conn . send ( body = yaml . dump ( message ), destination = response_destination ) def stop ( self ): '''Stop the transport.''' if self . request_conn is not None and self . request_conn . is_connected (): #unsubscribe from the request topic self . request_conn . unsubscribe ( destination = self . request_queue , id = id ( self )) # Disconnect request from the STOMP server self . request_conn . disconnect () if self . response_conn is not None and self . response_conn . is_connected (): #unsubscribe from the response queue self . response_conn . unsubscribe ( destination = self . response_queue , id = id ( self ) + 1 ) # Disconnect response from the STOMP server self . response_conn . disconnect () @property def host ( self ) -> str : '''Get the host.''' return self . _host @property def port ( self ) -> int : '''Get the port.''' return self . _port @property def agent_name ( self ) -> str : '''Get the agent name.''' return self . _agent_name @property def request_queue ( self ) -> str : '''Get the request queue.''' return '/queue/request/' + self . agent_name @property def response_queue ( self ) -> str : '''Get the response queue.''' return '/queue/response/' + self . agent_name agent_name : str property Get the agent name. host : str property Get the host. port : int property Get the port. request_queue : str property Get the request queue. response_queue : str property Get the response queue. __getstate__ () Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/transports/stomp.py 73 74 75 76 77 78 def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = super () . __getstate__ () del state [ 'request_conn' ] del state [ 'response_conn' ] return state __init__ ( host , port , agent_name ) Initialize the transport. Parameters: host ( str ) \u2013 the host port ( int ) \u2013 the port agent_name ( str ) \u2013 the agent name Source code in wiseagents/transports/stomp.py 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , host : str , port : int , agent_name : str ): '''Initialize the transport. Args: host (str): the host port (int): the port agent_name (str): the agent name''' self . _host = host self . _port = port self . _agent_name = agent_name send_request ( message , dest_agent_name ) Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the destination agent name Source code in wiseagents/transports/stomp.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () if self . request_conn . is_connected () == False : self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) if self . response_conn . is_connected () == False : self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) request_destination = '/queue/request/' + dest_agent_name logging . debug ( f \"Sending request { message } to { request_destination } \" ) self . request_conn . send ( body = yaml . dump ( message ), destination = request_destination ) send_response ( message , dest_agent_name ) Send a response message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the destination agent name Source code in wiseagents/transports/stomp.py 118 119 120 121 122 123 124 125 126 127 128 def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a response message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () response_destination = '/queue/response/' + dest_agent_name self . response_conn . send ( body = yaml . dump ( message ), destination = response_destination ) start () Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set Source code in wiseagents/transports/stomp.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def start ( self ): ''' Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set''' if ( self . request_conn is not None and self . request_conn . is_connected ()) and ( self . response_conn is not None and self . response_conn . is_connected ()): return hosts = [( self . host , self . port )] self . request_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . request_conn . set_listener ( 'WiseAgentRequestTopicListener' , WiseAgentRequestQueueListener ( self )) self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . request_conn . subscribe ( destination = self . request_queue , id = id ( self ), ack = 'auto' ) self . response_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . response_conn . set_listener ( 'WiseAgentResponseQueueListener' , WiseAgentResponseQueueListener ( self )) self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . response_conn . subscribe ( destination = self . response_queue , id = id ( self ) + 1 , ack = 'auto' ) stop () Stop the transport. Source code in wiseagents/transports/stomp.py 130 131 132 133 134 135 136 137 138 139 140 141 def stop ( self ): '''Stop the transport.''' if self . request_conn is not None and self . request_conn . is_connected (): #unsubscribe from the request topic self . request_conn . unsubscribe ( destination = self . request_queue , id = id ( self )) # Disconnect request from the STOMP server self . request_conn . disconnect () if self . response_conn is not None and self . response_conn . is_connected (): #unsubscribe from the response queue self . response_conn . unsubscribe ( destination = self . response_queue , id = id ( self ) + 1 ) # Disconnect response from the STOMP server self . response_conn . disconnect ()","title":"transports"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport","text":"Bases: WiseAgentTransport A transport for sending messages between agents using the STOMP protocol. Source code in wiseagents/transports/stomp.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 class StompWiseAgentTransport ( WiseAgentTransport ): '''A transport for sending messages between agents using the STOMP protocol.''' yaml_tag = u '!wiseagents.transports.StompWiseAgentTransport' request_conn : stomp . Connection = None response_conn : stomp . Connection = None def __init__ ( self , host : str , port : int , agent_name : str ): '''Initialize the transport. Args: host (str): the host port (int): the port agent_name (str): the agent name''' self . _host = host self . _port = port self . _agent_name = agent_name def __repr__ ( self ) -> str : return f \"host= { self . _host } , port= { self . _port } , agent_name= { self . _agent_name } \" def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = super () . __getstate__ () del state [ 'request_conn' ] del state [ 'response_conn' ] return state def start ( self ): ''' Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set''' if ( self . request_conn is not None and self . request_conn . is_connected ()) and ( self . response_conn is not None and self . response_conn . is_connected ()): return hosts = [( self . host , self . port )] self . request_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . request_conn . set_listener ( 'WiseAgentRequestTopicListener' , WiseAgentRequestQueueListener ( self )) self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . request_conn . subscribe ( destination = self . request_queue , id = id ( self ), ack = 'auto' ) self . response_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . response_conn . set_listener ( 'WiseAgentResponseQueueListener' , WiseAgentResponseQueueListener ( self )) self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . response_conn . subscribe ( destination = self . response_queue , id = id ( self ) + 1 , ack = 'auto' ) def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () if self . request_conn . is_connected () == False : self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) if self . response_conn . is_connected () == False : self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) request_destination = '/queue/request/' + dest_agent_name logging . debug ( f \"Sending request { message } to { request_destination } \" ) self . request_conn . send ( body = yaml . dump ( message ), destination = request_destination ) def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a response message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () response_destination = '/queue/response/' + dest_agent_name self . response_conn . send ( body = yaml . dump ( message ), destination = response_destination ) def stop ( self ): '''Stop the transport.''' if self . request_conn is not None and self . request_conn . is_connected (): #unsubscribe from the request topic self . request_conn . unsubscribe ( destination = self . request_queue , id = id ( self )) # Disconnect request from the STOMP server self . request_conn . disconnect () if self . response_conn is not None and self . response_conn . is_connected (): #unsubscribe from the response queue self . response_conn . unsubscribe ( destination = self . response_queue , id = id ( self ) + 1 ) # Disconnect response from the STOMP server self . response_conn . disconnect () @property def host ( self ) -> str : '''Get the host.''' return self . _host @property def port ( self ) -> int : '''Get the port.''' return self . _port @property def agent_name ( self ) -> str : '''Get the agent name.''' return self . _agent_name @property def request_queue ( self ) -> str : '''Get the request queue.''' return '/queue/request/' + self . agent_name @property def response_queue ( self ) -> str : '''Get the response queue.''' return '/queue/response/' + self . agent_name","title":"StompWiseAgentTransport"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.agent_name","text":"Get the agent name.","title":"agent_name"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.host","text":"Get the host.","title":"host"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.port","text":"Get the port.","title":"port"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.request_queue","text":"Get the request queue.","title":"request_queue"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.response_queue","text":"Get the response queue.","title":"response_queue"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.__getstate__","text":"Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/transports/stomp.py 73 74 75 76 77 78 def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = super () . __getstate__ () del state [ 'request_conn' ] del state [ 'response_conn' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.__init__","text":"Initialize the transport. Parameters: host ( str ) \u2013 the host port ( int ) \u2013 the port agent_name ( str ) \u2013 the agent name Source code in wiseagents/transports/stomp.py 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , host : str , port : int , agent_name : str ): '''Initialize the transport. Args: host (str): the host port (int): the port agent_name (str): the agent name''' self . _host = host self . _port = port self . _agent_name = agent_name","title":"__init__"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.send_request","text":"Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the destination agent name Source code in wiseagents/transports/stomp.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () if self . request_conn . is_connected () == False : self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) if self . response_conn . is_connected () == False : self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) request_destination = '/queue/request/' + dest_agent_name logging . debug ( f \"Sending request { message } to { request_destination } \" ) self . request_conn . send ( body = yaml . dump ( message ), destination = request_destination )","title":"send_request"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.send_response","text":"Send a response message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the destination agent name Source code in wiseagents/transports/stomp.py 118 119 120 121 122 123 124 125 126 127 128 def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a response message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () response_destination = '/queue/response/' + dest_agent_name self . response_conn . send ( body = yaml . dump ( message ), destination = response_destination )","title":"send_response"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.start","text":"Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set Source code in wiseagents/transports/stomp.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def start ( self ): ''' Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set''' if ( self . request_conn is not None and self . request_conn . is_connected ()) and ( self . response_conn is not None and self . response_conn . is_connected ()): return hosts = [( self . host , self . port )] self . request_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . request_conn . set_listener ( 'WiseAgentRequestTopicListener' , WiseAgentRequestQueueListener ( self )) self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . request_conn . subscribe ( destination = self . request_queue , id = id ( self ), ack = 'auto' ) self . response_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . response_conn . set_listener ( 'WiseAgentResponseQueueListener' , WiseAgentResponseQueueListener ( self )) self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . response_conn . subscribe ( destination = self . response_queue , id = id ( self ) + 1 , ack = 'auto' )","title":"start"},{"location":"reference/wiseagents/transports/#wiseagents.transports.StompWiseAgentTransport.stop","text":"Stop the transport. Source code in wiseagents/transports/stomp.py 130 131 132 133 134 135 136 137 138 139 140 141 def stop ( self ): '''Stop the transport.''' if self . request_conn is not None and self . request_conn . is_connected (): #unsubscribe from the request topic self . request_conn . unsubscribe ( destination = self . request_queue , id = id ( self )) # Disconnect request from the STOMP server self . request_conn . disconnect () if self . response_conn is not None and self . response_conn . is_connected (): #unsubscribe from the response queue self . response_conn . unsubscribe ( destination = self . response_queue , id = id ( self ) + 1 ) # Disconnect response from the STOMP server self . response_conn . disconnect ()","title":"stop"},{"location":"reference/wiseagents/transports/stomp/","text":"StompWiseAgentTransport Bases: WiseAgentTransport A transport for sending messages between agents using the STOMP protocol. Source code in wiseagents/transports/stomp.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 class StompWiseAgentTransport ( WiseAgentTransport ): '''A transport for sending messages between agents using the STOMP protocol.''' yaml_tag = u '!wiseagents.transports.StompWiseAgentTransport' request_conn : stomp . Connection = None response_conn : stomp . Connection = None def __init__ ( self , host : str , port : int , agent_name : str ): '''Initialize the transport. Args: host (str): the host port (int): the port agent_name (str): the agent name''' self . _host = host self . _port = port self . _agent_name = agent_name def __repr__ ( self ) -> str : return f \"host= { self . _host } , port= { self . _port } , agent_name= { self . _agent_name } \" def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = super () . __getstate__ () del state [ 'request_conn' ] del state [ 'response_conn' ] return state def start ( self ): ''' Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set''' if ( self . request_conn is not None and self . request_conn . is_connected ()) and ( self . response_conn is not None and self . response_conn . is_connected ()): return hosts = [( self . host , self . port )] self . request_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . request_conn . set_listener ( 'WiseAgentRequestTopicListener' , WiseAgentRequestQueueListener ( self )) self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . request_conn . subscribe ( destination = self . request_queue , id = id ( self ), ack = 'auto' ) self . response_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . response_conn . set_listener ( 'WiseAgentResponseQueueListener' , WiseAgentResponseQueueListener ( self )) self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . response_conn . subscribe ( destination = self . response_queue , id = id ( self ) + 1 , ack = 'auto' ) def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () if self . request_conn . is_connected () == False : self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) if self . response_conn . is_connected () == False : self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) request_destination = '/queue/request/' + dest_agent_name logging . debug ( f \"Sending request { message } to { request_destination } \" ) self . request_conn . send ( body = yaml . dump ( message ), destination = request_destination ) def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a response message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () response_destination = '/queue/response/' + dest_agent_name self . response_conn . send ( body = yaml . dump ( message ), destination = response_destination ) def stop ( self ): '''Stop the transport.''' if self . request_conn is not None and self . request_conn . is_connected (): #unsubscribe from the request topic self . request_conn . unsubscribe ( destination = self . request_queue , id = id ( self )) # Disconnect request from the STOMP server self . request_conn . disconnect () if self . response_conn is not None and self . response_conn . is_connected (): #unsubscribe from the response queue self . response_conn . unsubscribe ( destination = self . response_queue , id = id ( self ) + 1 ) # Disconnect response from the STOMP server self . response_conn . disconnect () @property def host ( self ) -> str : '''Get the host.''' return self . _host @property def port ( self ) -> int : '''Get the port.''' return self . _port @property def agent_name ( self ) -> str : '''Get the agent name.''' return self . _agent_name @property def request_queue ( self ) -> str : '''Get the request queue.''' return '/queue/request/' + self . agent_name @property def response_queue ( self ) -> str : '''Get the response queue.''' return '/queue/response/' + self . agent_name agent_name : str property Get the agent name. host : str property Get the host. port : int property Get the port. request_queue : str property Get the request queue. response_queue : str property Get the response queue. __getstate__ () Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/transports/stomp.py 73 74 75 76 77 78 def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = super () . __getstate__ () del state [ 'request_conn' ] del state [ 'response_conn' ] return state __init__ ( host , port , agent_name ) Initialize the transport. Parameters: host ( str ) \u2013 the host port ( int ) \u2013 the port agent_name ( str ) \u2013 the agent name Source code in wiseagents/transports/stomp.py 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , host : str , port : int , agent_name : str ): '''Initialize the transport. Args: host (str): the host port (int): the port agent_name (str): the agent name''' self . _host = host self . _port = port self . _agent_name = agent_name send_request ( message , dest_agent_name ) Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the destination agent name Source code in wiseagents/transports/stomp.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () if self . request_conn . is_connected () == False : self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) if self . response_conn . is_connected () == False : self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) request_destination = '/queue/request/' + dest_agent_name logging . debug ( f \"Sending request { message } to { request_destination } \" ) self . request_conn . send ( body = yaml . dump ( message ), destination = request_destination ) send_response ( message , dest_agent_name ) Send a response message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the destination agent name Source code in wiseagents/transports/stomp.py 118 119 120 121 122 123 124 125 126 127 128 def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a response message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () response_destination = '/queue/response/' + dest_agent_name self . response_conn . send ( body = yaml . dump ( message ), destination = response_destination ) start () Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set Source code in wiseagents/transports/stomp.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def start ( self ): ''' Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set''' if ( self . request_conn is not None and self . request_conn . is_connected ()) and ( self . response_conn is not None and self . response_conn . is_connected ()): return hosts = [( self . host , self . port )] self . request_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . request_conn . set_listener ( 'WiseAgentRequestTopicListener' , WiseAgentRequestQueueListener ( self )) self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . request_conn . subscribe ( destination = self . request_queue , id = id ( self ), ack = 'auto' ) self . response_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . response_conn . set_listener ( 'WiseAgentResponseQueueListener' , WiseAgentResponseQueueListener ( self )) self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . response_conn . subscribe ( destination = self . response_queue , id = id ( self ) + 1 , ack = 'auto' ) stop () Stop the transport. Source code in wiseagents/transports/stomp.py 130 131 132 133 134 135 136 137 138 139 140 141 def stop ( self ): '''Stop the transport.''' if self . request_conn is not None and self . request_conn . is_connected (): #unsubscribe from the request topic self . request_conn . unsubscribe ( destination = self . request_queue , id = id ( self )) # Disconnect request from the STOMP server self . request_conn . disconnect () if self . response_conn is not None and self . response_conn . is_connected (): #unsubscribe from the response queue self . response_conn . unsubscribe ( destination = self . response_queue , id = id ( self ) + 1 ) # Disconnect response from the STOMP server self . response_conn . disconnect () WiseAgentRequestQueueListener Bases: ConnectionListener A listener for the request queue. Source code in wiseagents/transports/stomp.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class WiseAgentRequestQueueListener ( stomp . ConnectionListener ): '''A listener for the request queue.''' def __init__ ( self , transport : WiseAgentTransport ): '''Initialize the listener. Args: ''' self . transport = transport def on_event ( self , event ): '''Handle an event.''' self . transport . event_receiver ( event ) def on_error ( self , error ): '''Handle an error.''' self . transport . error_receiver ( error ) def on_message ( self , message : stomp . utils . Frame ): '''Handle a message.''' self . transport . request_receiver ( yaml . load ( message . body , yaml . Loader )) __init__ ( transport ) Initialize the listener. Args: Source code in wiseagents/transports/stomp.py 14 15 16 17 18 19 def __init__ ( self , transport : WiseAgentTransport ): '''Initialize the listener. Args: ''' self . transport = transport on_error ( error ) Handle an error. Source code in wiseagents/transports/stomp.py 25 26 27 def on_error ( self , error ): '''Handle an error.''' self . transport . error_receiver ( error ) on_event ( event ) Handle an event. Source code in wiseagents/transports/stomp.py 21 22 23 def on_event ( self , event ): '''Handle an event.''' self . transport . event_receiver ( event ) on_message ( message ) Handle a message. Source code in wiseagents/transports/stomp.py 29 30 31 def on_message ( self , message : stomp . utils . Frame ): '''Handle a message.''' self . transport . request_receiver ( yaml . load ( message . body , yaml . Loader )) WiseAgentResponseQueueListener Bases: ConnectionListener A listener for the response queue. Source code in wiseagents/transports/stomp.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class WiseAgentResponseQueueListener ( stomp . ConnectionListener ): '''A listener for the response queue.''' def __init__ ( self , transport : WiseAgentTransport ): '''Initialize the listener. Args: transport (WiseAgentTransport): the transport''' self . transport = transport def on_error ( self , error ): '''Handle an error.''' self . transport . error_receiver ( error ) def on_message ( self , message : stomp . utils . Frame ): '''Handle a message.''' self . transport . response_receiver ( yaml . load ( message . body , yaml . Loader )) __init__ ( transport ) Initialize the listener. Parameters: transport ( WiseAgentTransport ) \u2013 the transport Source code in wiseagents/transports/stomp.py 35 36 37 38 39 40 def __init__ ( self , transport : WiseAgentTransport ): '''Initialize the listener. Args: transport (WiseAgentTransport): the transport''' self . transport = transport on_error ( error ) Handle an error. Source code in wiseagents/transports/stomp.py 42 43 44 def on_error ( self , error ): '''Handle an error.''' self . transport . error_receiver ( error ) on_message ( message ) Handle a message. Source code in wiseagents/transports/stomp.py 46 47 48 def on_message ( self , message : stomp . utils . Frame ): '''Handle a message.''' self . transport . response_receiver ( yaml . load ( message . body , yaml . Loader ))","title":"stomp"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport","text":"Bases: WiseAgentTransport A transport for sending messages between agents using the STOMP protocol. Source code in wiseagents/transports/stomp.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 class StompWiseAgentTransport ( WiseAgentTransport ): '''A transport for sending messages between agents using the STOMP protocol.''' yaml_tag = u '!wiseagents.transports.StompWiseAgentTransport' request_conn : stomp . Connection = None response_conn : stomp . Connection = None def __init__ ( self , host : str , port : int , agent_name : str ): '''Initialize the transport. Args: host (str): the host port (int): the port agent_name (str): the agent name''' self . _host = host self . _port = port self . _agent_name = agent_name def __repr__ ( self ) -> str : return f \"host= { self . _host } , port= { self . _port } , agent_name= { self . _agent_name } \" def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = super () . __getstate__ () del state [ 'request_conn' ] del state [ 'response_conn' ] return state def start ( self ): ''' Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set''' if ( self . request_conn is not None and self . request_conn . is_connected ()) and ( self . response_conn is not None and self . response_conn . is_connected ()): return hosts = [( self . host , self . port )] self . request_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . request_conn . set_listener ( 'WiseAgentRequestTopicListener' , WiseAgentRequestQueueListener ( self )) self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . request_conn . subscribe ( destination = self . request_queue , id = id ( self ), ack = 'auto' ) self . response_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . response_conn . set_listener ( 'WiseAgentResponseQueueListener' , WiseAgentResponseQueueListener ( self )) self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . response_conn . subscribe ( destination = self . response_queue , id = id ( self ) + 1 , ack = 'auto' ) def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () if self . request_conn . is_connected () == False : self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) if self . response_conn . is_connected () == False : self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) request_destination = '/queue/request/' + dest_agent_name logging . debug ( f \"Sending request { message } to { request_destination } \" ) self . request_conn . send ( body = yaml . dump ( message ), destination = request_destination ) def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a response message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () response_destination = '/queue/response/' + dest_agent_name self . response_conn . send ( body = yaml . dump ( message ), destination = response_destination ) def stop ( self ): '''Stop the transport.''' if self . request_conn is not None and self . request_conn . is_connected (): #unsubscribe from the request topic self . request_conn . unsubscribe ( destination = self . request_queue , id = id ( self )) # Disconnect request from the STOMP server self . request_conn . disconnect () if self . response_conn is not None and self . response_conn . is_connected (): #unsubscribe from the response queue self . response_conn . unsubscribe ( destination = self . response_queue , id = id ( self ) + 1 ) # Disconnect response from the STOMP server self . response_conn . disconnect () @property def host ( self ) -> str : '''Get the host.''' return self . _host @property def port ( self ) -> int : '''Get the port.''' return self . _port @property def agent_name ( self ) -> str : '''Get the agent name.''' return self . _agent_name @property def request_queue ( self ) -> str : '''Get the request queue.''' return '/queue/request/' + self . agent_name @property def response_queue ( self ) -> str : '''Get the response queue.''' return '/queue/response/' + self . agent_name","title":"StompWiseAgentTransport"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.agent_name","text":"Get the agent name.","title":"agent_name"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.host","text":"Get the host.","title":"host"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.port","text":"Get the port.","title":"port"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.request_queue","text":"Get the request queue.","title":"request_queue"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.response_queue","text":"Get the response queue.","title":"response_queue"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.__getstate__","text":"Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml. Source code in wiseagents/transports/stomp.py 73 74 75 76 77 78 def __getstate__ ( self ) -> object : '''Return the state of the transport. Removing the instance variable chain to avoid it is serialized/deserialized by pyyaml.''' state = super () . __getstate__ () del state [ 'request_conn' ] del state [ 'response_conn' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.__init__","text":"Initialize the transport. Parameters: host ( str ) \u2013 the host port ( int ) \u2013 the port agent_name ( str ) \u2013 the agent name Source code in wiseagents/transports/stomp.py 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , host : str , port : int , agent_name : str ): '''Initialize the transport. Args: host (str): the host port (int): the port agent_name (str): the agent name''' self . _host = host self . _port = port self . _agent_name = agent_name","title":"__init__"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.send_request","text":"Send a request message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the destination agent name Source code in wiseagents/transports/stomp.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def send_request ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a request message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () if self . request_conn . is_connected () == False : self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) if self . response_conn . is_connected () == False : self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) request_destination = '/queue/request/' + dest_agent_name logging . debug ( f \"Sending request { message } to { request_destination } \" ) self . request_conn . send ( body = yaml . dump ( message ), destination = request_destination )","title":"send_request"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.send_response","text":"Send a response message to an agent. Parameters: message ( WiseAgentMessage ) \u2013 the message to send dest_agent_name ( str ) \u2013 the destination agent name Source code in wiseagents/transports/stomp.py 118 119 120 121 122 123 124 125 126 127 128 def send_response ( self , message : WiseAgentMessage , dest_agent_name : str ): '''Send a response message to an agent. Args: message (WiseAgentMessage): the message to send dest_agent_name (str): the destination agent name''' # Send the message using the STOMP protocol if self . request_conn is None or self . response_conn is None : self . start () response_destination = '/queue/response/' + dest_agent_name self . response_conn . send ( body = yaml . dump ( message ), destination = response_destination )","title":"send_response"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.start","text":"Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set Source code in wiseagents/transports/stomp.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def start ( self ): ''' Start the transport. require the environment variables STOMP_USER and STOMP_PASSWORD to be set''' if ( self . request_conn is not None and self . request_conn . is_connected ()) and ( self . response_conn is not None and self . response_conn . is_connected ()): return hosts = [( self . host , self . port )] self . request_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . request_conn . set_listener ( 'WiseAgentRequestTopicListener' , WiseAgentRequestQueueListener ( self )) self . request_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . request_conn . subscribe ( destination = self . request_queue , id = id ( self ), ack = 'auto' ) self . response_conn = stomp . Connection ( host_and_ports = hosts , heartbeats = ( 60000 , 60000 )) self . response_conn . set_listener ( 'WiseAgentResponseQueueListener' , WiseAgentResponseQueueListener ( self )) self . response_conn . connect ( os . getenv ( \"STOMP_USER\" ), os . getenv ( \"STOMP_PASSWORD\" ), wait = True ) self . response_conn . subscribe ( destination = self . response_queue , id = id ( self ) + 1 , ack = 'auto' )","title":"start"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.StompWiseAgentTransport.stop","text":"Stop the transport. Source code in wiseagents/transports/stomp.py 130 131 132 133 134 135 136 137 138 139 140 141 def stop ( self ): '''Stop the transport.''' if self . request_conn is not None and self . request_conn . is_connected (): #unsubscribe from the request topic self . request_conn . unsubscribe ( destination = self . request_queue , id = id ( self )) # Disconnect request from the STOMP server self . request_conn . disconnect () if self . response_conn is not None and self . response_conn . is_connected (): #unsubscribe from the response queue self . response_conn . unsubscribe ( destination = self . response_queue , id = id ( self ) + 1 ) # Disconnect response from the STOMP server self . response_conn . disconnect ()","title":"stop"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.WiseAgentRequestQueueListener","text":"Bases: ConnectionListener A listener for the request queue. Source code in wiseagents/transports/stomp.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class WiseAgentRequestQueueListener ( stomp . ConnectionListener ): '''A listener for the request queue.''' def __init__ ( self , transport : WiseAgentTransport ): '''Initialize the listener. Args: ''' self . transport = transport def on_event ( self , event ): '''Handle an event.''' self . transport . event_receiver ( event ) def on_error ( self , error ): '''Handle an error.''' self . transport . error_receiver ( error ) def on_message ( self , message : stomp . utils . Frame ): '''Handle a message.''' self . transport . request_receiver ( yaml . load ( message . body , yaml . Loader ))","title":"WiseAgentRequestQueueListener"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.WiseAgentRequestQueueListener.__init__","text":"Initialize the listener. Args: Source code in wiseagents/transports/stomp.py 14 15 16 17 18 19 def __init__ ( self , transport : WiseAgentTransport ): '''Initialize the listener. Args: ''' self . transport = transport","title":"__init__"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.WiseAgentRequestQueueListener.on_error","text":"Handle an error. Source code in wiseagents/transports/stomp.py 25 26 27 def on_error ( self , error ): '''Handle an error.''' self . transport . error_receiver ( error )","title":"on_error"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.WiseAgentRequestQueueListener.on_event","text":"Handle an event. Source code in wiseagents/transports/stomp.py 21 22 23 def on_event ( self , event ): '''Handle an event.''' self . transport . event_receiver ( event )","title":"on_event"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.WiseAgentRequestQueueListener.on_message","text":"Handle a message. Source code in wiseagents/transports/stomp.py 29 30 31 def on_message ( self , message : stomp . utils . Frame ): '''Handle a message.''' self . transport . request_receiver ( yaml . load ( message . body , yaml . Loader ))","title":"on_message"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.WiseAgentResponseQueueListener","text":"Bases: ConnectionListener A listener for the response queue. Source code in wiseagents/transports/stomp.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class WiseAgentResponseQueueListener ( stomp . ConnectionListener ): '''A listener for the response queue.''' def __init__ ( self , transport : WiseAgentTransport ): '''Initialize the listener. Args: transport (WiseAgentTransport): the transport''' self . transport = transport def on_error ( self , error ): '''Handle an error.''' self . transport . error_receiver ( error ) def on_message ( self , message : stomp . utils . Frame ): '''Handle a message.''' self . transport . response_receiver ( yaml . load ( message . body , yaml . Loader ))","title":"WiseAgentResponseQueueListener"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.WiseAgentResponseQueueListener.__init__","text":"Initialize the listener. Parameters: transport ( WiseAgentTransport ) \u2013 the transport Source code in wiseagents/transports/stomp.py 35 36 37 38 39 40 def __init__ ( self , transport : WiseAgentTransport ): '''Initialize the listener. Args: transport (WiseAgentTransport): the transport''' self . transport = transport","title":"__init__"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.WiseAgentResponseQueueListener.on_error","text":"Handle an error. Source code in wiseagents/transports/stomp.py 42 43 44 def on_error ( self , error ): '''Handle an error.''' self . transport . error_receiver ( error )","title":"on_error"},{"location":"reference/wiseagents/transports/stomp/#wiseagents.transports.stomp.WiseAgentResponseQueueListener.on_message","text":"Handle a message. Source code in wiseagents/transports/stomp.py 46 47 48 def on_message ( self , message : stomp . utils . Frame ): '''Handle a message.''' self . transport . response_receiver ( yaml . load ( message . body , yaml . Loader ))","title":"on_message"},{"location":"reference/wiseagents/vectordb/","text":"Document Bases: BaseModel A document is a chunk of text. content (str): the string that makes up the chunk of text id (str): the optional id associated with the chunk of text metadata (Optional[dict]): optional information about the chunk of text Source code in wiseagents/vectordb/wise_agent_vector_db.py 12 13 14 15 16 17 18 19 20 21 22 class Document ( BaseModel ): \"\"\" A document is a chunk of text. content (str): the string that makes up the chunk of text id (str): the optional id associated with the chunk of text metadata (Optional[dict]): optional information about the chunk of text \"\"\" content : str id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) metadata : Optional [ dict ] = Field ( default_factory = dict ) LangChainWiseAgentVectorDB Bases: WiseAgentVectorDB An abstract class that makes use of a LangChain vector database. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 class LangChainWiseAgentVectorDB ( WiseAgentVectorDB ): \"\"\" An abstract class that makes use of a LangChain vector database. \"\"\" def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentVectorDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) @property def embedding_model_name ( self ): \"\"\"Get the name of the embedding model.\"\"\" return self . _embedding_model_name def convert_from_lang_chain_documents ( self , documents : List [ LangChainDocument ]) -> List [ Document ]: return [ Document ( content = document . page_content , metadata = document . metadata ) for document in documents ] @abstractmethod def get_or_create_collection ( self , collection_name : str ): ... @abstractmethod def delete_collection ( self , collection_name : str ): ... @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): ... @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): ... @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): ... @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ] = 4 ) -> List [ List [ Document ]]: ... embedding_model_name property Get the name of the embedding model. __init__ ( embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME ) Initialize a new instance of LangChainWiseAgentVectorDB. Parameters: embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentVectorDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 18 19 20 21 22 23 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj PGVectorLangChainWiseAgentVectorDB Bases: LangChainWiseAgentVectorDB A LangChainWiseAgentVectorDB implementation that makes use of a LangChain PGVector database. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class PGVectorLangChainWiseAgentVectorDB ( LangChainWiseAgentVectorDB ): \"\"\" A LangChainWiseAgentVectorDB implementation that makes use of a LangChain PGVector database. \"\"\" yaml_tag = u '!wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _vector_dbs = {} return obj def __init__ ( self , connection_string : str , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Args: connection_string (str): the connection string for the PGVector database embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" super () . __init__ ( embedding_model_name ) self . _connection_string = connection_string self . _vector_dbs = {} def __repr__ ( self ): \"\"\"Return a string representation of the vector DB.\"\"\" return ( f \" { self . __class__ . __name__ } (connection_string= { self . connection_string } ,\" f \"embedding_model_name= { self . embedding_model_name } )\" ) def __getstate__ ( self ) -> object : \"\"\"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_vector_dbs' ] del state [ '_embedding_function' ] return state @property def connection_string ( self ): \"\"\"Get the connection string.\"\"\" return self . _connection_string def get_or_create_collection ( self , collection_name : str ): if not hasattr ( self , \"_vector_dbs\" ): # instances populated from PyYAML won't have this set initially self . _vector_dbs = {} if collection_name not in self . _vector_dbs : self . _vector_dbs [ collection_name ] = PGVector ( embeddings = self . _embedding_function , collection_name = collection_name , connection = self . _connection_string ) def delete_collection ( self , collection_name : str ): self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : self . _vector_dbs [ collection_name ] . delete_collection () del self . _vector_dbs [ collection_name ] def insert_documents ( self , documents : List [ Document ], collection_name : str ): self . get_or_create_collection ( collection_name ) self . _vector_dbs [ collection_name ] . add_texts ( texts = [ doc . content for doc in documents ], ids = [ doc . id for doc in documents ], metadatas = [ doc . metadata for doc in documents ]) def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): self . get_or_create_collection ( collection_name ) self . insert_documents ( documents , collection_name ) def delete_documents ( self , document_ids : List [ str ], collection_name : str ): self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : self . _vector_dbs [ collection_name ] . delete ( ids = document_ids ) def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ] = 4 ) -> List [ List [ Document ]]: self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : return [ self . convert_from_lang_chain_documents ( self . _vector_dbs [ collection_name ] . similarity_search ( query , k )) for query in queries ] connection_string property Get the connection string. __getstate__ () Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 101 102 103 104 105 106 def __getstate__ ( self ) -> object : \"\"\"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_vector_dbs' ] del state [ '_embedding_function' ] return state __init__ ( connection_string , embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME ) Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Parameters: connection_string ( str ) \u2013 the connection string for the PGVector database embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , connection_string : str , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Args: connection_string (str): the connection string for the PGVector database embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" super () . __init__ ( embedding_model_name ) self . _connection_string = connection_string self . _vector_dbs = {} __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 76 77 78 79 80 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _vector_dbs = {} return obj __repr__ () Return a string representation of the vector DB. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 95 96 97 98 def __repr__ ( self ): \"\"\"Return a string representation of the vector DB.\"\"\" return ( f \" { self . __class__ . __name__ } (connection_string= { self . connection_string } ,\" f \"embedding_model_name= { self . embedding_model_name } )\" ) WiseAgentVectorDB Bases: YAMLObject Abstract class to define the interface for a WiseAgentVectorDB. Source code in wiseagents/vectordb/wise_agent_vector_db.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 class WiseAgentVectorDB ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentVectorDB.\"\"\" yaml_tag = u '!WiseAgentVectorDB' yaml_loader = WiseAgentsLoader @abstractmethod def get_or_create_collection ( self , collection_name : str ): \"\"\" Get the collection for the vector DB or create it if it doesn't already exist. Args: collection_name (str): the name of the collection \"\"\" ... @abstractmethod def delete_collection ( self , collection_name : str ): \"\"\" Delete the collection with the specified name from the vector DB. Args: collection_name (str): the name of the collection to delete \"\"\" ... @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): \"\"\" Delete documents from the specified collection in the vector DB. Args: ids (List[str]): the list of document IDs to be deleted collection_name (str): the name of the collection in the vector DB to delete the documents from \"\"\" ... @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ]) -> List [ List [ Document ]]: \"\"\" Retrieve documents from the specified collection in the vector DB using the given queries. Args: queries (List[str]): the list of queries where each query is a string collection_name (str): the name of the collection in the vector DB to query k (Optional[int]): the number of documents to retrieve for each query Returns: List[List[Document]]: the list containing a list of documents that were retrieved for each query \"\"\" ... delete_collection ( collection_name ) abstractmethod Delete the collection with the specified name from the vector DB. Parameters: collection_name ( str ) \u2013 the name of the collection to delete Source code in wiseagents/vectordb/wise_agent_vector_db.py 41 42 43 44 45 46 47 48 49 50 @abstractmethod def delete_collection ( self , collection_name : str ): \"\"\" Delete the collection with the specified name from the vector DB. Args: collection_name (str): the name of the collection to delete \"\"\" ... delete_documents ( ids , collection_name ) abstractmethod Delete documents from the specified collection in the vector DB. Parameters: ids ( List [ str ] ) \u2013 the list of document IDs to be deleted collection_name ( str ) \u2013 the name of the collection in the vector DB to delete the documents from Source code in wiseagents/vectordb/wise_agent_vector_db.py 77 78 79 80 81 82 83 84 85 86 87 @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): \"\"\" Delete documents from the specified collection in the vector DB. Args: ids (List[str]): the list of document IDs to be deleted collection_name (str): the name of the collection in the vector DB to delete the documents from \"\"\" ... get_or_create_collection ( collection_name ) abstractmethod Get the collection for the vector DB or create it if it doesn't already exist. Parameters: collection_name ( str ) \u2013 the name of the collection Source code in wiseagents/vectordb/wise_agent_vector_db.py 30 31 32 33 34 35 36 37 38 39 @abstractmethod def get_or_create_collection ( self , collection_name : str ): \"\"\" Get the collection for the vector DB or create it if it doesn't already exist. Args: collection_name (str): the name of the collection \"\"\" ... insert_documents ( documents , collection_name ) abstractmethod Insert the given documents into the specified collection in the vector DB. Parameters: documents ( List [ Document ] ) \u2013 the documents to be inserted into the specified collection collection_name ( str ) \u2013 the name of the collection in the vector DB to insert the documents into Source code in wiseagents/vectordb/wise_agent_vector_db.py 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... insert_or_update_documents ( documents , collection_name ) abstractmethod Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Parameters: documents ( List [ Document ] ) \u2013 the documents to be inserted into the specified collection collection_name ( str ) \u2013 the name of the collection in the vector DB to insert the documents into Source code in wiseagents/vectordb/wise_agent_vector_db.py 64 65 66 67 68 69 70 71 72 73 74 75 @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... query ( queries , collection_name , k ) abstractmethod Retrieve documents from the specified collection in the vector DB using the given queries. Parameters: queries ( List [ str ] ) \u2013 the list of queries where each query is a string collection_name ( str ) \u2013 the name of the collection in the vector DB to query k ( Optional [ int ] ) \u2013 the number of documents to retrieve for each query Returns: List [ List [ Document ]] \u2013 List[List[Document]]: the list containing a list of documents that were List [ List [ Document ]] \u2013 retrieved for each query Source code in wiseagents/vectordb/wise_agent_vector_db.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ]) -> List [ List [ Document ]]: \"\"\" Retrieve documents from the specified collection in the vector DB using the given queries. Args: queries (List[str]): the list of queries where each query is a string collection_name (str): the name of the collection in the vector DB to query k (Optional[int]): the number of documents to retrieve for each query Returns: List[List[Document]]: the list containing a list of documents that were retrieved for each query \"\"\" ...","title":"vectordb"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.Document","text":"Bases: BaseModel A document is a chunk of text. content (str): the string that makes up the chunk of text id (str): the optional id associated with the chunk of text metadata (Optional[dict]): optional information about the chunk of text Source code in wiseagents/vectordb/wise_agent_vector_db.py 12 13 14 15 16 17 18 19 20 21 22 class Document ( BaseModel ): \"\"\" A document is a chunk of text. content (str): the string that makes up the chunk of text id (str): the optional id associated with the chunk of text metadata (Optional[dict]): optional information about the chunk of text \"\"\" content : str id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) metadata : Optional [ dict ] = Field ( default_factory = dict )","title":"Document"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.LangChainWiseAgentVectorDB","text":"Bases: WiseAgentVectorDB An abstract class that makes use of a LangChain vector database. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 class LangChainWiseAgentVectorDB ( WiseAgentVectorDB ): \"\"\" An abstract class that makes use of a LangChain vector database. \"\"\" def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentVectorDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) @property def embedding_model_name ( self ): \"\"\"Get the name of the embedding model.\"\"\" return self . _embedding_model_name def convert_from_lang_chain_documents ( self , documents : List [ LangChainDocument ]) -> List [ Document ]: return [ Document ( content = document . page_content , metadata = document . metadata ) for document in documents ] @abstractmethod def get_or_create_collection ( self , collection_name : str ): ... @abstractmethod def delete_collection ( self , collection_name : str ): ... @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): ... @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): ... @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): ... @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ] = 4 ) -> List [ List [ Document ]]: ...","title":"LangChainWiseAgentVectorDB"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.LangChainWiseAgentVectorDB.embedding_model_name","text":"Get the name of the embedding model.","title":"embedding_model_name"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.LangChainWiseAgentVectorDB.__init__","text":"Initialize a new instance of LangChainWiseAgentVectorDB. Parameters: embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentVectorDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name )","title":"__init__"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.LangChainWiseAgentVectorDB.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 18 19 20 21 22 23 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj","title":"__new__"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB","text":"Bases: LangChainWiseAgentVectorDB A LangChainWiseAgentVectorDB implementation that makes use of a LangChain PGVector database. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class PGVectorLangChainWiseAgentVectorDB ( LangChainWiseAgentVectorDB ): \"\"\" A LangChainWiseAgentVectorDB implementation that makes use of a LangChain PGVector database. \"\"\" yaml_tag = u '!wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _vector_dbs = {} return obj def __init__ ( self , connection_string : str , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Args: connection_string (str): the connection string for the PGVector database embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" super () . __init__ ( embedding_model_name ) self . _connection_string = connection_string self . _vector_dbs = {} def __repr__ ( self ): \"\"\"Return a string representation of the vector DB.\"\"\" return ( f \" { self . __class__ . __name__ } (connection_string= { self . connection_string } ,\" f \"embedding_model_name= { self . embedding_model_name } )\" ) def __getstate__ ( self ) -> object : \"\"\"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_vector_dbs' ] del state [ '_embedding_function' ] return state @property def connection_string ( self ): \"\"\"Get the connection string.\"\"\" return self . _connection_string def get_or_create_collection ( self , collection_name : str ): if not hasattr ( self , \"_vector_dbs\" ): # instances populated from PyYAML won't have this set initially self . _vector_dbs = {} if collection_name not in self . _vector_dbs : self . _vector_dbs [ collection_name ] = PGVector ( embeddings = self . _embedding_function , collection_name = collection_name , connection = self . _connection_string ) def delete_collection ( self , collection_name : str ): self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : self . _vector_dbs [ collection_name ] . delete_collection () del self . _vector_dbs [ collection_name ] def insert_documents ( self , documents : List [ Document ], collection_name : str ): self . get_or_create_collection ( collection_name ) self . _vector_dbs [ collection_name ] . add_texts ( texts = [ doc . content for doc in documents ], ids = [ doc . id for doc in documents ], metadatas = [ doc . metadata for doc in documents ]) def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): self . get_or_create_collection ( collection_name ) self . insert_documents ( documents , collection_name ) def delete_documents ( self , document_ids : List [ str ], collection_name : str ): self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : self . _vector_dbs [ collection_name ] . delete ( ids = document_ids ) def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ] = 4 ) -> List [ List [ Document ]]: self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : return [ self . convert_from_lang_chain_documents ( self . _vector_dbs [ collection_name ] . similarity_search ( query , k )) for query in queries ]","title":"PGVectorLangChainWiseAgentVectorDB"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB.connection_string","text":"Get the connection string.","title":"connection_string"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB.__getstate__","text":"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 101 102 103 104 105 106 def __getstate__ ( self ) -> object : \"\"\"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_vector_dbs' ] del state [ '_embedding_function' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB.__init__","text":"Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Parameters: connection_string ( str ) \u2013 the connection string for the PGVector database embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , connection_string : str , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Args: connection_string (str): the connection string for the PGVector database embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" super () . __init__ ( embedding_model_name ) self . _connection_string = connection_string self . _vector_dbs = {}","title":"__init__"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 76 77 78 79 80 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _vector_dbs = {} return obj","title":"__new__"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB.__repr__","text":"Return a string representation of the vector DB. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 95 96 97 98 def __repr__ ( self ): \"\"\"Return a string representation of the vector DB.\"\"\" return ( f \" { self . __class__ . __name__ } (connection_string= { self . connection_string } ,\" f \"embedding_model_name= { self . embedding_model_name } )\" )","title":"__repr__"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.WiseAgentVectorDB","text":"Bases: YAMLObject Abstract class to define the interface for a WiseAgentVectorDB. Source code in wiseagents/vectordb/wise_agent_vector_db.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 class WiseAgentVectorDB ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentVectorDB.\"\"\" yaml_tag = u '!WiseAgentVectorDB' yaml_loader = WiseAgentsLoader @abstractmethod def get_or_create_collection ( self , collection_name : str ): \"\"\" Get the collection for the vector DB or create it if it doesn't already exist. Args: collection_name (str): the name of the collection \"\"\" ... @abstractmethod def delete_collection ( self , collection_name : str ): \"\"\" Delete the collection with the specified name from the vector DB. Args: collection_name (str): the name of the collection to delete \"\"\" ... @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): \"\"\" Delete documents from the specified collection in the vector DB. Args: ids (List[str]): the list of document IDs to be deleted collection_name (str): the name of the collection in the vector DB to delete the documents from \"\"\" ... @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ]) -> List [ List [ Document ]]: \"\"\" Retrieve documents from the specified collection in the vector DB using the given queries. Args: queries (List[str]): the list of queries where each query is a string collection_name (str): the name of the collection in the vector DB to query k (Optional[int]): the number of documents to retrieve for each query Returns: List[List[Document]]: the list containing a list of documents that were retrieved for each query \"\"\" ...","title":"WiseAgentVectorDB"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.WiseAgentVectorDB.delete_collection","text":"Delete the collection with the specified name from the vector DB. Parameters: collection_name ( str ) \u2013 the name of the collection to delete Source code in wiseagents/vectordb/wise_agent_vector_db.py 41 42 43 44 45 46 47 48 49 50 @abstractmethod def delete_collection ( self , collection_name : str ): \"\"\" Delete the collection with the specified name from the vector DB. Args: collection_name (str): the name of the collection to delete \"\"\" ...","title":"delete_collection"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.WiseAgentVectorDB.delete_documents","text":"Delete documents from the specified collection in the vector DB. Parameters: ids ( List [ str ] ) \u2013 the list of document IDs to be deleted collection_name ( str ) \u2013 the name of the collection in the vector DB to delete the documents from Source code in wiseagents/vectordb/wise_agent_vector_db.py 77 78 79 80 81 82 83 84 85 86 87 @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): \"\"\" Delete documents from the specified collection in the vector DB. Args: ids (List[str]): the list of document IDs to be deleted collection_name (str): the name of the collection in the vector DB to delete the documents from \"\"\" ...","title":"delete_documents"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.WiseAgentVectorDB.get_or_create_collection","text":"Get the collection for the vector DB or create it if it doesn't already exist. Parameters: collection_name ( str ) \u2013 the name of the collection Source code in wiseagents/vectordb/wise_agent_vector_db.py 30 31 32 33 34 35 36 37 38 39 @abstractmethod def get_or_create_collection ( self , collection_name : str ): \"\"\" Get the collection for the vector DB or create it if it doesn't already exist. Args: collection_name (str): the name of the collection \"\"\" ...","title":"get_or_create_collection"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.WiseAgentVectorDB.insert_documents","text":"Insert the given documents into the specified collection in the vector DB. Parameters: documents ( List [ Document ] ) \u2013 the documents to be inserted into the specified collection collection_name ( str ) \u2013 the name of the collection in the vector DB to insert the documents into Source code in wiseagents/vectordb/wise_agent_vector_db.py 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ...","title":"insert_documents"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.WiseAgentVectorDB.insert_or_update_documents","text":"Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Parameters: documents ( List [ Document ] ) \u2013 the documents to be inserted into the specified collection collection_name ( str ) \u2013 the name of the collection in the vector DB to insert the documents into Source code in wiseagents/vectordb/wise_agent_vector_db.py 64 65 66 67 68 69 70 71 72 73 74 75 @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ...","title":"insert_or_update_documents"},{"location":"reference/wiseagents/vectordb/#wiseagents.vectordb.WiseAgentVectorDB.query","text":"Retrieve documents from the specified collection in the vector DB using the given queries. Parameters: queries ( List [ str ] ) \u2013 the list of queries where each query is a string collection_name ( str ) \u2013 the name of the collection in the vector DB to query k ( Optional [ int ] ) \u2013 the number of documents to retrieve for each query Returns: List [ List [ Document ]] \u2013 List[List[Document]]: the list containing a list of documents that were List [ List [ Document ]] \u2013 retrieved for each query Source code in wiseagents/vectordb/wise_agent_vector_db.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ]) -> List [ List [ Document ]]: \"\"\" Retrieve documents from the specified collection in the vector DB using the given queries. Args: queries (List[str]): the list of queries where each query is a string collection_name (str): the name of the collection in the vector DB to query k (Optional[int]): the number of documents to retrieve for each query Returns: List[List[Document]]: the list containing a list of documents that were retrieved for each query \"\"\" ...","title":"query"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/","text":"LangChainWiseAgentVectorDB Bases: WiseAgentVectorDB An abstract class that makes use of a LangChain vector database. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 class LangChainWiseAgentVectorDB ( WiseAgentVectorDB ): \"\"\" An abstract class that makes use of a LangChain vector database. \"\"\" def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentVectorDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) @property def embedding_model_name ( self ): \"\"\"Get the name of the embedding model.\"\"\" return self . _embedding_model_name def convert_from_lang_chain_documents ( self , documents : List [ LangChainDocument ]) -> List [ Document ]: return [ Document ( content = document . page_content , metadata = document . metadata ) for document in documents ] @abstractmethod def get_or_create_collection ( self , collection_name : str ): ... @abstractmethod def delete_collection ( self , collection_name : str ): ... @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): ... @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): ... @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): ... @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ] = 4 ) -> List [ List [ Document ]]: ... embedding_model_name property Get the name of the embedding model. __init__ ( embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME ) Initialize a new instance of LangChainWiseAgentVectorDB. Parameters: embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentVectorDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 18 19 20 21 22 23 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj PGVectorLangChainWiseAgentVectorDB Bases: LangChainWiseAgentVectorDB A LangChainWiseAgentVectorDB implementation that makes use of a LangChain PGVector database. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class PGVectorLangChainWiseAgentVectorDB ( LangChainWiseAgentVectorDB ): \"\"\" A LangChainWiseAgentVectorDB implementation that makes use of a LangChain PGVector database. \"\"\" yaml_tag = u '!wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _vector_dbs = {} return obj def __init__ ( self , connection_string : str , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Args: connection_string (str): the connection string for the PGVector database embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" super () . __init__ ( embedding_model_name ) self . _connection_string = connection_string self . _vector_dbs = {} def __repr__ ( self ): \"\"\"Return a string representation of the vector DB.\"\"\" return ( f \" { self . __class__ . __name__ } (connection_string= { self . connection_string } ,\" f \"embedding_model_name= { self . embedding_model_name } )\" ) def __getstate__ ( self ) -> object : \"\"\"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_vector_dbs' ] del state [ '_embedding_function' ] return state @property def connection_string ( self ): \"\"\"Get the connection string.\"\"\" return self . _connection_string def get_or_create_collection ( self , collection_name : str ): if not hasattr ( self , \"_vector_dbs\" ): # instances populated from PyYAML won't have this set initially self . _vector_dbs = {} if collection_name not in self . _vector_dbs : self . _vector_dbs [ collection_name ] = PGVector ( embeddings = self . _embedding_function , collection_name = collection_name , connection = self . _connection_string ) def delete_collection ( self , collection_name : str ): self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : self . _vector_dbs [ collection_name ] . delete_collection () del self . _vector_dbs [ collection_name ] def insert_documents ( self , documents : List [ Document ], collection_name : str ): self . get_or_create_collection ( collection_name ) self . _vector_dbs [ collection_name ] . add_texts ( texts = [ doc . content for doc in documents ], ids = [ doc . id for doc in documents ], metadatas = [ doc . metadata for doc in documents ]) def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): self . get_or_create_collection ( collection_name ) self . insert_documents ( documents , collection_name ) def delete_documents ( self , document_ids : List [ str ], collection_name : str ): self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : self . _vector_dbs [ collection_name ] . delete ( ids = document_ids ) def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ] = 4 ) -> List [ List [ Document ]]: self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : return [ self . convert_from_lang_chain_documents ( self . _vector_dbs [ collection_name ] . similarity_search ( query , k )) for query in queries ] connection_string property Get the connection string. __getstate__ () Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 101 102 103 104 105 106 def __getstate__ ( self ) -> object : \"\"\"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_vector_dbs' ] del state [ '_embedding_function' ] return state __init__ ( connection_string , embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME ) Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Parameters: connection_string ( str ) \u2013 the connection string for the PGVector database embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , connection_string : str , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Args: connection_string (str): the connection string for the PGVector database embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" super () . __init__ ( embedding_model_name ) self . _connection_string = connection_string self . _vector_dbs = {} __new__ ( * args , ** kwargs ) Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 76 77 78 79 80 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _vector_dbs = {} return obj __repr__ () Return a string representation of the vector DB. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 95 96 97 98 def __repr__ ( self ): \"\"\"Return a string representation of the vector DB.\"\"\" return ( f \" { self . __class__ . __name__ } (connection_string= { self . connection_string } ,\" f \"embedding_model_name= { self . embedding_model_name } )\" )","title":"lang_chain_wise_agent_vector_db"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.LangChainWiseAgentVectorDB","text":"Bases: WiseAgentVectorDB An abstract class that makes use of a LangChain vector database. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 class LangChainWiseAgentVectorDB ( WiseAgentVectorDB ): \"\"\" An abstract class that makes use of a LangChain vector database. \"\"\" def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentVectorDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name ) @property def embedding_model_name ( self ): \"\"\"Get the name of the embedding model.\"\"\" return self . _embedding_model_name def convert_from_lang_chain_documents ( self , documents : List [ LangChainDocument ]) -> List [ Document ]: return [ Document ( content = document . page_content , metadata = document . metadata ) for document in documents ] @abstractmethod def get_or_create_collection ( self , collection_name : str ): ... @abstractmethod def delete_collection ( self , collection_name : str ): ... @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): ... @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): ... @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): ... @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ] = 4 ) -> List [ List [ Document ]]: ...","title":"LangChainWiseAgentVectorDB"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.LangChainWiseAgentVectorDB.embedding_model_name","text":"Get the name of the embedding model.","title":"embedding_model_name"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.LangChainWiseAgentVectorDB.__init__","text":"Initialize a new instance of LangChainWiseAgentVectorDB. Parameters: embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 25 26 27 28 29 30 31 32 33 34 def __init__ ( self , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of LangChainWiseAgentVectorDB. Args: embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" self . _embedding_model_name = embedding_model_name self . _embedding_function = HuggingFaceEmbeddings ( model_name = self . embedding_model_name )","title":"__init__"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.LangChainWiseAgentVectorDB.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 18 19 20 21 22 23 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _embedding_model_name = DEFAULT_EMBEDDING_MODEL_NAME obj . _embedding_function = HuggingFaceEmbeddings ( model_name = DEFAULT_EMBEDDING_MODEL_NAME ) return obj","title":"__new__"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.PGVectorLangChainWiseAgentVectorDB","text":"Bases: LangChainWiseAgentVectorDB A LangChainWiseAgentVectorDB implementation that makes use of a LangChain PGVector database. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class PGVectorLangChainWiseAgentVectorDB ( LangChainWiseAgentVectorDB ): \"\"\" A LangChainWiseAgentVectorDB implementation that makes use of a LangChain PGVector database. \"\"\" yaml_tag = u '!wiseagents.vectordb.PGVectorLangChainWiseAgentVectorDB' def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _vector_dbs = {} return obj def __init__ ( self , connection_string : str , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Args: connection_string (str): the connection string for the PGVector database embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" super () . __init__ ( embedding_model_name ) self . _connection_string = connection_string self . _vector_dbs = {} def __repr__ ( self ): \"\"\"Return a string representation of the vector DB.\"\"\" return ( f \" { self . __class__ . __name__ } (connection_string= { self . connection_string } ,\" f \"embedding_model_name= { self . embedding_model_name } )\" ) def __getstate__ ( self ) -> object : \"\"\"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_vector_dbs' ] del state [ '_embedding_function' ] return state @property def connection_string ( self ): \"\"\"Get the connection string.\"\"\" return self . _connection_string def get_or_create_collection ( self , collection_name : str ): if not hasattr ( self , \"_vector_dbs\" ): # instances populated from PyYAML won't have this set initially self . _vector_dbs = {} if collection_name not in self . _vector_dbs : self . _vector_dbs [ collection_name ] = PGVector ( embeddings = self . _embedding_function , collection_name = collection_name , connection = self . _connection_string ) def delete_collection ( self , collection_name : str ): self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : self . _vector_dbs [ collection_name ] . delete_collection () del self . _vector_dbs [ collection_name ] def insert_documents ( self , documents : List [ Document ], collection_name : str ): self . get_or_create_collection ( collection_name ) self . _vector_dbs [ collection_name ] . add_texts ( texts = [ doc . content for doc in documents ], ids = [ doc . id for doc in documents ], metadatas = [ doc . metadata for doc in documents ]) def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): self . get_or_create_collection ( collection_name ) self . insert_documents ( documents , collection_name ) def delete_documents ( self , document_ids : List [ str ], collection_name : str ): self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : self . _vector_dbs [ collection_name ] . delete ( ids = document_ids ) def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ] = 4 ) -> List [ List [ Document ]]: self . get_or_create_collection ( collection_name ) if collection_name in self . _vector_dbs : return [ self . convert_from_lang_chain_documents ( self . _vector_dbs [ collection_name ] . similarity_search ( query , k )) for query in queries ]","title":"PGVectorLangChainWiseAgentVectorDB"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.PGVectorLangChainWiseAgentVectorDB.connection_string","text":"Get the connection string.","title":"connection_string"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.PGVectorLangChainWiseAgentVectorDB.__getstate__","text":"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 101 102 103 104 105 106 def __getstate__ ( self ) -> object : \"\"\"Return the state of the vector DB. Removing _vector_dbs and _embedding_function to avoid them being serialized/deserialized by pyyaml.\"\"\" state = self . __dict__ . copy () del state [ '_vector_dbs' ] del state [ '_embedding_function' ] return state","title":"__getstate__"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.PGVectorLangChainWiseAgentVectorDB.__init__","text":"Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Parameters: connection_string ( str ) \u2013 the connection string for the PGVector database embedding_model_name ( Optional [ str ] , default: DEFAULT_EMBEDDING_MODEL_NAME ) \u2013 the optional name of the embedding model to use Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , connection_string : str , embedding_model_name : Optional [ str ] = DEFAULT_EMBEDDING_MODEL_NAME ): \"\"\" Initialize a new instance of PGVectorLangChainWiseAgentVectorDB. Args: connection_string (str): the connection string for the PGVector database embedding_model_name (Optional[str]): the optional name of the embedding model to use \"\"\" super () . __init__ ( embedding_model_name ) self . _connection_string = connection_string self . _vector_dbs = {}","title":"__init__"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.PGVectorLangChainWiseAgentVectorDB.__new__","text":"Create a new instance of the class, setting default values for the instance variables. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 76 77 78 79 80 def __new__ ( cls , * args , ** kwargs ): \"\"\"Create a new instance of the class, setting default values for the instance variables.\"\"\" obj = super () . __new__ ( cls ) obj . _vector_dbs = {} return obj","title":"__new__"},{"location":"reference/wiseagents/vectordb/lang_chain_wise_agent_vector_db/#wiseagents.vectordb.lang_chain_wise_agent_vector_db.PGVectorLangChainWiseAgentVectorDB.__repr__","text":"Return a string representation of the vector DB. Source code in wiseagents/vectordb/lang_chain_wise_agent_vector_db.py 95 96 97 98 def __repr__ ( self ): \"\"\"Return a string representation of the vector DB.\"\"\" return ( f \" { self . __class__ . __name__ } (connection_string= { self . connection_string } ,\" f \"embedding_model_name= { self . embedding_model_name } )\" )","title":"__repr__"},{"location":"reference/wiseagents/vectordb/wise_agent_vector_db/","text":"Document Bases: BaseModel A document is a chunk of text. content (str): the string that makes up the chunk of text id (str): the optional id associated with the chunk of text metadata (Optional[dict]): optional information about the chunk of text Source code in wiseagents/vectordb/wise_agent_vector_db.py 12 13 14 15 16 17 18 19 20 21 22 class Document ( BaseModel ): \"\"\" A document is a chunk of text. content (str): the string that makes up the chunk of text id (str): the optional id associated with the chunk of text metadata (Optional[dict]): optional information about the chunk of text \"\"\" content : str id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) metadata : Optional [ dict ] = Field ( default_factory = dict ) WiseAgentVectorDB Bases: YAMLObject Abstract class to define the interface for a WiseAgentVectorDB. Source code in wiseagents/vectordb/wise_agent_vector_db.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 class WiseAgentVectorDB ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentVectorDB.\"\"\" yaml_tag = u '!WiseAgentVectorDB' yaml_loader = WiseAgentsLoader @abstractmethod def get_or_create_collection ( self , collection_name : str ): \"\"\" Get the collection for the vector DB or create it if it doesn't already exist. Args: collection_name (str): the name of the collection \"\"\" ... @abstractmethod def delete_collection ( self , collection_name : str ): \"\"\" Delete the collection with the specified name from the vector DB. Args: collection_name (str): the name of the collection to delete \"\"\" ... @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): \"\"\" Delete documents from the specified collection in the vector DB. Args: ids (List[str]): the list of document IDs to be deleted collection_name (str): the name of the collection in the vector DB to delete the documents from \"\"\" ... @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ]) -> List [ List [ Document ]]: \"\"\" Retrieve documents from the specified collection in the vector DB using the given queries. Args: queries (List[str]): the list of queries where each query is a string collection_name (str): the name of the collection in the vector DB to query k (Optional[int]): the number of documents to retrieve for each query Returns: List[List[Document]]: the list containing a list of documents that were retrieved for each query \"\"\" ... delete_collection ( collection_name ) abstractmethod Delete the collection with the specified name from the vector DB. Parameters: collection_name ( str ) \u2013 the name of the collection to delete Source code in wiseagents/vectordb/wise_agent_vector_db.py 41 42 43 44 45 46 47 48 49 50 @abstractmethod def delete_collection ( self , collection_name : str ): \"\"\" Delete the collection with the specified name from the vector DB. Args: collection_name (str): the name of the collection to delete \"\"\" ... delete_documents ( ids , collection_name ) abstractmethod Delete documents from the specified collection in the vector DB. Parameters: ids ( List [ str ] ) \u2013 the list of document IDs to be deleted collection_name ( str ) \u2013 the name of the collection in the vector DB to delete the documents from Source code in wiseagents/vectordb/wise_agent_vector_db.py 77 78 79 80 81 82 83 84 85 86 87 @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): \"\"\" Delete documents from the specified collection in the vector DB. Args: ids (List[str]): the list of document IDs to be deleted collection_name (str): the name of the collection in the vector DB to delete the documents from \"\"\" ... get_or_create_collection ( collection_name ) abstractmethod Get the collection for the vector DB or create it if it doesn't already exist. Parameters: collection_name ( str ) \u2013 the name of the collection Source code in wiseagents/vectordb/wise_agent_vector_db.py 30 31 32 33 34 35 36 37 38 39 @abstractmethod def get_or_create_collection ( self , collection_name : str ): \"\"\" Get the collection for the vector DB or create it if it doesn't already exist. Args: collection_name (str): the name of the collection \"\"\" ... insert_documents ( documents , collection_name ) abstractmethod Insert the given documents into the specified collection in the vector DB. Parameters: documents ( List [ Document ] ) \u2013 the documents to be inserted into the specified collection collection_name ( str ) \u2013 the name of the collection in the vector DB to insert the documents into Source code in wiseagents/vectordb/wise_agent_vector_db.py 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... insert_or_update_documents ( documents , collection_name ) abstractmethod Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Parameters: documents ( List [ Document ] ) \u2013 the documents to be inserted into the specified collection collection_name ( str ) \u2013 the name of the collection in the vector DB to insert the documents into Source code in wiseagents/vectordb/wise_agent_vector_db.py 64 65 66 67 68 69 70 71 72 73 74 75 @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... query ( queries , collection_name , k ) abstractmethod Retrieve documents from the specified collection in the vector DB using the given queries. Parameters: queries ( List [ str ] ) \u2013 the list of queries where each query is a string collection_name ( str ) \u2013 the name of the collection in the vector DB to query k ( Optional [ int ] ) \u2013 the number of documents to retrieve for each query Returns: List [ List [ Document ]] \u2013 List[List[Document]]: the list containing a list of documents that were List [ List [ Document ]] \u2013 retrieved for each query Source code in wiseagents/vectordb/wise_agent_vector_db.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ]) -> List [ List [ Document ]]: \"\"\" Retrieve documents from the specified collection in the vector DB using the given queries. Args: queries (List[str]): the list of queries where each query is a string collection_name (str): the name of the collection in the vector DB to query k (Optional[int]): the number of documents to retrieve for each query Returns: List[List[Document]]: the list containing a list of documents that were retrieved for each query \"\"\" ...","title":"wise_agent_vector_db"},{"location":"reference/wiseagents/vectordb/wise_agent_vector_db/#wiseagents.vectordb.wise_agent_vector_db.Document","text":"Bases: BaseModel A document is a chunk of text. content (str): the string that makes up the chunk of text id (str): the optional id associated with the chunk of text metadata (Optional[dict]): optional information about the chunk of text Source code in wiseagents/vectordb/wise_agent_vector_db.py 12 13 14 15 16 17 18 19 20 21 22 class Document ( BaseModel ): \"\"\" A document is a chunk of text. content (str): the string that makes up the chunk of text id (str): the optional id associated with the chunk of text metadata (Optional[dict]): optional information about the chunk of text \"\"\" content : str id : Optional [ str ] = Field ( default_factory = lambda : str ( uuid . uuid4 ())) metadata : Optional [ dict ] = Field ( default_factory = dict )","title":"Document"},{"location":"reference/wiseagents/vectordb/wise_agent_vector_db/#wiseagents.vectordb.wise_agent_vector_db.WiseAgentVectorDB","text":"Bases: YAMLObject Abstract class to define the interface for a WiseAgentVectorDB. Source code in wiseagents/vectordb/wise_agent_vector_db.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 class WiseAgentVectorDB ( yaml . YAMLObject ): \"\"\"Abstract class to define the interface for a WiseAgentVectorDB.\"\"\" yaml_tag = u '!WiseAgentVectorDB' yaml_loader = WiseAgentsLoader @abstractmethod def get_or_create_collection ( self , collection_name : str ): \"\"\" Get the collection for the vector DB or create it if it doesn't already exist. Args: collection_name (str): the name of the collection \"\"\" ... @abstractmethod def delete_collection ( self , collection_name : str ): \"\"\" Delete the collection with the specified name from the vector DB. Args: collection_name (str): the name of the collection to delete \"\"\" ... @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ... @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): \"\"\" Delete documents from the specified collection in the vector DB. Args: ids (List[str]): the list of document IDs to be deleted collection_name (str): the name of the collection in the vector DB to delete the documents from \"\"\" ... @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ]) -> List [ List [ Document ]]: \"\"\" Retrieve documents from the specified collection in the vector DB using the given queries. Args: queries (List[str]): the list of queries where each query is a string collection_name (str): the name of the collection in the vector DB to query k (Optional[int]): the number of documents to retrieve for each query Returns: List[List[Document]]: the list containing a list of documents that were retrieved for each query \"\"\" ...","title":"WiseAgentVectorDB"},{"location":"reference/wiseagents/vectordb/wise_agent_vector_db/#wiseagents.vectordb.wise_agent_vector_db.WiseAgentVectorDB.delete_collection","text":"Delete the collection with the specified name from the vector DB. Parameters: collection_name ( str ) \u2013 the name of the collection to delete Source code in wiseagents/vectordb/wise_agent_vector_db.py 41 42 43 44 45 46 47 48 49 50 @abstractmethod def delete_collection ( self , collection_name : str ): \"\"\" Delete the collection with the specified name from the vector DB. Args: collection_name (str): the name of the collection to delete \"\"\" ...","title":"delete_collection"},{"location":"reference/wiseagents/vectordb/wise_agent_vector_db/#wiseagents.vectordb.wise_agent_vector_db.WiseAgentVectorDB.delete_documents","text":"Delete documents from the specified collection in the vector DB. Parameters: ids ( List [ str ] ) \u2013 the list of document IDs to be deleted collection_name ( str ) \u2013 the name of the collection in the vector DB to delete the documents from Source code in wiseagents/vectordb/wise_agent_vector_db.py 77 78 79 80 81 82 83 84 85 86 87 @abstractmethod def delete_documents ( self , ids : List [ str ], collection_name : str ): \"\"\" Delete documents from the specified collection in the vector DB. Args: ids (List[str]): the list of document IDs to be deleted collection_name (str): the name of the collection in the vector DB to delete the documents from \"\"\" ...","title":"delete_documents"},{"location":"reference/wiseagents/vectordb/wise_agent_vector_db/#wiseagents.vectordb.wise_agent_vector_db.WiseAgentVectorDB.get_or_create_collection","text":"Get the collection for the vector DB or create it if it doesn't already exist. Parameters: collection_name ( str ) \u2013 the name of the collection Source code in wiseagents/vectordb/wise_agent_vector_db.py 30 31 32 33 34 35 36 37 38 39 @abstractmethod def get_or_create_collection ( self , collection_name : str ): \"\"\" Get the collection for the vector DB or create it if it doesn't already exist. Args: collection_name (str): the name of the collection \"\"\" ...","title":"get_or_create_collection"},{"location":"reference/wiseagents/vectordb/wise_agent_vector_db/#wiseagents.vectordb.wise_agent_vector_db.WiseAgentVectorDB.insert_documents","text":"Insert the given documents into the specified collection in the vector DB. Parameters: documents ( List [ Document ] ) \u2013 the documents to be inserted into the specified collection collection_name ( str ) \u2013 the name of the collection in the vector DB to insert the documents into Source code in wiseagents/vectordb/wise_agent_vector_db.py 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def insert_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ...","title":"insert_documents"},{"location":"reference/wiseagents/vectordb/wise_agent_vector_db/#wiseagents.vectordb.wise_agent_vector_db.WiseAgentVectorDB.insert_or_update_documents","text":"Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Parameters: documents ( List [ Document ] ) \u2013 the documents to be inserted into the specified collection collection_name ( str ) \u2013 the name of the collection in the vector DB to insert the documents into Source code in wiseagents/vectordb/wise_agent_vector_db.py 64 65 66 67 68 69 70 71 72 73 74 75 @abstractmethod def insert_or_update_documents ( self , documents : List [ Document ], collection_name : str ): \"\"\" Insert the given documents into the specified collection in the vector DB, updating any documents that already exist in the collection. Args: documents (List[Document]): the documents to be inserted into the specified collection collection_name (str): the name of the collection in the vector DB to insert the documents into \"\"\" ...","title":"insert_or_update_documents"},{"location":"reference/wiseagents/vectordb/wise_agent_vector_db/#wiseagents.vectordb.wise_agent_vector_db.WiseAgentVectorDB.query","text":"Retrieve documents from the specified collection in the vector DB using the given queries. Parameters: queries ( List [ str ] ) \u2013 the list of queries where each query is a string collection_name ( str ) \u2013 the name of the collection in the vector DB to query k ( Optional [ int ] ) \u2013 the number of documents to retrieve for each query Returns: List [ List [ Document ]] \u2013 List[List[Document]]: the list containing a list of documents that were List [ List [ Document ]] \u2013 retrieved for each query Source code in wiseagents/vectordb/wise_agent_vector_db.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @abstractmethod def query ( self , queries : List [ str ], collection_name : str , k : Optional [ int ]) -> List [ List [ Document ]]: \"\"\" Retrieve documents from the specified collection in the vector DB using the given queries. Args: queries (List[str]): the list of queries where each query is a string collection_name (str): the name of the collection in the vector DB to query k (Optional[int]): the number of documents to retrieve for each query Returns: List[List[Document]]: the list containing a list of documents that were retrieved for each query \"\"\" ...","title":"query"},{"location":"reference/wiseagents/yaml/","text":"setup_yaml_for_env_vars () Configures the YAML Loader to do replacement of environment variables. It will replace YAML value strings such as '${HOST}' and '${PORT:80}' with environment variable lookups. In the first example, '${HOST}', it will replace the string with the value from doing os.getenv(\"HOST\") . If the environment variable 'HOST\" is not set, an exception will be thrown. In the second example, '${PORT:80}', we are doing the same but looking up `os.getenv(\"PORT\"). In this case, if the 'PORT' environment variable is not set, it will use the default value shows, which in this case is '80'. Source code in wiseagents/yaml/yaml_utils.py 49 50 51 52 53 54 55 56 57 58 59 60 def setup_yaml_for_env_vars (): \"\"\" Configures the YAML Loader to do replacement of environment variables. It will replace YAML value strings such as '${HOST}' and '${PORT:80}' with environment variable lookups. In the first example, '${HOST}', it will replace the string with the value from doing `os.getenv(\"HOST\")`. If the environment variable 'HOST\" is not set, an exception will be thrown. In the second example, '${PORT:80}', we are doing the same but looking up `os.getenv(\"PORT\"). In this case, if the 'PORT' environment variable is not set, it will use the default value shows, which in this case is '80'. \"\"\" yaml . add_implicit_resolver ( \"!env_var\" , _env_pattern ) yaml . add_constructor ( \"!env_var\" , _env_constructor )","title":"yaml"},{"location":"reference/wiseagents/yaml/#wiseagents.yaml.setup_yaml_for_env_vars","text":"Configures the YAML Loader to do replacement of environment variables. It will replace YAML value strings such as '${HOST}' and '${PORT:80}' with environment variable lookups. In the first example, '${HOST}', it will replace the string with the value from doing os.getenv(\"HOST\") . If the environment variable 'HOST\" is not set, an exception will be thrown. In the second example, '${PORT:80}', we are doing the same but looking up `os.getenv(\"PORT\"). In this case, if the 'PORT' environment variable is not set, it will use the default value shows, which in this case is '80'. Source code in wiseagents/yaml/yaml_utils.py 49 50 51 52 53 54 55 56 57 58 59 60 def setup_yaml_for_env_vars (): \"\"\" Configures the YAML Loader to do replacement of environment variables. It will replace YAML value strings such as '${HOST}' and '${PORT:80}' with environment variable lookups. In the first example, '${HOST}', it will replace the string with the value from doing `os.getenv(\"HOST\")`. If the environment variable 'HOST\" is not set, an exception will be thrown. In the second example, '${PORT:80}', we are doing the same but looking up `os.getenv(\"PORT\"). In this case, if the 'PORT' environment variable is not set, it will use the default value shows, which in this case is '80'. \"\"\" yaml . add_implicit_resolver ( \"!env_var\" , _env_pattern ) yaml . add_constructor ( \"!env_var\" , _env_constructor )","title":"setup_yaml_for_env_vars"},{"location":"reference/wiseagents/yaml/wise_yaml_loader/","text":"","title":"wise_yaml_loader"},{"location":"reference/wiseagents/yaml/yaml_utils/","text":"setup_yaml_for_env_vars () Configures the YAML Loader to do replacement of environment variables. It will replace YAML value strings such as '${HOST}' and '${PORT:80}' with environment variable lookups. In the first example, '${HOST}', it will replace the string with the value from doing os.getenv(\"HOST\") . If the environment variable 'HOST\" is not set, an exception will be thrown. In the second example, '${PORT:80}', we are doing the same but looking up `os.getenv(\"PORT\"). In this case, if the 'PORT' environment variable is not set, it will use the default value shows, which in this case is '80'. Source code in wiseagents/yaml/yaml_utils.py 49 50 51 52 53 54 55 56 57 58 59 60 def setup_yaml_for_env_vars (): \"\"\" Configures the YAML Loader to do replacement of environment variables. It will replace YAML value strings such as '${HOST}' and '${PORT:80}' with environment variable lookups. In the first example, '${HOST}', it will replace the string with the value from doing `os.getenv(\"HOST\")`. If the environment variable 'HOST\" is not set, an exception will be thrown. In the second example, '${PORT:80}', we are doing the same but looking up `os.getenv(\"PORT\"). In this case, if the 'PORT' environment variable is not set, it will use the default value shows, which in this case is '80'. \"\"\" yaml . add_implicit_resolver ( \"!env_var\" , _env_pattern ) yaml . add_constructor ( \"!env_var\" , _env_constructor )","title":"yaml_utils"},{"location":"reference/wiseagents/yaml/yaml_utils/#wiseagents.yaml.yaml_utils.setup_yaml_for_env_vars","text":"Configures the YAML Loader to do replacement of environment variables. It will replace YAML value strings such as '${HOST}' and '${PORT:80}' with environment variable lookups. In the first example, '${HOST}', it will replace the string with the value from doing os.getenv(\"HOST\") . If the environment variable 'HOST\" is not set, an exception will be thrown. In the second example, '${PORT:80}', we are doing the same but looking up `os.getenv(\"PORT\"). In this case, if the 'PORT' environment variable is not set, it will use the default value shows, which in this case is '80'. Source code in wiseagents/yaml/yaml_utils.py 49 50 51 52 53 54 55 56 57 58 59 60 def setup_yaml_for_env_vars (): \"\"\" Configures the YAML Loader to do replacement of environment variables. It will replace YAML value strings such as '${HOST}' and '${PORT:80}' with environment variable lookups. In the first example, '${HOST}', it will replace the string with the value from doing `os.getenv(\"HOST\")`. If the environment variable 'HOST\" is not set, an exception will be thrown. In the second example, '${PORT:80}', we are doing the same but looking up `os.getenv(\"PORT\"). In this case, if the 'PORT' environment variable is not set, it will use the default value shows, which in this case is '80'. \"\"\" yaml . add_implicit_resolver ( \"!env_var\" , _env_pattern ) yaml . add_constructor ( \"!env_var\" , _env_constructor )","title":"setup_yaml_for_env_vars"},{"location":"vectordb/","text":"How to start a vector database There is a script named run_vectordb.sh in the same directory of this document. The script starts pgvector in a container Be sure to define POD_CONTAINER variable before running this script. If a .env file is present, it will read the environment variables from there. The .env file should be in the same directory as the script. Rename the .env.example file to .env and set the environment variables.","title":"Index"},{"location":"vectordb/#how-to-start-a-vector-database","text":"There is a script named run_vectordb.sh in the same directory of this document. The script starts pgvector in a container Be sure to define POD_CONTAINER variable before running this script. If a .env file is present, it will read the environment variables from there. The .env file should be in the same directory as the script. Rename the .env.example file to .env and set the environment variables.","title":"How to start a vector database"}]}